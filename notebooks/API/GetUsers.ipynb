{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a list of MAL users\n",
    "* We start with a list of starting usernames, which can either be stored in `data/mal/user_facts/queue.txt` or specified in the notebook\n",
    "* Then, we do a breadth-first search of their friends until the friend graph is spanned\n",
    "* You can terminate or restart the notebook at any point without losing progress. All users found so far will be stored at `data/mal/user_facts/usernames.txt`. The adjacency list of the friend graph will be stored at `data/mal/user_facts/friends_list.csv`.\n",
    "* This notebook will run indefinitely. You must manually terminate once an acceptable number of users have been found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from ratelimit import limits, sleep_and_retry\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outdir\n",
    "data_path = \"../../data/mal/user_facts\"\n",
    "if not os.path.exists(data_path):\n",
    "    os.mkdir(data_path)\n",
    "os.chdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging\n",
    "logger = logging.getLogger(\"GetUsers\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter(\n",
    "    \"%(name)s:%(levelname)s:%(asctime)s: %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "for stream in [logging.FileHandler(\"get_users.log\"), logging.StreamHandler()]:\n",
    "    stream.setFormatter(formatter)\n",
    "    logger.addHandler(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GetUsers:INFO:2022-01-03 15:27:34: Starting with 129 users in queue and 1415536 processed users for a total of 1415665 users!\n"
     ]
    }
   ],
   "source": [
    "# reasonable defaults if this is the first time running the notebook\n",
    "queue = [\"Fro116\"]\n",
    "usernames = set()\n",
    "closed_nodes = set()\n",
    "shuffle_on_rerun = True\n",
    "\n",
    "# if we rerunning the notebook, then resume execution where we last left off\n",
    "if os.path.exists(\"queue.txt\"):\n",
    "    with open(\"queue.txt\") as f:\n",
    "        queue = [x.strip() for x in f.readlines() if x.strip()]\n",
    "if os.path.exists(\"usernames.txt\"):\n",
    "    with open(\"usernames.txt\") as f:\n",
    "        usernames = {x.strip() for x in f.readlines() if x.strip()}\n",
    "if os.path.exists(\"closed_nodes.txt\"):\n",
    "    with open(\"closed_nodes.txt\") as f:\n",
    "        closed_nodes = {x.strip() for x in f.readlines() if x.strip()}\n",
    "\n",
    "# verify consistency of loaded data structures\n",
    "# they might be inconsistent if the notebook crashed mid-save\n",
    "queue = [x for x in queue if x not in closed_nodes]\n",
    "queue = queue + list(usernames - closed_nodes - set(queue))\n",
    "usernames |= set(queue)\n",
    "open_nodes = set(queue)\n",
    "if shuffle_on_rerun:\n",
    "    np.random.shuffle(queue)\n",
    "\n",
    "logger.info(\n",
    "    f\"Starting with {len(queue)} users in queue and {len(closed_nodes)} processed \"\n",
    "    f\"users for a total of {len(usernames)} users!\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queue = [x for x in queue if \"%\" not in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "usernames = {x for x in usernames if \"%\" not in x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "open_nodes = {x for x in open_nodes if \"%\" not in x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_nodes = {x for x in closed_nodes if \"%\" not in x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply rate limiting with exponential backoff for unexpected errors\n",
    "@sleep_and_retry\n",
    "@limits(calls=1, period=3)\n",
    "def call_api(url, retry_timeout=1):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code in [403, 429, 500, 503]:\n",
    "            # This can occur if MAL servers go down\n",
    "            raise Exception(f\"{response.status_code}\")\n",
    "    except Exception as e:\n",
    "        logger.warning(\n",
    "            f\"Received error {str(e)} while accessing {url}. Retrying in {retry_timeout} seconds\"\n",
    "        )\n",
    "        time.sleep(retry_timeout)\n",
    "        retry_timeout = min(retry_timeout * 2, 3600)\n",
    "        return call_api(url, retry_timeout)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse a user's MAL profile page for their friends\n",
    "def get_friends(username):\n",
    "    url = f\"https://myanimelist.net/profile/{username}/friends\"\n",
    "    response = call_api(url)\n",
    "    if response.status_code in [404]:\n",
    "        # the user may have deleted their account\n",
    "        return set()\n",
    "    if not response.ok:\n",
    "        logger.warning(f\"Error {response} received when handling {url}\")\n",
    "        return set()\n",
    "    friend_urls = re.findall(\n",
    "        '''https://myanimelist.net/profile/[^\"/#]+\"''', response.text\n",
    "    )\n",
    "    friends = {x[len(\"https://myanimelist.net/profile/\") : -len('\"')] for x in friend_urls}\n",
    "    return {x for x in friends if \"%\" not in x}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atomic saving utilities\n",
    "@contextlib.contextmanager\n",
    "def atomic_overwrite(filename):\n",
    "    temp = filename + \"~\"\n",
    "    with open(temp, \"w\") as f:\n",
    "        yield f\n",
    "    os.replace(temp, filename)\n",
    "\n",
    "\n",
    "def atomic_to_csv(collection, filename):\n",
    "    with atomic_overwrite(filename) as f:\n",
    "        pd.Series(collection).to_csv(f, header=False, index=False)\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def atomic_append(filename):\n",
    "    temp = filename + \"~\"\n",
    "    with open(temp, \"w\") as f:\n",
    "        yield f\n",
    "\n",
    "    temp2 = temp + \"~\"\n",
    "    with open(temp2, \"wb\") as wfd:\n",
    "        for f in [filename, temp]:\n",
    "            with open(f, \"rb\") as fd:\n",
    "                shutil.copyfileobj(fd, wfd)\n",
    "    os.remove(temp)\n",
    "    os.replace(temp2, filename)\n",
    "\n",
    "\n",
    "def atomic_append_dataframe_to_csv(df, filename):\n",
    "    first_run = not os.path.exists(filename)\n",
    "    temp = filename + \"~\"\n",
    "    with atomic_append(filename) as f:\n",
    "        df.to_csv(f, index=False, header=first_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snapshot hourly to amortize the cost of the disk I/O\n",
    "def should_save(reason):\n",
    "    should_save = False\n",
    "    if reason not in save_reasons:\n",
    "        save_reasons[reason] = (0, 1)\n",
    "    iterations_since_last_write, iterations_until_next_write = save_reasons[reason]\n",
    "    iterations_since_last_write += 1\n",
    "    if iterations_since_last_write >= iterations_until_next_write:\n",
    "        iterations_since_last_write = 0\n",
    "        iterations_until_next_write = min(2 * iterations_until_next_write, 1200)\n",
    "        should_save = True\n",
    "        logger.info(\n",
    "            f\"Writing data for {reason}. Will next write data \"\n",
    "            f\"after {iterations_until_next_write} iterations\"\n",
    "        )\n",
    "    save_reasons[reason] = (iterations_since_last_write, iterations_until_next_write)\n",
    "    return should_save\n",
    "\n",
    "\n",
    "save_reasons = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If the notebook crashed before saving the friends list,\n",
    "# then we need to get the friends lists for the missing users\n",
    "def verify_friends_list_consistency():\n",
    "    logger.info(\"Verifying consistency of existing entries in friends_list.csv\")\n",
    "    users_with_friends = set()\n",
    "    if os.path.exists(\"friends_list.csv\"):\n",
    "        with open(\"friends_list.csv\", \"r\") as f:\n",
    "            next(f)\n",
    "            for line in tqdm(f):\n",
    "                username, _ = line.split(\",\")\n",
    "                users_with_friends.add(username)\n",
    "\n",
    "    friends_list = pd.DataFrame()\n",
    "    new_users = set(closed_nodes) - users_with_friends\n",
    "    for user in tqdm(new_users):\n",
    "        friends = list(get_friends(user) | {user})\n",
    "        friends_list = friends_list.append(\n",
    "            pd.DataFrame.from_dict(\n",
    "                {\"Username\": [user] * len(friends), \"Friend\": friends}\n",
    "            )\n",
    "        )\n",
    "\n",
    "        if should_save(\"verify_friends_list_consistency\"):\n",
    "            atomic_append_dataframe_to_csv(friends_list, \"friends_list.csv\")\n",
    "            friends_list = pd.DataFrame()\n",
    "    atomic_append_dataframe_to_csv(friends_list, \"friends_list.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GetUsers:INFO:2022-01-03 15:27:05: Verifying consistency of existing entries in friends_list.csv\n",
      "9084681it [00:05, 1678936.74it/s]"
     ]
    }
   ],
   "source": [
    "verify_friends_list_consistency()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "# we use a generator for profiling with tqdm\n",
    "def generator():\n",
    "    while True:\n",
    "        yield\n",
    "\n",
    "\n",
    "# Breadth first search\n",
    "friends_list = pd.DataFrame()\n",
    "for _ in tqdm(generator()):\n",
    "    if not queue:\n",
    "        break\n",
    "    username = queue[0]\n",
    "    queue = queue[1:]\n",
    "    friends = get_friends(username)\n",
    "\n",
    "    usernames |= friends\n",
    "    new_friends = [x for x in friends if x not in closed_nodes and x not in open_nodes]\n",
    "    queue = queue + new_friends\n",
    "    open_nodes |= set(new_friends)\n",
    "    open_nodes.remove(username)\n",
    "    closed_nodes.add(username)\n",
    "    friends |= {username}\n",
    "    friends_list = friends_list.append(\n",
    "        pd.DataFrame.from_dict(\n",
    "            {\"Username\": [username] * len(friends), \"Friend\": list(friends)}\n",
    "        )\n",
    "    )\n",
    "\n",
    "    if should_save(\"users\"):\n",
    "        atomic_to_csv(sorted(list(usernames)), \"usernames.txt\")\n",
    "        atomic_to_csv(sorted(list(closed_nodes)), \"closed_nodes.txt\")\n",
    "        atomic_to_csv(queue, \"queue.txt\")\n",
    "        atomic_append_dataframe_to_csv(friends_list, \"friends_list.csv\")\n",
    "        friends_list = pd.DataFrame()\n",
    "        logger.info(\n",
    "            f\"Successfully wrote {len(queue)} users in queue and {len(closed_nodes)} \"\n",
    "            f\"processed users for a total of {len(usernames)} users!\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_162775/2315412709.py:12: DeprecationWarning: The default dtype for empty Series will be 'object' instead of 'float64' in a future version. Specify a dtype explicitly to silence this warning.\n",
      "  pd.Series(collection).to_csv(f, header=False, index=False)\n"
     ]
    }
   ],
   "source": [
    "# Final save\n",
    "atomic_to_csv(sorted(list(usernames)), \"usernames.txt\")\n",
    "atomic_to_csv(sorted(list(closed_nodes)), \"closed_nodes.txt\")\n",
    "atomic_to_csv(queue, \"queue.txt\")\n",
    "atomic_append_dataframe_to_csv(friends_list, \"friends_list.csv\")\n",
    "logger.info(\"Finished collecting users\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

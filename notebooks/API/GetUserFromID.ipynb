{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generating a list of MAL usernames\n",
    "* We look up a username by querying their user id\n",
    "* You can terminate or restart the notebook at any point without losing progress. All users found so far will be stored at `data/mal/user_facts/usernames_from_id.txt`.\n",
    "* This notebook will run indefinitely. You must manually terminate once an acceptable number of users have been found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import contextlib\n",
    "import logging\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from ratelimit import limits, sleep_and_retry\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outdir\n",
    "data_path = \"../../data/mal/user_facts\"\n",
    "if not os.path.exists(data_path):\n",
    "    os.mkdir(data_path)\n",
    "os.chdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging\n",
    "logger = logging.getLogger(\"GetUserFromID\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter(\n",
    "    \"%(name)s:%(levelname)s:%(asctime)s: %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "for stream in [\n",
    "    logging.FileHandler(\"get_user_from_id.log\"),\n",
    "    logging.StreamHandler(),\n",
    "]:\n",
    "    stream.setFormatter(formatter)\n",
    "    logger.addHandler(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if we rerunning the notebook, then resume execution where we last left off\n",
    "usernames = set()\n",
    "if os.path.exists(\"usernames_from_id.txt\"):\n",
    "    with open(\"usernames_from_id.txt\") as f:\n",
    "        usernames = {x.strip() for x in f.readlines() if x.strip()}\n",
    "\n",
    "userid = 1\n",
    "if os.path.exists(\"current_userid.txt\"):\n",
    "    with open(\"current_userid.txt\") as f:\n",
    "        userid = int([x.strip() for x in f.readlines() if x.strip()][0])\n",
    "\n",
    "logger.info(f\"Starting with {len(usernames)} stored usernames at residue {userid}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply rate limiting with exponential backoff for unexpected errors\n",
    "@sleep_and_retry\n",
    "@limits(calls=1, period=3)\n",
    "def call_api(url, retry_timeout=1):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        if response.status_code in [403, 429, 500, 503]:\n",
    "            # This can occur if MAL servers go down\n",
    "            raise Exception(f\"{response.status_code}\")\n",
    "    except Exception as e:\n",
    "        logger.warning(\n",
    "            f\"Received error {str(e)} while accessing {url}. Retrying in {retry_timeout} seconds\"\n",
    "        )\n",
    "        time.sleep(retry_timeout)\n",
    "        retry_timeout = min(retry_timeout * 2, 3600)\n",
    "        return call_api(url, retry_timeout)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns all usernames that have commented on the given userid's profile\n",
    "def get_usernames(userid):\n",
    "    url = f\"https://myanimelist.net/comments.php?id={userid}\"\n",
    "    response = call_api(url)\n",
    "    if response.status_code in [404]:\n",
    "        # the user may have deleted their account\n",
    "        return set()\n",
    "    if not response.ok:\n",
    "        logger.warning(f\"Error {response} received when handling {url}\")\n",
    "        return set()\n",
    "    urls = re.findall('''/profile/[^\"/#%]+\"''', response.text)\n",
    "    users = {x[len(\"/profile/\") : -len('\"')] for x in urls}\n",
    "    return users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# atomic saving utilities\n",
    "@contextlib.contextmanager\n",
    "def atomic_overwrite(filename):\n",
    "    temp = filename + \"~\"\n",
    "    with open(temp, \"w\") as f:\n",
    "        yield f\n",
    "    os.replace(temp, filename)\n",
    "\n",
    "\n",
    "def atomic_to_csv(collection, filename):\n",
    "    with atomic_overwrite(filename) as f:\n",
    "        pd.Series(collection).to_csv(f, header=False, index=False)\n",
    "\n",
    "\n",
    "@contextlib.contextmanager\n",
    "def atomic_append(filename):\n",
    "    temp = filename + \"~\"\n",
    "    with open(temp, \"w\") as f:\n",
    "        yield f\n",
    "\n",
    "    temp2 = temp + \"~\"\n",
    "    with open(temp2, \"wb\") as wfd:\n",
    "        for f in [filename, temp]:\n",
    "            with open(f, \"rb\") as fd:\n",
    "                shutil.copyfileobj(fd, wfd)\n",
    "    os.remove(temp)\n",
    "    os.replace(temp2, filename)\n",
    "\n",
    "\n",
    "def atomic_append_dataframe_to_csv(df, filename):\n",
    "    first_run = not os.path.exists(filename)\n",
    "    temp = filename + \"~\"\n",
    "    with atomic_append(filename) as f:\n",
    "        df.to_csv(f, index=False, header=first_run)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# snapshot hourly to amortize the cost of the disk I/O\n",
    "def should_save(reason):\n",
    "    should_save = False\n",
    "    if reason not in save_reasons:\n",
    "        save_reasons[reason] = (0, 1)\n",
    "    iterations_since_last_write, iterations_until_next_write = save_reasons[reason]\n",
    "    iterations_since_last_write += 1\n",
    "    if iterations_since_last_write >= iterations_until_next_write:\n",
    "        iterations_since_last_write = 0\n",
    "        iterations_until_next_write = min(2 * iterations_until_next_write, 1200)\n",
    "        should_save = True\n",
    "        logger.info(\n",
    "            f\"Writing data for {reason}. Will next write data \"\n",
    "            f\"after {iterations_until_next_write} iterations\"\n",
    "        )\n",
    "    save_reasons[reason] = (iterations_since_last_write, iterations_until_next_write)\n",
    "    return should_save\n",
    "\n",
    "\n",
    "save_reasons = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def save():\n",
    "    atomic_to_csv(sorted(list(usernames)), \"usernames_from_id.txt\")\n",
    "    atomic_to_csv([userid], \"current_userid.txt\")\n",
    "    logger.info(f\"Successfully wrote {len(usernames)} users at residue {userid}\")\n",
    "\n",
    "\n",
    "# we search through user ids using a cyclic group to avoid temporal bias\n",
    "maxid_prime_number = 14999981  # a prime number that upper bounds the number of MAL ids\n",
    "cyclic_generator = 3\n",
    "while True:\n",
    "    while (userid * cyclic_generator) % maxid_prime_number != 1:\n",
    "        usernames |= get_usernames(userid)\n",
    "        userid = (userid * cyclic_generator) % maxid_prime_number\n",
    "        if should_save(\"users\"):\n",
    "            save()\n",
    "    save()\n",
    "    maxid_prime_number *= 2"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

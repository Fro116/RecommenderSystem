{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1915b44a-3a42-431f-bd6c-94edf9e5bc36",
   "metadata": {},
   "source": [
    "# Getting MAL anime-lists\n",
    "* We collect the anime-list for each username in `data/mal/user_facts/usernames.txt` and `data/mal/user_facts/recent_usernames.txt`\n",
    "* You can terminate or restart the notebook at any point without losing progress. All anime-lists found so far will be stored at `data/mal/user_anime_facts/user_anime_list.csv` \n",
    "* This notebook will run indefinitely. You must manually terminate once an acceptable number of anime-lists have been found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "16a55928-bc2d-4dfb-974f-2480e13c1f0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "import random\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "from ratelimit import limits, sleep_and_retry\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65822b0-3bec-4869-94e1-d956684c4bba",
   "metadata": {},
   "source": [
    "## Basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e50d2d6-3aa2-4ae2-b6cb-8daa401f6ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# outdir\n",
    "data_path = \"../../data/mal/user_anime_facts\"\n",
    "if not os.path.exists(data_path):\n",
    "    os.mkdir(data_path)\n",
    "os.chdir(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbd8b363-578a-44d6-a82a-1005d9ca3cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# logging\n",
    "logger = logging.getLogger(\"GetUserAnimeLists\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter(\n",
    "    \"%(name)s:%(levelname)s:%(asctime)s: %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "for stream in [\n",
    "    logging.FileHandler(\"get_user_anime_lists.log\"),\n",
    "    logging.StreamHandler(),\n",
    "]:\n",
    "    stream.setFormatter(formatter)\n",
    "    logger.addHandler(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd55c16-a8c1-4b3b-87c1-2b8aef672917",
   "metadata": {},
   "source": [
    "## Parse MAL API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a36dd4e4-5e93-4e57-bfca-8f271e4afce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "token = json.load(open(\"../mal_authentication/token.json\", \"r\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a872e694-1db1-4d9c-b84f-6d6ed5700f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# apply rate limiting with exponential backoff for unexpected errors\n",
    "@sleep_and_retry\n",
    "@limits(calls=1, period=0.75)\n",
    "def call_api(url, retry_timeout=1):\n",
    "    try:\n",
    "        response = requests.get(\n",
    "            url, headers={\"Authorization\": f'Bearer {token[\"access_token\"]}'}\n",
    "        )\n",
    "        if response.status_code in [500] and retry_timeout < 3600:\n",
    "            # This can occur if MAL servers go down or if the page doesnt exist\n",
    "            raise Exception(f\"{response.status_code}\")\n",
    "    except Exception as e:\n",
    "        logger.warning(\n",
    "            f\"Received error {str(e)} while accessing {url}. Retrying in {retry_timeout} seconds\"\n",
    "        )\n",
    "        time.sleep(retry_timeout)\n",
    "        retry_timeout = min(retry_timeout * 2, 3600)\n",
    "        return call_api(url, retry_timeout)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1ab2a76-a736-4d48-92dc-6d422fdf08a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# utilities for extracting an anime list from the MAL API\n",
    "def parse_json_node(x):\n",
    "    uid = x[\"node\"][\"id\"]\n",
    "    score = x[\"list_status\"][\"score\"]\n",
    "    status = \"\"\n",
    "    if \"status\" in x[\"list_status\"]:\n",
    "        status = x[\"list_status\"][\"status\"]\n",
    "    return uid, score, status\n",
    "\n",
    "\n",
    "def process_json(json):\n",
    "    df = pd.DataFrame.from_records(\n",
    "        [parse_json_node(x) for x in json[\"data\"]],\n",
    "        columns=[\"anime_id\", \"my_score\", \"status\"],\n",
    "    )\n",
    "    return df.loc[lambda x: x[\"status\"] != \"plan_to_watch\"].drop(\"status\", axis=1)\n",
    "\n",
    "\n",
    "def get_user_anime_list(username):\n",
    "    anime_lists = []\n",
    "    more_pages = True\n",
    "    url = f\"https://api.myanimelist.net/v2/users/{username}/animelist?limit=1000&fields=list_status&nsfw=true\"\n",
    "    while more_pages:\n",
    "        response = call_api(url)\n",
    "        if response.status_code in [403, 404, 500]:\n",
    "            # 403: This can occur if the user privated their list\n",
    "            # 404: This can occur if the user deleted their account\n",
    "            # 500: This can occur if the user deleted their account\n",
    "            return pd.DataFrame(), False\n",
    "        if not response.ok:\n",
    "            logger.warning(f\"Error {response} received when handling {url}\")\n",
    "            return pd.DataFrame(), False\n",
    "\n",
    "        json = response.json()\n",
    "        anime_lists.append(process_json(json))\n",
    "        more_pages = \"next\" in json[\"paging\"]\n",
    "        if more_pages:\n",
    "            url = json[\"paging\"][\"next\"]\n",
    "    user_anime_list = pd.concat(anime_lists, ignore_index=True)\n",
    "    user_anime_list[\"username\"] = username\n",
    "    return user_anime_list, True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a62ff0ad-79e3-4c16-8299-17e62fd93913",
   "metadata": {},
   "source": [
    "## Clean up previous run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8521b1b7-7bed-4e3e-88b0-6b6dd14b6cd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entries in  user_status.csv  and user_anime_list.csv can be malformed if the\n",
    "# notebook crashes in the middle of saving a file. This function removes any\n",
    "# malformed lines.\n",
    "def verify_user_status_consistency():\n",
    "    logger.info(\"Verifying consistency of entries in user_status.csv\")\n",
    "    input_fn = \"user_status.csv\"\n",
    "    if not os.path.exists(input_fn):\n",
    "        return\n",
    "    output_fn = input_fn + \"~\"\n",
    "    user_status = pd.read_csv(\"user_status.csv\")\n",
    "    with open(input_fn, \"r\") as in_file:\n",
    "        with open(output_fn, \"w\") as out_file:\n",
    "            header = False\n",
    "            for line in tqdm(in_file):\n",
    "                if not header:\n",
    "                    header = True\n",
    "                    correct_header = \"username,access_timestamp,success\\n\"\n",
    "                    if line.strip() != correct_header.strip():\n",
    "                        logger.warning(\n",
    "                            f\"Replacing malformed header line {line.strip} \"\n",
    "                            f\"with correct header {correct_header.strip()}\"\n",
    "                        )\n",
    "                        line = correct_header\n",
    "                    out_file.write(line)\n",
    "                    continue\n",
    "                fields = line.strip().split(\",\")\n",
    "                if len(fields) != 3:\n",
    "                    logger.warning(\n",
    "                        f\"Deleting malformed line in user_anime_list.csv {line} \"\n",
    "                    )\n",
    "                    continue\n",
    "                out_file.write(line)\n",
    "    os.replace(output_fn, input_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f2c1b8-99ed-4bb3-8c15-338d0709db5a",
   "metadata": {},
   "source": [
    "## Sort users by recency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "622d5273-5795-41ce-a967-c91f63c0631c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_usernames():\n",
    "    usernames = []\n",
    "    with open(\"../user_facts/usernames.txt\", \"r\") as f:\n",
    "        usernames += [x.strip() for x in f.readlines()]\n",
    "    with open(\"../user_facts/recent_usernames.txt\", \"r\") as f:\n",
    "        usernames += [x.strip() for x in f.readlines()]\n",
    "    return usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a74b6b41-a93b-434a-9408-261b11ba7b68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_user_status():\n",
    "    user_status_file = \"user_status.csv\"\n",
    "    if os.path.exists(user_status_file):\n",
    "        return pd.read_csv(user_status_file)\n",
    "    else:\n",
    "        return pd.DataFrame.from_dict(\n",
    "            {\n",
    "                \"username\": [],\n",
    "                \"access_timestamp\": [],\n",
    "                \"success\": [],\n",
    "            }\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1279a574-9d37-489a-9366-12cf46399574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prioritize_users():\n",
    "    usernames = read_usernames()\n",
    "    user_status = read_user_status()\n",
    "    new_users = list(set(usernames) - set(user_status[\"username\"]))\n",
    "    random.shuffle(new_users)\n",
    "    existing_users = list(user_status.sort_values(by=\"access_timestamp\")[\"username\"])\n",
    "    logger.info(\n",
    "        f\"Getting the anime lists of {len(new_users)} new users and refreshing \"\n",
    "        f\"the anime lists of {len(existing_users)} existing users!\"\n",
    "    )\n",
    "    return new_users + existing_users"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f61b54-8179-4dda-8e9a-a4d8a0b9234f",
   "metadata": {},
   "source": [
    "## Continuously refresh anime lists\n",
    "* TODO documentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4098f0a2-fb1e-4022-a154-ad82a362d4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_block(file, user_field, users):\n",
    "    outfile = file + \"~\"\n",
    "    blockfile = file + \".block\"\n",
    "    with open(outfile, \"w\") as out_file:\n",
    "        # copy over all the unchaged users\n",
    "        if os.path.exists(file):\n",
    "            with open(file, \"r\") as in_file:\n",
    "                header = False\n",
    "                for line in tqdm(in_file):\n",
    "                    if not header:\n",
    "                        header = True\n",
    "                        out_file.write(line)\n",
    "                        continue\n",
    "                    fields = line.strip().split(\",\")\n",
    "                    if fields[user_field] not in users:\n",
    "                        out_file.write(line)\n",
    "\n",
    "        # copy over the new block\n",
    "        with open(blockfile, \"r\") as in_file:\n",
    "            header = False\n",
    "            for line in tqdm(in_file):\n",
    "                if not header:\n",
    "                    header = True\n",
    "                    continue\n",
    "                out_file.write(line)\n",
    "    os.replace(outfile, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb7f788a-4908-417d-b4d8-c76f1e18d209",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_blocks():\n",
    "    users = set(pd.read_csv(\"user_status.csv.block\")[\"username\"])\n",
    "    merge_block(\"user_anime_list.csv\", 2, users)    \n",
    "    merge_block(\"user_status.csv\", 0, users)    \n",
    "    logger.info(f\"Merging block of {len(users)} users into the main database\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eff37af-acda-491d-9f30-2deec9e4c6a5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GetUserAnimeLists:INFO:2022-04-19 05:05:34: Getting the anime lists of 675237 new users and refreshing the anime lists of 1663752 existing users!\n",
      "  4%|██████▏                                                                                                                                                       | 3881/100000 [49:49<20:13:47,  1.32it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 17%|█████████████████████████▌                                                                                                                                 | 16529/100000 [3:32:58<17:12:26,  1.35it/s]GetUserAnimeLists:WARNING:2022-04-19 08:38:33: Received error HTTPSConnectionPool(host='api.myanimelist.net', port=443): Max retries exceeded with url: /v2/users/Onskel/animelist?limit=1000&fields=list_status&nsfw=true (Caused by SSLError(SSLError(\"bad handshake: SysCallError(104, 'ECONNRESET')\"))) while accessing https://api.myanimelist.net/v2/users/Onskel/animelist?limit=1000&fields=list_status&nsfw=true. Retrying in 1 seconds\n",
      " 17%|██████████████████████████▍                                                                                                                                | 17035/100000 [3:39:32<16:45:38,  1.37it/s]GetUserAnimeLists:WARNING:2022-04-19 08:45:07: Received error HTTPSConnectionPool(host='api.myanimelist.net', port=443): Max retries exceeded with url: /v2/users/doinkboink/animelist?limit=1000&fields=list_status&nsfw=true (Caused by SSLError(SSLError(\"bad handshake: SysCallError(104, 'ECONNRESET')\"))) while accessing https://api.myanimelist.net/v2/users/doinkboink/animelist?limit=1000&fields=list_status&nsfw=true. Retrying in 1 seconds\n",
      " 17%|███████████████████████████                                                                                                                                | 17451/100000 [3:44:52<16:42:45,  1.37it/s]IOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      " 29%|████████████████████████████████████████████▊                                                                                                              | 28923/100000 [6:12:08<15:29:24,  1.27it/s]"
     ]
    }
   ],
   "source": [
    "# get the anime list for each new user and write to disk\n",
    "while True:\n",
    "    usernames = prioritize_users()[:100000]\n",
    "    block = set()\n",
    "    for username in tqdm(usernames):\n",
    "        user_anime_list, ok = get_user_anime_list(username)\n",
    "        user_anime_list.to_csv(\n",
    "            \"user_anime_list.csv.block\",\n",
    "            index=False,\n",
    "            mode=\"w\" if not block else \"a+\",\n",
    "            header=not block,\n",
    "        )\n",
    "        pd.DataFrame.from_dict(\n",
    "            {\n",
    "                \"username\": [username],\n",
    "                \"access_timestamp\": [int(datetime.datetime.now().timestamp())],\n",
    "                \"success\": [ok],\n",
    "            }\n",
    "        ).to_csv(\n",
    "            \"user_status.csv.block\",\n",
    "            index=False,\n",
    "            mode=\"w\" if not block else \"a+\",\n",
    "            header=not block,\n",
    "        )\n",
    "        block.add(username)\n",
    "    merge_blocks()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3758ece-9b72-47b4-ae6a-aa364e0443e3",
   "metadata": {},
   "source": [
    "# Item Collaborative Filtering\n",
    "* This notebook implements item-based collaborative filtering\n",
    "* Prediction is $\\tilde r_{ij} = \\dfrac{\\sum_{k \\in N(j)} w_{kj}^{\\lambda_w}r_{ik}^{\\lambda_r}}{\\sum_{k \\in N(j)} w_{kj}^{\\lambda_w} + \\lambda}$ for item-based collaborative filtering\n",
    "* $r_{ij}$ is the rating for user $i$ and item $j$\n",
    "* $w_{kj}$ is the similarity between items $j$ and $k$\n",
    "* $N(j)$ is the largest $K$ sorted by $w_{kj}$\n",
    "* $\\lambda_w, \\lambda_r, \\lambda$ are regularization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17593ac-3260-4c01-a5df-91edfcd17e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "residual_alphas = [];\n",
    "@nbinclude(\"Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff8e524-e8f8-48bd-9ca7-c28a05a122b8",
   "metadata": {},
   "source": [
    "## Determine the neighborhoods for each user and item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c68e6-5d2d-470b-a513-9ba157a4ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "function read_similarity_matrix(outdir)\n",
    "    read_params(outdir)[\"S\"]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd34115c-51b5-4af1-908d-4322a46d5918",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_abs_neighborhood(item, S, K)\n",
    "    weights = S[:, item]\n",
    "    # ensure that the neighborhood for an item does not include itself\n",
    "    weights[item] = Inf\n",
    "    K = Int(min(K, length(weights) - 1))    \n",
    "    order = partialsortperm(abs.(weights), 2:K+1, rev = true)\n",
    "    order, weights[order]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ebb580-b942-4113-8d60-78a83042d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "isnonzero(x) = !isapprox(x, 0.0, atol=eps(Float64))\n",
    "\n",
    "# exponentially decay x\n",
    "function decay(x, a)\n",
    "    isnonzero(x) ? sign(x) * abs(x)^a : zero(eltype(a))\n",
    "end\n",
    "\n",
    "# each prediction is just the weighted sum of all items in the neighborhood\n",
    "# we apply regularization terms to decay the weights, ratings, and final prediction\n",
    "function make_prediction(item, users, R, get_neighborhood, λ)\n",
    "    if item > size(R)[2]\n",
    "        # the item was not in our training set; we have no information\n",
    "        return zeros(length(item))\n",
    "    end\n",
    "    items, weights = get_neighborhood(item)\n",
    "    weights = decay.(weights, λ[1])\n",
    "    predictions = zeros(eltype(weights), length(users))\n",
    "    weight_sum = zeros(eltype(weights), length(users))\n",
    "    for u = 1:length(users)\n",
    "        for (i, weight) in zip(items, weights)\n",
    "            if isnonzero(R[users[u], i])\n",
    "                predictions[u] += weight * decay(R[users[u], i], λ[2])\n",
    "                weight_sum[u] += abs(weight)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    for u = 1:length(users)\n",
    "        if isnonzero(weight_sum[u] + λ[3])\n",
    "            predictions[u] /= (weight_sum[u] + λ[3])\n",
    "        end\n",
    "    end\n",
    "    predictions\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5214736f-516e-4d6f-8f0b-92171355ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "function collaborative_filtering(training, inference, get_neighborhood, λ)\n",
    "    R = sparse(\n",
    "        training.user,\n",
    "        training.item,\n",
    "        training.rating,\n",
    "        maximum(training.user),\n",
    "        maximum(training.item),\n",
    "    )\n",
    "\n",
    "    preds = zeros(eltype(λ), length(inference.rating))\n",
    "    @tprogress Threads.@threads for item in collect(Set(inference.item))\n",
    "        mask = inference.item .== item\n",
    "        preds[mask] =\n",
    "            make_prediction(item, inference.user[mask], R, get_neighborhood, λ)\n",
    "    end\n",
    "\n",
    "    preds\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c815cbbe-7300-4c9d-9163-4e554a9752e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.@kwdef mutable struct cf_params\n",
    "    name::Any\n",
    "    training_residuals::Any\n",
    "    validation_residuals::Any\n",
    "    neighborhood_type::Any\n",
    "    S::Any # the similarity matrix\n",
    "    K::Any # the neighborhood size\n",
    "    λ::Vector{Float64} = [1.0, 1.0, 0.0] # [weight_decay, rating_decay, prediction_decay]\n",
    "end;\n",
    "\n",
    "to_dict(x::T) where {T} = Dict(string(fn) => getfield(x, fn) for fn ∈ fieldnames(T));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cf908b-4b56-412a-9765-c13021874f41",
   "metadata": {},
   "source": [
    "## Item based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904a3cc2-c5e7-4e1b-810a-b3616c4d1b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_training(residual_alphas)\n",
    "    get_residuals(\"training\", residual_alphas)\n",
    "end\n",
    "\n",
    "function get_validation(residual_alphas)\n",
    "    get_residuals(\"validation\", residual_alphas)\n",
    "end\n",
    "\n",
    "function get_inference()\n",
    "    training = get_split(\"training\")\n",
    "    validation = get_split(\"validation\")\n",
    "    test = get_split(\"test\")\n",
    "    RatingsDataset(\n",
    "        user = [training.user; validation.user; test.user],\n",
    "        item = [training.item; validation.item; test.item],\n",
    "        rating = fill(\n",
    "            0.0,\n",
    "            length(training.rating) + length(validation.item) + length(test.item),\n",
    "        ),\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755b9b34-ffa0-48d9-bf99-5ee735c04036",
   "metadata": {},
   "outputs": [],
   "source": [
    "function optimize_model(param)\n",
    "    # unpack parameters\n",
    "    training = get_training(param.training_residuals)\n",
    "    validation = get_validation(param.validation_residuals)\n",
    "    S = read_similarity_matrix(param.S)\n",
    "    K = param.K\n",
    "    neighborhood_types = Dict(\"abs\" => get_abs_neighborhood)\n",
    "    neighborhoods = i -> neighborhood_types[param.neighborhood_type](i, S, K)\n",
    "\n",
    "    # optimize hyperparameters\n",
    "    function validation_mse(λ)\n",
    "        pred = collaborative_filtering(training, validation, neighborhoods, λ)\n",
    "        truth = validation.rating\n",
    "        β = pred \\ truth\n",
    "        loss = mse(truth, pred .* β)\n",
    "        @debug \"loss: $loss β: $β: λ $λ\"\n",
    "        loss\n",
    "    end\n",
    "    res = optimize(\n",
    "        validation_mse,\n",
    "        param.λ,\n",
    "        LBFGS(),\n",
    "        autodiff = :forward,\n",
    "        Optim.Options(show_trace = true, extended_trace = true),\n",
    "    )\n",
    "    param.λ = Optim.minimizer(res)\n",
    "\n",
    "    # save predictions\n",
    "    inference = get_inference()\n",
    "    preds = collaborative_filtering(training, inference, neighborhoods, param.λ)\n",
    "    sparse_preds = sparse(inference.user, inference.item, preds)\n",
    "    function model(users, items, predictions)\n",
    "        result = zeros(length(users))\n",
    "        for i = 1:length(users)\n",
    "            if users[i] <= size(predictions)[1] && items[i] <= size(predictions)[2]\n",
    "                result[i] = predictions[users[i], items[i]]\n",
    "            end\n",
    "        end\n",
    "        result\n",
    "    end\n",
    "    write_predictions(\n",
    "        (users, items) -> model(users, items, sparse_preds),\n",
    "        outdir = param.name,\n",
    "        residual_alphas = param.validation_residuals,\n",
    "        save_training = true,\n",
    "    )\n",
    "    write_params(to_dict(param), outdir = param.name)\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

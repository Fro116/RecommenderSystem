{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3758ece-9b72-47b4-ae6a-aa364e0443e3",
   "metadata": {},
   "source": [
    "# Item Collaborative Filtering\n",
    "* This notebook implements item-based collaborative filtering\n",
    "* Prediction is $\\tilde r_{ij} = \\dfrac{\\sum_{k \\in N(j)} f(w_{kj})g(t_{ik})h(r_{ik})}{\\sum_{k \\in N(j)} f(w_{kj})g(t_{ik}) + \\lambda}$\n",
    "* $r_{ij}$ is the rating for user $i$ and item $j$\n",
    "* $w_{kj}$ is the similarity between items $j$ and $k$\n",
    "* $t_{ik}$ is a measure of how long ago user $i$ watched item $k$\n",
    "* $f, g, h$ are exponential functions\n",
    "* $N(j)$ is the largest $K$ items sorted by $|w_{kj}|$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17593ac-3260-4c01-a5df-91edfcd17e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import LinearAlgebra: norm\n",
    "import Setfield: @set\n",
    "import SparseArrays: sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff8e524-e8f8-48bd-9ca7-c28a05a122b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Determine the neighborhoods for each user and item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275b8d1d-b0f1-4a72-bff2-ed1c615beae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_correlation_matrix_outdir(residual_alphas, name = name)\n",
    "    # if the matrix is already stored on disk, return its filepath\n",
    "    # otherwise, regenerate the matrix and store it to disk\n",
    "    outdir = \"$name/$(hash(residual_alphas))\"\n",
    "    if ispath(get_data_path(\"alphas/$outdir\"))\n",
    "        return outdir\n",
    "    end\n",
    "\n",
    "    @info \"generating similarity matrix for $residual_alphas\"\n",
    "    training = RatingsDataset64(get_residuals(\"training\", residual_alphas))\n",
    "    R = sparse(\n",
    "        training.user,\n",
    "        training.item,\n",
    "        training.rating,\n",
    "        maximum(training.user),\n",
    "        num_items(),\n",
    "    )\n",
    "    S = zeros(eltype(R), num_items(), num_items())\n",
    "\n",
    "    norms = map(norm, eachslice(R, dims = 2))\n",
    "    norms[norms.==0] .= 1 # prevent division by 0\n",
    "    @tprogress Threads.@threads for i = 1:size(S)[1]\n",
    "        S[:, i] = vec(R[:, i]' * R) ./ norms ./ norms[i]\n",
    "    end\n",
    "\n",
    "    write_params(Dict(\"S\" => S), outdir)\n",
    "    outdir\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ffe121-d4c6-4260-a7df-2ad19b9bed25",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_causal_matrix_outdir(residual_alphas, name = name)\n",
    "    salt = hash(\"causal\")\n",
    "    outdir = \"$name/$(hash(residual_alphas) + salt)\"\n",
    "    if ispath(get_data_path(\"alphas/$outdir\"))\n",
    "        return outdir\n",
    "    end\n",
    "\n",
    "    @info \"generating causal similarity matrix for $residual_alphas\"\n",
    "    training = get_residuals(\"training\", residual_alphas)\n",
    "    training = filter(training, training.timestamp .> 0) \n",
    "    Ts = sparse(\n",
    "        convert.(Int64, training.user),\n",
    "        convert.(Int64, training.item),\n",
    "        training.timestamp,\n",
    "        maximum(training.user),\n",
    "        num_items(),\n",
    "    )    \n",
    "    R = sparse(\n",
    "        convert.(Int64, training.user),\n",
    "        convert.(Int64, training.item),\n",
    "        training.rating,\n",
    "        maximum(training.user),\n",
    "        num_items(),\n",
    "    )\n",
    "    S = zeros(eltype(R), num_items(), num_items())\n",
    "    \n",
    "    function safe_norm(x)\n",
    "        ret = norm(x)\n",
    "        ret == 0 ? 1 : ret      \n",
    "    end\n",
    "\n",
    "    @showprogress for i = 1:size(S)[2]\n",
    "        i_norm = safe_norm(R[:, i])\n",
    "        Threads.@threads for j = 1:size(S)[1]\n",
    "            t = R[:, j] .* (Ts[:, j] .> Ts[:, i]) # filter to users who watched j after watching i\n",
    "            S[j, i] = SparseArrays.dot(R[:, i], t) / i_norm / safe_norm(t) \n",
    "        end\n",
    "    end\n",
    "\n",
    "    write_params(Dict(\"S\" => S), outdir)\n",
    "    outdir\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "687c68e6-5d2d-470b-a513-9ba157a4ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "function read_similarity_matrix(outdir)\n",
    "    read_params(outdir)[\"S\"]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b1a1a11-feca-45a0-ae58-a4d46232add9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_neighborhood_fn(neighborhood_type)\n",
    "    if neighborhood_type == \"abs\"\n",
    "        return get_abs_neighborhood\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd34115c-51b5-4af1-908d-4322a46d5918",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_abs_neighborhood(item, S, K)\n",
    "    weights = S[:, item]\n",
    "    # ensure that the neighborhood for an item does not include itself\n",
    "    weights[item] = Inf\n",
    "    K = Int(min(K, length(weights) - 1))\n",
    "    order = partialsortperm(abs.(weights), 2:K+1, rev = true)\n",
    "    order, weights[order]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00ebb580-b942-4113-8d60-78a83042d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "isnonzero(x) = !isapprox(x, 0.0, atol = eps(Float32))\n",
    "\n",
    "# each prediction is just the weighted sum of all items in the neighborhood\n",
    "# we apply regularization terms to decay the weights, ratings, and final prediction\n",
    "function make_prediction(item, users, R, T, get_neighborhood, λ)\n",
    "    items, weights = get_neighborhood(item)\n",
    "    weights = powerdecay(weights, λ[2])\n",
    "    predictions = zeros(eltype(weights), length(users))\n",
    "    weight_sum = zeros(eltype(weights), length(users))\n",
    "    for u = 1:length(users)\n",
    "        for (i, weight) in zip(items, weights)\n",
    "            if isnonzero(R[users[u], i])\n",
    "                t = powerlawdecay(1 - T[users[u], i], exp(λ[4]))\n",
    "                predictions[u] += weight * powerdecay(R[users[u], i], λ[3]) * t\n",
    "                weight_sum[u] += abs(weight) * t\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    for u = 1:length(users)\n",
    "        predictions[u] = predictions[u] / (weight_sum[u] + exp(λ[1]))\n",
    "    end\n",
    "    predictions\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5214736f-516e-4d6f-8f0b-92171355ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "function collaborative_filtering(training, inference, get_neighborhood, λ)\n",
    "    R = sparse(training.user, training.item, training.rating, num_users(), num_items())\n",
    "    T = sparse(\n",
    "        training.user,\n",
    "        training.item,\n",
    "        max.(training.timestamp, 0.0),\n",
    "        num_users(),\n",
    "        num_items(),\n",
    "    )\n",
    "\n",
    "    preds = zeros(eltype(λ), length(inference.user))\n",
    "    @tprogress Threads.@threads for item in collect(Set(inference.item))\n",
    "        mask = inference.item .== item\n",
    "        preds[mask] = make_prediction(item, inference.user[mask], R, T, get_neighborhood, λ)\n",
    "    end\n",
    "    preds\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c815cbbe-7300-4c9d-9163-4e554a9752e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@with_kw struct cf_params\n",
    "    name::Any\n",
    "    training_residuals::Any\n",
    "    validation_residuals::Any\n",
    "    neighborhood_type::Any\n",
    "    S::Any # the similarity matrix\n",
    "    K::Any # the neighborhood size\n",
    "    λ::Vector{Float32}\n",
    "end;\n",
    "\n",
    "to_dict(x::T) where {T} = Dict(string(fn) => getfield(x, fn) for fn ∈ fieldnames(T));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cf908b-4b56-412a-9765-c13021874f41",
   "metadata": {},
   "source": [
    "## Item based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "904a3cc2-c5e7-4e1b-810a-b3616c4d1b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_residuals(split, residual_alphas)\n",
    "    df = get_split(split, \"explicit\")\n",
    "    ratings = df.rating - read_alpha(residual_alphas, split, \"explicit\", false).rating\n",
    "    if split == \"training\"\n",
    "        timestamps = df.timestamp\n",
    "    else\n",
    "        timestamps = []\n",
    "    end\n",
    "    RatingsDataset(\n",
    "        user = df.user,\n",
    "        item = df.item,\n",
    "        rating = ratings,\n",
    "        timestamp = timestamps,\n",
    "    )\n",
    "end\n",
    "\n",
    "function get_training(residual_alphas)\n",
    "    get_residuals(\"training\", residual_alphas)\n",
    "end\n",
    "\n",
    "function get_validation(residual_alphas)\n",
    "    get_residuals(\"validation\", residual_alphas)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "755b9b34-ffa0-48d9-bf99-5ee735c04036",
   "metadata": {},
   "outputs": [],
   "source": [
    "function optimize_model(param)\n",
    "    # unpack parameters\n",
    "    redirect_logging(get_data_path(\"alphas/$(param.name)\"))\n",
    "    training = get_training(param.training_residuals)\n",
    "    validation = get_validation(param.validation_residuals)\n",
    "    S = read_similarity_matrix(param.S)\n",
    "    K = param.K\n",
    "    neighborhoods = i -> get_neighborhood_fn(param.neighborhood_type)(i, S, K)\n",
    "\n",
    "    # optimize hyperparameters\n",
    "    function validation_mse(λ)\n",
    "        preds = collaborative_filtering(training, validation, neighborhoods, λ)\n",
    "        loss = residualized_loss(param.validation_residuals, \"explicit\", false, preds)\n",
    "        @info \"loss: $loss\"\n",
    "        loss\n",
    "    end\n",
    "    res = Optim.optimize(\n",
    "        validation_mse,\n",
    "        param.λ,\n",
    "        Optim.NewtonTrustRegion(),\n",
    "        autodiff = :forward,\n",
    "        Optim.Options(show_trace = true, extended_trace = true, iterations = 30),\n",
    "    )\n",
    "    param = @set param.λ = Optim.minimizer(res)\n",
    "\n",
    "    function model(users, items)\n",
    "        inference = RatingsDataset(user = users, item = items)\n",
    "        collaborative_filtering(training, inference, neighborhoods, param.λ)\n",
    "    end\n",
    "\n",
    "    # save predictions\n",
    "    write_params(to_dict(param), param.name)\n",
    "    write_alpha(\n",
    "        model,\n",
    "        name;\n",
    "        log = false,\n",
    "    )    \n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3758ece-9b72-47b4-ae6a-aa364e0443e3",
   "metadata": {},
   "source": [
    "# Generalized Neural Network\n",
    "* A denoising autoencoder that learns the user's ratings and implicit ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "54170f91-c85c-4207-9939-572cad4db024",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "import BSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d17593ac-3260-4c01-a5df-91edfcd17e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "using NBInclude\n",
    "@nbinclude(\"Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08801fd4-7057-49f0-9fa7-9854d17494cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = gpu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ede3b9a1-1dc8-4b10-aab0-03ceb5d27be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(20220313 * hash(name));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638f2e93-80aa-4d4f-90ee-d70e3610cd13",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8f724408-2a16-4d0d-adb3-9a1ddbe283bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "const training = get_residuals(\"training\", residual_alphas)\n",
    "const validation = get_residuals(\"validation\", residual_alphas)\n",
    "const implicit_training = get_split(\"implicit_training\")\n",
    "const n_items = num_items() + 1 # leave room to map unseen items\n",
    "const n_users = maximum(training.user) + 1; # leave room to map unseen users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eb458301-7baa-4bd1-88c1-bd8c9193bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column accesses are faster than row accesses, so we make this an (item, user) matrix \n",
    "const R = sparse(training.item, training.user, training.rating, n_items, n_users)\n",
    "const Ri = sparse(\n",
    "    implicit_training.item,\n",
    "    implicit_training.user,\n",
    "    implicit_training.rating,\n",
    "    n_items,\n",
    "    n_users,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5cad5b01-a2a1-48a8-8eef-954062f7d630",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_rating_sum(split)\n",
    "    counts = zeros(Float32, n_users, Threads.nthreads())\n",
    "    @tprogress Threads.@threads for i = 1:length(split.rating)\n",
    "        counts[split.user[i], Threads.threadid()] += split.rating[i]\n",
    "    end\n",
    "    counts = sum(counts, dims = 2)\n",
    "    counts\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bebdee68-2760-434e-bb32-3ceb59dd04f2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:07 ( 0.54 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:04 ( 0.45 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:04 ( 0.47 μs/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "const implicit_counts = get_rating_sum(implicit_training)\n",
    "const rating_counts = get_rating_sum(\n",
    "    RatingsDataset(\n",
    "        training.user,\n",
    "        training.item,\n",
    "        fill(one(eltype(training.rating)), length(training.rating)),\n",
    "    ),\n",
    ")\n",
    "const rating_sum = get_rating_sum(get_split(\"training\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fd21001b-3626-4bf2-82aa-ba04ba89df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_data(split, j, train)\n",
    "    # inputs are the user's ratings (unseen shows get mapped to zero) + implicit ratings + heterogenous features\n",
    "    # during training, outputs are the user's ratings + implicit ratings \n",
    "    # during inference, outputs are the user's rating + implicit rating for a held out item on their list\n",
    "\n",
    "    # handle users and items that aren't in the training set\n",
    "    u = min(split.user[j], n_users)\n",
    "    i = min(split.item[j], n_items)\n",
    "    erased = R[i, u] != 0\n",
    "\n",
    "    # ratings\n",
    "    X1 = collect(R[:, u])\n",
    "    X1[i] = 0\n",
    "    # implicit ratings\n",
    "    X2 = collect(Ri[:, u])\n",
    "    X2[i] = 0\n",
    "    # heterogeneous features\n",
    "    features = [\n",
    "        max(implicit_counts[u] - erased, 0) / n_items, # fraction of items seen\n",
    "        max(rating_counts[u] - erased, 0) / n_items,  # fraction of items rated\n",
    "        (rating_sum[u] - R[i, u]) / max(rating_counts[u] - erased, 1) / 10, # average rating\n",
    "    ]\n",
    "    features = convert.(Float32, features)\n",
    "    X3 = vcat(features, features .^ 2, sqrt.(features))\n",
    "\n",
    "    X = vcat(X1, X2, X3)\n",
    "\n",
    "    # outputs\n",
    "    Y1 = zeros(eltype(X1), length(X1))\n",
    "    Y2 = zeros(eltype(X2), length(X2))\n",
    "    if train\n",
    "        mask = X2 .!= 0\n",
    "        Y1[mask] .= X1[mask]\n",
    "        Y2[mask] .= X2[mask]\n",
    "    else\n",
    "        Y1[i] = split.rating[j]\n",
    "        Y2[i] = 1\n",
    "    end\n",
    "    \n",
    "    if train\n",
    "        X *= 0.5 # undo the dropout scaling\n",
    "    end\n",
    "\n",
    "    (X, Y1, Y2)\n",
    "end\n",
    "\n",
    "function get_batch(split, block_size, train)\n",
    "    idxs = rand(1:length(split.rating), block_size)\n",
    "    data = [[] for j = 1:Threads.nthreads()]\n",
    "    Threads.@threads for i = 1:length(idxs)\n",
    "        push!(data[Threads.threadid()], get_data(split, idxs[i], train))\n",
    "    end\n",
    "    X = Flux.batch([data[t][i][1] for t = 1:Threads.nthreads() for i = 1:length(data[t])])\n",
    "    Y1 = Flux.batch([data[t][i][2] for t = 1:Threads.nthreads() for i = 1:length(data[t])])\n",
    "    Y2 = Flux.batch([data[t][i][3] for t = 1:Threads.nthreads() for i = 1:length(data[t])])\n",
    "    [(X, (Y1, Y2))] |> device\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5406c13a-b4e4-4cad-9fa3-ba51e3e65b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function generate_model()\n",
    "    # inputs are the user's ratings for all shows (unseen shows get mapped to zero) + implicit ratings + heterogenous features\n",
    "    # outputs are the user's ratings for all shows (unseen shows get mapped to zero), implicit ratings\n",
    "    # we will train ratings using mse on observed shows, and implicit ratings via crossentropy loss\n",
    "    encoder = Chain(\n",
    "        Dense(n_items + n_items + 9, 512, relu),\n",
    "        Dense(512, 256, relu),\n",
    "        Dense(256, 128, relu),\n",
    "    )\n",
    "    rating_decoder =\n",
    "        Chain(Dense(128, 256, relu), Dense(256, 512, relu), Dense(512, n_items))\n",
    "    implicit_decoder =\n",
    "        Chain(Dense(128, 256, relu), Dense(256, 512, relu), Dense(512, n_items))\n",
    "    m = Chain(Dropout(0.5), encoder, Split(rating_decoder, implicit_decoder)) |> device\n",
    "    m\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4988ea0-8a00-41f1-857f-6064ef3806a7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2068c6b4-911b-400d-89ca-f7971d8de0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "function rating_loss(ŷ, y)\n",
    "    # only compute loss on items the user has seen\n",
    "    mask = y .!= 0\n",
    "    Flux.mse(ŷ[mask], y[mask])\n",
    "end\n",
    "\n",
    "implicit_loss(ŷ, y) = Flux.logitcrossentropy(ŷ, y)\n",
    "\n",
    "function loss_components(m, x, y)\n",
    "    ŷ = m(x)\n",
    "    (rating_loss(ŷ[1], y[1]), implicit_loss(ŷ[2], y[2]))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49d99b66-1951-42d5-9922-e02785ad1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "function reset_training()\n",
    "    global best_loss = Inf\n",
    "    global patience = 30\n",
    "    global smoothing = 0.9\n",
    "    global iters_without_improvement = 0\n",
    "    global min_improvement = 1e-4\n",
    "    global continue_training = true\n",
    "    global iters = 0\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0397c765-0d9c-44b5-bd7c-60cc9ed44d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_model(model_name, seed)\n",
    "    Random.seed!(seed)\n",
    "    m = generate_model()\n",
    "    ps = Flux.params(m)\n",
    "    reset_training()\n",
    "    BLAS.set_num_threads(Threads.nthreads())\n",
    "\n",
    "    # Setup early stopping callbacks\n",
    "    function evalcb(split, train, epochs)\n",
    "        losses = []\n",
    "        @showprogress for epoch = 1:epochs\n",
    "            push!(losses, loss_components(m, get_batch(split, 128, train)[1]...))\n",
    "        end\n",
    "        reduce(.+, losses) ./ length(losses)\n",
    "    end\n",
    "\n",
    "    function evalcb()\n",
    "        # print losses and perform early stopping\n",
    "        testmode!(m)\n",
    "        @debug \"iteration: $iters\"\n",
    "        training_losses = evalcb(training, false, 100)\n",
    "        training_loss = sum(training_losses ./ training_baseline_loss)\n",
    "        @debug \"training losses: $(training_losses) -> $(training_loss)\"\n",
    "        inference_losses = evalcb(validation, false, 500)\n",
    "        inference_loss = sum(inference_losses ./ inference_baseline_loss)\n",
    "        if best_loss != Inf\n",
    "            inference_loss = smoothing * best_loss + (1 - smoothing) * inference_loss\n",
    "        end\n",
    "        @debug \"validation losses: $(inference_losses) -> $(inference_loss)\"\n",
    "        if inference_loss + min_improvement < best_loss\n",
    "            global best_loss = inference_loss\n",
    "            global iters_without_improvement = 0\n",
    "            BSON.@save \"../../data/alphas/$name/model.$(model_name).bson\" m\n",
    "        else\n",
    "            global iters_without_improvement += 1\n",
    "            if iters_without_improvement >= patience\n",
    "                global continue_training = false\n",
    "            end\n",
    "        end\n",
    "        trainmode!(m)\n",
    "    end\n",
    "\n",
    "    # Setup loss\n",
    "    training_baseline_loss = evalcb(training, false, 1000)\n",
    "    inference_baseline_loss = evalcb(validation, false, 1000)\n",
    "    throttled_cb = Flux.throttle(evalcb, 600)\n",
    "    opt = ADAM(0.001, (0.9, 0.999), 1e-5)\n",
    "\n",
    "    function loss(x, y)\n",
    "        sum(loss_components(m, x, y) ./ training_baseline_loss)\n",
    "    end\n",
    "\n",
    "    # Train model\n",
    "    while continue_training\n",
    "        batch = get_batch(training, 128, true)\n",
    "        Flux.train!(loss, ps, batch, opt, cb = throttled_cb)\n",
    "        global iters += 1\n",
    "    end\n",
    "\n",
    "    Dict(\n",
    "        \"name\" => \"$name.$model_name\",\n",
    "        \"loss\" => best_loss,\n",
    "        \"patience\" => patience,\n",
    "        \"iters\" => iters,\n",
    "        \"model\" => \"../../data/alphas/$name/model.$(model_name).bson\",\n",
    "        \"residual_alphas\" => residual_alphas,\n",
    "        \"seed\" => seed,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdd719b-7f8b-491e-bafa-8aa56a9545e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Write predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ceec8522-af45-44ab-a398-afba5f255efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_data(u)\n",
    "    # ratings\n",
    "    X1 = collect(R[:, u])\n",
    "    # implicit ratings\n",
    "    X2 = collect(Ri[:, u])\n",
    "    # heterogeneous features\n",
    "    features = [\n",
    "        implicit_counts[u] / n_items, # fraction of items seen\n",
    "        rating_counts[u] / n_items,  # fraction of items rated\n",
    "        rating_sum[u] / max(rating_counts[u], 1) / 10, # average rating\n",
    "    ]\n",
    "    features = convert.(Float32, features)\n",
    "    X3 = vcat(features, features .^ 2, sqrt.(features))\n",
    "    vcat(X1, X2, X3)\n",
    "end\n",
    "\n",
    "function get_batch(users)\n",
    "    data = [[] for j = 1:Threads.nthreads()]\n",
    "    Threads.@threads for i = 1:length(users)\n",
    "        push!(data[Threads.threadid()], get_data(users[i]))\n",
    "    end\n",
    "    X = Flux.batch([data[t][i] for t = 1:Threads.nthreads() for i = 1:length(data[t])])\n",
    "    X |> device\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3af0b836-f8dd-4a6d-b9d1-c20f1d518bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "function gmodel(m, users, items)\n",
    "    # index users\n",
    "    user_to_output_idxs = [Dict() for t = 1:Threads.nthreads()]\n",
    "    @tprogress Threads.@threads for j = 1:length(users)\n",
    "        u = users[j]\n",
    "        t = Threads.threadid()\n",
    "        if u ∉ keys(user_to_output_idxs[t])\n",
    "            user_to_output_idxs[t][u] = []\n",
    "        end\n",
    "        push!(user_to_output_idxs[t][u], j)\n",
    "    end\n",
    "    user_to_output_idxs = merge(vcat, user_to_output_idxs...)\n",
    "\n",
    "    # allocate outputs\n",
    "    ratings = zeros(Float32, length(users))\n",
    "    implicit = zeros(Float32, length(users))\n",
    "\n",
    "    # split users into mini-batches\n",
    "    deduped_users = collect(Set(users))\n",
    "    batch(arr, n) = [arr[i:min(i + n - 1, end)] for i = 1:n:length(arr)]\n",
    "    batches = batch(deduped_users, 128)\n",
    "\n",
    "    # compute predictions\n",
    "    @tprogress Threads.@threads for i = 1:length(batches)\n",
    "        b = batches[i]\n",
    "        user_to_input_idx = Dict(zip(b, 1:length(b)))\n",
    "        alpha = m(get_batch(b)) |> cpu\n",
    "        alpha[2] .= exp.(alpha[2])\n",
    "        alpha[2] .= alpha[2] ./ sum(alpha[2], dims = 1)\n",
    "\n",
    "        for u in b\n",
    "            input_idx = user_to_input_idx[u]\n",
    "            for output_idx in user_to_output_idxs[u]\n",
    "                ratings[output_idx] = alpha[1][items[output_idx], input_idx]\n",
    "                implicit[output_idx] = alpha[2][items[output_idx], input_idx]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    ratings, implicit\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9327642b-9991-44d5-ab0c-7ce6033d461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_prediction(sparse_preds, users, items)\n",
    "    preds = zeros(length(users))\n",
    "    @tprogress Threads.@threads for j = 1:length(preds)\n",
    "        preds[j] = sparse_preds[users[j], items[j]]\n",
    "    end\n",
    "    preds\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "46d999f4-f2b4-4d71-944b-754aead7de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "function save_model(params)\n",
    "    BSON.@load params[\"model\"] m\n",
    "    testmode!(m)\n",
    "    BLAS.set_num_threads(1) # gmodel already multithreads\n",
    "\n",
    "    full_df = reduce(cat, [training, validation, get_residuals(\"test\", residual_alphas)])\n",
    "    ratings, implicit_ratings = gmodel(m, full_df.user, full_df.item)\n",
    "    sparse_preds = sparse(full_df.user, full_df.item, ratings)\n",
    "    implicit_preds = sparse(full_df.user, full_df.item, implicit_ratings)\n",
    "\n",
    "    write_params(params, outdir = params[\"name\"])\n",
    "    write_predictions(\n",
    "        (users, items) -> make_prediction(sparse_preds, users, items),\n",
    "        residual_alphas = residual_alphas,\n",
    "        outdir = params[\"name\"],\n",
    "    )\n",
    "    write_predictions(\n",
    "        (users, items) -> make_prediction(implicit_preds, users, items),\n",
    "        residual_alphas = [],\n",
    "        outdir = params[\"name\"] * \".Implicit\",\n",
    "        implicit = true,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4670b295-b3f0-44ce-8220-958a9147f410",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220313 05:58:17 The GPU function is being called but the GPU is not accessible. \n",
      "\u001b[38;5;6m\u001b[1m└ \u001b[22m\u001b[39mDefaulting back to the CPU. (No action is required if you want to run on the CPU).\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:01:52\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:01:40\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 06:02:42 iteration: 0\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 06:02:53 training losses: (1.6555859f0, 4913.1475f0) -> 1.98928\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:50\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 06:03:43 validation losses: (1.7344704f0, 9.847233f0) -> 1.9890811\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 06:14:02 iteration: 418\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 06:14:12 training losses: (1.4135252f0, 4146.787f0) -> 1.68878\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 06:15:02 validation losses: (1.5733336f0, 7.057634f0) -> 1.9515685558319094\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 06:25:16 iteration: 806\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 06:25:26 training losses: (1.3520155f0, 4068.6875f0) -> 1.6358626\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 06:26:14 validation losses: (1.5406662f0, 6.9595947f0) -> 1.914948539733887\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 06:36:29 iteration: 1210\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 06:36:39 training losses: (1.376381f0, 4021.5435f0) -> 1.6411316\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 06:37:28 validation losses: (1.5205092f0, 6.918221f0) -> 1.8804207177162173\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 06:47:43 iteration: 1608\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 06:47:53 training losses: (1.4012642f0, 4139.1953f0) -> 1.6798347\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 06:48:43 validation losses: (1.5477939f0, 6.8851476f0) -> 1.850566226053238\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 06:58:58 iteration: 2001\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 06:59:07 training losses: (1.4758258f0, 3935.4287f0) -> 1.6840003\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 06:59:57 validation losses: (1.5248001f0, 6.85572f0) -> 1.82208684486866\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 07:10:12 iteration: 2379\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 07:10:23 training losses: (1.3102003f0, 4055.0122f0) -> 1.6078107\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 07:11:11 validation losses: (1.539614f0, 6.85263f0) -> 1.7972690171246528\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 07:21:26 iteration: 2778\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 07:21:36 training losses: (1.2897558f0, 3931.0967f0) -> 1.5705347\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 07:22:26 validation losses: (1.4901172f0, 6.803337f0) -> 1.7716092264275074\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 07:32:40 iteration: 3175\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 07:32:51 training losses: (1.2751153f0, 3955.775f0) -> 1.5666354\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:51\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 07:33:42 validation losses: (1.4814888f0, 6.7925835f0) -> 1.7479140754598665\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 07:43:58 iteration: 3572\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 07:44:07 training losses: (1.2311493f0, 4023.2246f0) -> 1.5535867\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 07:44:55 validation losses: (1.4820701f0, 6.7740536f0) -> 1.7264334675125736\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 07:55:09 iteration: 3974\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 07:55:18 training losses: (1.2461996f0, 4015.4832f0) -> 1.561138\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 07:56:06 validation losses: (1.4973422f0, 6.767682f0) -> 1.7079073592828922\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 08:06:21 iteration: 4368\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 08:06:31 training losses: (1.2427603f0, 4001.172f0) -> 1.5561806\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 08:07:20 validation losses: (1.4925406f0, 6.767922f0) -> 1.6909624104029428\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 08:17:36 iteration: 4756\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 08:17:45 training losses: (1.2296339f0, 4050.4795f0) -> 1.5581474\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 08:18:33 validation losses: (1.4713012f0, 6.772211f0) -> 1.6745440153175435\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 08:28:48 iteration: 5151\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 08:28:58 training losses: (1.199381f0, 4009.9177f0) -> 1.5316886\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 08:29:46 validation losses: (1.4570676f0, 6.74911f0) -> 1.6587210405970074\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 08:40:01 iteration: 5545\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 08:40:11 training losses: (1.1884078f0, 3977.154f0) -> 1.5184636\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 08:41:00 validation losses: (1.4808798f0, 6.7472253f0) -> 1.645819465139907\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 08:51:15 iteration: 5931\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 08:51:24 training losses: (1.2003889f0, 3946.5034f0) -> 1.5195534\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 08:52:13 validation losses: (1.4487046f0, 6.7300205f0) -> 1.6321981070811165\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 09:02:28 iteration: 6320\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 09:02:38 training losses: (1.1648191f0, 4022.7822f0) -> 1.51336\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 09:03:26 validation losses: (1.4707433f0, 6.7296057f0) -> 1.6211917625404548\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 09:13:41 iteration: 6709\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 09:13:51 training losses: (1.1871061f0, 3895.758f0) -> 1.5013168\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 09:14:40 validation losses: (1.4557961f0, 6.7306542f0) -> 1.610444113004549\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 09:24:55 iteration: 7113\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 09:25:05 training losses: (1.2444465f0, 3984.9685f0) -> 1.5539443\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 09:25:54 validation losses: (1.5147165f0, 6.7465634f0) -> 1.6042935649052357\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 09:36:09 iteration: 7502\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 09:36:20 training losses: (1.1409385f0, 3964.778f0) -> 1.4872515\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 09:37:09 validation losses: (1.4665421f0, 6.7246594f0) -> 1.5957878171946194\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 09:47:25 iteration: 7900\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 09:47:35 training losses: (1.1989361f0, 3927.6912f0) -> 1.5148933\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 09:48:24 validation losses: (1.4502512f0, 6.727957f0) -> 1.5872368818115223\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 09:58:39 iteration: 8298\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 09:58:49 training losses: (1.1399033f0, 3933.531f0) -> 1.480345\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 09:59:38 validation losses: (1.453295f0, 6.6989317f0) -> 1.579419994854125\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 10:09:53 iteration: 8686\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 10:10:03 training losses: (1.1444172f0, 4052.1982f0) -> 1.5069264\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 10:10:52 validation losses: (1.474297f0, 6.730424f0) -> 1.5739024738995961\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 10:21:06 iteration: 9079\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 10:21:17 training losses: (1.1649163f0, 3917.8877f0) -> 1.492337\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 10:22:07 validation losses: (1.4620464f0, 6.7107244f0) -> 1.5680379266019522\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 10:32:21 iteration: 9471\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 10:32:31 training losses: (1.1782036f0, 3809.791f0) -> 1.478652\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 10:33:19 validation losses: (1.4573859f0, 6.7107067f0) -> 1.56249381850444\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 10:43:35 iteration: 9864\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 10:43:45 training losses: (1.1349082f0, 3891.3535f0) -> 1.4688456\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 10:44:34 validation losses: (1.4365157f0, 6.7123103f0) -> 1.5563299573983196\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 10:54:48 iteration: 10263\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 10:54:58 training losses: (1.1220698f0, 3808.9043f0) -> 1.444506\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:46\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 10:55:45 validation losses: (1.4291868f0, 6.70001f0) -> 1.5502395794563393\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 11:06:00 iteration: 10651\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 11:06:10 training losses: (1.1750131f0, 3963.1143f0) -> 1.5075364\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 11:06:58 validation losses: (1.4608792f0, 6.7125807f0) -> 1.546693602124414\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 11:17:14 iteration: 11040\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 11:17:24 training losses: (1.2321507f0, 3908.8157f0) -> 1.5311986\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 11:18:13 validation losses: (1.4465555f0, 6.7093124f0) -> 1.542651998030747\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 11:28:28 iteration: 11429\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 11:28:38 training losses: (1.1314669f0, 3939.0269f0) -> 1.4763446\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 11:29:26 validation losses: (1.4523696f0, 6.699558f0) -> 1.5392471674331472\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 11:39:41 iteration: 11820\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 11:39:51 training losses: (1.1506497f0, 3974.2585f0) -> 1.4950335\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 11:40:40 validation losses: (1.4414582f0, 6.7064185f0) -> 1.5356300821824473\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 11:50:56 iteration: 12210\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 11:51:06 training losses: (1.1249826f0, 3897.368f0) -> 1.4640481\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 11:51:54 validation losses: (1.4376633f0, 6.699409f0) -> 1.5320870892039182\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 12:02:10 iteration: 12610\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 12:02:19 training losses: (1.0886879f0, 3831.2983f0) -> 1.4288068\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:46\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 12:03:06 validation losses: (1.4608792f0, 6.6945205f0) -> 1.530172993168048\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 12:13:22 iteration: 13008\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 12:13:31 training losses: (1.0745916f0, 4116.1445f0) -> 1.4775255\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:46\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 12:14:18 validation losses: (1.4464941f0, 6.688376f0) -> 1.5275673950536355\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 12:24:33 iteration: 13402\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 12:24:43 training losses: (1.091243f0, 3918.9866f0) -> 1.4479766\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 12:25:32 validation losses: (1.440377f0, 6.687544f0) -> 1.5248649911424492\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 12:35:48 iteration: 13794\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 12:35:58 training losses: (1.1264989f0, 3959.5557f0) -> 1.4774642\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 12:36:46 validation losses: (1.4561331f0, 6.7013607f0) -> 1.5234718319482483\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 12:47:01 iteration: 14195\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 12:47:11 training losses: (1.0898547f0, 3808.1416f0) -> 1.4248587\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 12:48:00 validation losses: (1.4449902f0, 6.6827283f0) -> 1.5213932272827813\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 12:58:14 iteration: 14592\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 12:58:24 training losses: (1.119259f0, 3969.031f0) -> 1.4749876\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 12:59:12 validation losses: (1.4641993f0, 6.679682f0) -> 1.5205872485371996\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 13:09:27 iteration: 14984\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 13:09:37 training losses: (1.0924034f0, 3932.5332f0) -> 1.4514014\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 13:10:24 validation losses: (1.4635192f0, 6.682548f0) -> 1.5198521759509358\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 13:20:39 iteration: 15378\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 13:20:49 training losses: (1.0933468f0, 3961.8257f0) -> 1.4578595\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 13:21:38 validation losses: (1.4364909f0, 6.698344f0) -> 1.5178092849015576\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 13:31:53 iteration: 15770\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 13:32:03 training losses: (1.0548626f0, 4101.286f0) -> 1.4626008\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 13:32:52 validation losses: (1.4328979f0, 6.688363f0) -> 1.5156644104504033\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 13:43:07 iteration: 16162\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 13:43:17 training losses: (1.0801386f0, 4063.2568f0) -> 1.4702526\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 13:44:06 validation losses: (1.4427049f0, 6.6787615f0) -> 1.5141959355995158\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 13:54:21 iteration: 16556\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 13:54:31 training losses: (1.0772508f0, 3903.2688f0) -> 1.4363506\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 13:55:19 validation losses: (1.4545077f0, 6.683092f0) -> 1.5135914951615124\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 14:05:35 iteration: 16948\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 14:05:44 training losses: (1.0963911f0, 3904.59f0) -> 1.4481983\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 14:06:33 validation losses: (1.4549222f0, 6.688727f0) -> 1.5131283584284116\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 14:16:48 iteration: 17337\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 14:16:58 training losses: (1.100048f0, 3930.1553f0) -> 1.4555492\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 14:17:48 validation losses: (1.4442962f0, 6.6969447f0) -> 1.5121888622385857\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 14:28:03 iteration: 17723\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 14:28:13 training losses: (1.0613382f0, 3982.0164f0) -> 1.4425483\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:50\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 14:29:04 validation losses: (1.4297374f0, 6.678892f0) -> 1.5103295956321894\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 14:39:19 iteration: 18116\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 14:39:28 training losses: (1.0487456f0, 3883.5725f0) -> 1.415143\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 14:40:16 validation losses: (1.4588871f0, 6.6898913f0) -> 1.5104306263567513\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 14:50:18 iteration: 18507\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 14:50:27 training losses: (1.0429443f0, 4045.8357f0) -> 1.4442443\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:45\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 14:51:13 validation losses: (1.4562333f0, 6.683295f0) -> 1.51021228262201\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 15:01:28 iteration: 18895\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 15:01:38 training losses: (1.0679615f0, 4002.1738f0) -> 1.4506075\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 15:02:25 validation losses: (1.4447169f0, 6.685073f0) -> 1.5094678583301457\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 15:12:41 iteration: 19282\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 15:12:52 training losses: (1.0775763f0, 3909.8147f0) -> 1.4378631\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 15:13:42 validation losses: (1.4384667f0, 6.681971f0) -> 1.5084098740718384\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 15:23:57 iteration: 19669\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 15:24:06 training losses: (1.0308592f0, 3984.199f0) -> 1.4245436\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 15:24:54 validation losses: (1.4468386f0, 6.697781f0) -> 1.508095732119824\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 15:35:09 iteration: 20057\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 15:35:19 training losses: (1.0785192f0, 3854.9565f0) -> 1.4274083\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:46\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 15:36:06 validation losses: (1.4248288f0, 6.659632f0) -> 1.506170252669286\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 15:46:21 iteration: 20447\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 15:46:31 training losses: (1.048437f0, 3964.5457f0) -> 1.4312303\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 15:47:20 validation losses: (1.4266886f0, 6.665464f0) -> 1.5046026048437637\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 15:57:36 iteration: 20836\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 15:57:47 training losses: (1.0835379f0, 3886.9333f0) -> 1.436872\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:50\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 15:58:37 validation losses: (1.4150395f0, 6.68015f0) -> 1.5026763681211366\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 16:08:53 iteration: 21224\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 16:09:02 training losses: (1.0596704f0, 3824.199f0) -> 1.4098208\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 16:09:50 validation losses: (1.4399801f0, 6.679795f0) -> 1.5023617628489399\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 16:20:05 iteration: 21618\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 16:20:15 training losses: (1.0364109f0, 3924.4187f0) -> 1.4158883\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 16:21:03 validation losses: (1.437643f0, 6.671774f0) -> 1.501863874489766\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 16:31:19 iteration: 22009\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 16:31:28 training losses: (1.0347806f0, 3969.0535f0) -> 1.4238725\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 16:32:15 validation losses: (1.4310571f0, 6.6894784f0) -> 1.501219866420062\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 16:42:30 iteration: 22396\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 16:42:40 training losses: (1.0678518f0, 3801.252f0) -> 1.4101596\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 16:43:30 validation losses: (1.4507537f0, 6.6852474f0) -> 1.5017207959996743\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 16:53:32 iteration: 22783\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 16:53:42 training losses: (1.0415115f0, 3916.009f0) -> 1.4172845\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 16:54:31 validation losses: (1.4388986f0, 6.6768947f0) -> 1.500959775816111\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 17:04:46 iteration: 23166\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 17:04:56 training losses: (1.0300099f0, 3989.0305f0) -> 1.4250007\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:50\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 17:05:46 validation losses: (1.434344f0, 6.698157f0) -> 1.5006817656493558\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 17:16:02 iteration: 23543\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 17:16:12 training losses: (1.0345166f0, 3936.8628f0) -> 1.417243\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 17:16:59 validation losses: (1.4361033f0, 6.6701484f0) -> 1.5002475450399255\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 17:27:15 iteration: 23924\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 17:27:26 training losses: (1.0244231f0, 3999.91f0) -> 1.4238065\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:50\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 17:28:16 validation losses: (1.427513f0, 6.6815033f0) -> 1.4994820478525224\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 17:38:31 iteration: 24305\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 17:38:41 training losses: (1.0171936f0, 3931.9082f0) -> 1.4057646\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 17:39:29 validation losses: (1.4124403f0, 6.658784f0) -> 1.4977026930123385\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 17:49:45 iteration: 24694\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 17:49:55 training losses: (1.0202595f0, 3954.9421f0) -> 1.4122493\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:46\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 17:50:41 validation losses: (1.4559803f0, 6.6652827f0) -> 1.4986507669690088\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 18:00:44 iteration: 25085\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 18:00:54 training losses: (1.0145384f0, 3963.1492f0) -> 1.4104369\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 18:01:42 validation losses: (1.4493735f0, 6.7100396f0) -> 1.4987283126118616\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 18:11:43 iteration: 25474\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 18:11:53 training losses: (0.98325396f0, 3993.0537f0) -> 1.3975163\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 18:12:41 validation losses: (1.4351187f0, 6.6638f0) -> 1.4974457637074425\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 18:22:57 iteration: 25862\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 18:23:07 training losses: (1.0404165f0, 3927.426f0) -> 1.4189165\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 18:23:55 validation losses: (1.4490008f0, 6.674416f0) -> 1.4981141521575603\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 18:33:57 iteration: 26260\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 18:34:07 training losses: (1.0291166f0, 3990.4753f0) -> 1.4247504\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 18:34:55 validation losses: (1.4347817f0, 6.685751f0) -> 1.497418160641447\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 18:44:57 iteration: 26655\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 18:45:08 training losses: (1.015791f0, 3860.509f0) -> 1.3905661\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 18:45:58 validation losses: (1.438675f0, 6.679037f0) -> 1.4975720836761148\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 18:56:01 iteration: 27047\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 18:56:11 training losses: (1.0333978f0, 3920.2146f0) -> 1.41322\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 18:56:59 validation losses: (1.4242221f0, 6.683698f0) -> 1.4967950060012492\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 19:07:15 iteration: 27431\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 19:07:24 training losses: (1.003838f0, 3912.8586f0) -> 1.3938544\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:51\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 19:08:16 validation losses: (1.4515929f0, 6.682286f0) -> 1.497756219569673\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 19:18:17 iteration: 27823\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 19:18:27 training losses: (1.0138581f0, 3888.298f0) -> 1.3949815\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 19:19:17 validation losses: (1.4304637f0, 6.680423f0) -> 1.4965320951380627\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 19:29:31 iteration: 28215\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:11\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 19:29:43 training losses: (1.0583817f0, 3912.459f0) -> 1.4267795\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:53\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 19:30:36 validation losses: (1.4406176f0, 6.6820807f0) -> 1.496891474125233\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 19:40:39 iteration: 28606\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 19:40:49 training losses: (1.0333116f0, 4013.1682f0) -> 1.4318497\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 19:41:37 validation losses: (1.4367745f0, 6.6813188f0) -> 1.496664535400715\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 19:51:41 iteration: 28988\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 19:51:51 training losses: (1.0374416f0, 3821.057f0) -> 1.3957381\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 19:52:38 validation losses: (1.4305754f0, 6.6725125f0) -> 1.4962215417598155\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 20:02:52 iteration: 29378\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 20:03:02 training losses: (1.0375389f0, 3850.2798f0) -> 1.4016702\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:50\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 20:03:52 validation losses: (1.4417769f0, 6.66921f0) -> 1.4965474361754478\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 20:13:54 iteration: 29771\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 20:14:05 training losses: (1.0358169f0, 3998.5203f0) -> 1.4304218\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:50\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 20:14:56 validation losses: (1.4442738f0, 6.679531f0) -> 1.496794652400118\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 20:24:58 iteration: 30165\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 20:25:08 training losses: (1.0217888f0, 3826.9165f0) -> 1.387444\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 20:25:55 validation losses: (1.4287914f0, 6.665778f0) -> 1.495771908221346\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 20:36:10 iteration: 30554\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 20:36:20 training losses: (1.0060775f0, 3947.3105f0) -> 1.4021337\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 20:37:08 validation losses: (1.4363368f0, 6.672596f0) -> 1.4958668441692309\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 20:47:10 iteration: 30951\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 20:47:20 training losses: (1.0181503f0, 3845.9824f0) -> 1.3890742\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 20:48:09 validation losses: (1.4067781f0, 6.658306f0) -> 1.4940357417980152\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 20:58:24 iteration: 31341\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 20:58:34 training losses: (1.000074f0, 3897.3193f0) -> 1.3884536\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 20:59:23 validation losses: (1.4352107f0, 6.6672535f0) -> 1.4941858241962778\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 21:09:25 iteration: 31727\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 21:09:36 training losses: (1.0017403f0, 3874.576f0) -> 1.3848908\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:49\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 21:10:25 validation losses: (1.4464326f0, 6.6898627f0) -> 1.4950554559635507\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220313 21:20:28 iteration: 32113\n",
      "\u001b[32mProgress:  67%|███████████████████████████▌             |  ETA: 0:00:03\u001b[39m"
     ]
    }
   ],
   "source": [
    "seeds = hash.(rand(Int, 1))\n",
    "for i in 1:length(seeds)\n",
    "    save_model(train_model(i, seeds[i]))\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

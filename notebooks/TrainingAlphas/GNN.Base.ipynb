{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3758ece-9b72-47b4-ae6a-aa364e0443e3",
   "metadata": {},
   "source": [
    "# Generalized Neural Network\n",
    "* A denoising autoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9787e03-9bd7-4e71-9d1e-0499334a045d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"GNN.Rating.Test\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "const name = \"GNN.Rating.Test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54170f91-c85c-4207-9939-572cad4db024",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "import BSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17593ac-3260-4c01-a5df-91edfcd17e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "using NBInclude\n",
    "@nbinclude(\"Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08801fd4-7057-49f0-9fa7-9854d17494cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "const device = gpu;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c030f566-08b7-46ad-9b69-182e559a9f89",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "abba16e9-f406-49c4-8af1-6e0afde838c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@with_kw struct Hyperparams\n",
    "    # model\n",
    "    train_implicit_model::Bool\n",
    "    use_derived_features::Bool\n",
    "    # training\n",
    "    activation::String\n",
    "    autoencode::Bool\n",
    "    batch_size::Int\n",
    "    dropout_perc::Float32\n",
    "    dropout_rescale::Bool\n",
    "    layers::Vector{Int}\n",
    "    l2penalty::Float32\n",
    "    learning_rate::Float32\n",
    "    optimizer::String\n",
    "    patience::Int\n",
    "    # loss functions\n",
    "    sampling_weight_scheme::String\n",
    "    training_residuals::Vector{String}\n",
    "    training_weight_scheme::String\n",
    "    use_residualized_validation_loss::Bool\n",
    "    validation_residuals::Vector{String}\n",
    "    validation_weight_scheme::String\n",
    "    # misc\n",
    "    seed::UInt64\n",
    "end\n",
    "\n",
    "function to_dict(x::Hyperparams)\n",
    "    Dict(string(key) => getfield(x, key) for key ∈ fieldnames(Hyperparams))\n",
    "end\n",
    "\n",
    "function Base.string(x::Hyperparams)\n",
    "    fields = [x for x in fieldnames(Hyperparams)]\n",
    "    max_field_size = maximum(length(string(k)) for k in fields)\n",
    "    ret = \"Hyperparameters:\\n\"\n",
    "    for f in fields\n",
    "        ret *= \"$(rpad(string(f), max_field_size)) => $(getfield(x, f))\\n\"\n",
    "    end\n",
    "    ret\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f724408-2a16-4d0d-adb3-9a1ddbe283bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "const n_items = num_items() + 1 # leave room to map unseen items\n",
    "const n_users = maximum(get_split(\"training\").user) + 1; # leave room to map unseen users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa2f87d3-1942-4abc-88ca-6b83433443c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column accesses are faster than row accesses, so we make this an (item, user) matrix \n",
    "function to_sparse_mat(split)\n",
    "    sparse(split.item, split.user, split.rating, n_items, n_users)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cad5b01-a2a1-48a8-8eef-954062f7d630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function get_derived_feature(split, agg)\n",
    "    sums = zeros(Float32, n_users, Threads.nthreads())\n",
    "    counts = zeros(Float32, n_users, Threads.nthreads())\n",
    "    @tprogress Threads.@threads for i = 1:length(split.rating)\n",
    "        sums[split.user[i], Threads.threadid()] += split.rating[i]\n",
    "        counts[split.user[i], Threads.threadid()] += 1\n",
    "    end\n",
    "    sums = sum(sums, dims = 2)\n",
    "    counts = sum(counts, dims = 2)\n",
    "    sparse(agg.(sums, counts)')\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "47f70afa-60b0-4dac-bfa2-f4648e4145f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_epoch(split)\n",
    "    # todo support G.autoencode = false\n",
    "    @assert G.autoencode\n",
    "\n",
    "    # construct inputs\n",
    "    X = vcat(\n",
    "        to_sparse_mat(get_residuals(\"training\", G.training_residuals)),\n",
    "        to_sparse_mat(get_split(\"implicit_training\")),\n",
    "    )\n",
    "    if G.use_derived_features\n",
    "        Xd = vcat(\n",
    "            # fraction of implicit items\n",
    "            get_derived_feature(\n",
    "                get_split(\"implicit_training\"),\n",
    "                (sum, count) -> count / n_items,\n",
    "            ),\n",
    "            # fraction of seen items\n",
    "            get_derived_feature(get_split(\"training\"), (sum, count) -> count / n_items),\n",
    "            # average item rating\n",
    "            get_derived_feature(\n",
    "                get_split(\"training\"),\n",
    "                (sum, count) -> sum / max(1, count) / 10,\n",
    "            ),\n",
    "        )\n",
    "        X = vcat(X, Xd, Xd .^ 2, sqrt.(Xd))\n",
    "    end\n",
    "    if split == \"training\" && G.dropout_rescale\n",
    "        X .* (1 - G.dropout_perc)\n",
    "    end\n",
    "\n",
    "    # construct outputs\n",
    "    Y = to_sparse_mat(get_residuals(split, G.validation_residuals))\n",
    "    if G.train_implicit_model\n",
    "        Y.nzval .= 1\n",
    "    end\n",
    "\n",
    "    # How much to weight each user in the loss function    \n",
    "    function count_to_weight(x)\n",
    "        scheme = split == \"training\" ? G.training_weight_scheme : G.validation_weight_scheme\n",
    "        weighting_scheme(x, scheme)\n",
    "    end\n",
    "    W = get_derived_feature(get_split(split), (_, count) -> count_to_weight(count))\n",
    "\n",
    "    X, Y, W\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "203dd198-8047-4470-8e80-4640739dd8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_sampling_order(split)\n",
    "    weights = vec(\n",
    "        collect(\n",
    "            get_derived_feature(\n",
    "                get_split(split),\n",
    "                (_, count) -> weighting_scheme(count, G.sampling_weight_scheme),\n",
    "            ),\n",
    "        ),\n",
    "    )\n",
    "    sample(1:n_users, Weights(weights), n_users)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72f35efa-decd-42ed-bcae-f7ea7cab6a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_batch(epoch, iter, batch_size, sampling_order)\n",
    "    range = sampling_order[(iter-1)*batch_size+1:min(iter * batch_size, size(epoch[1])[2])]\n",
    "    process(x) = collect(x[:, range]) |> device\n",
    "    [process.(epoch)]\n",
    "end;\n",
    "\n",
    "function get_batch(epoch, iter, batch_size)\n",
    "    sampling_order = 1:size(epoch[1])[2]\n",
    "    get_batch(epoch, iter, batch_size, sampling_order)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "844da183-e84b-407e-b398-d16d1c283d8e",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5406c13a-b4e4-4cad-9fa3-ba51e3e65b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function generate_model()\n",
    "    # inputs are the user's ratings for all shows (unseen shows get mapped to zero) + implicit ratings + heterogenous features\n",
    "    # outputs are the user's ratings for all shows (unseen shows get mapped to zero), implicit ratings\n",
    "    # we will train ratings using mse on observed shows, and implicit ratings via crossentropy loss\n",
    "    n_inputs = n_items + n_items + (G.use_derived_features ? 9 : 0)\n",
    "    layers = [[n_inputs]; G.layers; [n_items]]\n",
    "    if G.activation == \"relu\"\n",
    "        activation = relu\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "    autoencoder = [Dense(layers[i], layers[i+1], activation) for i = 1:length(layers)-1]\n",
    "    m = Chain(Dropout(G.dropout_perc), autoencoder...) |> device\n",
    "    m |> device\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4988ea0-8a00-41f1-857f-6064ef3806a7",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "735c1cdd-01f6-49da-b0d4-241c68909355",
   "metadata": {},
   "outputs": [],
   "source": [
    "function evaluate(m, split)\n",
    "    BLAS.set_num_threads(1)\n",
    "\n",
    "    df = get_split(split)\n",
    "    users = df.user\n",
    "    items = df.item\n",
    "\n",
    "    # index users\n",
    "    user_to_output_idxs = [Dict() for t = 1:Threads.nthreads()]\n",
    "    @tprogress Threads.@threads for j = 1:length(users)\n",
    "        u = users[j]\n",
    "        t = Threads.threadid()\n",
    "        if u ∉ keys(user_to_output_idxs[t])\n",
    "            user_to_output_idxs[t][u] = []\n",
    "        end\n",
    "        push!(user_to_output_idxs[t][u], j)\n",
    "    end\n",
    "    user_to_output_idxs = merge(vcat, user_to_output_idxs...)\n",
    "\n",
    "    # compute predictions\n",
    "    ratings = zeros(Float32, length(users))\n",
    "    epoch = get_epoch(split)\n",
    "    epoch = (epoch[1], epoch[2], collect(1:n_users)')\n",
    "    batch_size = 16\n",
    "    @tprogress Threads.@threads for iter = 1:Int(ceil(n_users / batch_size))\n",
    "        batch = get_batch(epoch, iter, batch_size)[1]\n",
    "        alpha = m(batch[1]) |> cpu\n",
    "        if G.train_implicit_model\n",
    "            alpha .= exp.(alpha)\n",
    "            alpha .= alpha ./ sum(alpha, dims = 1)\n",
    "        end\n",
    "\n",
    "        for j = 1:size(alpha)[2]\n",
    "            u = batch[3][1, j] # ??????? HOW DID THIS OWRK AT ALL?????\n",
    "            if u ∉ keys(user_to_output_idxs)\n",
    "                continue\n",
    "            end\n",
    "            for output_idx in user_to_output_idxs[u]\n",
    "                ratings[output_idx] = alpha[items[output_idx], j]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    BLAS.set_num_threads(Threads.nthreads())\n",
    "\n",
    "    RatingsDataset(user = users, item = items, rating = ratings)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2068c6b4-911b-400d-89ca-f7971d8de0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "function rating_loss(ŷ, y, weights)\n",
    "    # only compute loss on items the user has seen\n",
    "    mask = y .!= 0\n",
    "    per_user_mse =\n",
    "        sum(((ŷ .- y) .* mask) .^ 2, dims = 1) ./\n",
    "        max.(one(eltype(weights)), sum(mask, dims = 1))\n",
    "    dot(per_user_mse, weights) / sum(weights)\n",
    "end\n",
    "\n",
    "function implicit_loss(ŷ, y, weights)\n",
    "    agg(x) = dot(x, weights)\n",
    "    Flux.logitcrossentropy(ŷ, y, agg = agg) / sum(weights)\n",
    "end\n",
    "\n",
    "loss(m, x, y, weights) =\n",
    "    G.train_implicit_model ? implicit_loss(m(x), y, weights) : rating_loss(m(x), y, weights);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7e91d19-5df7-40f9-a817-c206dd695a60",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_loss(m, split)\n",
    "    BLAS.set_num_threads(1)\n",
    "\n",
    "    epoch = get_epoch(split)\n",
    "    batch_size = 16\n",
    "    losses = zeros(Threads.nthreads())\n",
    "    @tprogress Threads.@threads for iter = 1:Int(ceil(n_users / batch_size))\n",
    "        batch = get_batch(epoch, iter, batch_size)\n",
    "        losses[Threads.threadid()] += loss(m, batch[1]...) * sum(batch[1][3])\n",
    "    end\n",
    "\n",
    "    BLAS.set_num_threads(Threads.nthreads())\n",
    "\n",
    "    sum(losses) / sum(epoch[3])\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fa52df75-53f1-424c-91b3-2b98aaf7c1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_residualized_loss(m, split)\n",
    "    rating = evaluate(m, split).rating\n",
    "    df = get_residuals(split, G.validation_residuals)\n",
    "\n",
    "    # turn per-user weights into per-item weights\n",
    "    W = get_derived_feature(\n",
    "        df,\n",
    "        (_, count) ->\n",
    "            weighting_scheme(count, G.validation_weight_scheme) *\n",
    "            weighting_scheme(count, \"inverse\"),\n",
    "    )\n",
    "    weights = zeros(eltype(rating), length(df.user))\n",
    "    Threads.@threads for i = 1:length(weights)\n",
    "        weights[i] = W[df.user[i]]\n",
    "    end\n",
    "\n",
    "    if G.train_implicit_model\n",
    "        @assert false\n",
    "    else\n",
    "        Y = df.rating .* sqrt.(weights)\n",
    "        X = rating .* sqrt.(weights)\n",
    "        β = X \\ Y\n",
    "        @info \"beta: $β\"\n",
    "        return mse(Y, X .* β, weights)\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2503872c-79e8-405c-acbb-518416c5c360",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c791e6dc-8d74-4004-8dd7-6a87d6599434",
   "metadata": {},
   "outputs": [],
   "source": [
    "function checkpoint(m)\n",
    "    loss_fn = G.use_residualized_validation_loss ? get_residualized_loss : get_loss\n",
    "    training_loss = loss_fn(m, \"training\")\n",
    "    validation_loss = loss_fn(m, \"validation\")\n",
    "    @info \"training loss $training_loss, validation loss $validation_loss\"\n",
    "    validation_loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd02cc13-2680-4297-a746-784faaba3a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "function continue_training(m, stop_criteria, model_path)\n",
    "    validation_loss = checkpoint(m)\n",
    "    if validation_loss < stop_criteria.loss\n",
    "        BSON.@save model_path m\n",
    "    end\n",
    "    !stop!(stop_criteria, validation_loss)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d61e7743-4bc9-4f75-a38d-b5e02ed1e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_epoch!(m, opt; checkpoint_rate = 0.1)\n",
    "    BLAS.set_num_threads(Threads.nthreads())\n",
    "    ps = Flux.params(m)\n",
    "    train_loss(x, y, w) = loss(m, x, y, w)\n",
    "    epoch = get_epoch(\"training\")\n",
    "    sampling_order = get_sampling_order(\"training\")\n",
    "\n",
    "    nbatches = Int(ceil(size(epoch[1])[2] / G.batch_size))\n",
    "    @showprogress for iter = 1:nbatches\n",
    "        batch = get_batch(epoch, iter, G.batch_size, sampling_order)\n",
    "        Flux.train!(train_loss, ps, batch, opt)\n",
    "\n",
    "        if iter % Int(round(nbatches * checkpoint_rate)) == 0\n",
    "            checkpoint(m)\n",
    "        end\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4ade3b7-52e5-4b22-9337-694708eb76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_model(hyperparams::Hyperparams)\n",
    "    # unpack parameters\n",
    "    global G = hyperparams\n",
    "    Random.seed!(G.seed)\n",
    "    m = generate_model()\n",
    "    if G.optimizer == \"ADAM\"\n",
    "        opt = ADAMW(G.learning_rate, (0.9, 0.999), G.l2penalty)\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "    stop_criteria = early_stopper(patience = G.patience)\n",
    "    model_path = \"../../data/alphas/$name/model.$(hash(G)).bson\"\n",
    "\n",
    "    # Train model\n",
    "    while continue_training(m, stop_criteria, model_path)\n",
    "        train_epoch!(m, opt)\n",
    "    end\n",
    "\n",
    "    model_path\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdd719b-7f8b-491e-bafa-8aa56a9545e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Write predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9327642b-9991-44d5-ab0c-7ce6033d461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_prediction(sparse_preds, users, items)\n",
    "    preds = zeros(length(users))\n",
    "    @tprogress Threads.@threads for j = 1:length(preds)\n",
    "        preds[j] = sparse_preds[users[j], items[j]]\n",
    "    end\n",
    "    preds\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "46d999f4-f2b4-4d71-944b-754aead7de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "function save_model(model_path, hyperparams::Hyperparams, outdir)\n",
    "    global G = hyperparams\n",
    "    BSON.@load model_path m\n",
    "    training = evaluate(m, \"training\")\n",
    "    validation = evaluate(m, \"validation\")\n",
    "    test = evaluate(m, \"test\")\n",
    "    df = reduce(cat, [training, validation, test])\n",
    "    sparse_preds = sparse(df.user, df.item, df.rating)\n",
    "\n",
    "    write_predictions(\n",
    "        (users, items) -> make_prediction(sparse_preds, users, items),\n",
    "        residual_alphas = G.validation_residuals,\n",
    "        outdir = outdir,\n",
    "        implicit = G.train_implicit_model,\n",
    "    )\n",
    "    params = to_dict(G)\n",
    "    params[\"model\"] = model_path\n",
    "    write_params(params, outdir = outdir)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c26b887e-756b-440e-bbd6-b2842fd184b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "function fit(hyperparams::Hyperparams, outdir)\n",
    "    redirect_logging(\"../../data/alphas/$outdir\")\n",
    "    @info string(hyperparams)    \n",
    "    model_path = train_model(hyperparams)\n",
    "    save_model(model_path, hyperparams, outdir)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "252b8c25-eaca-43e2-8992-3d8a1ae37409",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hyperparams\n",
       "  train_implicit_model: Bool true\n",
       "  use_derived_features: Bool true\n",
       "  activation: String \"relu\"\n",
       "  autoencode: Bool true\n",
       "  batch_size: Int64 128\n",
       "  dropout_perc: Float32 0.5f0\n",
       "  dropout_rescale: Bool false\n",
       "  layers: Array{Int64}((5,)) [512, 256, 128, 256, 512]\n",
       "  l2penalty: Float32 1.0f-5\n",
       "  learning_rate: Float32 0.001f0\n",
       "  optimizer: String \"ADAM\"\n",
       "  patience: Int64 10\n",
       "  sampling_weight_scheme: String \"linear\"\n",
       "  training_residuals: Array{String}((1,))\n",
       "  training_weight_scheme: String \"linear\"\n",
       "  use_residualized_validation_loss: Bool false\n",
       "  validation_residuals: Array{String}((1,))\n",
       "  validation_weight_scheme: String \"constant\"\n",
       "  seed: UInt64 0x811af080737da77b\n"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams = Hyperparams(\n",
    "    use_derived_features = true,\n",
    "    train_implicit_model = true,\n",
    "    activation = \"relu\",\n",
    "    autoencode = true,\n",
    "    batch_size = 128,\n",
    "    dropout_perc = 0.5,\n",
    "    dropout_rescale = false,\n",
    "    layers = [512, 256, 128, 256, 512],\n",
    "    l2penalty = 1e-5,\n",
    "    learning_rate = 0.001,\n",
    "    optimizer = \"ADAM\",\n",
    "    patience = 10,\n",
    "    sampling_weight_scheme = \"linear\",\n",
    "    training_residuals = [\"UserItemBiases\"],\n",
    "    training_weight_scheme = \"linear\",\n",
    "    use_residualized_validation_loss = false,\n",
    "    validation_residuals = [\"UserItemBiases\"],\n",
    "    validation_weight_scheme = \"constant\",\n",
    "    seed = 20220501 * hash(name),\n",
    ")\n",
    "\n",
    "#fit(hyperparams, \"GNN.Rating.Test.2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3758ece-9b72-47b4-ae6a-aa364e0443e3",
   "metadata": {},
   "source": [
    "# Generalized Neural Network\n",
    "* A denoising autoencoder "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9787e03-9bd7-4e71-9d1e-0499334a045d",
   "metadata": {},
   "outputs": [],
   "source": [
    "const name = \"GNN.Rating.Test\"\n",
    "const training_residuals = [\"UserItemBiases\"]\n",
    "const validation_residuals = [\"UserItemBiases\"]\n",
    "const derived_features = true\n",
    "const train_implicit_model = false\n",
    "const autoencode = true\n",
    "const batch_size = 128\n",
    "const dropout_perc = 0.5\n",
    "const l2penalty = 1e-5\n",
    "const learning_rate = 0.001\n",
    "const num_seeds = 1;\n",
    "const optimizer = \"ADAM\";\n",
    "# TODO train models with different parameter settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54170f91-c85c-4207-9939-572cad4db024",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "import BSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17593ac-3260-4c01-a5df-91edfcd17e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "using NBInclude\n",
    "@nbinclude(\"Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08801fd4-7057-49f0-9fa7-9854d17494cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "const device = gpu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ede3b9a1-1dc8-4b10-aab0-03ceb5d27be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(20220410 * hash(name));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638f2e93-80aa-4d4f-90ee-d70e3610cd13",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f724408-2a16-4d0d-adb3-9a1ddbe283bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "const n_items = num_items() + 1 # leave room to map unseen items\n",
    "const n_users = maximum(get_split(\"training\").user) + 1; # leave room to map unseen users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aa2f87d3-1942-4abc-88ca-6b83433443c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "to_sparse_mat (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# column accesses are faster than row accesses, so we make this an (item, user) matrix \n",
    "function to_sparse_mat(split)\n",
    "    sparse(split.item, split.user, split.rating, n_items, n_users)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cad5b01-a2a1-48a8-8eef-954062f7d630",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function get_derived_feature(split, agg)\n",
    "    sums = zeros(Float32, n_users, Threads.nthreads())\n",
    "    counts = zeros(Float32, n_users, Threads.nthreads())\n",
    "    @tprogress Threads.@threads for i = 1:length(split.rating)\n",
    "        sums[split.user[i], Threads.threadid()] += split.rating[i]\n",
    "        counts[split.user[i], Threads.threadid()] += 1\n",
    "    end\n",
    "    sums = sum(sums, dims = 2)\n",
    "    counts = sum(counts, dims = 2)\n",
    "    sparse(agg.(sums, counts)')\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "47f70afa-60b0-4dac-bfa2-f4648e4145f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_epoch(split)\n",
    "    # todo support autoencode = false\n",
    "    @assert autoencode\n",
    "\n",
    "    # construct inputs\n",
    "    X = vcat(\n",
    "        to_sparse_mat(get_residuals(\"training\", training_residuals)),\n",
    "        to_sparse_mat(get_split(\"implicit_training\")),\n",
    "    )\n",
    "    if derived_features\n",
    "        Xd = vcat(\n",
    "            # fraction of seen items\n",
    "            get_derived_feature(get_split(\"training\"), (sum, count) -> count / n_items),\n",
    "            # fraction of implicit items\n",
    "            get_derived_feature(\n",
    "                get_split(\"implicit_training\"),\n",
    "                (sum, count) -> count / n_items,\n",
    "            ),\n",
    "            # average item rating\n",
    "            get_derived_feature(\n",
    "                get_split(\"training\"),\n",
    "                (sum, count) -> sum / max(1, count) / 10,\n",
    "            ),\n",
    "        )\n",
    "        X = vcat(X, Xd, Xd .^ 2, sqrt.(Xd))\n",
    "    end\n",
    "\n",
    "    # construct outputs\n",
    "    Y = to_sparse_mat(get_residuals(split, validation_residuals))\n",
    "    if train_implicit_model\n",
    "        Y.nzval .= 1\n",
    "    end\n",
    "\n",
    "    # randomly shuffle the users\n",
    "    order = randperm(size(X)[2])\n",
    "    X = X[:, order]\n",
    "    Y = Y[:, order]\n",
    "\n",
    "    X, Y\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2bb83e9b-431e-4ac8-b80f-01ed8b4114d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:06 ( 2.07 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:07 ( 1.78 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:05 ( 1.86 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:05 ( 1.81 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:07 ( 1.78 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:05 ( 1.84 μs/it)\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(sparse([6191, 6700, 6976, 7160, 7162, 7169, 7969, 8487, 8563, 8595  …  36936, 37907, 37908, 37909, 37910, 37911, 37912, 37913, 37914, 37915], [1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  1320150, 1320150, 1320150, 1320150, 1320150, 1320150, 1320150, 1320150, 1320150, 1320150], Float32[-0.86373305, 0.41021174, 0.13650393, -2.22978, -0.3714294, -0.5365475, -0.063417554, 0.44583693, 1.9406518, -0.9813562  …  1.0, 0.0067007863, 0.008389173, 0.79133856, 4.490054f-5, 7.037823f-5, 0.6262167, 0.08185833, 0.09159243, 0.88957214], 37915, 1320150), sparse(Int32[4265, 7422, 9367, 12640, 735, 1855, 3272, 7169, 8529, 8996  …  7256, 11088, 11411, 13248, 14253, 14325, 14568, 15162, 16351, 16829], [1, 1, 1, 1, 2, 2, 2, 2, 2, 2  …  1320150, 1320150, 1320150, 1320150, 1320150, 1320150, 1320150, 1320150, 1320150, 1320150], Float32[-0.3389134, 1.1170983, -1.0159798, -0.27521604, -1.1530313, -1.0277189, 1.0618806, 0.88071936, -0.302486, -3.8224938  …  -0.5345252, 0.19452278, 0.75691026, 0.62451655, 0.45544934, -1.8180276, 1.1493496, -0.89031065, -0.81876546, 0.11922366], 18953, 1320150))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X, Y = get_epoch(\"validation\")\n",
    "X2, Y2 = get_epoch(\"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "62229354-b71a-4b07-9ad3-0c60727c4429",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2.1703885f8, 11978.103f0, 2.1703885f8, 11978.102f0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(X), sum(Y), sum(X2), sum(Y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72f35efa-decd-42ed-bcae-f7ea7cab6a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_batch(X, Y, iter, batch_size)\n",
    "    range = (iter-1)*batch_size+1:min(iter * batch_size, size(X)[2])\n",
    "    [(collect(X[:, range]) |> device, collect(Y[:, range]) |> device)]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5406c13a-b4e4-4cad-9fa3-ba51e3e65b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function generate_model()\n",
    "    # inputs are the user's ratings for all shows (unseen shows get mapped to zero) + implicit ratings + heterogenous features\n",
    "    # outputs are the user's ratings for all shows (unseen shows get mapped to zero), implicit ratings\n",
    "    # we will train ratings using mse on observed shows, and implicit ratings via crossentropy loss\n",
    "    n_inputs = n_items + n_items + (derived_features ? 9 : 0)\n",
    "    encoder =\n",
    "        Chain(Dense(n_inputs, 512, relu), Dense(512, 256, relu), Dense(256, 128, relu))\n",
    "    decoder = Chain(Dense(128, 256, relu), Dense(256, 512, relu), Dense(512, n_items))\n",
    "    m = Chain(Dropout(dropout_perc), encoder, decoder) |> device\n",
    "    m |> device\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4988ea0-8a00-41f1-857f-6064ef3806a7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2068c6b4-911b-400d-89ca-f7971d8de0dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "loss (generic function with 1 method)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function rating_loss(ŷ, y)\n",
    "    # only compute loss on items the user has seen\n",
    "    # TODO try mult on gpu\n",
    "    mask = y .!= 0\n",
    "    mean((ŷ[mask] .- y[mask]) .^ 2)\n",
    "end\n",
    "\n",
    "implicit_loss(ŷ, y) = Flux.logitcrossentropy(ŷ, y)\n",
    "\n",
    "loss(m, x, y) = train_implicit_model ? implicit_loss(m(x), y) : rating_loss(m(x), y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68c3fe61-bc3c-4180-a5df-2507a6e8a664",
   "metadata": {},
   "outputs": [],
   "source": [
    "function reset_training()\n",
    "    global best_loss = Inf\n",
    "    global iteration = 0\n",
    "    global epoch = 0\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a7e91d19-5df7-40f9-a817-c206dd695a60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "get_validation_loss (generic function with 1 method)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_validation_loss(m)\n",
    "    X, Y = get_epoch(\"validation\")\n",
    "    losses = [0.0 for x = 1:Threads.nthreads()]\n",
    "    @tprogress Threads.@threads for iter = 1:Int(ceil(size(X)[2] / batch_size))\n",
    "        batch = get_batch(X, Y, iter, batch_size)\n",
    "        losses[Threads.threadid()] += loss(m, batch[1]...) * size(batch[1][1])[2]\n",
    "        #push!(losses[Threads.threadid()], loss(m, batch[1]...) * size(batch[1][1])[2])\n",
    "    end\n",
    "    #sum([sum(x) for x in losses]) / size(X)[2]\n",
    "    sum(losses) / size(X)[2]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "88faa942-b7fc-4e36-a320-6d9ddbba83df",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220416 05:26:37 The GPU function is being called but the GPU is not accessible. \n",
      "\u001b[38;5;6m\u001b[1m└ \u001b[22m\u001b[39mDefaulting back to the CPU. (No action is required if you want to run on the CPU).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dropout(0.5),\n",
       "  Chain(\n",
       "    Dense(37915 => 512, relu),          \u001b[90m# 19_412_992 parameters\u001b[39m\n",
       "    Dense(512 => 256, relu),            \u001b[90m# 131_328 parameters\u001b[39m\n",
       "    Dense(256 => 128, relu),            \u001b[90m# 32_896 parameters\u001b[39m\n",
       "  ),\n",
       "  Chain(\n",
       "    Dense(128 => 256, relu),            \u001b[90m# 33_024 parameters\u001b[39m\n",
       "    Dense(256 => 512, relu),            \u001b[90m# 131_584 parameters\u001b[39m\n",
       "    Dense(512 => 18953),                \u001b[90m# 9_722_889 parameters\u001b[39m\n",
       "  ),\n",
       ") \u001b[90m                  # Total: 12 arrays, \u001b[39m29_464_713 parameters, 112.400 MiB."
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = generate_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "50241a9e-ae41-4468-8c08-c2f65c069bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:05 ( 1.88 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:07 ( 1.77 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:05 ( 1.86 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:01:24 ( 0.40  s/it)\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.7429431451821251"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_validation_loss(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba59ee9a-698f-485a-90d2-6e64d9b58966",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:06 ( 1.94 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:07 ( 1.78 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:05 ( 1.87 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:01:19 ( 0.37  s/it)\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.743045823037595"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_validation_loss(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5c652208-866c-48d8-991d-fcb06cfd0cd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:06 ( 1.99 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:07 ( 1.78 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:06 ( 1.93 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:01:25 ( 0.40  s/it)\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.7431525926388056"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_validation_loss(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dd02cc13-2680-4297-a746-784faaba3a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "function continue_training(m)\n",
    "    validation_loss = get_validation_loss(m)\n",
    "    @info \"Epoch $epoch, loss $validation_loss, best_loss $best_loss\"\n",
    "    if validation_loss < best_loss\n",
    "        global best_loss = validation_loss\n",
    "        BSON.@save \"../../data/alphas/$name/model.$(model_name).bson\" m\n",
    "        return true\n",
    "    else\n",
    "        return false\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4ade3b7-52e5-4b22-9337-694708eb76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_model(model_name, seed)\n",
    "    # create model\n",
    "    Random.seed!(seed)\n",
    "    m = generate_model()\n",
    "    ps = Flux.params(m)\n",
    "    #BLAS.set_num_threads(Threads.nthreads())\n",
    "    BLAS.set_num_threads(1)\n",
    "\n",
    "\n",
    "    # setup optimizer\n",
    "    reset_training()\n",
    "    function evalcb()\n",
    "        @info \"Epoch $epoch, Iteration $iteration\"\n",
    "    end\n",
    "    throttled_cb = Flux.throttle(evalcb, 60)\n",
    "    if optimizer == \"ADAM\"\n",
    "        opt = ADAMW(learning_rate, (0.9, 0.999), l2penalty)\n",
    "    end\n",
    "    training_loss(x, y) = loss(m, x, y)\n",
    "\n",
    "    # Train model\n",
    "    while continue_training(m)\n",
    "        X, Y = get_epoch(\"training\")\n",
    "        for iter = 1:Int(ceil(size(X)[2] / batch_size))\n",
    "            batch = get_batch(X, Y, iter, batch_size)\n",
    "            Flux.train!(training_loss, ps, batch, opt)\n",
    "            global iteration += 1\n",
    "            throttled_cb()\n",
    "        end\n",
    "        global epoch += 1\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2041bd59-f665-456c-a97a-f605d9c2cf84",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name = name\n",
    "seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "43991795-7e13-4891-9c1e-aeddff512ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 45 with single threaded\n",
    "# 55 while multi-threaded (32 openblas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bf6aeb7-a78f-4c75-a308-2d6a16e1f0c4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:06 ( 1.92 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:07 ( 1.78 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:05 ( 1.86 μs/it)\u001b[39m\n",
      "\u001b[32mProgress:  51%|█████████████▉             |  ETA: 0:00:39 ( 0.37  s/it)\u001b[39m"
     ]
    }
   ],
   "source": [
    "train_model(model_name, seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdd719b-7f8b-491e-bafa-8aa56a9545e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Write predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af0b836-f8dd-4a6d-b9d1-c20f1d518bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "function gmodel(m, users, items)\n",
    "    # index users\n",
    "    user_to_output_idxs = [Dict() for t = 1:Threads.nthreads()]\n",
    "    @tprogress Threads.@threads for j = 1:length(users)\n",
    "        u = users[j]\n",
    "        t = Threads.threadid()\n",
    "        if u ∉ keys(user_to_output_idxs[t])\n",
    "            user_to_output_idxs[t][u] = []\n",
    "        end\n",
    "        push!(user_to_output_idxs[t][u], j)\n",
    "    end\n",
    "    user_to_output_idxs = merge(vcat, user_to_output_idxs...)\n",
    "\n",
    "    # allocate outputs\n",
    "    ratings = zeros(Float32, length(users))\n",
    "\n",
    "    # split users into mini-batches\n",
    "    deduped_users = collect(Set(users))\n",
    "    batch(arr, n) = [arr[i:min(i + n - 1, end)] for i = 1:n:length(arr)]\n",
    "    batches = batch(deduped_users, 128)\n",
    "\n",
    "    # compute predictions\n",
    "    @tprogress Threads.@threads for i = 1:length(batches)\n",
    "        b = batches[i]\n",
    "        user_to_input_idx = Dict(zip(b, 1:length(b)))\n",
    "        alpha = m(get_batch(b)) |> cpu\n",
    "        if train_implicit_model\n",
    "            alpha .= exp.(alpha)\n",
    "            alpha .= alpha ./ sum(alpha, dims = 1)\n",
    "        end\n",
    "\n",
    "        for u in b\n",
    "            input_idx = user_to_input_idx[u]\n",
    "            for output_idx in user_to_output_idxs[u]\n",
    "                ratings[output_idx] = alpha[items[output_idx], input_idx]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    ratings\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9327642b-9991-44d5-ab0c-7ce6033d461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_prediction(sparse_preds, users, items)\n",
    "    preds = zeros(length(users))\n",
    "    @tprogress Threads.@threads for j = 1:length(preds)\n",
    "        preds[j] = sparse_preds[users[j], items[j]]\n",
    "    end\n",
    "    preds\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d999f4-f2b4-4d71-944b-754aead7de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "function save_model(params)\n",
    "    BSON.@load params[\"model\"] m\n",
    "    testmode!(m)\n",
    "    BLAS.set_num_threads(1) # gmodel already multithreads\n",
    "\n",
    "    full_df = reduce(cat, [training, validation, get_split(\"test\")])\n",
    "    ratings = gmodel(m, full_df.user, full_df.item)\n",
    "    sparse_preds = sparse(full_df.user, full_df.item, ratings)\n",
    "\n",
    "    write_params(params, outdir = params[\"name\"])\n",
    "    write_predictions(\n",
    "        (users, items) -> make_prediction(sparse_preds, users, items),\n",
    "        residual_alphas = validation_residuals,\n",
    "        outdir = params[\"name\"],\n",
    "        implicit = train_implicit_model,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26b887e-756b-440e-bbd6-b2842fd184b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function fit(num_seeds, start = 1)\n",
    "#     seeds = hash.(rand(Int, num_seeds))\n",
    "#     for i = start:length(seeds)\n",
    "#         save_model(train_model(i, seeds[i]))\n",
    "#     end\n",
    "# end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3758ece-9b72-47b4-ae6a-aa364e0443e3",
   "metadata": {},
   "source": [
    "# Generalized Neural Network\n",
    "* A denoising autoencoder that learns the user's ratings and implicit ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54170f91-c85c-4207-9939-572cad4db024",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "import BSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17593ac-3260-4c01-a5df-91edfcd17e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "using NBInclude\n",
    "@nbinclude(\"Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08801fd4-7057-49f0-9fa7-9854d17494cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = gpu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede3b9a1-1dc8-4b10-aab0-03ceb5d27be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(20220313 * hash(name));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638f2e93-80aa-4d4f-90ee-d70e3610cd13",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f724408-2a16-4d0d-adb3-9a1ddbe283bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "const training = get_residuals(\"training\", residual_alphas)\n",
    "const validation = get_residuals(\"validation\", residual_alphas)\n",
    "const implicit_training = get_split(\"implicit_training\")\n",
    "const n_items = num_items() + 1 # leave room to map unseen items\n",
    "const n_users = maximum(training.user) + 1; # leave room to map unseen users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb458301-7baa-4bd1-88c1-bd8c9193bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column accesses are faster than row accesses, so we make this an (item, user) matrix \n",
    "const R = sparse(training.item, training.user, training.rating, n_items, n_users)\n",
    "const Ri = sparse(\n",
    "    implicit_training.item,\n",
    "    implicit_training.user,\n",
    "    implicit_training.rating,\n",
    "    n_items,\n",
    "    n_users,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70c5c8ef-5e23-4ea7-af03-3030ec54f4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "const dropout_perc = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cad5b01-a2a1-48a8-8eef-954062f7d630",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_rating_sum(split)\n",
    "    counts = zeros(Float32, n_users, Threads.nthreads())\n",
    "    @tprogress Threads.@threads for i = 1:length(split.rating)\n",
    "        counts[split.user[i], Threads.threadid()] += split.rating[i]\n",
    "    end\n",
    "    counts = sum(counts, dims = 2)\n",
    "    counts\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebdee68-2760-434e-bb32-3ceb59dd04f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "const implicit_counts = get_rating_sum(implicit_training)\n",
    "const rating_counts = get_rating_sum(\n",
    "    RatingsDataset(\n",
    "        training.user,\n",
    "        training.item,\n",
    "        fill(one(eltype(training.rating)), length(training.rating)),\n",
    "    ),\n",
    ")\n",
    "const rating_sum = get_rating_sum(get_split(\"training\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd21001b-3626-4bf2-82aa-ba04ba89df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_data(split, j, train)\n",
    "    # inputs are the user's ratings (unseen shows get mapped to zero) + implicit ratings + heterogenous features\n",
    "    #     we randomly hold out one item from the input and apply dropout to the rest\n",
    "    # during training, outputs are the user's ratings\n",
    "    # during inference, outputs are the user's rating for the held out item\n",
    "\n",
    "    # handle users and items that aren't in the training set\n",
    "    u = min(split.user[j], n_users)\n",
    "    i = min(split.item[j], n_items)\n",
    "    held_out = R[i, u] != 0\n",
    "\n",
    "    # ratings\n",
    "    X1 = collect(R[:, u])\n",
    "    X1[i] = 0\n",
    "    # implicit ratings\n",
    "    X2 = collect(Ri[:, u])\n",
    "    X2[i] = 0\n",
    "    # heterogeneous features\n",
    "    features = [\n",
    "        max(implicit_counts[u] - held_out, 0) / n_items, # fraction of items seen\n",
    "        max(rating_counts[u] - held_out, 0) / n_items,  # fraction of items rated\n",
    "        (rating_sum[u] - R[i, u]) / max(rating_counts[u] - held_out, 1) / 10, # average rating\n",
    "    ]\n",
    "    features = convert.(Float32, features)\n",
    "    X3 = vcat(features, features .^ 2, sqrt.(features))\n",
    "\n",
    "    X = vcat(X1, X2, X3)\n",
    "\n",
    "    # outputs\n",
    "    Y = zeros(eltype(X1), length(X1))\n",
    "    if train\n",
    "        mask = X2 .!= 0\n",
    "        if train_implicit_model\n",
    "            Y[mask] .= 1\n",
    "        else\n",
    "            Y[mask] .= X1[mask]\n",
    "        end\n",
    "    else\n",
    "        if train_implicit_model\n",
    "            Y[i] = 1\n",
    "        else\n",
    "            Y[i] = split.rating[j]\n",
    "        end\n",
    "    end\n",
    "\n",
    "    (X, Y)\n",
    "end\n",
    "\n",
    "function get_batch(split, block_size, train)\n",
    "    idxs = rand(1:length(split.rating), block_size)\n",
    "    data = [[] for j = 1:Threads.nthreads()]\n",
    "    Threads.@threads for i = 1:length(idxs)\n",
    "        push!(data[Threads.threadid()], get_data(split, idxs[i], train))\n",
    "    end\n",
    "    X = Flux.batch([data[t][i][1] for t = 1:Threads.nthreads() for i = 1:length(data[t])])\n",
    "    Y = Flux.batch([data[t][i][2] for t = 1:Threads.nthreads() for i = 1:length(data[t])])\n",
    "    [(X, Y)] |> device\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5406c13a-b4e4-4cad-9fa3-ba51e3e65b3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function generate_model()\n",
    "    # inputs are the user's ratings for all shows (unseen shows get mapped to zero) + implicit ratings + heterogenous features\n",
    "    # outputs are the user's ratings for all shows (unseen shows get mapped to zero), implicit ratings\n",
    "    # we will train ratings using mse on observed shows, and implicit ratings via crossentropy loss\n",
    "    encoder = Chain(\n",
    "        Dense(n_items + n_items + 9, 512, relu),\n",
    "        Dense(512, 256, relu),\n",
    "        Dense(256, 128, relu),\n",
    "    )\n",
    "    decoder =\n",
    "        Chain(Dense(128, 256, relu), Dense(256, 512, relu), Dense(512, n_items))\n",
    "    m = Chain(Dropout(dropout_perc), encoder, decoder) |> device\n",
    "    m\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4988ea0-8a00-41f1-857f-6064ef3806a7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2068c6b4-911b-400d-89ca-f7971d8de0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "function rating_loss(ŷ, y)\n",
    "    # only compute loss on items the user has seen\n",
    "    mask = y .!= 0\n",
    "    Flux.mse(ŷ[mask], y[mask])\n",
    "end\n",
    "\n",
    "implicit_loss(ŷ, y) = Flux.logitcrossentropy(ŷ, y)\n",
    "\n",
    "function loss_components(m, x, y)\n",
    "    ŷ = m(x)\n",
    "    if train_implicit_model\n",
    "        return implicit_loss(ŷ, y)\n",
    "    else\n",
    "        return rating_loss(ŷ, y)\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d99b66-1951-42d5-9922-e02785ad1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "function reset_training()\n",
    "    global best_loss = Inf\n",
    "    global patience = 30\n",
    "    global smoothing = 0.9\n",
    "    global smoothing_loss = Inf\n",
    "    global iters_without_improvement = 0\n",
    "    global min_improvement = 1e-4\n",
    "    global continue_training = true\n",
    "    global iters = 0\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0397c765-0d9c-44b5-bd7c-60cc9ed44d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_model(model_name, seed)\n",
    "    Random.seed!(seed)\n",
    "    m = generate_model()\n",
    "    ps = Flux.params(m)\n",
    "    reset_training()\n",
    "    BLAS.set_num_threads(Threads.nthreads())\n",
    "\n",
    "    # Setup early stopping callbacks\n",
    "    function evalcb(split, train, epochs)\n",
    "        losses = []\n",
    "        @showprogress for epoch = 1:epochs\n",
    "            push!(losses, loss_components(m, get_batch(split, 128, train)[1]...))\n",
    "        end\n",
    "        reduce(.+, losses) ./ length(losses)\n",
    "    end\n",
    "\n",
    "    function evalcb()\n",
    "        # print losses and perform early stopping\n",
    "        testmode!(m)\n",
    "        @debug \"iteration: $iters\"\n",
    "        training_losses = evalcb(training, true, 100) \n",
    "        training_loss = sum(training_losses ./ training_baseline_loss)\n",
    "        @debug \"training losses: $(training_losses) -> $(training_loss)\"\n",
    "        inference_losses = evalcb(validation, false, 500)\n",
    "        inference_loss = sum(inference_losses ./ inference_baseline_loss)\n",
    "        if smoothing_loss == Inf\n",
    "            global smoothing_loss = inference_loss\n",
    "        else\n",
    "            global smoothing_loss = smoothing * smoothing_loss + (1 - smoothing) * inference_loss\n",
    "        end\n",
    "        inference_loss = smoothing_loss\n",
    "        @debug \"validation losses: $(inference_losses) -> $(inference_loss)\"\n",
    "        if inference_loss + min_improvement < best_loss\n",
    "            global best_loss = inference_loss\n",
    "            global iters_without_improvement = 0\n",
    "            BSON.@save \"../../data/alphas/$name/model.$(model_name).bson\" m\n",
    "        else\n",
    "            global iters_without_improvement += 1\n",
    "            if iters_without_improvement >= patience\n",
    "                global continue_training = false\n",
    "            end\n",
    "        end\n",
    "        trainmode!(m)\n",
    "    end\n",
    "\n",
    "    # Setup loss\n",
    "    training_baseline_loss = evalcb(training, true, 1000)\n",
    "    inference_baseline_loss = evalcb(validation, false, 1000)  \n",
    "    throttled_cb = Flux.throttle(evalcb, 600)\n",
    "    opt = ADAM(0.001, (0.9, 0.999), 1e-5)\n",
    "\n",
    "    function loss(x, y)\n",
    "        loss_components(m, x, y) / training_baseline_loss\n",
    "    end\n",
    "\n",
    "    # Train model\n",
    "    while continue_training\n",
    "        batch = get_batch(training, 128, true)\n",
    "        Flux.train!(loss, ps, batch, opt, cb = throttled_cb)\n",
    "        global iters += 1\n",
    "    end\n",
    "\n",
    "    Dict(\n",
    "        \"name\" => \"$name.$model_name\",\n",
    "        \"loss\" => best_loss,\n",
    "        \"patience\" => patience,\n",
    "        \"iters\" => iters,\n",
    "        \"model\" => \"../../data/alphas/$name/model.$(model_name).bson\",\n",
    "        \"residual_alphas\" => residual_alphas,\n",
    "        \"seed\" => seed,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdd719b-7f8b-491e-bafa-8aa56a9545e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Write predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceec8522-af45-44ab-a398-afba5f255efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_data(u)\n",
    "    # ratings\n",
    "    X1 = collect(R[:, u])\n",
    "    # implicit ratings\n",
    "    X2 = collect(Ri[:, u])\n",
    "    # heterogeneous features\n",
    "    features = [\n",
    "        implicit_counts[u] / n_items, # fraction of items seen\n",
    "        rating_counts[u] / n_items,  # fraction of items rated\n",
    "        rating_sum[u] / max(rating_counts[u], 1) / 10, # average rating\n",
    "    ]\n",
    "    features = convert.(Float32, features)\n",
    "    X3 = vcat(features, features .^ 2, sqrt.(features))\n",
    "    vcat(X1, X2, X3)\n",
    "end\n",
    "\n",
    "function get_batch(users)\n",
    "    data = [[] for j = 1:Threads.nthreads()]\n",
    "    Threads.@threads for i = 1:length(users)\n",
    "        push!(data[Threads.threadid()], get_data(users[i]))\n",
    "    end\n",
    "    X = Flux.batch([data[t][i] for t = 1:Threads.nthreads() for i = 1:length(data[t])])\n",
    "    X |> device\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3af0b836-f8dd-4a6d-b9d1-c20f1d518bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "function gmodel(m, users, items)\n",
    "    # index users\n",
    "    user_to_output_idxs = [Dict() for t = 1:Threads.nthreads()]\n",
    "    @tprogress Threads.@threads for j = 1:length(users)\n",
    "        u = users[j]\n",
    "        t = Threads.threadid()\n",
    "        if u ∉ keys(user_to_output_idxs[t])\n",
    "            user_to_output_idxs[t][u] = []\n",
    "        end\n",
    "        push!(user_to_output_idxs[t][u], j)\n",
    "    end\n",
    "    user_to_output_idxs = merge(vcat, user_to_output_idxs...)\n",
    "\n",
    "    # allocate outputs\n",
    "    ratings = zeros(Float32, length(users))\n",
    "\n",
    "    # split users into mini-batches\n",
    "    deduped_users = collect(Set(users))\n",
    "    batch(arr, n) = [arr[i:min(i + n - 1, end)] for i = 1:n:length(arr)]\n",
    "    batches = batch(deduped_users, 128)\n",
    "\n",
    "    # compute predictions\n",
    "    @tprogress Threads.@threads for i = 1:length(batches)\n",
    "        b = batches[i]\n",
    "        user_to_input_idx = Dict(zip(b, 1:length(b)))\n",
    "        alpha = m(get_batch(b)) |> cpu\n",
    "        if train_implicit_model\n",
    "            alpha .= exp.(alpha)\n",
    "            alpha .= alpha ./ sum(alpha, dims = 1)\n",
    "        end\n",
    "\n",
    "        for u in b\n",
    "            input_idx = user_to_input_idx[u]\n",
    "            for output_idx in user_to_output_idxs[u]\n",
    "                ratings[output_idx] = alpha[items[output_idx], input_idx]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    ratings\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9327642b-9991-44d5-ab0c-7ce6033d461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_prediction(sparse_preds, users, items)\n",
    "    preds = zeros(length(users))\n",
    "    @tprogress Threads.@threads for j = 1:length(preds)\n",
    "        preds[j] = sparse_preds[users[j], items[j]]\n",
    "    end\n",
    "    preds\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d999f4-f2b4-4d71-944b-754aead7de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "function save_model(params)\n",
    "    BSON.@load params[\"model\"] m\n",
    "    testmode!(m)\n",
    "    BLAS.set_num_threads(1) # gmodel already multithreads\n",
    "\n",
    "    full_df = reduce(cat, [training, validation, get_residuals(\"test\", residual_alphas)])\n",
    "    ratings = gmodel(m, full_df.user, full_df.item)\n",
    "    sparse_preds = sparse(full_df.user, full_df.item, ratings)\n",
    "\n",
    "    write_params(params, outdir = params[\"name\"])\n",
    "    write_predictions(\n",
    "        (users, items) -> make_prediction(sparse_preds, users, items),\n",
    "        residual_alphas = residual_alphas,\n",
    "        outdir = params[\"name\"],\n",
    "        implicit = train_implicit_model,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26b887e-756b-440e-bbd6-b2842fd184b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "function fit(num_seeds, start=1)\n",
    "    seeds = hash.(rand(Int, num_seeds))\n",
    "    for i in start:length(seeds)\n",
    "        save_model(train_model(i, seeds[i]))\n",
    "    end;\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

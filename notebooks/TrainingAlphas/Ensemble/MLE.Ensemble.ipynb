{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# Ranking\n",
    "* This is trained to learn the partial ordering implied by each user's watches\n",
    "* Items that are watched are preferred to items that have not been watched\n",
    "* If two items have been watched, then the impression metadata determines\n",
    "  which one, if any, is liked more\n",
    "* It uses the position aware maximum likehood estimation loss  \n",
    "* The inputs to this model are features generated by other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"MLE.Base.ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251beacd-fc32-41cf-8554-0257172239dc",
   "metadata": {},
   "source": [
    "## Define Subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f7e3e1-4486-47ff-8a45-bdc4108724bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@with_kw struct EnsembleFeatures <: Features\n",
    "    user_features::SparseMatrixCSC{Float32,Int32}\n",
    "    query_features::Matrix{Float32}\n",
    "    preprocessing_data::Dict\n",
    "\n",
    "    priorities::Matrix{Float16}\n",
    "\n",
    "    index_to_item::Vector{Int32}\n",
    "    user_to_indexes::Dict{Int32,Vector{Int32}}\n",
    "    item_user_index::SparseMatrixCSC{Int32,Int32}\n",
    "end\n",
    "\n",
    "function get_inference_data(f::Features)\n",
    "    f.preprocessing_data\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb2021e-a39a-498c-96a5-86f8604b1a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_query_features(alphas::Vector{String}, split::String, content::String)\n",
    "    @info \"getting $split $content alphas\"\n",
    "    df = get_raw_split(split, content)\n",
    "    T = Float16\n",
    "    A = Matrix{T}(undef, length(df.user), length(alphas))\n",
    "    @tprogress Threads.@threads for i = 1:length(alphas)\n",
    "        A[:, i] = convert.(T, read_raw_alpha(alphas[i], split, content).rating)\n",
    "    end\n",
    "    collect(A')\n",
    "end;\n",
    "\n",
    "function normalize(x::AbstractArray; dims = 1)\n",
    "    T = eltype(x)\n",
    "    x = convert.(Float32, x)\n",
    "    μ = mean(x, dims = dims)\n",
    "    σ = std(x, dims = dims, mean = μ, corrected = false)\n",
    "    convert.(T, (x .- μ) ./ σ), Dict(\"μ\" => μ, \"σ\" => σ)\n",
    "end\n",
    "\n",
    "function get_implicit_features()\n",
    "    df = get_split(\"training\", \"implicit\")\n",
    "    sparse(df.item, df.user, df.rating, num_items(), num_users())\n",
    "end\n",
    "\n",
    "function get_explicit_features()\n",
    "    df = get_split(\"training\", \"explicit\")\n",
    "    sparse(df.item, df.user, df.rating, num_items(), num_users())\n",
    "end\n",
    "\n",
    "function get_user_features()\n",
    "    vcat(get_implicit_features(), get_explicit_features())\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041526a7-4e69-429e-a594-e04958619e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_features(alphas::Vector{String})\n",
    "    contents = all_contents\n",
    "    splits = [\"test\"]\n",
    "\n",
    "    user_to_indexes = get_user_to_indexes(\n",
    "        [(split, content) for split in splits for content in contents],\n",
    "        (split, content) -> true,\n",
    "    )\n",
    "\n",
    "    hreduce(f; agg = hcat) =\n",
    "        reduce(agg, f(split, content) for split in splits for content in contents)\n",
    "    user_features = get_user_features()\n",
    "    query_features, preprocessing_data = normalize(\n",
    "        hreduce((split, content) -> get_query_features(alphas, split, content));\n",
    "        dims = 2,\n",
    "    )\n",
    "    query_features = convert.(Float32, query_features)\n",
    "    priorities = hreduce(get_priorities)\n",
    "    index_to_item =\n",
    "        hreduce((split, content) -> get_raw_split(split, content).item; agg = vcat)\n",
    "\n",
    "    item_user_index = sparse(Int32[], Int32[], Int32[], num_items(), num_users())\n",
    "    idx = 1\n",
    "    for split in splits\n",
    "        for content in contents\n",
    "            df = get_raw_split(split, content)\n",
    "            sp =\n",
    "                sparse(df.item, df.user, fill(1, length(df.item)), num_items(), num_users())\n",
    "            @tprogress Threads.@threads for i = 1:length(df.item)\n",
    "                sp[df.item[i], df.user[i]] = i + (idx - 1)\n",
    "            end\n",
    "            item_user_index += sp\n",
    "            idx += length(df.item)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    EnsembleFeatures(\n",
    "        user_features = user_features,\n",
    "        query_features = query_features,\n",
    "        preprocessing_data = preprocessing_data,\n",
    "        priorities = priorities,\n",
    "        index_to_item = index_to_item,\n",
    "        user_to_indexes = user_to_indexes,\n",
    "        item_user_index = item_user_index,\n",
    "    )\n",
    "end\n",
    "\n",
    "function get_user_embedding(u::Integer, f::Features)\n",
    "    f.user_features[:, u]\n",
    "end\n",
    "\n",
    "function get_item_embedding(q::Integer, f::Features)\n",
    "    f.index_to_item[q]\n",
    "end;\n",
    "\n",
    "function get_query_embedding(q::Integer, f::Features)\n",
    "    f.query_features[:, q]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7128e537-8c3f-42fe-8a2a-3ff888b32db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_sample(f::Features, training::Bool, list_size::Integer)\n",
    "    max_training_user = Int(floor(num_users() * 0.9))\n",
    "    if training\n",
    "        user_range = Int32(1):Int32(max_training_user)\n",
    "    else\n",
    "        user_range = Int32(max_training_user + 1):Int32(num_users())\n",
    "    end\n",
    "\n",
    "    while true\n",
    "        # sample a random user\n",
    "        u = rand(user_range)\n",
    "        if u ∉ keys(f.user_to_indexes)\n",
    "            continue\n",
    "        end\n",
    "        idxs = f.user_to_indexes[u]\n",
    "        if length(idxs) < list_size\n",
    "            continue\n",
    "        end\n",
    "        # sample random items for the user\n",
    "        list = sample(idxs, list_size; replace = false)\n",
    "        if all(f.priorities[1, i] == 0 for i in list)\n",
    "            # need atleast one positive example to train on\n",
    "            continue\n",
    "        end\n",
    "        prefs =\n",
    "            get_preferences(list, (i, j) -> compare(f.priorities[:, i], f.priorities[:, j]))\n",
    "        # batch the input features  \n",
    "        u_embs = hcat(fill(get_user_embedding(u, f), list_size)...)\n",
    "        a_embs = Int32[get_item_embedding(q, f) for q in list]\n",
    "        q_embs = hcat((get_query_embedding(q, f) for q in list)...)\n",
    "        return u_embs, a_embs, q_embs, prefs\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be8534e-28c5-4dfe-8ee5-780c0938e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_batch(\n",
    "    f::Features,\n",
    "    training::Bool,\n",
    "    list_size::Integer,\n",
    "    batch_size::Integer,\n",
    "    holdout::Float32,\n",
    ")\n",
    "    u_embs = SparseMatrixCSC{Float32,Int32}[]\n",
    "    a_embs = Vector{Int32}[]\n",
    "    q_embs = Matrix{Float32}[]\n",
    "    prefs = Matrix{Int32}[]\n",
    "    for _ = 1:batch_size\n",
    "        u_emb, a_emb, q_emb, pref = get_sample(f, training, list_size)\n",
    "        push!(u_embs, u_emb)\n",
    "        push!(a_embs, a_emb)\n",
    "        push!(q_embs, q_emb)\n",
    "        push!(prefs, pref)\n",
    "    end\n",
    "\n",
    "    # move to GPU\n",
    "    U = device(hcat(u_embs...))\n",
    "    A = device(hcat(a_embs...))\n",
    "    Q = device(Flux.batch(q_embs))\n",
    "    P = device(Flux.batch(prefs))\n",
    "    tsize = (size(U)[1], size(U)[2] ÷ batch_size, batch_size)\n",
    "    if training\n",
    "        randfn = CUDA.functional() ? CUDA.rand : rand\n",
    "        mask = randfn(num_items()) .>= holdout\n",
    "        U .*= repeat(mask, size(U)[1] ÷ size(mask)[1])\n",
    "    end\n",
    "    (reshape(U, tsize), A, Q), P\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0986b43e-f425-4b0a-b971-6b14da745bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function build_model(hyp::Hyperparams)\n",
    "    K = hyp.embedding_size\n",
    "    Chain(\n",
    "        Join(\n",
    "            vcat,\n",
    "            Dense((num_items()) * 2 => K),\n",
    "            Embedding((num_items()) => K; init = Flux.glorot_uniform),\n",
    "            identity,\n",
    "        ),\n",
    "        Dense(K * 2 + length(hyp.alphas), K, relu),\n",
    "        Dense(K => K ÷ 2, relu),\n",
    "        Dense(K ÷ 2, 1),\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b136e77e-c674-4ee7-99d2-803ec985200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function inference_model(\n",
    "    hyp::Hyperparams,\n",
    "    f::Features,\n",
    "    split::String,\n",
    "    content::String;\n",
    "    raw_splits = true,\n",
    ")\n",
    "    @info \"making predictions for $split $content\"\n",
    "\n",
    "    if raw_splits\n",
    "        df = get_raw_split(split, content)\n",
    "    else\n",
    "        df = get_split(split, content)\n",
    "    end\n",
    "    if split in [\"training\", \"validation\"]\n",
    "        return zeros(Float32, length(df.item))\n",
    "    end\n",
    "\n",
    "    output = Array{Float32}(undef, length(df.item))\n",
    "    @showprogress for batch in\n",
    "                      collect(Iterators.partition(1:length(df.item), hyp.batch_size))\n",
    "        u_embs = SparseVector{Float32,Int32}[]\n",
    "        a_embs = Int32[]\n",
    "        q_embs = Vector{Float32}[]\n",
    "        for i in batch\n",
    "            push!(u_embs, get_user_embedding(df.user[i], f))\n",
    "            push!(a_embs, df.item[i])\n",
    "            push!(q_embs, get_query_embedding(f.item_user_index[df.item[i], df.user[i]], f))\n",
    "        end\n",
    "        U, A, Q = device(hcat(u_embs...)), device(a_embs), device(hcat(q_embs...))\n",
    "        output[batch] .= cpu(vec(m((U, A, Q))))\n",
    "    end\n",
    "    output\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a616677-313b-4e3b-847d-662c703dd666",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d6135b-e053-47c4-8533-ba217f79cf0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function get_alphas(allow_ptw::Bool)\n",
    "    alphas = [\n",
    "        \"LinearExplicit\"\n",
    "        \"LinearImplicit\"\n",
    "        \"Explicit\"\n",
    "        \"NonlinearImplicit\"\n",
    "        explicit_raw_alphas\n",
    "        implicit_raw_alphas\n",
    "        nondirectional_raw_alphas\n",
    "    ]\n",
    "    if allow_ptw\n",
    "        alphas = vcat(\n",
    "            alphas,\n",
    "            [\n",
    "                \"LinearPtw\"\n",
    "                \"NonlinearPtw\"\n",
    "                ptw_raw_alphas\n",
    "            ],\n",
    "        )\n",
    "    end\n",
    "    alphas\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376e6681-572c-41a9-9b4e-08088b2bb6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp = Hyperparams(\n",
    "    alphas = [],\n",
    "    batch_size = 1024,\n",
    "    embedding_size = 256,\n",
    "    holdout = NaN,\n",
    "    l2penalty = NaN,\n",
    "    learning_rate = NaN,\n",
    "    list_size = 16,\n",
    "    seed = 20220609,\n",
    ")\n",
    "hyp = @set hyp.alphas = get_alphas(false)\n",
    "hyp = create_hyperparams(hyp, [0.0f0, 0.0f0, 0.0f0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248d034a-3777-4530-96ad-8fe07f8bceaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_alpha(hyp, \"MLE.Ensemble\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b4c07c1-a6a0-4161-adc0-bf53ae5c54ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1.304526987566872 with alphas = [\"MLE.Training\"]\n",
    "# 1.1126399600829462 with all non-ptw alphas"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

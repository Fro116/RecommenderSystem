{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# Ranking\n",
    "* This is trained to learn the partial ordering implied by each user's watches\n",
    "* Items that are watched are preferred to items that have not been watched\n",
    "* If two items have been watched, then the impression metadata determines\n",
    "  which one, if any, is liked more\n",
    "* It uses the position aware maximum likehood estimation loss  \n",
    "* The inputs to this model are features generated by other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5781704c-40c0-48ca-8563-6e6e2d7ae045",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "task = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import NBInclude: @nbinclude\n",
    "import Statistics: quantile\n",
    "@nbinclude(\"MLE.Base.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f7e3e1-4486-47ff-8a45-bdc4108724bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@with_kw struct EnsembleFeatures <: Features\n",
    "    query_features::Matrix{Float32}\n",
    "    preprocessing_data::Dict\n",
    "    priorities::Matrix{Float16}\n",
    "    index_to_item::Vector{Int32}\n",
    "    user_to_indexes::Dict{Int32,Vector{Int32}}\n",
    "    item_user_index::SparseMatrixCSC{Int32,Int32}\n",
    "    user_to_watched_indexes::Dict{Int32,Vector{Int32}}\n",
    "end\n",
    "\n",
    "function get_inference_data(f::Features)\n",
    "    f.preprocessing_data\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb2021e-a39a-498c-96a5-86f8604b1a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_query_features(\n",
    "    alphas::Vector{String},\n",
    "    split::String,\n",
    "    task::String,\n",
    "    content::String,\n",
    ")\n",
    "    @info \"getting $split $content alphas\"\n",
    "    df = get_raw_split(split, task, content)\n",
    "    T = Float16\n",
    "    A = Matrix{T}(undef, length(df.user), length(alphas))\n",
    "    @tprogress Threads.@threads for i = 1:length(alphas)\n",
    "        if occursin(\"NonlinearImplicit\", alphas[i])\n",
    "            transform = identity\n",
    "        elseif occursin(\"ItemCount\", alphas[i])\n",
    "            transform = x -> log(x + 1)\n",
    "        elseif occursin(\"Variance\", alphas[i]) || occursin(\"implicit\", lowercase(alphas[i]))\n",
    "            transform = x -> log(x + Float32(eps(Float64)))\n",
    "        else\n",
    "            transform = identity\n",
    "        end\n",
    "        A[:, i] =\n",
    "            transform.(convert.(T, read_raw_alpha(alphas[i], split, task, content).rating))\n",
    "    end\n",
    "    collect(A')\n",
    "end;\n",
    "\n",
    "function normalize!(x::AbstractArray; clip_std = 3)\n",
    "    T = eltype(x)\n",
    "    N = size(x)[1]\n",
    "    μ = zeros(Float32, N)\n",
    "    σ = ones(Float32, N)\n",
    "    for i = 1:N\n",
    "        y = convert.(Float32, x[i, :])\n",
    "        if all((y .>= 0) .&& (y .<= 1))\n",
    "            # the parameter is uniformly scaled\n",
    "            μ[i] = mean(y)\n",
    "            σ[i] = 1\n",
    "        else\n",
    "            μ[i] = mean(y)\n",
    "            σ[i] = std(y, mean = μ[i], corrected = false)\n",
    "        end\n",
    "        q = (y .- μ[i]) ./ σ[i]\n",
    "        @info \"normalization metrics for alpha $i: $(μ[i]), $(σ[i]), $(minimum(q)), \" *\n",
    "              \"$(quantile(q, 0.1)), $(quantile(q, 0.9)), $(maximum(q))\"\n",
    "        if (abs(maximum(q)) > clip_std) || (abs(minimum(q)) > clip_std)\n",
    "            @info \"clipping values to [-$clip_std, $clip_std]\"\n",
    "        end\n",
    "        x[i, :] = convert.(T, (x[i, :] .- μ[i]) ./ σ[i])\n",
    "    end\n",
    "    clamp!(x, -clip_std, clip_std)\n",
    "    x, Dict(\"μ\" => μ, \"σ\" => σ, \"clip_std\" => clip_std)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041526a7-4e69-429e-a594-e04958619e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_features(alphas::Vector{String}, task::String)\n",
    "    @info \"using alphas $alphas\"\n",
    "    contents = ALL_CONTENTS\n",
    "    splits = [\"test\"]\n",
    "\n",
    "    hreduce(f; agg = hcat) =\n",
    "        reduce(agg, f(split, task, content) for split in splits for content in contents)\n",
    "    query_features, preprocessing_data = normalize!(\n",
    "        hreduce((split, task, content) -> get_query_features(alphas, split, task, content)),\n",
    "    )\n",
    "    query_features = convert.(Float32, query_features)\n",
    "\n",
    "    user_to_indexes = get_user_to_indexes(\n",
    "        [(split, content) for split in splits for content in contents],\n",
    "        task,\n",
    "        (split, content) -> true,\n",
    "    )\n",
    "    user_to_watched_indexes = get_user_to_indexes(\n",
    "        [(split, content) for split in splits for content in contents],\n",
    "        task,\n",
    "        (split, content) -> content in [\"implicit\", \"explicit\"],\n",
    "    )\n",
    "\n",
    "    priorities = hreduce(get_priorities)\n",
    "    index_to_item = hreduce(\n",
    "        (split, task, content) -> get_raw_split(split, task, content).item;\n",
    "        agg = vcat,\n",
    "    )\n",
    "    item_user_index = sparse(Int32[], Int32[], Int32[], num_items(), num_users())\n",
    "    idx = 0\n",
    "    for split in splits\n",
    "        for content in contents\n",
    "            df = get_raw_split(split, task, content)\n",
    "            item_user_index += sparse(\n",
    "                df.item,\n",
    "                df.user,\n",
    "                idx+1:idx+length(df.item),\n",
    "                num_items(),\n",
    "                num_users(),\n",
    "            )\n",
    "            idx += length(df.item)\n",
    "        end\n",
    "    end\n",
    "    EnsembleFeatures(\n",
    "        query_features = query_features,\n",
    "        preprocessing_data = preprocessing_data,\n",
    "        priorities = priorities,\n",
    "        index_to_item = index_to_item,\n",
    "        user_to_indexes = user_to_indexes,\n",
    "        item_user_index = item_user_index,\n",
    "        user_to_watched_indexes = user_to_watched_indexes,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1def829-53fc-4b99-8d63-4588e3a6506e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function random_subsample(a, N; rng = rng)\n",
    "    size = min(length(a), N)\n",
    "    sample(rng, a, size; replace = false)\n",
    "end\n",
    "\n",
    "function subsample(u::Int32, list_size::Integer, f::Features; rng = rng)\n",
    "    # filter out users that haven't watched any items\n",
    "    if u ∉ keys(f.user_to_indexes)\n",
    "        return Int32[], false\n",
    "    end\n",
    "    if u in keys(f.user_to_watched_indexes)\n",
    "        watched_list = f.user_to_watched_indexes[u]\n",
    "    else\n",
    "        return Int32[], false\n",
    "    end\n",
    "    list = random_subsample(f.user_to_indexes[u], list_size; rng = rng)\n",
    "\n",
    "    # ensure at least one item is watched\n",
    "    if all(f.priorities[1, i] == 0 for i in list)\n",
    "        list[1] = rand(rng, watched_list)\n",
    "    end\n",
    "\n",
    "    # pad to list_size\n",
    "    while length(list) < list_size\n",
    "        push!(list, -1)\n",
    "    end\n",
    "    list, true\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a15b4f-c145-4f60-8121-070fa298f834",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_query_embedding(f::Features, q::Integer)\n",
    "    if q == -1\n",
    "        return zeros(Float32, size(f.query_features)[1])\n",
    "    else\n",
    "        return f.query_features[:, q]\n",
    "    end\n",
    "end\n",
    "\n",
    "function get_priority_embedding(f::Features, i::Integer)\n",
    "    if i == -1\n",
    "        return Float16[NaN, NaN, NaN, NaN]\n",
    "    else\n",
    "        return f.priorities[:, i]\n",
    "    end\n",
    "end\n",
    "\n",
    "function get_sample(f::Features, training::Bool, list_size::Integer; rng = rng)\n",
    "    max_training_user = Int(floor(num_users() * 0.9))\n",
    "    if training\n",
    "        user_range = Int32(1):Int32(max_training_user)\n",
    "    else\n",
    "        user_range = Int32(max_training_user + 1):Int32(num_users())\n",
    "    end\n",
    "\n",
    "    while true\n",
    "        u = rand(rng, user_range)\n",
    "        list, ok = subsample(u, list_size, f; rng = rng)\n",
    "        if !ok\n",
    "            continue\n",
    "        end\n",
    "        prefs = Flux.batch(get_priority_embedding(f, i) for i in list)\n",
    "        q_embs = hcat((get_query_embedding(f, q) for q in list)...)\n",
    "        return q_embs, prefs\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9608638d-81f1-40ff-97d0-cee4ac275ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_batch(\n",
    "    f::Features,\n",
    "    training::Bool,\n",
    "    list_size::Integer,\n",
    "    batch_size::Integer;\n",
    "    rng,\n",
    ")\n",
    "    q_embs = Matrix{Float32}[]\n",
    "    prefs = Matrix{Float16}[]\n",
    "    for _ = 1:batch_size\n",
    "        q_emb, pref = get_sample(f, training, list_size; rng = rng)\n",
    "        push!(q_embs, q_emb)\n",
    "        push!(prefs, pref)\n",
    "    end\n",
    "\n",
    "    # move to GPU\n",
    "    Q = device(Flux.batch(q_embs))\n",
    "    P = device(Flux.batch(prefs))\n",
    "    Q, P\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0986b43e-f425-4b0a-b971-6b14da745bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function build_model(hyp::Hyperparams)\n",
    "    K = hyp.embedding_size\n",
    "    Chain(\n",
    "        Dense(length(hyp.alphas), K, relu),\n",
    "        Dense(K => div(K, 2), relu),\n",
    "        Dense(div(K, 2), 1),\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a616677-313b-4e3b-847d-662c703dd666",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d6135b-e053-47c4-8533-ba217f79cf0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function get_alphas(task::String)\n",
    "    alphas = [\n",
    "        \"$task/LinearImplicit\"\n",
    "        \"$task/Explicit\"\n",
    "        nondirectional_raw_alphas\n",
    "        \"$task/LinearExplicit\"\n",
    "        \"$task/NonlinearImplicit\"\n",
    "        implicit_raw_alphas(task)\n",
    "        explicit_raw_alphas(task)\n",
    "    ]\n",
    "    # this alpha is non-personalized and overfits to the objective function\n",
    "    forbidden_alphas = [\"$task/ExplicitUserItemBiases\"]\n",
    "    [x for x in alphas if x ∉ forbidden_alphas]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a38015d-9693-456b-8d24-e84028ed6760",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_interaction_weights(task::String)\n",
    "    if task == \"random\"\n",
    "        return Float32[2.0^-10, 1, 0, 0]\n",
    "    elseif task == \"temporal\"\n",
    "        return Float32[2.0^-10, 1, 0, 0]\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5f13e4-a12e-4b0d-9485-585e435275f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyp = Hyperparams(\n",
    "    alphas = get_alphas(task),\n",
    "    batch_size = 64,\n",
    "    embedding_size = 256,\n",
    "    l2penalty = NaN,\n",
    "    learning_rate = NaN,\n",
    "    list_size = 1024,\n",
    "    seed = 20220609,\n",
    "    ranking_weight = 1.0,\n",
    "    interaction_weights = get_interaction_weights(task),\n",
    ")\n",
    "hyp = create_hyperparams(hyp, [0.0f0, 0.0f0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fa7cf1-7c61-44d1-9c48-49f4a1d18e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = get_features(hyp.alphas, task);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c48cc7-82ff-4483-ad28-d5e40f5bbf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_alpha(hyp, task, \"$task/MLE.Ensemble\"; features = features)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

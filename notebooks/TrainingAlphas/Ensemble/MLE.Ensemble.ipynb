{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# Ranking\n",
    "* This is trained to learn the partial ordering implied by each user's watches\n",
    "* Items that are watched are preferred to items that have not been watched\n",
    "* If two items have been watched, then the impression metadata determines\n",
    "  which one, if any, is liked more\n",
    "* It uses the position aware maximum likehood estimation loss  \n",
    "* The inputs to this model are features generated by other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"MLE.Base.ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "251beacd-fc32-41cf-8554-0257172239dc",
   "metadata": {},
   "source": [
    "## Define Subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d4f7e3e1-4486-47ff-8a45-bdc4108724bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@with_kw struct EnsembleFeatures <: Features\n",
    "    user_features::SparseMatrixCSC{Float32,Int32}\n",
    "    query_features::Matrix{Float32}\n",
    "    preprocessing_data::Dict\n",
    "\n",
    "    priorities::Matrix{Float16}\n",
    "\n",
    "    index_to_item::Vector{Int32}\n",
    "    user_to_indexes::Dict{Int32,Vector{Int32}}\n",
    "end\n",
    "\n",
    "function get_inference_data(f::Features)\n",
    "    f.preprocessing_data\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ddb2021e-a39a-498c-96a5-86f8604b1a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_query_features(alphas::Vector{String}, split::String, content::String)\n",
    "    @info \"getting $split $content alphas\"\n",
    "    df = get_raw_split(split, content)\n",
    "    T = Float16\n",
    "    A = Matrix{T}(undef, length(df.user), length(alphas))\n",
    "    @tprogress Threads.@threads for i = 1:length(alphas)\n",
    "        A[:, i] = convert.(T, read_raw_alpha(alphas[i], split, content).rating)\n",
    "    end\n",
    "    collect(A')\n",
    "end;\n",
    "\n",
    "function normalize(x::AbstractArray; dims = 1)\n",
    "    T = eltype(x)\n",
    "    x = convert.(Float32, x)\n",
    "    μ = mean(x, dims = dims)\n",
    "    σ = std(x, dims = dims, mean = μ, corrected = false)\n",
    "    convert.(T, (x .- μ) ./ σ), Dict(\"μ\" => μ, \"σ\" => σ)\n",
    "end\n",
    "\n",
    "function get_implicit_features()\n",
    "    df = get_split(\"training\", \"implicit\")\n",
    "    sparse(df.item, df.user, df.rating, num_items(), num_users())\n",
    "end\n",
    "\n",
    "function get_explicit_features()\n",
    "    df = get_split(\"training\", \"explicit\")\n",
    "    sparse(df.item, df.user, df.rating, num_items(), num_users())\n",
    "end\n",
    "\n",
    "function get_user_features()\n",
    "    vcat(get_implicit_features(), get_explicit_features())\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "041526a7-4e69-429e-a594-e04958619e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_features(alphas::Vector{String}, allow_ptw_in_labels::Bool)\n",
    "    contents = all_contents\n",
    "    if !allow_ptw_in_labels\n",
    "        contents = filter(x -> x != \"ptw\", contents)\n",
    "    end\n",
    "    splits = [\"test\"]\n",
    "\n",
    "    user_to_indexes = get_user_to_indexes(\n",
    "        [(split, content) for split in splits for content in contents],\n",
    "        (split, content) -> true,\n",
    "    )\n",
    "\n",
    "    hreduce(f; agg = hcat) =\n",
    "        reduce(agg, f(split, content) for split in splits for content in contents)\n",
    "    user_features = get_user_features()\n",
    "    query_features, preprocessing_data = normalize(\n",
    "        hreduce((split, content) -> get_query_features(alphas, split, content));\n",
    "        dims = 2,\n",
    "    )\n",
    "    query_features = convert.(Float32, query_features)\n",
    "    priorities = hreduce(get_priorities)\n",
    "    index_to_item =\n",
    "        hreduce((split, content) -> get_raw_split(split, content).item; agg = vcat)\n",
    "\n",
    "    EnsembleFeatures(\n",
    "        user_features = user_features,\n",
    "        query_features = query_features,\n",
    "        preprocessing_data = preprocessing_data,\n",
    "        priorities = priorities,\n",
    "        index_to_item = index_to_item,\n",
    "        user_to_indexes = user_to_indexes,\n",
    "    )\n",
    "end\n",
    "\n",
    "function get_user_embedding(u::Integer, f::Features)\n",
    "    f.user_features[:, u]\n",
    "end\n",
    "\n",
    "function get_item_embedding(q::Integer, f::Features)\n",
    "    f.index_to_item[q]\n",
    "end;\n",
    "\n",
    "function get_query_embedding(q::Integer, f::Features)\n",
    "    f.query_features[:, q]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7128e537-8c3f-42fe-8a2a-3ff888b32db3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_sample(f::Features, training::Bool, list_size::Integer)\n",
    "    max_training_user = Int(floor(num_users() * 0.9))\n",
    "    if training\n",
    "        user_range = Int32(1):Int32(max_training_user)\n",
    "    else\n",
    "        user_range = Int32(max_training_user + 1):Int32(num_users())\n",
    "    end\n",
    "\n",
    "    while true\n",
    "        # sample a random user\n",
    "        u = rand(user_range)\n",
    "        if u ∉ keys(f.user_to_indexes)\n",
    "            continue\n",
    "        end\n",
    "        idxs = f.user_to_indexes[u]\n",
    "        if length(idxs) >= list_size\n",
    "            # sample random items for the user\n",
    "            list = sample(idxs, list_size; replace = false)\n",
    "            # construct a random ranking that is consistent with the user's preferences            \n",
    "            if all(f.priorities[1, i] == 0 for i in list)\n",
    "                # if all the objects are unseen, then topological_sort will fail.\n",
    "                # topological_sort takes O(N^2) time, so we use this check to\n",
    "                # fail fast in O(N) time\n",
    "                continue\n",
    "            end\n",
    "            if !topological_sort!(\n",
    "                list,\n",
    "                (i, j) -> compare(f.priorities[:, i], f.priorities[:, j]),\n",
    "            )\n",
    "                continue\n",
    "            end\n",
    "\n",
    "            # batch the input features  \n",
    "            u_embs = hcat(fill(get_user_embedding(u, f), list_size)...)\n",
    "            a_embs = Int32[get_item_embedding(q, f) for q in list]\n",
    "            q_embs = hcat((get_query_embedding(q, f) for q in list)...)\n",
    "            return u_embs, a_embs, q_embs\n",
    "        end\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4be8534e-28c5-4dfe-8ee5-780c0938e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_batch(f::Features, training::Bool, list_size::Integer, batch_size::Integer)\n",
    "    u_embs = SparseMatrixCSC{Float32,Int32}[]\n",
    "    a_embs = Vector{Int32}[]\n",
    "    q_embs = Matrix{Float32}[]\n",
    "    for _ = 1:batch_size\n",
    "        u_emb, a_emb, q_emb = get_sample(f, training, list_size)\n",
    "        push!(u_embs, u_emb)\n",
    "        push!(a_embs, a_emb)\n",
    "        push!(q_embs, q_emb)\n",
    "    end\n",
    "    hcat(u_embs...), hcat(a_embs...), Flux.batch(q_embs)\n",
    "end\n",
    "\n",
    "function get_batch(c::Channel, training::Bool, holdout::Float32)\n",
    "    u_embs, a_embs, q_embs = device.(take!(c))\n",
    "    batch_size = size(a_embs)[2]\n",
    "    tsize = (size(u_embs)[1], size(u_embs)[2] ÷ batch_size, batch_size)\n",
    "    if training\n",
    "        randfn = CUDA.functional() ? CUDA.rand : rand\n",
    "        mask = randfn(num_items()) .>= holdout\n",
    "        u_embs .*= repeat(mask, size(u_embs)[1] ÷ size(mask)[1])\n",
    "    end\n",
    "    reshape(u_embs, tsize), a_embs, q_embs\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0986b43e-f425-4b0a-b971-6b14da745bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function build_model(hyp::Hyperparams)\n",
    "    K = hyp.embedding_size\n",
    "    Chain(\n",
    "        Join(\n",
    "            vcat,\n",
    "            Dense(num_items() * 2 => K),\n",
    "            Embedding(num_items() => K; init = Flux.glorot_uniform),\n",
    "            identity,\n",
    "        ),\n",
    "        Dense(length(hyp.alphas) + K * 2, K, relu),\n",
    "        Dense(K => K ÷ 2, relu),\n",
    "        Dense(K ÷ 2, 1),\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b136e77e-c674-4ee7-99d2-803ec985200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function model(\n",
    "    hyp::Hyperparams,\n",
    "    f::Features,\n",
    "    split::String,\n",
    "    content::String;\n",
    "    raw_splits = true,\n",
    ")\n",
    "    if raw_splits\n",
    "        df = get_raw_split(split, content)\n",
    "    else\n",
    "        df = get_split(split, content)\n",
    "    end\n",
    "    if split in [\"training\", \"validation\"]\n",
    "        return zeros(Float32, length(df.item))\n",
    "    end\n",
    "\n",
    "    output = Array{Float32}(undef, length(df.item))\n",
    "    @showprogress for batch in\n",
    "                      collect(Iterators.partition(1:length(df.item), hyp.batch_size))\n",
    "        u_embs = SparseVector{Float32,Int32}[]\n",
    "        a_embs = Int32[]\n",
    "        q_embs = Matrix{Int32}[]\n",
    "        for i in batch\n",
    "            push!(u_embs, get_user_embedding(df.user[i], f))\n",
    "            push!(a_embs, get_item_embedding(df.item[i], f))\n",
    "            push!(q_embs, get_query_embedding(df.item[i], f))\n",
    "        end\n",
    "        U, A, Q = device(hcat(u_embs...)), device(vcat(a_embs...)), device(hcat(q_embs...))\n",
    "        output[batch] .= cpu(vec(m((U, A, Q))))\n",
    "    end\n",
    "    output\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a616677-313b-4e3b-847d-662c703dd666",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "376e6681-572c-41a9-9b4e-08088b2bb6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hyperparams\n",
       "  allow_ptw_in_labels: Bool false\n",
       "  alphas: Array{String}((19,))\n",
       "  batch_size: Int32 1024\n",
       "  holdout: Float32 0.26894143f0\n",
       "  l2penalty: Float32 1.0f-5\n",
       "  learning_rate: Float32 0.0003f0\n",
       "  list_size: Int32 2\n",
       "  seed: UInt64 0x0000000001348ac1\n"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = [\n",
    "    \"LinearExplicit\"\n",
    "    \"LinearImplicit\"\n",
    "    \"LinearPtw\"\n",
    "    \"Explicit\"\n",
    "    \"NonlinearImplicit\"\n",
    "    \"NonlinearPtw\"\n",
    "    explicit_raw_alphas\n",
    "    implicit_raw_alphas\n",
    "    ptw_raw_alphas\n",
    "    nondirectional_raw_alphas\n",
    "];\n",
    "hyp = Hyperparams(\n",
    "    allow_ptw_in_labels = false,\n",
    "    alphas = alphas,\n",
    "    batch_size = 1024,\n",
    "    embedding_size = 256,\n",
    "    holdout = NaN,\n",
    "    l2penalty = NaN,\n",
    "    learning_rate = NaN,\n",
    "    list_size = 64,\n",
    "    seed = 20220609,\n",
    ")\n",
    "hyp = create_hyperparams(hyp, [0.0f0, 0.0f0, 0.0f0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248d034a-3777-4530-96ad-8fe07f8bceaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221126 17:57:27 Training model...\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221126 17:57:27 Initializing model\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221126 17:57:28 Getting data\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.19 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 (50.98 ns/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221126 18:03:56 getting test explicit alphas\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221126 18:05:15 getting test implicit alphas\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221126 18:05:22 getting test negative alphas\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221126 18:06:20 getting test explicit priorities\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:06 ( 3.80 μs/it)\u001b[39mit)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221126 18:06:33 getting test implicit priorities\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 3.35 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221126 18:06:40 getting test negative priorities\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:48 ( 2.74 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221126 18:07:49 Testing channels\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221126 18:08:06 ((45410, 2, 1024), (2, 1024), (19, 2, 1024))\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221126 18:08:06 ((45410, 2, 1024), (2, 1024), (19, 2, 1024))\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221126 18:08:06 Training model...\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:42\u001b[39m:48\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:01:53\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221126 18:13:42 loss 0.059106093613835814\n",
      "\u001b[32mProgress:  10%|████                                     |  ETA: 0:02:58\u001b[39m"
     ]
    }
   ],
   "source": [
    "train_alpha(hyp, \"MLE.Neural\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98097c60-d064-4faa-9e6d-720707628fba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 0.18465150250650614 using new mle loss formulation ( -> 64 -> 32 -> 1)\n",
    "# 0.1770052581855019 using input normalization\n",
    "# going wider by 4x didn't help\n",
    "# going deeper by 2 layers didn't help\n",
    "# 0.18148092587706433 using 50% drpout make things worse\n",
    "# 0.05950891730785771 by scaling the loss function down (should be a no-op)\n",
    "# 0.056652724017389744 with double embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c704589f-19b3-410e-bc5a-ac58a13a7e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_checkpoints::Integer = 100\n",
    "# epochs_per_checkpoint::Integer = 1\n",
    "# patience::Integer = 0\n",
    "# verbose::Bool = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc957cd-b575-4b71-9fa5-123a34c239a5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# if verbose\n",
    "#     @info \"Initializing model\"\n",
    "# end\n",
    "# opt = ADAMW(hyp.learning_rate, (0.9, 0.999), hyp.l2penalty)\n",
    "# rng = Random.Xoshiro(hyp.seed)\n",
    "# Random.seed!(rand(rng, UInt64))\n",
    "# if CUDA.functional()\n",
    "#     Random.seed!(CUDA.default_rng(), rand(rng, UInt64))\n",
    "#     Random.seed!(CUDA.CURAND.default_rng(), rand(rng, UInt64))\n",
    "# end\n",
    "# m = build_model(hyp) |> device\n",
    "# best_model = m |> cpu\n",
    "# ps = Flux.params(m)\n",
    "# stopper = early_stopper(\n",
    "#     max_iters = max_checkpoints,\n",
    "#     patience = patience,\n",
    "#     min_rel_improvement = 1e-3,\n",
    "# )\n",
    "# batchloss(x...) = position_aware_list_mle_loss(m, x)\n",
    "# epoch_size = Int(round(num_users() / hyp.batch_size))\n",
    "# function loginfo(x)\n",
    "#     if verbose\n",
    "#         @info x\n",
    "#     end\n",
    "# end\n",
    "\n",
    "# loginfo(\"Getting data\")\n",
    "# f = get_features(hyp.alphas, false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceea1cb2-0a28-42f3-b3cd-df57100f251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup_channel(training) = setup_batch_channel(f, training, hyp, 64)\n",
    "# training_batches = setup_channel(true)\n",
    "# test_batches = setup_channel(false)\n",
    "# @info \"Testing channels\"\n",
    "# @info size.(get_batch(training_batches, true, hyp.holdout))\n",
    "# @info size.(get_batch(test_batches, false, hyp.holdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259e713c-7978-41bf-9666-74aed3627f88",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @showprogress for _ = 1:epoch_size\n",
    "#     batch = get_batch(training_batches, true, hyp.holdout)\n",
    "# end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

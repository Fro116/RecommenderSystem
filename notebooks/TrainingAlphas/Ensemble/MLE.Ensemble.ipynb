{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# Ranking\n",
    "* This is trained to learn the partial ordering implied by each user's watches\n",
    "* Items that are watched are preferred to items that have not been watched\n",
    "* If two items have been watched, then the impression metadata determines\n",
    "  which one, if any, is liked more\n",
    "* It uses the position aware maximum likehood estimation loss  \n",
    "* The inputs to this model are features generated by other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5781704c-40c0-48ca-8563-6e6e2d7ae045",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "medium = \"\"\n",
    "task = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import NBInclude: @nbinclude\n",
    "import Statistics: quantile\n",
    "import Flux: Chain, Dense, Dropout, LayerNorm, relu, SkipConnection\n",
    "@nbinclude(\"MLE.Base.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f7e3e1-4486-47ff-8a45-bdc4108724bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kwdef struct EnsembleFeatures <: Features\n",
    "    query_features::Matrix{Float32}\n",
    "    preprocessing_data::Dict\n",
    "    priorities::Matrix{Float16}\n",
    "    index_to_item::Vector{Int32}\n",
    "    user_to_indexes::Dict{Int32,Vector{Int32}}\n",
    "    item_user_index::SparseMatrixCSC{Int32,Int32}\n",
    "    user_to_watched_indexes::Dict{Int32,Vector{Int32}}\n",
    "end\n",
    "\n",
    "function get_inference_data(f::Features)\n",
    "    f.preprocessing_data\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb2021e-a39a-498c-96a5-86f8604b1a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_query_features(\n",
    "    alphas::Vector{String},\n",
    "    split::String,\n",
    "    task::String,\n",
    "    content::String,\n",
    "    medium::String,\n",
    ")\n",
    "    @info \"getting $split $task $content $medium alphas\"\n",
    "    df = get_raw_split(split, task, content, medium)\n",
    "    T = Float16\n",
    "    A = Matrix{T}(undef, length(df.user), length(alphas))\n",
    "    @tprogress Threads.@threads for i = 1:length(alphas)\n",
    "        if occursin(\"ItemCount\", alphas[i]) || occursin(\"UserVariance\", alphas[i])\n",
    "            transform = x -> log(x + 1)\n",
    "        else\n",
    "            transform = identity\n",
    "        end\n",
    "        A[:, i] =\n",
    "            transform.(\n",
    "                convert.(T, read_raw_alpha(alphas[i], split, task, content, medium).rating),\n",
    "            )\n",
    "    end\n",
    "    collect(A')\n",
    "end;\n",
    "\n",
    "function normalize!(x::AbstractArray, alphas::Vector{String}; clip = 10)\n",
    "    T = eltype(x)\n",
    "    N = size(x)[1]\n",
    "    μ = zeros(Float32, N)\n",
    "    σ = ones(Float32, N)\n",
    "    for i = 1:N\n",
    "        y = convert.(Float32, x[i, :])\n",
    "        if occursin(\"ItemCount\", alphas[i]) || occursin(\"UserVariance\", alphas[i])\n",
    "            μ[i] = mean(y)\n",
    "            σ[i] = std(y, mean = μ[i], corrected = false)\n",
    "        elseif occursin(\"implicit\", lowercase(alphas[i]))\n",
    "            μ[i] = 0\n",
    "            σ[i] = 1\n",
    "        elseif occursin(\"explicit\", lowercase(alphas[i])) ||\n",
    "               occursin(\"UserAverage\", alphas[i])\n",
    "            μ[i] = 0\n",
    "            σ[i] = 10\n",
    "        else\n",
    "            @assert false\n",
    "        end\n",
    "        q = (y .- μ[i]) ./ σ[i]\n",
    "        @info \"normalization metrics for alpha $(alphas[i]): [$(minimum(y)) $(maximum(y))] \" *\n",
    "              \"[$(μ[i]) $(σ[i])] [$(minimum(q)) $(maximum(q))]\"\n",
    "        @assert (abs(maximum(q)) <= clip) && (abs(minimum(q)) <= clip)\n",
    "        x[i, :] = convert.(T, (x[i, :] .- μ[i]) ./ σ[i])\n",
    "    end\n",
    "    x, Dict(\"μ\" => μ, \"σ\" => σ)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "041526a7-4e69-429e-a594-e04958619e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_features(alphas::Vector{String}, task::String, medium::String)\n",
    "    @info \"using alphas $alphas\"\n",
    "    contents = ALL_CONTENTS\n",
    "    splits = [\"test\"]\n",
    "\n",
    "    hreduce(f; agg = hcat) = reduce(\n",
    "        agg,\n",
    "        f(split, task, content, medium) for split in splits for content in contents\n",
    "    )\n",
    "    query_features, preprocessing_data = normalize!(\n",
    "        hreduce(\n",
    "            (split, task, content, medium) ->\n",
    "                get_query_features(alphas, split, task, content, medium),\n",
    "        ),\n",
    "        alphas,\n",
    "    )\n",
    "    query_features = convert.(Float32, query_features)\n",
    "\n",
    "    user_to_indexes = get_user_to_indexes(\n",
    "        [(split, content) for split in splits for content in contents],\n",
    "        task,\n",
    "        medium,\n",
    "        (split, content) -> true,\n",
    "    )\n",
    "    user_to_watched_indexes = get_user_to_indexes(\n",
    "        [(split, content) for split in splits for content in contents],\n",
    "        task,\n",
    "        medium,\n",
    "        (split, content) -> content in [\"implicit\", \"explicit\"],\n",
    "    )\n",
    "\n",
    "    priorities = hreduce(get_priorities)\n",
    "    index_to_item = hreduce(\n",
    "        (split, task, content, medium) ->\n",
    "            get_raw_split(split, task, content, medium).item;\n",
    "        agg = vcat,\n",
    "    )\n",
    "    item_user_index =\n",
    "        sparse(Int32[], Int32[], Int32[], num_items(medium), num_users(medium))\n",
    "    idx = 0\n",
    "    for split in splits\n",
    "        for content in contents\n",
    "            df = get_raw_split(split, task, content, medium)\n",
    "            item_user_index += sparse(\n",
    "                df.item,\n",
    "                df.user,\n",
    "                idx+1:idx+length(df.item),\n",
    "                num_items(medium),\n",
    "                num_users(medium),\n",
    "            )\n",
    "            idx += length(df.item)\n",
    "        end\n",
    "    end\n",
    "    EnsembleFeatures(\n",
    "        query_features = query_features,\n",
    "        preprocessing_data = preprocessing_data,\n",
    "        priorities = priorities,\n",
    "        index_to_item = index_to_item,\n",
    "        user_to_indexes = user_to_indexes,\n",
    "        item_user_index = item_user_index,\n",
    "        user_to_watched_indexes = user_to_watched_indexes,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3b1a28-9eb1-4eab-9185-5fdc53076e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "function random_subsample(a, N; rng = rng)\n",
    "    size = min(length(a), N)\n",
    "    sample(rng, a, size; replace = false)\n",
    "end\n",
    "\n",
    "function subsample(u::Int32, list_size::Integer, f::Features; rng = rng)\n",
    "    # filter out users that haven't watched any items\n",
    "    if u ∉ keys(f.user_to_indexes)\n",
    "        return Int32[], false\n",
    "    end\n",
    "    if u in keys(f.user_to_watched_indexes)\n",
    "        watched_list = f.user_to_watched_indexes[u]\n",
    "    else\n",
    "        return Int32[], false\n",
    "    end\n",
    "    list = random_subsample(f.user_to_indexes[u], list_size; rng = rng)\n",
    "\n",
    "    # ensure at least one item is watched\n",
    "    if all(f.priorities[1, i] == 0 for i in list)\n",
    "        list[1] = rand(rng, watched_list)\n",
    "    end\n",
    "\n",
    "    # pad to list_size\n",
    "    while length(list) < list_size\n",
    "        push!(list, -1)\n",
    "    end\n",
    "    list, true\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8a15b4f-c145-4f60-8121-070fa298f834",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_query_embedding(f::Features, q::Integer)\n",
    "    if q == -1\n",
    "        return zeros(Float32, size(f.query_features)[1])\n",
    "    else\n",
    "        return f.query_features[:, q]\n",
    "    end\n",
    "end\n",
    "\n",
    "function get_priority_embedding(f::Features, i::Integer)\n",
    "    if i == -1\n",
    "        return Float16[NaN, NaN, NaN, NaN]\n",
    "    else\n",
    "        return f.priorities[:, i]\n",
    "    end\n",
    "end\n",
    "\n",
    "function get_sample(f::Features, training::Bool, list_size::Integer; rng = rng)\n",
    "    max_training_user = Int(floor(num_users(medium) * 0.9))\n",
    "    if training\n",
    "        user_range = Int32(1):Int32(max_training_user)\n",
    "    else\n",
    "        user_range = Int32(max_training_user + 1):Int32(num_users(medium))\n",
    "    end\n",
    "\n",
    "    while true\n",
    "        u = rand(rng, user_range)\n",
    "        list, ok = subsample(u, list_size, f; rng = rng)\n",
    "        if !ok\n",
    "            continue\n",
    "        end\n",
    "        prefs = Flux.batch(get_priority_embedding(f, i) for i in list)\n",
    "        q_embs = hcat((get_query_embedding(f, q) for q in list)...)\n",
    "        return q_embs, prefs\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9608638d-81f1-40ff-97d0-cee4ac275ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_batch(\n",
    "    f::Features,\n",
    "    training::Bool,\n",
    "    list_size::Integer,\n",
    "    batch_size::Integer;\n",
    "    rng,\n",
    ")\n",
    "    q_embs = Matrix{Float32}[]\n",
    "    prefs = Matrix{Float16}[]\n",
    "    for _ = 1:batch_size\n",
    "        q_emb, pref = get_sample(f, training, list_size; rng = rng)\n",
    "        push!(q_embs, q_emb)\n",
    "        push!(prefs, pref)\n",
    "    end\n",
    "\n",
    "    # move to GPU\n",
    "    Q = device(Flux.batch(q_embs))\n",
    "    P = device(Flux.batch(prefs))\n",
    "    Q, P\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0986b43e-f425-4b0a-b971-6b14da745bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function build_model(hyp::Hyperparams)\n",
    "    K = hyp.embedding_size\n",
    "    Chain(\n",
    "        Dense(length(hyp.alphas), K, relu),\n",
    "        Dense(K => div(K, 2), relu),\n",
    "        Dense(div(K, 2) => div(K, 4), relu),\n",
    "        Dense(div(K, 4), 1),\n",
    "    )\n",
    "    # TODO experiment with model sizing\n",
    "    # Chain(\n",
    "    #     Dense(length(hyp.alphas), K, relu),\n",
    "    #     SkipConnection(Chain(LayerNorm(K), Dense(K, K, relu), Dense(K, K, relu)), +),\n",
    "    #     SkipConnection(Chain(LayerNorm(K), Dense(K, K, relu), Dense(K, K, relu)), +),\n",
    "    #     SkipConnection(Chain(LayerNorm(K), Dense(K, K, relu), Dense(K, K, relu)), +),\n",
    "    #     Dense(K, 1),\n",
    "    # )\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a616677-313b-4e3b-847d-662c703dd666",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d6135b-e053-47c4-8533-ba217f79cf0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function get_alphas(task::String, medium::String)\n",
    "    alphas = [\n",
    "        \"$medium/$task/LinearImplicit\"\n",
    "        \"$medium/$task/LinearExplicit\"\n",
    "        nondirectional_raw_alphas(task, medium)\n",
    "        implicit_raw_alphas(task, medium)\n",
    "        explicit_raw_alphas(task, medium)\n",
    "    ]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a38015d-9693-456b-8d24-e84028ed6760",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_interaction_weights(task::String, medium::String)\n",
    "    if task == \"temporal_causal\"\n",
    "        return Float32[2.0^-10, 1, 0, 0]\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae5f13e4-a12e-4b0d-9485-585e435275f8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyp = Hyperparams(\n",
    "    alphas = get_alphas(task, medium),\n",
    "    batch_size = 64,\n",
    "    embedding_size = 1024,\n",
    "    learning_rate = 1e-4,\n",
    "    l2penalty = 1e-2,\n",
    "    list_size = 1024,\n",
    "    seed = 20220609,\n",
    "    ranking_weight = 1.0,\n",
    "    interaction_weights = get_interaction_weights(task, medium),\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05fa7cf1-7c61-44d1-9c48-49f4a1d18e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = get_features(hyp.alphas, task, medium);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8f0aec-69c5-462b-856c-7bd2bb5a57ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i = 0:6\n",
    "    hyp = @set hyp.interaction_weights = [10.0^-i, 1, 0, 0] # TODO\n",
    "    train_alpha(hyp, task, medium, \"$medium/$task/MLE.Ensemble.$i\"; features = features)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0-rc2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# NonlinearModel\n",
    "* Uses LightGBM to estimate a given (user, item) prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: lib_lightgbm not found in system dirs, trying fallback\n",
      "└ @ LightGBM /home/kundan/.julia/packages/LightGBM/A7zVd/src/LightGBM.jl:25\n"
     ]
    }
   ],
   "source": [
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"TreeModelBase.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "617b0a49-44bb-4ee9-87ee-990ad7ec3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "implicit = false;\n",
    "linear_alphas = [\"LinearExplicit\", \"LinearImplicit\"]\n",
    "all_features = [explicit_raw_alphas; implicit_raw_alphas; linear_alphas];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "517ce91a-bf09-446a-8be9-a7c5bbe0c0f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.018742 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 13662955, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 0.002014\n",
      "Iteration: 1, test_1's l2: 1.586974376701175\n",
      "Iteration: 2, test_1's l2: 1.5821925584753251\n",
      "Iteration: 3, test_1's l2: 1.5785215074945531\n",
      "Iteration: 4, test_1's l2: 1.5751877190835535\n",
      "Iteration: 5, test_1's l2: 1.5725129805396472\n",
      "Iteration: 6, test_1's l2: 1.5702980685691432\n",
      "Iteration: 7, test_1's l2: 1.5684981662950328\n",
      "Iteration: 8, test_1's l2: 1.5672061515577556\n",
      "Iteration: 9, test_1's l2: 1.565954767753929\n",
      "Iteration: 10, test_1's l2: 1.5649653599758269\n",
      "Iteration: 11, test_1's l2: 1.56405265258401\n",
      "Iteration: 12, test_1's l2: 1.5634447876401714\n",
      "Iteration: 13, test_1's l2: 1.5630764609722905\n",
      "Iteration: 14, test_1's l2: 1.5625575313061801\n",
      "Iteration: 15, test_1's l2: 1.5620204529367363\n",
      "Iteration: 16, test_1's l2: 1.561614492085602\n",
      "Iteration: 17, test_1's l2: 1.5612420860877232\n",
      "Iteration: 18, test_1's l2: 1.5609735824442097\n",
      "Iteration: 19, test_1's l2: 1.5607931190958686\n",
      "Iteration: 20, test_1's l2: 1.560661628473487\n",
      "Iteration: 21, test_1's l2: 1.5605264603458555\n",
      "Iteration: 22, test_1's l2: 1.5603139509356372\n",
      "Iteration: 23, test_1's l2: 1.560245766465194\n",
      "Iteration: 24, test_1's l2: 1.5601665142213763\n",
      "Iteration: 25, test_1's l2: 1.5601998053999269\n",
      "Iteration: 26, test_1's l2: 1.5601446181992222\n",
      "Iteration: 27, test_1's l2: 1.5601059506783221\n",
      "Iteration: 28, test_1's l2: 1.560136732747898\n",
      "Iteration: 29, test_1's l2: 1.560170273268009\n",
      "Iteration: 30, test_1's l2: 1.560234118921935\n",
      "Iteration: 31, test_1's l2: 1.5602250809271452\n",
      "Iteration: 32, test_1's l2: 1.5600833412146544\n",
      "Iteration: 33, test_1's l2: 1.5599703886983898\n",
      "Iteration: 34, test_1's l2: 1.5600130693425946\n",
      "Iteration: 35, test_1's l2: 1.5599059144207643\n",
      "Iteration: 36, test_1's l2: 1.5597960693901016\n",
      "Iteration: 37, test_1's l2: 1.5597373655810594\n",
      "Iteration: 38, test_1's l2: 1.5596224795715872\n",
      "Iteration: 39, test_1's l2: 1.5595273180778335\n",
      "Iteration: 40, test_1's l2: 1.5595319474463776\n",
      "Iteration: 41, test_1's l2: 1.559464391218511\n",
      "Iteration: 42, test_1's l2: 1.5595547838447834\n",
      "Iteration: 43, test_1's l2: 1.5595159159914593\n",
      "Iteration: 44, test_1's l2: 1.5593998597290393\n",
      "Iteration: 45, test_1's l2: 1.5593702304669592\n",
      "Iteration: 46, test_1's l2: 1.5593322949278774\n",
      "Iteration: 47, test_1's l2: 1.5592811957138057\n",
      "Iteration: 48, test_1's l2: 1.5592920557999164\n",
      "Iteration: 49, test_1's l2: 1.559301232458057\n",
      "Iteration: 50, test_1's l2: 1.5593556802386848\n",
      "Iteration: 51, test_1's l2: 1.559434264480997\n",
      "Iteration: 52, test_1's l2: 1.5594923716641638\n",
      "Iteration: 53, test_1's l2: 1.5595323132637604\n",
      "Iteration: 54, test_1's l2: 1.5595650926100866\n",
      "Iteration: 55, test_1's l2: 1.5596225078131947\n",
      "Iteration: 56, test_1's l2: 1.559589082975619\n",
      "Early stopping at iteration 57, the best iteration round is 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220618 14:19:01 Saving model... (this may take a while)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.59 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220618 14:20:25 validation loss: 1.5216319075537477, β: [0.9998336953046232, 1.3743581143703474]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:06 ( 1.17 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220618 14:20:36 training loss: 0.8634630130283252, β: [0.9998336953046232, 1.3743581143703474]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:06 ( 1.16 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.20 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.19 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 1.16 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.22 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.20 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.79 μs/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    all_features,\n",
    "    [\"LinearExplicit\"],\n",
    "    implicit,\n",
    "    \"validation\",\n",
    "    \"NonlinearExplicit\",\n",
    "    false,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4928ac14-f5c8-4119-9215-7e9f61e97cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function save_final_explicit_model()\n",
    "    linear_splits = reduce(\n",
    "        cat,\n",
    "        [read_alpha(\"LinearExplicit\", split, implicit) for split in all_raw_splits],\n",
    "    )\n",
    "    nonlinear_splits = reduce(\n",
    "        cat,\n",
    "        [read_alpha(\"NonlinearExplicit\", split, implicit) for split in all_raw_splits],\n",
    "    )\n",
    "    sparse_preds = sparse(\n",
    "        linear_splits.user,\n",
    "        linear_splits.item,\n",
    "        linear_splits.rating + nonlinear_splits.rating,\n",
    "    )\n",
    "    write_alpha(sparse_preds, [], implicit, \"Explicit\"; log_test_split=true)\n",
    "    write_params(Dict(\"alphas\" => [\"LinearExplicit\", \"NonlinearExplicit\"]), \"Explicit\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ed398d5-ecd5-4707-829b-0a6e09c40ee6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.31 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220618 14:21:13 validation loss: 1.5268711740796663, β: [1.0001019184984978]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:07 ( 1.24 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220618 14:21:22 training loss: 0.839517470434867, β: [1.0001019184984978]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:07 ( 1.24 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.28 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.27 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 1.24 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.29 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.28 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.85 μs/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "save_final_explicit_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-rc1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

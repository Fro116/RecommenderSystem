{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# NonlinearModel\n",
    "* Uses LightGBM to estimate a given (user, item) prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: lib_lightgbm not found in system dirs, trying fallback\n",
      "└ @ LightGBM /home/kundan/.julia/packages/LightGBM/A7zVd/src/LightGBM.jl:25\n"
     ]
    }
   ],
   "source": [
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"TreeModelBase.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "030e45c3-c896-4848-b746-830e6b0e5c5a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 09:21:07 getting features for implicit, validation\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 09:21:32 getting features for negative, validation\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 (18.78 ns/it)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 22233206, number of negative: 379124361\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.914558 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 401357567, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.055395 -> initscore=-2.836277\n",
      "[LightGBM] [Info] Start training from score -2.836277\n",
      "Iteration: 1, test_1's binary_logloss: 0.19239608215182882, \n",
      "Iteration: 1, test_1's auc: 0.9046994451908371\n",
      "Iteration: 2, test_1's binary_logloss: 0.18292158630041983, \n",
      "Iteration: 2, test_1's auc: 0.9083165568685627\n",
      "Iteration: 3, test_1's binary_logloss: 0.17477825718508067, \n",
      "Iteration: 3, test_1's auc: 0.9113320057089125\n",
      "Iteration: 4, test_1's binary_logloss: 0.15091664244530636, \n",
      "Iteration: 4, test_1's auc: 0.9400486664703498\n",
      "Iteration: 5, test_1's binary_logloss: 0.14663871896455954, \n",
      "Iteration: 5, test_1's auc: 0.9400904578988493\n",
      "Iteration: 6, test_1's binary_logloss: 0.1321125232232448, \n",
      "Iteration: 6, test_1's auc: 0.9509694116473878\n",
      "Iteration: 7, test_1's binary_logloss: 0.12912471747899804, \n",
      "Iteration: 7, test_1's auc: 0.9509100155628749\n",
      "Iteration: 8, test_1's binary_logloss: 0.1183182332175354, \n",
      "Iteration: 8, test_1's auc: 0.9571802473731531\n",
      "Iteration: 9, test_1's binary_logloss: 0.11028434015610507, \n",
      "Iteration: 9, test_1's auc: 0.9615148144619401\n",
      "Iteration: 10, test_1's binary_logloss: 0.10404242532945635, \n",
      "Iteration: 10, test_1's auc: 0.9636108782082291\n",
      "Iteration: 11, test_1's binary_logloss: 0.10198181177976648, \n",
      "Iteration: 11, test_1's auc: 0.9635577416627275\n",
      "Iteration: 12, test_1's binary_logloss: 0.10054538425852766, \n",
      "Iteration: 12, test_1's auc: 0.963520091552883\n",
      "Iteration: 13, test_1's binary_logloss: 0.09921756542447022, \n",
      "Iteration: 13, test_1's auc: 0.9633812157109191\n",
      "Iteration: 14, test_1's binary_logloss: 0.09296471038315154, \n",
      "Iteration: 14, test_1's auc: 0.966518165632102\n",
      "Iteration: 15, test_1's binary_logloss: 0.0881964764720847, \n",
      "Iteration: 15, test_1's auc: 0.968523039600285\n",
      "Iteration: 16, test_1's binary_logloss: 0.0870418724518627, \n",
      "Iteration: 16, test_1's auc: 0.9685799517683481\n",
      "Iteration: 17, test_1's binary_logloss: 0.0862502818026214, \n",
      "Iteration: 17, test_1's auc: 0.9685767364839891\n",
      "Iteration: 18, test_1's binary_logloss: 0.08393720813409775, \n",
      "Iteration: 18, test_1's auc: 0.9692752965983747\n",
      "Iteration: 19, test_1's binary_logloss: 0.07949539564441244, \n",
      "Iteration: 19, test_1's auc: 0.971323357945759\n",
      "Iteration: 20, test_1's binary_logloss: 0.07542222312852342, \n",
      "Iteration: 20, test_1's auc: 0.9732556540635684\n",
      "Iteration: 21, test_1's binary_logloss: 0.07486126712589909, \n",
      "Iteration: 21, test_1's auc: 0.973269061441286\n",
      "Iteration: 22, test_1's binary_logloss: 0.07217909478523248, \n",
      "Iteration: 22, test_1's auc: 0.9741342985826961\n",
      "Iteration: 23, test_1's binary_logloss: 0.07171477978275408, \n",
      "Iteration: 23, test_1's auc: 0.9741865128040575\n",
      "Iteration: 24, test_1's binary_logloss: 0.06856652103668026, \n",
      "Iteration: 24, test_1's auc: 0.9754638488420919\n",
      "Iteration: 25, test_1's binary_logloss: 0.06815618591304132, \n",
      "Iteration: 25, test_1's auc: 0.9755277782651126\n",
      "Iteration: 26, test_1's binary_logloss: 0.06780821044044175, \n",
      "Iteration: 26, test_1's auc: 0.9755918438645889\n",
      "Iteration: 27, test_1's binary_logloss: 0.06503952585718778, \n",
      "Iteration: 27, test_1's auc: 0.9767203304748439\n",
      "Iteration: 28, test_1's binary_logloss: 0.06256514609833766, \n",
      "Iteration: 28, test_1's auc: 0.9777030338197719\n",
      "Iteration: 29, test_1's binary_logloss: 0.06034150406324099, \n",
      "Iteration: 29, test_1's auc: 0.9785474684265081\n",
      "Iteration: 30, test_1's binary_logloss: 0.06010250723536513, \n",
      "Iteration: 30, test_1's auc: 0.9786299380268706\n",
      "Iteration: 31, test_1's binary_logloss: 0.05987682624425178, \n",
      "Iteration: 31, test_1's auc: 0.9786762092445938\n",
      "Iteration: 32, test_1's binary_logloss: 0.05972495821998415, \n",
      "Iteration: 32, test_1's auc: 0.9787175535703311\n",
      "Iteration: 33, test_1's binary_logloss: 0.058898311005224385, \n",
      "Iteration: 33, test_1's auc: 0.979081494626193\n",
      "Iteration: 34, test_1's binary_logloss: 0.05742423378202121, \n",
      "Iteration: 34, test_1's auc: 0.9795794049311831\n",
      "Iteration: 35, test_1's binary_logloss: 0.05563398300120431, \n",
      "Iteration: 35, test_1's auc: 0.9803440989102763\n",
      "Iteration: 36, test_1's binary_logloss: 0.0539826187828661, \n",
      "Iteration: 36, test_1's auc: 0.9810744258054553\n",
      "Iteration: 37, test_1's binary_logloss: 0.0524969835400971, \n",
      "Iteration: 37, test_1's auc: 0.9816775628232046\n",
      "Iteration: 38, test_1's binary_logloss: 0.05113320754397375, \n",
      "Iteration: 38, test_1's auc: 0.9822140172637043\n",
      "Iteration: 39, test_1's binary_logloss: 0.05035319395875597, \n",
      "Iteration: 39, test_1's auc: 0.9825438164611024\n",
      "Iteration: 40, test_1's binary_logloss: 0.0492322301079304, \n",
      "Iteration: 40, test_1's auc: 0.9829827959580628\n",
      "Iteration: 41, test_1's binary_logloss: 0.04892474758251921, \n",
      "Iteration: 41, test_1's auc: 0.9831968033294283\n",
      "Iteration: 42, test_1's binary_logloss: 0.04821982855528413, \n",
      "Iteration: 42, test_1's auc: 0.9835015450682043\n",
      "Iteration: 43, test_1's binary_logloss: 0.048108397058457784, \n",
      "Iteration: 43, test_1's auc: 0.983601443280889\n",
      "Iteration: 44, test_1's binary_logloss: 0.04800270655698497, \n",
      "Iteration: 44, test_1's auc: 0.9836807017797238\n",
      "Iteration: 45, test_1's binary_logloss: 0.04700374589736986, \n",
      "Iteration: 45, test_1's auc: 0.9841024818162368\n",
      "Iteration: 46, test_1's binary_logloss: 0.046910615372778956, \n",
      "Iteration: 46, test_1's auc: 0.9841780057677386\n",
      "Iteration: 47, test_1's binary_logloss: 0.046832487690856385, \n",
      "Iteration: 47, test_1's auc: 0.9842376943946973\n",
      "Iteration: 48, test_1's binary_logloss: 0.045980952981425745, \n",
      "Iteration: 48, test_1's auc: 0.9845543615313194\n",
      "Iteration: 49, test_1's binary_logloss: 0.04591189975877439, \n",
      "Iteration: 49, test_1's auc: 0.9846217917868978\n",
      "Iteration: 50, test_1's binary_logloss: 0.0458586030376228, \n",
      "Iteration: 50, test_1's auc: 0.9846663318452541\n",
      "Iteration: 51, test_1's binary_logloss: 0.04532658293454296, \n",
      "Iteration: 51, test_1's auc: 0.9848635346979925\n",
      "Iteration: 52, test_1's binary_logloss: 0.045228949904973, \n",
      "Iteration: 52, test_1's auc: 0.9849216797592273\n",
      "Iteration: 53, test_1's binary_logloss: 0.04501231637681455, \n",
      "Iteration: 53, test_1's auc: 0.9850891896161318\n",
      "Iteration: 54, test_1's binary_logloss: 0.044220060033580304, \n",
      "Iteration: 54, test_1's auc: 0.9853979199298399\n",
      "Iteration: 55, test_1's binary_logloss: 0.0435817959469421, \n",
      "Iteration: 55, test_1's auc: 0.9856365061138025\n",
      "Iteration: 56, test_1's binary_logloss: 0.04351900758323471, \n",
      "Iteration: 56, test_1's auc: 0.9857015453733609\n",
      "Iteration: 57, test_1's binary_logloss: 0.04334966756870594, \n",
      "Iteration: 57, test_1's auc: 0.9857985245769271\n",
      "Iteration: 58, test_1's binary_logloss: 0.04271219297619629, \n",
      "Iteration: 58, test_1's auc: 0.9860815376376704\n",
      "Iteration: 59, test_1's binary_logloss: 0.042667695066240414, \n",
      "Iteration: 59, test_1's auc: 0.9861318099326495\n",
      "Iteration: 60, test_1's binary_logloss: 0.042074959122343956, \n",
      "Iteration: 60, test_1's auc: 0.9863645142354651\n",
      "Iteration: 61, test_1's binary_logloss: 0.04158967241966655, \n",
      "Iteration: 61, test_1's auc: 0.9865856336861322\n",
      "Iteration: 62, test_1's binary_logloss: 0.04153422203868545, \n",
      "Iteration: 62, test_1's auc: 0.9866518608715965\n",
      "Iteration: 63, test_1's binary_logloss: 0.041090810063007556, \n",
      "Iteration: 63, test_1's auc: 0.9868279670956059\n",
      "Iteration: 64, test_1's binary_logloss: 0.04104106321004752, \n",
      "Iteration: 64, test_1's auc: 0.9868882848932778\n",
      "Iteration: 65, test_1's binary_logloss: 0.0407394873669284, \n",
      "Iteration: 65, test_1's auc: 0.987028617937009\n",
      "Iteration: 66, test_1's binary_logloss: 0.04064624272366449, \n",
      "Iteration: 66, test_1's auc: 0.9870954149847528\n",
      "Iteration: 67, test_1's binary_logloss: 0.04020537550400942, \n",
      "Iteration: 67, test_1's auc: 0.9872961932516676\n",
      "Iteration: 68, test_1's binary_logloss: 0.040170112898739646, \n",
      "Iteration: 68, test_1's auc: 0.9873449310147573\n",
      "Iteration: 69, test_1's binary_logloss: 0.04012074461957857, \n",
      "Iteration: 69, test_1's auc: 0.9873960735789332\n",
      "Iteration: 70, test_1's binary_logloss: 0.0396827692417525, \n",
      "Iteration: 70, test_1's auc: 0.9875816818754025\n",
      "Iteration: 71, test_1's binary_logloss: 0.039422739119995096, \n",
      "Iteration: 71, test_1's auc: 0.9877248366655355\n",
      "Iteration: 72, test_1's binary_logloss: 0.039386245475809184, \n",
      "Iteration: 72, test_1's auc: 0.9877656001613179\n",
      "Iteration: 73, test_1's binary_logloss: 0.039121398555269506, \n",
      "Iteration: 73, test_1's auc: 0.9879246310580378\n",
      "Iteration: 74, test_1's binary_logloss: 0.039088714874901724, \n",
      "Iteration: 74, test_1's auc: 0.987950076777729\n",
      "Iteration: 75, test_1's binary_logloss: 0.03881279242608756, \n",
      "Iteration: 75, test_1's auc: 0.9880890175519768\n",
      "Iteration: 76, test_1's binary_logloss: 0.03879749523546048, \n",
      "Iteration: 76, test_1's auc: 0.9881166528972565\n",
      "Iteration: 77, test_1's binary_logloss: 0.038642766615873785, \n",
      "Iteration: 77, test_1's auc: 0.9882107507114768\n",
      "Iteration: 78, test_1's binary_logloss: 0.03861536898376936, \n",
      "Iteration: 78, test_1's auc: 0.988237293913734\n",
      "Iteration: 79, test_1's binary_logloss: 0.038585146875499805, \n",
      "Iteration: 79, test_1's auc: 0.9882705579383616\n",
      "Iteration: 80, test_1's binary_logloss: 0.03858260272986839, \n",
      "Iteration: 80, test_1's auc: 0.9882857166201736\n",
      "Iteration: 81, test_1's binary_logloss: 0.03841970182833432, \n",
      "Iteration: 81, test_1's auc: 0.9883811267709809\n",
      "Iteration: 82, test_1's binary_logloss: 0.038354174484535764, \n",
      "Iteration: 82, test_1's auc: 0.9884195267573876\n",
      "Iteration: 83, test_1's binary_logloss: 0.038363909524125446, \n",
      "Iteration: 83, test_1's auc: 0.9884360534283755\n",
      "Iteration: 84, test_1's binary_logloss: 0.038263000673427916, \n",
      "Iteration: 84, test_1's auc: 0.9885030241556236\n",
      "Iteration: 85, test_1's binary_logloss: 0.03817753577868559, \n",
      "Iteration: 85, test_1's auc: 0.988564896345863\n",
      "Iteration: 86, test_1's binary_logloss: 0.03816054602152793, \n",
      "Iteration: 86, test_1's auc: 0.9885904458007199\n",
      "Iteration: 87, test_1's binary_logloss: 0.03780171737586941, \n",
      "Iteration: 87, test_1's auc: 0.9887238813108528\n",
      "Iteration: 88, test_1's binary_logloss: 0.03777392569700238, \n",
      "Iteration: 88, test_1's auc: 0.9887665660438385\n",
      "Iteration: 89, test_1's binary_logloss: 0.03769737842911226, \n",
      "Iteration: 89, test_1's auc: 0.9888144462758645\n",
      "Iteration: 90, test_1's binary_logloss: 0.03735665823367682, \n",
      "Iteration: 90, test_1's auc: 0.9889327957687009\n",
      "Iteration: 91, test_1's binary_logloss: 0.0373376131947967, \n",
      "Iteration: 91, test_1's auc: 0.9889583231788723\n",
      "Iteration: 92, test_1's binary_logloss: 0.037090280746559345, \n",
      "Iteration: 92, test_1's auc: 0.9890995900681463\n",
      "Iteration: 93, test_1's binary_logloss: 0.03684566298251666, \n",
      "Iteration: 93, test_1's auc: 0.9892012747784473\n",
      "Iteration: 94, test_1's binary_logloss: 0.03662853796561348, \n",
      "Iteration: 94, test_1's auc: 0.9892932604697342\n",
      "Iteration: 95, test_1's binary_logloss: 0.03656802731749602, \n",
      "Iteration: 95, test_1's auc: 0.9893383106580294\n",
      "Iteration: 96, test_1's binary_logloss: 0.03635282271410436, \n",
      "Iteration: 96, test_1's auc: 0.9894402920757543\n",
      "Iteration: 97, test_1's binary_logloss: 0.036129828377523904, \n",
      "Iteration: 97, test_1's auc: 0.9895078945249867\n",
      "Iteration: 98, test_1's binary_logloss: 0.03592427127443341, \n",
      "Iteration: 98, test_1's auc: 0.9895966066154086\n",
      "Iteration: 99, test_1's binary_logloss: 0.036030345921510554, \n",
      "Iteration: 99, test_1's auc: 0.9896206510825676\n",
      "Iteration: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 09:53:40 Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100, test_1's binary_logloss: 0.03591585746322649, \n",
      "Iteration: 100, test_1's auc: 0.9896685749685804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 09:53:42 not logging split losses\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 09:53:42 predicting training explicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 09:53:55 predicting training implicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 09:54:01 predicting training negative\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 09:54:04 predicting training ptw\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 09:54:10 predicting validation explicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 09:54:11 saving chunk 1 out of 1 (15118941 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:15\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 09:54:42 predicting validation implicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 09:54:42 saving chunk 1 out of 1 (9581039 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 09:55:06 predicting validation negative\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 09:55:07 saving chunk 1 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 09:56:17 saving chunk 2 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 09:57:29 saving chunk 3 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 09:58:40 saving chunk 4 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 09:59:50 saving chunk 5 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:00:59 saving chunk 6 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:02:08 saving chunk 7 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:03:16 saving chunk 8 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:04:25 saving chunk 9 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:20\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:05:06 predicting validation ptw\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:05:07 saving chunk 1 out of 1 (8205676 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:05:29 predicting test explicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:05:30 saving chunk 1 out of 1 (15121362 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:15\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:06:01 predicting test implicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:06:01 saving chunk 1 out of 1 (9573324 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:06:25 predicting test negative\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:06:26 saving chunk 1 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:07:38 saving chunk 2 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:08:50 saving chunk 3 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:10:00 saving chunk 4 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:13:30 saving chunk 7 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:14:38 saving chunk 8 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:15:47 saving chunk 9 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:19\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:16:29 predicting test ptw\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:16:29 saving chunk 1 out of 1 (8208159 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    [\n",
    "        explicit_raw_alphas\n",
    "        implicit_raw_alphas\n",
    "        nondirectional_raw_alphas\n",
    "        [\"LinearExplicit\", \"LinearImplicit\"]\n",
    "    ],\n",
    "    String[],\n",
    "    [\"implicit\", \"negative\"],\n",
    "    true,\n",
    "    \"validation\",\n",
    "    false,\n",
    "    \"NonlinearImplicit\";\n",
    "    λ = nothing,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdba16d7-658e-488e-b076-ef3700d5e9b7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:16:57 getting features for implicit, validation\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:17:18 getting features for negative, validation\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 (13.27 ns/it)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 22233206, number of negative: 379124361\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.923311 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 401357567, number of used features: 11\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.055395 -> initscore=-2.836277\n",
      "[LightGBM] [Info] Start training from score -2.836277\n",
      "Iteration: 1, test_1's binary_logloss: 0.19239608215182882, \n",
      "Iteration: 1, test_1's auc: 0.9046994451908371\n",
      "Iteration: 2, test_1's binary_logloss: 0.1829215863004198, \n",
      "Iteration: 2, test_1's auc: 0.9083165568685627\n",
      "Iteration: 3, test_1's binary_logloss: 0.17477825718508067, \n",
      "Iteration: 3, test_1's auc: 0.9113320057089125\n",
      "Iteration: 4, test_1's binary_logloss: 0.1509166424453064, \n",
      "Iteration: 4, test_1's auc: 0.9400486664703498\n",
      "Iteration: 5, test_1's binary_logloss: 0.1466387189645596, \n",
      "Iteration: 5, test_1's auc: 0.9400904578988493\n",
      "Iteration: 6, test_1's binary_logloss: 0.13211252322324485, \n",
      "Iteration: 6, test_1's auc: 0.9509694116473878\n",
      "Iteration: 7, test_1's binary_logloss: 0.129124717478998, \n",
      "Iteration: 7, test_1's auc: 0.9509100155628749\n",
      "Iteration: 8, test_1's binary_logloss: 0.1183182332175354, \n",
      "Iteration: 8, test_1's auc: 0.9571802473731531\n",
      "Iteration: 9, test_1's binary_logloss: 0.11028434015610508, \n",
      "Iteration: 9, test_1's auc: 0.9615148144619401\n",
      "Iteration: 10, test_1's binary_logloss: 0.10404242532945636, \n",
      "Iteration: 10, test_1's auc: 0.9636108782082291\n",
      "Iteration: 11, test_1's binary_logloss: 0.10198181177976648, \n",
      "Iteration: 11, test_1's auc: 0.9635577416627275\n",
      "Iteration: 12, test_1's binary_logloss: 0.10054538425852766, \n",
      "Iteration: 12, test_1's auc: 0.963520091552883\n",
      "Iteration: 13, test_1's binary_logloss: 0.09921756542447022, \n",
      "Iteration: 13, test_1's auc: 0.9633812157109191\n",
      "Iteration: 14, test_1's binary_logloss: 0.09296471038315154, \n",
      "Iteration: 14, test_1's auc: 0.966518165632102\n",
      "Iteration: 15, test_1's binary_logloss: 0.0881964764720847, \n",
      "Iteration: 15, test_1's auc: 0.968523039600285\n",
      "Iteration: 16, test_1's binary_logloss: 0.08704187245186275, \n",
      "Iteration: 16, test_1's auc: 0.9685799517683481\n",
      "Iteration: 17, test_1's binary_logloss: 0.08625028180262137, \n",
      "Iteration: 17, test_1's auc: 0.9685767364839891\n",
      "Iteration: 18, test_1's binary_logloss: 0.08393720813409772, \n",
      "Iteration: 18, test_1's auc: 0.9692752965983747\n",
      "Iteration: 19, test_1's binary_logloss: 0.07949539564441244, \n",
      "Iteration: 19, test_1's auc: 0.971323357945759\n",
      "Iteration: 20, test_1's binary_logloss: 0.07542222312852342, \n",
      "Iteration: 20, test_1's auc: 0.9732556540635684\n",
      "Iteration: 21, test_1's binary_logloss: 0.07486126712589909, \n",
      "Iteration: 21, test_1's auc: 0.973269061441286\n",
      "Iteration: 22, test_1's binary_logloss: 0.07217909478523248, \n",
      "Iteration: 22, test_1's auc: 0.9741342985826961\n",
      "Iteration: 23, test_1's binary_logloss: 0.07171477978275408, \n",
      "Iteration: 23, test_1's auc: 0.9741865128040575\n",
      "Iteration: 24, test_1's binary_logloss: 0.06856652103668028, \n",
      "Iteration: 24, test_1's auc: 0.9754638488420919\n",
      "Iteration: 25, test_1's binary_logloss: 0.0681561859130413, \n",
      "Iteration: 25, test_1's auc: 0.9755277782651126\n",
      "Iteration: 26, test_1's binary_logloss: 0.06780821044044173, \n",
      "Iteration: 26, test_1's auc: 0.9755918438645889\n",
      "Iteration: 27, test_1's binary_logloss: 0.06503952585718778, \n",
      "Iteration: 27, test_1's auc: 0.9767203304748439\n",
      "Iteration: 28, test_1's binary_logloss: 0.06256514609833766, \n",
      "Iteration: 28, test_1's auc: 0.9777030338197719\n",
      "Iteration: 29, test_1's binary_logloss: 0.060341504063240875, \n",
      "Iteration: 29, test_1's auc: 0.9785474684265081\n",
      "Iteration: 30, test_1's binary_logloss: 0.06010250723536511, \n",
      "Iteration: 30, test_1's auc: 0.9786299380268706\n",
      "Iteration: 31, test_1's binary_logloss: 0.05987682624425178, \n",
      "Iteration: 31, test_1's auc: 0.9786762092445938\n",
      "Iteration: 32, test_1's binary_logloss: 0.05972495821998413, \n",
      "Iteration: 32, test_1's auc: 0.9787175535703311\n",
      "Iteration: 33, test_1's binary_logloss: 0.05889831100522438, \n",
      "Iteration: 33, test_1's auc: 0.979081494626193\n",
      "Iteration: 34, test_1's binary_logloss: 0.05742423378202106, \n",
      "Iteration: 34, test_1's auc: 0.9795794049311831\n",
      "Iteration: 35, test_1's binary_logloss: 0.055633983001204305, \n",
      "Iteration: 35, test_1's auc: 0.9803440989102763\n",
      "Iteration: 36, test_1's binary_logloss: 0.0539826187828661, \n",
      "Iteration: 36, test_1's auc: 0.9810744258054553\n",
      "Iteration: 37, test_1's binary_logloss: 0.05249698354009708, \n",
      "Iteration: 37, test_1's auc: 0.9816775628232046\n",
      "Iteration: 38, test_1's binary_logloss: 0.05113320754397376, \n",
      "Iteration: 38, test_1's auc: 0.9822140172637043\n",
      "Iteration: 39, test_1's binary_logloss: 0.05035319395875597, \n",
      "Iteration: 39, test_1's auc: 0.9825438164611024\n",
      "Iteration: 40, test_1's binary_logloss: 0.04923223010793038, \n",
      "Iteration: 40, test_1's auc: 0.9829827959580628\n",
      "Iteration: 41, test_1's binary_logloss: 0.04892474758251915, \n",
      "Iteration: 41, test_1's auc: 0.9831968033294283\n",
      "Iteration: 42, test_1's binary_logloss: 0.048219828555284096, \n",
      "Iteration: 42, test_1's auc: 0.9835015450682043\n",
      "Iteration: 43, test_1's binary_logloss: 0.04810839705845774, \n",
      "Iteration: 43, test_1's auc: 0.983601443280889\n",
      "Iteration: 44, test_1's binary_logloss: 0.04800270655698493, \n",
      "Iteration: 44, test_1's auc: 0.9836807017797238\n",
      "Iteration: 45, test_1's binary_logloss: 0.04700374589736986, \n",
      "Iteration: 45, test_1's auc: 0.9841024818162368\n",
      "Iteration: 46, test_1's binary_logloss: 0.046910615372778935, \n",
      "Iteration: 46, test_1's auc: 0.9841780057677386\n",
      "Iteration: 47, test_1's binary_logloss: 0.04683248769085636, \n",
      "Iteration: 47, test_1's auc: 0.9842376943946973\n",
      "Iteration: 48, test_1's binary_logloss: 0.04598095298142575, \n",
      "Iteration: 48, test_1's auc: 0.9845543615313194\n",
      "Iteration: 49, test_1's binary_logloss: 0.04591189975877437, \n",
      "Iteration: 49, test_1's auc: 0.9846217917868978\n",
      "Iteration: 50, test_1's binary_logloss: 0.045858603037622764, \n",
      "Iteration: 50, test_1's auc: 0.9846663318452541\n",
      "Iteration: 51, test_1's binary_logloss: 0.04532658293454293, \n",
      "Iteration: 51, test_1's auc: 0.9848635346979925\n",
      "Iteration: 52, test_1's binary_logloss: 0.04522894990497298, \n",
      "Iteration: 52, test_1's auc: 0.9849216797592273\n",
      "Iteration: 53, test_1's binary_logloss: 0.04501231637681453, \n",
      "Iteration: 53, test_1's auc: 0.9850891896161318\n",
      "Iteration: 54, test_1's binary_logloss: 0.04422006003358029, \n",
      "Iteration: 54, test_1's auc: 0.9853979199298399\n",
      "Iteration: 55, test_1's binary_logloss: 0.04358179594694212, \n",
      "Iteration: 55, test_1's auc: 0.9856365061138025\n",
      "Iteration: 56, test_1's binary_logloss: 0.04351900758323473, \n",
      "Iteration: 56, test_1's auc: 0.9857015453733609\n",
      "Iteration: 57, test_1's binary_logloss: 0.04334966756870592, \n",
      "Iteration: 57, test_1's auc: 0.9857985245769271\n",
      "Iteration: 58, test_1's binary_logloss: 0.04271219297619626, \n",
      "Iteration: 58, test_1's auc: 0.9860815376376704\n",
      "Iteration: 59, test_1's binary_logloss: 0.04266769506624031, \n",
      "Iteration: 59, test_1's auc: 0.9861318099326495\n",
      "Iteration: 60, test_1's binary_logloss: 0.04207495912234399, \n",
      "Iteration: 60, test_1's auc: 0.9863645142354651\n",
      "Iteration: 61, test_1's binary_logloss: 0.041589672419666546, \n",
      "Iteration: 61, test_1's auc: 0.9865856336861322\n",
      "Iteration: 62, test_1's binary_logloss: 0.04153422203868543, \n",
      "Iteration: 62, test_1's auc: 0.9866518608715965\n",
      "Iteration: 63, test_1's binary_logloss: 0.04109081006300759, \n",
      "Iteration: 63, test_1's auc: 0.9868279670956059\n",
      "Iteration: 64, test_1's binary_logloss: 0.04104106321004755, \n",
      "Iteration: 64, test_1's auc: 0.9868882848932778\n",
      "Iteration: 65, test_1's binary_logloss: 0.0407394873669284, \n",
      "Iteration: 65, test_1's auc: 0.987028617937009\n",
      "Iteration: 66, test_1's binary_logloss: 0.04064624272366448, \n",
      "Iteration: 66, test_1's auc: 0.9870954149847528\n",
      "Iteration: 67, test_1's binary_logloss: 0.04020537550400942, \n",
      "Iteration: 67, test_1's auc: 0.9872961932516676\n",
      "Iteration: 68, test_1's binary_logloss: 0.04017011289873966, \n",
      "Iteration: 68, test_1's auc: 0.9873449310147573\n",
      "Iteration: 69, test_1's binary_logloss: 0.04012074461957852, \n",
      "Iteration: 69, test_1's auc: 0.9873960735789332\n",
      "Iteration: 70, test_1's binary_logloss: 0.0396827692417525, \n",
      "Iteration: 70, test_1's auc: 0.9875816818754025\n",
      "Iteration: 71, test_1's binary_logloss: 0.03942273911999508, \n",
      "Iteration: 71, test_1's auc: 0.9877248366655355\n",
      "Iteration: 72, test_1's binary_logloss: 0.03938624547580915, \n",
      "Iteration: 72, test_1's auc: 0.9877656001613179\n",
      "Iteration: 73, test_1's binary_logloss: 0.039121398555269485, \n",
      "Iteration: 73, test_1's auc: 0.9879246310580378\n",
      "Iteration: 74, test_1's binary_logloss: 0.03908871487490176, \n",
      "Iteration: 74, test_1's auc: 0.987950076777729\n",
      "Iteration: 75, test_1's binary_logloss: 0.038812792426087525, \n",
      "Iteration: 75, test_1's auc: 0.9880890175519768\n",
      "Iteration: 76, test_1's binary_logloss: 0.03879749523546061, \n",
      "Iteration: 76, test_1's auc: 0.9881166528972565\n",
      "Iteration: 77, test_1's binary_logloss: 0.03864276661587392, \n",
      "Iteration: 77, test_1's auc: 0.9882107507114768\n",
      "Iteration: 78, test_1's binary_logloss: 0.03861536898376951, \n",
      "Iteration: 78, test_1's auc: 0.988237293913734\n",
      "Iteration: 79, test_1's binary_logloss: 0.038585146875499944, \n",
      "Iteration: 79, test_1's auc: 0.9882705579383616\n",
      "Iteration: 80, test_1's binary_logloss: 0.03858260272986851, \n",
      "Iteration: 80, test_1's auc: 0.9882857166201736\n",
      "Iteration: 81, test_1's binary_logloss: 0.038419701828334436, \n",
      "Iteration: 81, test_1's auc: 0.9883811267709809\n",
      "Iteration: 82, test_1's binary_logloss: 0.03835417448453592, \n",
      "Iteration: 82, test_1's auc: 0.9884195267573876\n",
      "Iteration: 83, test_1's binary_logloss: 0.0383639095241256, \n",
      "Iteration: 83, test_1's auc: 0.9884360534283755\n",
      "Iteration: 84, test_1's binary_logloss: 0.03826300067342801, \n",
      "Iteration: 84, test_1's auc: 0.9885030241556236\n",
      "Iteration: 85, test_1's binary_logloss: 0.03817753577868569, \n",
      "Iteration: 85, test_1's auc: 0.988564896345863\n",
      "Iteration: 86, test_1's binary_logloss: 0.038160546021528005, \n",
      "Iteration: 86, test_1's auc: 0.9885904458007199\n",
      "Iteration: 87, test_1's binary_logloss: 0.03780171737586959, \n",
      "Iteration: 87, test_1's auc: 0.9887238813108528\n",
      "Iteration: 88, test_1's binary_logloss: 0.03777392569700253, \n",
      "Iteration: 88, test_1's auc: 0.9887665660438385\n",
      "Iteration: 89, test_1's binary_logloss: 0.037697378429112444, \n",
      "Iteration: 89, test_1's auc: 0.9888144462758645\n",
      "Iteration: 90, test_1's binary_logloss: 0.03735665823367701, \n",
      "Iteration: 90, test_1's auc: 0.9889327957687009\n",
      "Iteration: 91, test_1's binary_logloss: 0.03733761319479686, \n",
      "Iteration: 91, test_1's auc: 0.9889583231788723\n",
      "Iteration: 92, test_1's binary_logloss: 0.03709028074655945, \n",
      "Iteration: 92, test_1's auc: 0.9890995900681463\n",
      "Iteration: 93, test_1's binary_logloss: 0.036845662982516854, \n",
      "Iteration: 93, test_1's auc: 0.9892012747784473\n",
      "Iteration: 94, test_1's binary_logloss: 0.036628537965613606, \n",
      "Iteration: 94, test_1's auc: 0.9892932604697342\n",
      "Iteration: 95, test_1's binary_logloss: 0.036568027317495665, \n",
      "Iteration: 95, test_1's auc: 0.9893383106580294\n",
      "Iteration: 96, test_1's binary_logloss: 0.03635282271410399, \n",
      "Iteration: 96, test_1's auc: 0.9894402920757641\n",
      "Iteration: 97, test_1's binary_logloss: 0.03612982837752362, \n",
      "Iteration: 97, test_1's auc: 0.9895078945249867\n",
      "Iteration: 98, test_1's binary_logloss: 0.03592427127443313, \n",
      "Iteration: 98, test_1's auc: 0.9895966066154086\n",
      "Iteration: 99, test_1's binary_logloss: 0.03603034592151031, \n",
      "Iteration: 99, test_1's auc: 0.9896206510825676\n",
      "Iteration: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:49:21 Saving model...\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:49:21 not logging split losses\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:49:21 predicting training explicit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100, test_1's binary_logloss: 0.03591585746322624, \n",
      "Iteration: 100, test_1's auc: 0.9896685749685804\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:49:34 predicting training implicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:49:39 predicting training negative\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:49:42 predicting training ptw\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:49:48 predicting validation explicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:49:49 saving chunk 1 out of 1 (15118941 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:15\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:50:20 predicting validation implicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:50:20 saving chunk 1 out of 1 (9581039 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:50:45 predicting validation negative\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:50:46 saving chunk 1 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:51:56 saving chunk 2 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:53:07 saving chunk 3 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:54:19 saving chunk 4 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:55:30 saving chunk 5 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:56:39 saving chunk 6 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:57:48 saving chunk 7 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 10:58:57 saving chunk 8 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:00:07 saving chunk 9 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:20\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:00:48 predicting validation ptw\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:00:49 saving chunk 1 out of 1 (8205676 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:01:11 predicting test explicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:01:12 saving chunk 1 out of 1 (15121362 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:15\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:01:43 predicting test implicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:01:44 saving chunk 1 out of 1 (9573324 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:02:07 predicting test negative\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:02:09 saving chunk 1 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:03:21 saving chunk 2 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:04:33 saving chunk 3 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:05:44 saving chunk 4 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:48\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:06:56 saving chunk 5 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:10:25 saving chunk 8 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:47\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:11:36 saving chunk 9 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:20\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:12:18 predicting test ptw\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:12:19 saving chunk 1 out of 1 (8208159 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    [\n",
    "        explicit_raw_alphas\n",
    "        implicit_raw_alphas\n",
    "        nondirectional_raw_alphas\n",
    "        [\"LinearExplicit\", \"LinearImplicit\"]\n",
    "    ],\n",
    "    String[],\n",
    "    [\"implicit\", \"negative\"],\n",
    "    true,\n",
    "    \"validation\",\n",
    "    false,\n",
    "    \"NonlinearImplicit\";\n",
    "    λ = nothing,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "36e4e38f-c51c-49b1-9c18-029b74d2752b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:12:47 getting features for ptw, validation\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:13:01 getting features for negative, validation\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 8.54 ns/it)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 7384619, number of negative: 379124361\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 1.062880 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3568\n",
      "[LightGBM] [Info] Number of data points in the train set: 386508980, number of used features: 14\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.019106 -> initscore=-3.938465\n",
      "[LightGBM] [Info] Start training from score -3.938465\n",
      "Iteration: 1, test_1's binary_logloss: 0.07072842549009997, \n",
      "Iteration: 1, test_1's auc: 0.9134776396982345\n",
      "Iteration: 2, test_1's binary_logloss: 0.06790714537838037, \n",
      "Iteration: 2, test_1's auc: 0.9293507940841982\n",
      "Iteration: 3, test_1's binary_logloss: 0.06524528241978036, \n",
      "Iteration: 3, test_1's auc: 0.9349462144520488\n",
      "Iteration: 4, test_1's binary_logloss: 0.06313833946240294, \n",
      "Iteration: 4, test_1's auc: 0.9369017367671848\n",
      "Iteration: 5, test_1's binary_logloss: 0.061024832076345716, \n",
      "Iteration: 5, test_1's auc: 0.9388525874862911\n",
      "Iteration: 6, test_1's binary_logloss: 0.05938045660302894, \n",
      "Iteration: 6, test_1's auc: 0.9400470080404205\n",
      "Iteration: 7, test_1's binary_logloss: 0.05756550764240875, \n",
      "Iteration: 7, test_1's auc: 0.941435902625397\n",
      "Iteration: 8, test_1's binary_logloss: 0.05656244877383038, \n",
      "Iteration: 8, test_1's auc: 0.9423797261315418\n",
      "Iteration: 9, test_1's binary_logloss: 0.05553598390857048, \n",
      "Iteration: 9, test_1's auc: 0.943003225402447\n",
      "Iteration: 10, test_1's binary_logloss: 0.05473609231484249, \n",
      "Iteration: 10, test_1's auc: 0.9436012618924216\n",
      "Iteration: 11, test_1's binary_logloss: 0.05384422470120139, \n",
      "Iteration: 11, test_1's auc: 0.9442491100910387\n",
      "Iteration: 12, test_1's binary_logloss: 0.05303231646177104, \n",
      "Iteration: 12, test_1's auc: 0.9447737547824013\n",
      "Iteration: 13, test_1's binary_logloss: 0.05218195147682856, \n",
      "Iteration: 13, test_1's auc: 0.9455885853946744\n",
      "Iteration: 14, test_1's binary_logloss: 0.05156871963586777, \n",
      "Iteration: 14, test_1's auc: 0.9459232986588593\n",
      "Iteration: 15, test_1's binary_logloss: 0.051191677725458455, \n",
      "Iteration: 15, test_1's auc: 0.946400065995476\n",
      "Iteration: 16, test_1's binary_logloss: 0.05064889834699268, \n",
      "Iteration: 16, test_1's auc: 0.9467999747035388\n",
      "Iteration: 17, test_1's binary_logloss: 0.05016871354149115, \n",
      "Iteration: 17, test_1's auc: 0.9471603928438639\n",
      "Iteration: 18, test_1's binary_logloss: 0.049395810647697706, \n",
      "Iteration: 18, test_1's auc: 0.9478961340840061\n",
      "Iteration: 19, test_1's binary_logloss: 0.048965555287378226, \n",
      "Iteration: 19, test_1's auc: 0.9484094366394173\n",
      "Iteration: 20, test_1's binary_logloss: 0.04863586151911732, \n",
      "Iteration: 20, test_1's auc: 0.9488078168504228\n",
      "Iteration: 21, test_1's binary_logloss: 0.04834646404534781, \n",
      "Iteration: 21, test_1's auc: 0.9490177888136374\n",
      "Iteration: 22, test_1's binary_logloss: 0.04770961810942562, \n",
      "Iteration: 22, test_1's auc: 0.9496490572847033\n",
      "Iteration: 23, test_1's binary_logloss: 0.04750888362135342, \n",
      "Iteration: 23, test_1's auc: 0.9499828443005329\n",
      "Iteration: 24, test_1's binary_logloss: 0.04731819165082468, \n",
      "Iteration: 24, test_1's auc: 0.9502656577569151\n",
      "Iteration: 25, test_1's binary_logloss: 0.04711829275771536, \n",
      "Iteration: 25, test_1's auc: 0.9504463119213082\n",
      "Iteration: 26, test_1's binary_logloss: 0.04682757233998788, \n",
      "Iteration: 26, test_1's auc: 0.9507291193170763\n",
      "Iteration: 27, test_1's binary_logloss: 0.04651457445767785, \n",
      "Iteration: 27, test_1's auc: 0.9511179899008001\n",
      "Iteration: 28, test_1's binary_logloss: 0.0463735084345306, \n",
      "Iteration: 28, test_1's auc: 0.9513019233300555\n",
      "Iteration: 29, test_1's binary_logloss: 0.04621511493912906, \n",
      "Iteration: 29, test_1's auc: 0.9515283972032966\n",
      "Iteration: 30, test_1's binary_logloss: 0.046019326891336594, \n",
      "Iteration: 30, test_1's auc: 0.9518811209117702\n",
      "Iteration: 31, test_1's binary_logloss: 0.04576578218019577, \n",
      "Iteration: 31, test_1's auc: 0.9522220043082062\n",
      "Iteration: 32, test_1's binary_logloss: 0.045631094144480445, \n",
      "Iteration: 32, test_1's auc: 0.95237577621615\n",
      "Iteration: 33, test_1's binary_logloss: 0.04554067183790703, \n",
      "Iteration: 33, test_1's auc: 0.9524682515439918\n",
      "Iteration: 34, test_1's binary_logloss: 0.04521542638684729, \n",
      "Iteration: 34, test_1's auc: 0.9527988906574996\n",
      "Iteration: 35, test_1's binary_logloss: 0.04511889552754944, \n",
      "Iteration: 35, test_1's auc: 0.9530411455039257\n",
      "Iteration: Iteration: 43, test_1's binary_logloss: 0.043568841474583994, \n",
      "Iteration: 43, test_1's auc: 0.9553047562748214\n",
      "Iteration: 44, test_1's binary_logloss: 0.043502005991812864, \n",
      "Iteration: 44, test_1's auc: 0.9554156275760363\n",
      "Iteration: 45, test_1's binary_logloss: 0.04329748132993229, \n",
      "Iteration: 45, test_1's auc: 0.9558429088884701\n",
      "Iteration: 46, test_1's binary_logloss: 0.043037125741151594, \n",
      "Iteration: 46, test_1's auc: 0.9562091805929426\n",
      "Iteration: 47, test_1's binary_logloss: 0.0428478103481451, \n",
      "Iteration: 47, test_1's auc: 0.956404501388678\n",
      "Iteration: 48, test_1's binary_logloss: 0.042721907081654, \n",
      "Iteration: 48, test_1's auc: 0.956711214200208\n",
      "Iteration: 49, test_1's binary_logloss: 0.042452177593868164, \n",
      "Iteration: 49, test_1's auc: 0.9569925444030848\n",
      "Iteration: 50, test_1's binary_logloss: 0.0422681877801878, \n",
      "Iteration: 50, test_1's auc: 0.9576376273966688\n",
      "Iteration: 51, test_1's binary_logloss: 0.04215204760327615, \n",
      "Iteration: 51, test_1's auc: 0.957835965636261\n",
      "Iteration: 52, test_1's binary_logloss: 0.04209756730588538, \n",
      "Iteration: 52, test_1's auc: 0.9579193623143349\n",
      "Iteration: 53, test_1's binary_logloss: 0.041865202704449676, \n",
      "Iteration: 53, test_1's auc: 0.9582808204630778\n",
      "Iteration: 54, test_1's binary_logloss: 0.04170577829143393, \n",
      "Iteration: 54, test_1's auc: 0.9588130749855746\n",
      "Iteration: 55, test_1's binary_logloss: 0.041539706320312654, \n",
      "Iteration: 55, test_1's auc: 0.9592364583510686\n",
      "Iteration: 56, test_1's binary_logloss: 0.04143203951985279, \n",
      "Iteration: 56, test_1's auc: 0.9596184737090037\n",
      "Iteration: 57, test_1's binary_logloss: 0.041191928270824504, \n",
      "Iteration: 57, test_1's auc: 0.9600172932633749\n",
      "Iteration: 58, test_1's binary_logloss: 0.041131978912517554, \n",
      "Iteration: 58, test_1's auc: 0.960111156052068\n",
      "Iteration: 59, test_1's binary_logloss: 0.04109855666020117, \n",
      "Iteration: 59, test_1's auc: 0.9601757769900287\n",
      "Iteration: 60, test_1's binary_logloss: 0.041068463270604344, \n",
      "Iteration: 60, test_1's auc: 0.9602596823841707\n",
      "Iteration: 61, test_1's binary_logloss: 0.04091652924984505, \n",
      "Iteration: 61, test_1's auc: 0.9606967184650193\n",
      "Iteration: 62, test_1's binary_logloss: 0.040813170483811216, \n",
      "Iteration: 62, test_1's auc: 0.9607980265326223\n",
      "Iteration: 63, test_1's binary_logloss: 0.04071685113898933, \n",
      "Iteration: 63, test_1's auc: 0.9609100386572086\n",
      "Iteration: 64, test_1's binary_logloss: 0.0406738226919655, \n",
      "Iteration: 64, test_1's auc: 0.9609968047268335\n",
      "Iteration: 65, test_1's binary_logloss: 0.04060602106916856, \n",
      "Iteration: 65, test_1's auc: 0.9611741479824988\n",
      "Iteration: 66, test_1's binary_logloss: 0.04044434075032634, \n",
      "Iteration: 66, test_1's auc: 0.9614320804163672\n",
      "Iteration: 67, test_1's binary_logloss: 0.040311607613135736, \n",
      "Iteration: 67, test_1's auc: 0.9616729543181848\n",
      "Iteration: 68, test_1's binary_logloss: 0.04020046385333616, \n",
      "Iteration: 68, test_1's auc: 0.9622440319711862\n",
      "Iteration: 69, test_1's binary_logloss: 0.04013089528971251, \n",
      "Iteration: 69, test_1's auc: 0.9623768110808998\n",
      "Iteration: 70, test_1's binary_logloss: 0.040003846011119275, \n",
      "Iteration: 70, test_1's auc: 0.9627067063988638\n",
      "Iteration: 71, test_1's binary_logloss: 0.03976888635019976, \n",
      "Iteration: 71, test_1's auc: 0.9630061380442785\n",
      "Iteration: 72, test_1's binary_logloss: 0.03971825981262721, \n",
      "Iteration: 72, test_1's auc: 0.9630889935635065\n",
      "Iteration: 73, test_1's binary_logloss: 0.039656416459721046, \n",
      "Iteration: 73, test_1's auc: 0.9632141843227149\n",
      "Iteration: 74, test_1's binary_logloss: 0.03947139416097653, \n",
      "Iteration: 74, test_1's auc: 0.9633892802964542\n",
      "Iteration: 75, test_1's binary_logloss: 0.03938442749274275, \n",
      "Iteration: 75, test_1's auc: 0.9636194017379823\n",
      "Iteration: 76, test_1's binary_logloss: 0.03933856046148061, \n",
      "Iteration: 76, test_1's auc: 0.9636879676320479\n",
      "Iteration: 77, test_1's binary_logloss: 0.03925340236400852, \n",
      "Iteration: 77, test_1's auc: 0.9639736877943588\n",
      "Iteration: 78, test_1's binary_logloss: 0.0392175763013713, \n",
      "Iteration: 78, test_1's auc: 0.964045177264055\n",
      "Iteration: 79, test_1's binary_logloss: 0.03901541579677319, \n",
      "Iteration: 79, test_1's auc: 0.9642707582475062\n",
      "Iteration: 80, test_1's binary_logloss: 0.038934230032529285, \n",
      "Iteration: 80, test_1's auc: 0.9645079981519958\n",
      "Iteration: 81, test_1's binary_logloss: 0.03888898884744812, \n",
      "Iteration: 81, test_1's auc: 0.964596449783603\n",
      "Iteration: 82, test_1's binary_logloss: 0.03884724419882956, \n",
      "Iteration: 82, test_1's auc: 0.9646882964861293\n",
      "Iteration: 83, test_1's binary_logloss: 0.03881656218282513, \n",
      "Iteration: 83, test_1's auc: 0.964862141367687\n",
      "Iteration: 84, test_1's binary_logloss: 0.03876765595247856, \n",
      "Iteration: 84, test_1's auc: 0.9649485867499495\n",
      "Iteration: 85, test_1's binary_logloss: 0.03866085164351655, \n",
      "Iteration: 85, test_1's auc: 0.9653764529779033\n",
      "Iteration: 86, test_1's binary_logloss: 0.038616257512682, \n",
      "Iteration: 86, test_1's auc: 0.9654620503540372\n",
      "Iteration: 87, test_1's binary_logloss: 0.03849077328247311, \n",
      "Iteration: 87, test_1's auc: 0.9655514365649039\n",
      "Iteration: 88, test_1's binary_logloss: 0.03846852327816391, \n",
      "Iteration: 88, test_1's auc: 0.9656045433657026\n",
      "Iteration: 89, test_1's binary_logloss: 0.038270203565517226, \n",
      "Iteration: 89, test_1's auc: 0.9658330062020573\n",
      "Iteration: 90, test_1's binary_logloss: 0.03817540827328971, \n",
      "Iteration: 90, test_1's auc: 0.965915209233128\n",
      "Iteration: 91, test_1's binary_logloss: 0.03811730684216601, \n",
      "Iteration: 91, test_1's auc: 0.9660018777960111\n",
      "Iteration: 92, test_1's binary_logloss: 0.03797091934032612, \n",
      "Iteration: 92, test_1's auc: 0.9662973638052799\n",
      "Iteration: 93, test_1's binary_logloss: 0.03788565688447793, \n",
      "Iteration: 93, test_1's auc: 0.9665880752019319\n",
      "Iteration: 94, test_1's binary_logloss: 0.037817100791431926, \n",
      "Iteration: 94, test_1's auc: 0.9666655592740211\n",
      "Iteration: 95, test_1's binary_logloss: 0.03778802555900089, \n",
      "Iteration: 95, test_1's auc: 0.9667286580344036\n",
      "Iteration: 96, test_1's binary_logloss: 0.03763444505380379, \n",
      "Iteration: 96, test_1's auc: 0.9669992846547175\n",
      "Iteration: 97, test_1's binary_logloss: 0.03754342014773697, \n",
      "Iteration: 97, test_1's auc: 0.9670997583724875\n",
      "Iteration: 98, test_1's binary_logloss: 0.03749420110976026, \n",
      "Iteration: 98, test_1's auc: 0.9671377097414429\n",
      "Iteration: 99, test_1's binary_logloss: 0.037392606910238844, \n",
      "Iteration: 99, test_1's auc: 0.9672323835017889\n",
      "Iteration: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:41:19 Saving model...\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:41:19 not logging split losses\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:41:19 predicting training explicit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100, test_1's binary_logloss: 0.037363916501775556, \n",
      "Iteration: 100, test_1's auc: 0.9672903338021819\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:41:33 predicting training implicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:41:38 predicting training negative\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:41:41 predicting training ptw\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:41:47 predicting validation explicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:41:48 saving chunk 1 out of 1 (15118941 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:15\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:42:20 predicting validation implicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:42:20 saving chunk 1 out of 1 (9581039 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:42:44 predicting validation negative\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:42:45 saving chunk 1 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:42\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:43:55 saving chunk 2 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:42\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:45:05 saving chunk 3 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:42\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:46:13 saving chunk 4 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:42\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:47:21 saving chunk 5 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:42\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:48:29 saving chunk 6 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:42\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:49:37 saving chunk 7 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:42\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:50:46 saving chunk 8 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:42\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:51:54 saving chunk 9 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:17\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:52:38 predicting validation ptw\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:52:38 saving chunk 1 out of 1 (8205676 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:53:01 predicting test explicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:53:02 saving chunk 1 out of 1 (15121362 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:15\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:53:33 predicting test implicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:53:34 saving chunk 1 out of 1 (9573324 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:53:57 predicting test negative\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:53:59 saving chunk 1 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:42\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:55:09 saving chunk 2 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:42\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:56:18 saving chunk 3 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:42\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:57:29 saving chunk 4 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:42\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:58:39 saving chunk 5 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:42\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 11:59:47 saving chunk 6 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:42\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:00:54 saving chunk 7 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:42\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:02:02 saving chunk 8 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:42\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:03:11 saving chunk 9 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:18\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:03:55 predicting test ptw\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:03:56 saving chunk 1 out of 1 (8208159 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    [\n",
    "        explicit_raw_alphas\n",
    "        implicit_raw_alphas\n",
    "        ptw_raw_alphas\n",
    "        nondirectional_raw_alphas\n",
    "        [\"LinearExplicit\", \"LinearImplicit\", \"LinearPtw\"]\n",
    "    ],\n",
    "    String[],\n",
    "    [\"ptw\", \"negative\"],\n",
    "    true,\n",
    "    \"validation\",\n",
    "    false,\n",
    "    \"NonlinearPtw\";\n",
    "    λ = nothing,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "517ce91a-bf09-446a-8be9-a7c5bbe0c0f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:04:24 getting features for explicit, validation\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.037368 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 13606482, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.003684\n",
      "Iteration: 1, test_1's l2: 1.7321795585014892\n",
      "Iteration: 2, test_1's l2: 1.7267967536467759\n",
      "Iteration: 3, test_1's l2: 1.722776555251156\n",
      "Iteration: 4, test_1's l2: 1.719385825889084\n",
      "Iteration: 5, test_1's l2: 1.716303067068894\n",
      "Iteration: 6, test_1's l2: 1.7139746776866192\n",
      "Iteration: 7, test_1's l2: 1.7115982011355282\n",
      "Iteration: 8, test_1's l2: 1.7101195872403416\n",
      "Iteration: 9, test_1's l2: 1.708333033804636\n",
      "Iteration: 10, test_1's l2: 1.7067528403152454\n",
      "Iteration: 11, test_1's l2: 1.7053511172442082\n",
      "Iteration: 12, test_1's l2: 1.7042280423890688\n",
      "Iteration: 13, test_1's l2: 1.7032866741392396\n",
      "Iteration: 14, test_1's l2: 1.7024353172097517\n",
      "Iteration: 15, test_1's l2: 1.701739421652151\n",
      "Iteration: 16, test_1's l2: 1.7013084352530745\n",
      "Iteration: 17, test_1's l2: 1.700864733605439\n",
      "Iteration: 18, test_1's l2: 1.700399802870319\n",
      "Iteration: 19, test_1's l2: 1.7000845301682834\n",
      "Iteration: 20, test_1's l2: 1.6995532637386814\n",
      "Iteration: 21, test_1's l2: 1.6992635555767095\n",
      "Iteration: 22, test_1's l2: 1.699084044435624\n",
      "Iteration: 23, test_1's l2: 1.6987869311842896\n",
      "Iteration: 24, test_1's l2: 1.6985251248107227\n",
      "Iteration: 25, test_1's l2: 1.6983251963766774\n",
      "Iteration: 26, test_1's l2: 1.698070633067335\n",
      "Iteration: 27, test_1's l2: 1.6978272376865462\n",
      "Iteration: 28, test_1's l2: 1.6977248755365424\n",
      "Iteration: 29, test_1's l2: 1.6975802374172484\n",
      "Iteration: 30, test_1's l2: 1.6974544013548403\n",
      "Iteration: 31, test_1's l2: 1.697337413191699\n",
      "Iteration: 32, test_1's l2: 1.6972073184401817\n",
      "Iteration: 33, test_1's l2: 1.697102171197306\n",
      "Iteration: 34, test_1's l2: 1.6968311435085819\n",
      "Iteration: 35, test_1's l2: 1.6969263567795094\n",
      "Iteration: 36, test_1's l2: 1.6970023289587997\n",
      "Iteration: 37, test_1's l2: 1.696968153119752\n",
      "Iteration: 38, test_1's l2: 1.6968898110053057\n",
      "Iteration: 39, test_1's l2: 1.6969158216475249\n",
      "Iteration: 40, test_1's l2: 1.6969184837250926\n",
      "Iteration: 41, test_1's l2: 1.6969769588558006\n",
      "Iteration: 42, test_1's l2: 1.6969376632850914\n",
      "Iteration: 43, test_1's l2: 1.696877973541191\n",
      "Early stopping at iteration 44, the best iteration round is 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:05:01 Saving model...\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:05:01 not logging split losses\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:05:01 predicting training explicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:05:10 predicting training implicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:05:14 predicting training negative\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:05:17 predicting training ptw\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:05:22 predicting validation explicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:05:22 saving chunk 1 out of 1 (15118941 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:04\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:05:39 predicting validation implicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:05:39 saving chunk 1 out of 1 (9581039 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:03\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:05:54 predicting validation negative\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:05:56 saving chunk 1 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:14\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:06:34 saving chunk 2 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:14\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:07:09 saving chunk 3 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:14\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:07:44 saving chunk 4 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:14\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:08:20 saving chunk 5 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:14\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:08:55 saving chunk 6 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:14\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:09:30 saving chunk 7 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:14\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:10:05 saving chunk 8 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:14\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:10:40 saving chunk 9 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:06\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:11:07 predicting validation ptw\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:11:07 saving chunk 1 out of 1 (8205676 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:11:23 predicting test explicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:11:24 saving chunk 1 out of 1 (15121362 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:03\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:11:43 predicting test implicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:11:43 saving chunk 1 out of 1 (9573324 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:03\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:12:00 predicting test negative\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:12:01 saving chunk 1 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:14\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:12:39 saving chunk 2 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:14\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:13:16 saving chunk 3 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:14\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:13:53 saving chunk 4 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:14\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:14:32 saving chunk 5 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:14\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:15:10 saving chunk 6 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:14\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:15:46 saving chunk 7 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:14\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:16:21 saving chunk 8 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:14\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:16:57 saving chunk 9 out of 9 (420927700 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:06\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:17:25 predicting test ptw\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:17:25 saving chunk 1 out of 1 (8208159 / 50000000)\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    [\n",
    "        explicit_raw_alphas\n",
    "        implicit_raw_alphas\n",
    "        nondirectional_raw_alphas\n",
    "        [\"LinearExplicit\", \"LinearImplicit\"]\n",
    "    ],\n",
    "    [\"LinearExplicit\"],\n",
    "    [\"explicit\"],\n",
    "    false,\n",
    "    \"validation\",\n",
    "    false,\n",
    "    \"NonlinearExplicit\";\n",
    "    λ = nothing,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4928ac14-f5c8-4119-9215-7e9f61e97cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function save_final_explicit_model()\n",
    "    function model(split::String, content::String; raw_splits = true)\n",
    "        @info \"saving $split $content\"\n",
    "        split_fn = raw_splits ? get_raw_split : get_split\n",
    "        alpha_fn = raw_splits ? read_raw_alpha : read_alpha\n",
    "        if split == \"training\"\n",
    "            return zeros(Float32, length(split_fn(split, content).user))\n",
    "        end\n",
    "        linear_split = alpha_fn(\"LinearExplicit\", split, content).rating\n",
    "        nonlinear_split = alpha_fn(\"NonlinearExplicit\", split, content).rating\n",
    "        linear_split + nonlinear_split\n",
    "    end\n",
    "    write_params(Dict(\"alphas\" => [\"LinearExplicit\", \"NonlinearExplicit\"]), \"Explicit\")\n",
    "    write_alpha(\n",
    "        model,\n",
    "        \"Explicit\";\n",
    "        by_split = true,\n",
    "        log = true,\n",
    "        log_content = \"explicit\",\n",
    "        log_splits = [\"validation\", \"test\"],\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ed398d5-ecd5-4707-829b-0a6e09c40ee6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:17:48 saving validation explicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:17:51 validation loss: 1.6565418, β: Float32[1.0002911]\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:17:51 saving test explicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:17:52 test loss: 1.6999956, β: Float32[1.0002911]\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:17:52 saving training explicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:18:01 saving training implicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:18:05 saving training negative\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:18:08 saving training ptw\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:18:13 saving validation explicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:18:13 saving validation implicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:18:13 saving validation negative\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:18:16 saving validation ptw\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:18:17 saving test explicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:18:18 saving test implicit\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:18:18 saving test negative\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 12:18:20 saving test ptw\n"
     ]
    }
   ],
   "source": [
    "save_final_explicit_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-rc1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# NonlinearModel\n",
    "* Uses LightGBM to estimate a given (user, item) prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: lib_lightgbm found in system dirs!\n",
      "└ @ LightGBM /Users/kundan/.julia/packages/LightGBM/A7zVd/src/LightGBM.jl:28\n"
     ]
    }
   ],
   "source": [
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"TreeModelBase.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "617b0a49-44bb-4ee9-87ee-990ad7ec3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "implicit = false;\n",
    "linear_alphas = [\"LinearExplicit\", \"LinearImplicit\"]\n",
    "all_features = [explicit_raw_alphas; implicit_raw_alphas; linear_alphas];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "517ce91a-bf09-446a-8be9-a7c5bbe0c0f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 (80.38 ns/it)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.093915 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1267\n",
      "[LightGBM] [Info] Number of data points in the train set: 22508916, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 0.002249\n",
      "Iteration: 1, test_1's l2: 1.44140495318669\n",
      "Iteration: 2, test_1's l2: 1.438652788553925\n",
      "Iteration: 3, test_1's l2: 1.4369691185971265\n",
      "Iteration: 4, test_1's l2: 1.4348929980681895\n",
      "Iteration: 5, test_1's l2: 1.433150108333627\n",
      "Iteration: 6, test_1's l2: 1.4316767248105173\n",
      "Iteration: 7, test_1's l2: 1.4304860571758513\n",
      "Iteration: 8, test_1's l2: 1.4297916352757856\n",
      "Iteration: 9, test_1's l2: 1.429026142185753\n",
      "Iteration: 10, test_1's l2: 1.4283073924230447\n",
      "Iteration: 11, test_1's l2: 1.4277192318818503\n",
      "Iteration: 12, test_1's l2: 1.4273726525642292\n",
      "Iteration: 13, test_1's l2: 1.426951145146347\n",
      "Iteration: 14, test_1's l2: 1.426522212639681\n",
      "Iteration: 15, test_1's l2: 1.426223072746032\n",
      "Iteration: 16, test_1's l2: 1.425951296688821\n",
      "Iteration: 17, test_1's l2: 1.4257823797241802\n",
      "Iteration: 18, test_1's l2: 1.42557345159987\n",
      "Iteration: 19, test_1's l2: 1.4254143489011573\n",
      "Iteration: 20, test_1's l2: 1.4252629134267416\n",
      "Iteration: 21, test_1's l2: 1.4251129248027377\n",
      "Iteration: 22, test_1's l2: 1.4250252206649667\n",
      "Iteration: 23, test_1's l2: 1.4249512687670154\n",
      "Iteration: 24, test_1's l2: 1.4248311243915515\n",
      "Iteration: 25, test_1's l2: 1.424681898099608\n",
      "Iteration: 26, test_1's l2: 1.4246692809690713\n",
      "Iteration: 27, test_1's l2: 1.4246196891391023\n",
      "Iteration: 28, test_1's l2: 1.424627370344279\n",
      "Iteration: 29, test_1's l2: 1.4245836961365792\n",
      "Iteration: 30, test_1's l2: 1.4246095468757076\n",
      "Iteration: 31, test_1's l2: 1.4245678575730123\n",
      "Iteration: 32, test_1's l2: 1.424565520169548\n",
      "Iteration: 33, test_1's l2: 1.4244729693280234\n",
      "Iteration: 34, test_1's l2: 1.424475380115354\n",
      "Iteration: 35, test_1's l2: 1.4244176477126713\n",
      "Iteration: 36, test_1's l2: 1.4243833134167192\n",
      "Iteration: 37, test_1's l2: 1.4243637773510316\n",
      "Iteration: 38, test_1's l2: 1.424349345040275\n",
      "Iteration: 39, test_1's l2: 1.4243553181139759\n",
      "Iteration: 40, test_1's l2: 1.4243388237494627\n",
      "Iteration: 41, test_1's l2: 1.4243511953583639\n",
      "Iteration: 42, test_1's l2: 1.4243599515665581\n",
      "Iteration: 43, test_1's l2: 1.42435154446371\n",
      "Iteration: 44, test_1's l2: 1.4243835536170997\n",
      "Iteration: 45, test_1's l2: 1.4243502424297323\n",
      "Iteration: 46, test_1's l2: 1.4243720802068642\n",
      "Iteration: 47, test_1's l2: 1.4243763475173314\n",
      "Iteration: 48, test_1's l2: 1.424317686007309\n",
      "Iteration: 49, test_1's l2: 1.4243202399529784\n",
      "Iteration: 50, test_1's l2: 1.424268749350893\n",
      "Iteration: 51, test_1's l2: 1.4242529930216663\n",
      "Iteration: 52, test_1's l2: 1.4242747256169028\n",
      "Iteration: 53, test_1's l2: 1.4242700279863716\n",
      "Iteration: 54, test_1's l2: 1.4243317706822223\n",
      "Iteration: 55, test_1's l2: 1.424357384213903\n",
      "Iteration: 56, test_1's l2: 1.4243728982627535\n",
      "Iteration: 57, test_1's l2: 1.4243843924525965\n",
      "Iteration: 58, test_1's l2: 1.4244231925937725\n",
      "Iteration: 59, test_1's l2: 1.4244212479137877\n",
      "Iteration: 60, test_1's l2: 1.4244157609984192\n",
      "Early stopping at iteration 61, the best iteration round is 51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220626 12:11:46 Saving model... (this may take a while)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:23 ( 0.83 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 0.75 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 0.75 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:08 ( 0.76 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.80 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.81 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 0.53 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 0.53 μs/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    all_features,\n",
    "    [\"LinearExplicit\"],\n",
    "    implicit,\n",
    "    [\"validation\"],\n",
    "    \"NonlinearExplicit\",\n",
    "    false,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4928ac14-f5c8-4119-9215-7e9f61e97cc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function save_final_explicit_model()\n",
    "    linear_splits = reduce(\n",
    "        cat,\n",
    "        [read_alpha(\"LinearExplicit\", split, implicit) for split in all_raw_splits],\n",
    "    )\n",
    "    nonlinear_splits = reduce(\n",
    "        cat,\n",
    "        [read_alpha(\"NonlinearExplicit\", split, implicit) for split in all_raw_splits],\n",
    "    )\n",
    "    sparse_preds = sparse(\n",
    "        linear_splits.user,\n",
    "        linear_splits.item,\n",
    "        linear_splits.rating + nonlinear_splits.rating,\n",
    "    )\n",
    "    write_alpha(sparse_preds, [], implicit, \"Explicit\"; log_test_split = true)\n",
    "    write_params(Dict(\"alphas\" => [\"LinearExplicit\", \"NonlinearExplicit\"]), \"Explicit\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2ed398d5-ecd5-4707-829b-0a6e09c40ee6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 0.83 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220626 12:22:08 validation loss: 1.4078117354243573, β: [1.000089581744362]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:21 ( 0.77 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 (10.36 ns/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220626 12:22:32 training loss: 1.4135426322218732, β: [1.000089581744362]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 0.81 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 (30.58 ns/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220626 12:22:36 test loss: 1.4340805291315342, β: [1.000089581744362]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:21 ( 0.77 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 0.83 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 0.83 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:08 ( 0.77 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.78 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.82 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 0.52 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 0.51 μs/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "save_final_explicit_model()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-rc1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

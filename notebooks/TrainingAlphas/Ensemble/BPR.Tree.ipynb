{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# Bayesian Personalized Ranking using Trees\n",
    "* Used as the ranking model of the recommender system\n",
    "* This is trained to learn the partial ordering implied by each user's watches\n",
    "* This is trained on pairs of items, both of which have been watched by a user\n",
    "* The impression metadata determines which one, if any, is liked more"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LightGBM\n",
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"BPR.ipynb\")\n",
    "@nbinclude(\"EnsembleInputs.ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9217decf-ddb5-462c-bf63-9e868c6ffb32",
   "metadata": {},
   "source": [
    "## Lightgbm Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaabf561-dd38-46fd-93ee-a465b51d9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO move to a shared LGBM package\n",
    "\n",
    "function augment_dataset(ds, y, w)\n",
    "    LightGBM.LGBM_DatasetSetField(ds, \"label\", y)\n",
    "    LightGBM.LGBM_DatasetSetField(ds, \"weight\", w)\n",
    "    ds\n",
    "end\n",
    "\n",
    "function create_train_dataset(X, y, w, estimator)\n",
    "    augment_dataset(\n",
    "        LightGBM.LGBM_DatasetCreateFromMat(X, LightGBM.stringifyparams(estimator), false),\n",
    "        y,\n",
    "        w,\n",
    "    )\n",
    "end\n",
    "\n",
    "function create_test_dataset(X, y, w, estimator, train_ds)\n",
    "    augment_dataset(\n",
    "        LightGBM.LGBM_DatasetCreateFromMat(\n",
    "            X,\n",
    "            LightGBM.stringifyparams(estimator),\n",
    "            train_ds,\n",
    "            false,\n",
    "        ),\n",
    "        y,\n",
    "        w,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3e679a-1818-489a-8144-7925f00f343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_pairwise_dataset(\n",
    "    split,\n",
    "    user_features,\n",
    "    training;\n",
    "    batch_size = 1024,\n",
    "    epochs = 10000,\n",
    ")\n",
    "    @info \"getting pairwise dataset\"\n",
    "    Xs = [[] for _ in 1:Threads.nthreads()]\n",
    "    ys = [[] for _ in 1:Threads.nthreads()]\n",
    "    @tprogress Threads.@threads for _ = 1:epochs\n",
    "        batch = get_batch(split, user_features, batch_size)\n",
    "        push!(Xs[Threads.threadid()], cpu(batch[1][1])')\n",
    "        push!(ys[Threads.threadid()], cpu(batch[1][2])')\n",
    "    end\n",
    "    Xs = [vcat(z...) for z in Xs]\n",
    "    ys = [vcat(z...) for z in ys]\n",
    "    X = vcat(Xs...)\n",
    "    y = vec(vcat(ys...))\n",
    "    w = copy(y)\n",
    "    w .= 1\n",
    "    X, y, w\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd36b5c4-e382-4442-acb7-41e623521076",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43e26b6-4fd8-4772-bf0a-1ef99c8c4cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_alpha(outdir, allow_ptw)\n",
    "    set_logging_outdir(outdir)\n",
    "    alphas = [\n",
    "        \"LinearExplicit\"\n",
    "        \"LinearImplicit\"\n",
    "        \"Explicit\"    \n",
    "        \"NonlinearImplicit\"\n",
    "        explicit_raw_alphas\n",
    "        implicit_raw_alphas\n",
    "        nondirectional_raw_alphas    \n",
    "    ]\n",
    "    if allow_ptw\n",
    "        append!(alphas, ptw_raw_alphas)\n",
    "        append!(alphas, [\"NonlinearPtw\"])\n",
    "    end\n",
    "\n",
    "    training, test, user_features = get_data(alphas, allow_ptw, false)\n",
    "    estimator = LGBMClassification(\n",
    "        objective = \"binary\",\n",
    "        num_iterations = 100,\n",
    "        learning_rate = 0.01,\n",
    "        early_stopping_round = 10,\n",
    "        feature_fraction = 0.8,\n",
    "        bagging_fraction = 0.9,\n",
    "        bagging_freq = 1,\n",
    "        num_leaves = 1000,\n",
    "        num_class = 1,\n",
    "        metric = [\"auc\", \"binary_logloss\"],\n",
    "    )\n",
    "    X_train, y_train, w_train = get_pairwise_dataset(training, user_features, false)\n",
    "    X_test, y_test, w_test = get_pairwise_dataset(test, user_features, false)\n",
    "\n",
    "    train_ds = create_train_dataset(X_train, y_train, w_train, estimator)\n",
    "    test_ds = create_test_dataset(X_test, y_test, w_test, estimator, train_ds)\n",
    "    fit!(estimator, train_ds, test_ds)\n",
    "    write_params(Dict(\"model\" => estimator, \"alphas\" => alphas), outdir)\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

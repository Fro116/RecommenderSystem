{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# Ensemble\n",
    "* Runs all the ensemble alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import NBInclude: @nbinclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94933991-1dbe-45f9-9a7d-850d1c090592",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"../Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edf2b7dc-6ec0-44f9-9f88-1df84ba11362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:30:29 alphas: [\"ExplicitUserItemBiases\", \"ExplicitItemCF\", \"NeuralExplicitItemCFUntuned\", \"NeuralExplicitAutoencoder\"]\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:30:29 coefficients: Float32[1.0179684, 0.13086191, 0.29706454, 0.7206209]\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:01\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:01\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:06\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.05 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:30:46 validation loss: 1.3307458161824315, β: [0.9999977294581752]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:08 ( 0.91 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 (10.96 ns/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:30:59 training loss: 67.37459122582702, β: [0.9999977294581752]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.10 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:31:01 test loss: 1.3399693089047162, β: [0.9999977294581752]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:08 ( 0.93 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.03 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.04 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:03 ( 0.96 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.16 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.06 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.93 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.93 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:25\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:33:46 alphas: [\"NeuralImplicitUserItemBiases\", \"NeuralImplicitMatrixFactorization\", \"NeuralImplicitItemCFUntuned\", \"NeuralImplicitAutoencoderUntuned\", \"NeuralImplicitEaseUntuned\"]\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:33:46 coefficients: Float32[6.809186f-7, 0.18537387, 0.18452036, 0.49037346, 0.13973111, 5.54689f-7]\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:19\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:15\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:14\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:14\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:15\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:16\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:01:38\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.02 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:36:02 validation loss: 5.665073070989268, β: Float32[6.1708306f-7, 0.9999994]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:12 ( 0.92 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 8.57 ns/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:36:21 training loss: 24.21860478768231, β: Float32[6.1708306f-7, 0.9999994]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.08 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:36:24 test loss: 5.657896465547285, β: Float32[6.1708306f-7, 0.9999994]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:08 ( 0.91 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.02 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.01 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:03 ( 0.91 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.03 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.04 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.92 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.92 μs/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@nbinclude(\"LinearModel.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "517ce91a-bf09-446a-8be9-a7c5bbe0c0f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:36:53 lib_lightgbm not found in system dirs, trying fallback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.071606 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3060\n",
      "[LightGBM] [Info] Number of data points in the train set: 22508916, number of used features: 12\n",
      "[LightGBM] [Info] Start training from score -0.001518\n",
      "Iteration: 1, test_1's l2: 1.3273852499174879\n",
      "Iteration: 2, test_1's l2: 1.3249400057338667\n",
      "Iteration: 3, test_1's l2: 1.3226635771735333\n",
      "Iteration: 4, test_1's l2: 1.3207750726758474\n",
      "Iteration: 5, test_1's l2: 1.3190805616009937\n",
      "Iteration: 6, test_1's l2: 1.317811706462618\n",
      "Iteration: 7, test_1's l2: 1.316707027042262\n",
      "Iteration: 8, test_1's l2: 1.315683146927257\n",
      "Iteration: 9, test_1's l2: 1.3147405773499747\n",
      "Iteration: 10, test_1's l2: 1.3140495327354285\n",
      "Iteration: 11, test_1's l2: 1.313401230899681\n",
      "Iteration: 12, test_1's l2: 1.3127172978855772\n",
      "Iteration: 13, test_1's l2: 1.3121240850788194\n",
      "Iteration: 14, test_1's l2: 1.3117979930858723\n",
      "Iteration: 15, test_1's l2: 1.3114666950601748\n",
      "Iteration: 16, test_1's l2: 1.311010665918782\n",
      "Iteration: 17, test_1's l2: 1.3107699950727043\n",
      "Iteration: 18, test_1's l2: 1.3105074296272232\n",
      "Iteration: 19, test_1's l2: 1.3101959895513609\n",
      "Iteration: 20, test_1's l2: 1.3099916357394288\n",
      "Iteration: 21, test_1's l2: 1.3097166420025523\n",
      "Iteration: 22, test_1's l2: 1.3093797668537333\n",
      "Iteration: 23, test_1's l2: 1.3091722611760923\n",
      "Iteration: 24, test_1's l2: 1.3088534325814367\n",
      "Iteration: 25, test_1's l2: 1.308632718938027\n",
      "Iteration: 26, test_1's l2: 1.3085421600956055\n",
      "Iteration: 27, test_1's l2: 1.3084252576573947\n",
      "Iteration: 28, test_1's l2: 1.3083450912149714\n",
      "Iteration: 29, test_1's l2: 1.3082580253021228\n",
      "Iteration: 30, test_1's l2: 1.308183944543168\n",
      "Iteration: 31, test_1's l2: 1.308023355447528\n",
      "Iteration: 32, test_1's l2: 1.3080265681881598\n",
      "Iteration: 33, test_1's l2: 1.307894932622472\n",
      "Iteration: 34, test_1's l2: 1.3078045134053922\n",
      "Iteration: 35, test_1's l2: 1.3077452111983472\n",
      "Iteration: 36, test_1's l2: 1.30760781530195\n",
      "Iteration: 37, test_1's l2: 1.3076250068255153\n",
      "Iteration: 38, test_1's l2: 1.3075789012609642\n",
      "Iteration: 39, test_1's l2: 1.3075744615852647\n",
      "Iteration: 40, test_1's l2: 1.3075942749357057\n",
      "Iteration: 41, test_1's l2: 1.3075532587611491\n",
      "Iteration: 42, test_1's l2: 1.307518889148449\n",
      "Iteration: 43, test_1's l2: 1.3074806350547714\n",
      "Iteration: 44, test_1's l2: 1.307559931792358\n",
      "Iteration: 45, test_1's l2: 1.307569610128698\n",
      "Iteration: 46, test_1's l2: 1.3075945166160061\n",
      "Iteration: 47, test_1's l2: 1.3075395969383077\n",
      "Iteration: 48, test_1's l2: 1.307496276386417\n",
      "Iteration: 49, test_1's l2: 1.3075103448015988\n",
      "Iteration: 50, test_1's l2: 1.3075080801159726\n",
      "Iteration: 51, test_1's l2: 1.307512959677184\n",
      "Iteration: 52, test_1's l2: 1.3074317416669115\n",
      "Iteration: 53, test_1's l2: 1.3074021214637315\n",
      "Iteration: 54, test_1's l2: 1.3074175160591655\n",
      "Iteration: 55, test_1's l2: 1.3074836286482119\n",
      "Iteration: 56, test_1's l2: 1.307455382288435\n",
      "Iteration: 57, test_1's l2: 1.3074098061236326\n",
      "Iteration: 58, test_1's l2: 1.3074225987677803\n",
      "Iteration: 59, test_1's l2: 1.3074211956223867\n",
      "Iteration: 60, test_1's l2: 1.3074370805155566\n",
      "Iteration: 61, test_1's l2: 1.3075108017242139\n",
      "Iteration: 62, test_1's l2: 1.3075201338069051\n",
      "Early stopping at iteration 63, the best iteration round is 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:37:41 Saving model...\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:01:04\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:39:15 Average model value: 0.06302204\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:39:15 Average model absolute value: 0.17623074\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:08 ( 0.93 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.03 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.04 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:03 ( 0.93 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.04 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.04 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.92 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.92 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.04 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:39:59 validation loss: 1.2672896400740596, β: [1.0002732712372806]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:08 ( 0.92 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 (11.94 ns/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:40:11 training loss: 67.37459122582702, β: [1.0002732712372806]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.02 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:40:14 test loss: 1.3174962580183918, β: [1.0002732712372806]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:08 ( 0.94 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.03 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.07 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:03 ( 0.93 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.05 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.06 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.93 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.92 μs/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@nbinclude(\"NonlinearModel.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "765ef7e7-abf6-432e-b55d-2eea75753f32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.12 μs/it)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.198628 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 66963121, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 0.102471\n",
      "Iteration: 1, test_1's l2: 0.0412862075244398\n",
      "Iteration: 2, test_1's l2: 0.036266885682966536\n",
      "Iteration: 3, test_1's l2: 0.03297598129839444\n",
      "Iteration: 4, test_1's l2: 0.029536986184990295\n",
      "Iteration: 5, test_1's l2: 0.026746924640987397\n",
      "Iteration: 6, test_1's l2: 0.024490565110493103\n",
      "Iteration: 7, test_1's l2: 0.022678404222311706\n",
      "Iteration: 8, test_1's l2: 0.02118588823552605\n",
      "Iteration: 9, test_1's l2: 0.019980365583901358\n",
      "Iteration: 10, test_1's l2: 0.019228813678883624\n",
      "Iteration: 11, test_1's l2: 0.018388897534850835\n",
      "Iteration: 12, test_1's l2: 0.017709023749094416\n",
      "Iteration: 13, test_1's l2: 0.017162436900538914\n",
      "Iteration: 14, test_1's l2: 0.016712430409342123\n",
      "Iteration: 15, test_1's l2: 0.016347832486709235\n",
      "Iteration: 16, test_1's l2: 0.01613791472991563\n",
      "Iteration: 17, test_1's l2: 0.01596593518453566\n",
      "Iteration: 18, test_1's l2: 0.015740430011357387\n",
      "Iteration: 19, test_1's l2: 0.015558588795722092\n",
      "Iteration: 20, test_1's l2: 0.015409352353105109\n",
      "Iteration: 21, test_1's l2: 0.015287014441318397\n",
      "Iteration: 22, test_1's l2: 0.015189042180010309\n",
      "Iteration: 23, test_1's l2: 0.015108812798410025\n",
      "Iteration: 24, test_1's l2: 0.015044629343750688\n",
      "Iteration: 25, test_1's l2: 0.014989843761055688\n",
      "Iteration: 26, test_1's l2: 0.01494743992009369\n",
      "Iteration: 27, test_1's l2: 0.01490944614230663\n",
      "Iteration: 28, test_1's l2: 0.014879645418277167\n",
      "Iteration: 29, test_1's l2: 0.014855687513619702\n",
      "Iteration: 30, test_1's l2: 0.014845135440511964\n",
      "Iteration: 31, test_1's l2: 0.014825879698366067\n",
      "Iteration: 32, test_1's l2: 0.014810751271184735\n",
      "Iteration: 33, test_1's l2: 0.014804991896550422\n",
      "Iteration: 34, test_1's l2: 0.014792322578216036\n",
      "Iteration: 35, test_1's l2: 0.01478322991836967\n",
      "Iteration: 36, test_1's l2: 0.014774375003014678\n",
      "Iteration: 37, test_1's l2: 0.014767544898877383\n",
      "Iteration: 38, test_1's l2: 0.014765910086045678\n",
      "Iteration: 39, test_1's l2: 0.014765013581352005\n",
      "Iteration: 40, test_1's l2: 0.0147616561693599\n",
      "Iteration: 41, test_1's l2: 0.014759013687823204\n",
      "Iteration: 42, test_1's l2: 0.01475904810153483\n",
      "Iteration: 43, test_1's l2: 0.014758899586070498\n",
      "Iteration: 44, test_1's l2: 0.014754737473399426\n",
      "Iteration: 45, test_1's l2: 0.014755183770126351\n",
      "Iteration: 46, test_1's l2: 0.014754836746552284\n",
      "Iteration: 47, test_1's l2: 0.01475408751112919\n",
      "Iteration: 48, test_1's l2: 0.01475440492717682\n",
      "Iteration: 49, test_1's l2: 0.01475457472607393\n",
      "Iteration: 50, test_1's l2: 0.014754151886988252\n",
      "Iteration: 51, test_1's l2: 0.014753706929380158\n",
      "Iteration: 52, test_1's l2: 0.01475345035631184\n",
      "Iteration: 53, test_1's l2: 0.014752614024391672\n",
      "Iteration: 54, test_1's l2: 0.014753342842468991\n",
      "Iteration: 55, test_1's l2: 0.014753248801076924\n",
      "Iteration: 56, test_1's l2: 0.014753044265346035\n",
      "Iteration: 57, test_1's l2: 0.014752803225215489\n",
      "Iteration: 58, test_1's l2: 0.014752340522156989\n",
      "Iteration: 59, test_1's l2: 0.01475155981549974\n",
      "Iteration: 60, test_1's l2: 0.014751666447406943\n",
      "Iteration: 61, test_1's l2: 0.014753122403575217\n",
      "Iteration: 62, test_1's l2: 0.014753185380573576\n",
      "Iteration: 63, test_1's l2: 0.014753641502291024\n",
      "Iteration: 64, test_1's l2: 0.01475455081479861\n",
      "Iteration: 65, test_1's l2: 0.014754784168946405\n",
      "Iteration: 66, test_1's l2: 0.014755394618606716\n",
      "Iteration: 67, test_1's l2: 0.01475519848161475\n",
      "Iteration: 68, test_1's l2: 0.014756136360714793\n",
      "Early stopping at iteration 69, the best iteration round is 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:44:48 Saving model...\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:38\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:51:20 Average model value: 0.041031033\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:51:20 Average model absolute value: 0.041050255\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:07 ( 0.81 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.96 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.96 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:03 ( 0.82 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.98 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.96 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.86 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.88 μs/it)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.078683 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 22508916, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score 0.808913\n",
      "Iteration: 1, test_1's l2: 0.6259334588133137\n",
      "Iteration: 2, test_1's l2: 0.6172625268740717\n",
      "Iteration: 3, test_1's l2: 0.6104240293426865\n",
      "Iteration: 4, test_1's l2: 0.6042995935313697\n",
      "Iteration: 5, test_1's l2: 0.599222198907919\n",
      "Iteration: 6, test_1's l2: 0.5950764284438029\n",
      "Iteration: 7, test_1's l2: 0.5915859764941065\n",
      "Iteration: 8, test_1's l2: 0.5887605829133024\n",
      "Iteration: 9, test_1's l2: 0.5863359178834958\n",
      "Iteration: 10, test_1's l2: 0.5844637241333194\n",
      "Iteration: 11, test_1's l2: 0.5828154806728885\n",
      "Iteration: 12, test_1's l2: 0.5814259874069879\n",
      "Iteration: 13, test_1's l2: 0.5800978810828602\n",
      "Iteration: 14, test_1's l2: 0.5788448432194873\n",
      "Iteration: 15, test_1's l2: 0.5778936142967166\n",
      "Iteration: 16, test_1's l2: 0.5771648240032143\n",
      "Iteration: 17, test_1's l2: 0.5764835617195042\n",
      "Iteration: 18, test_1's l2: 0.5757418573326637\n",
      "Iteration: 19, test_1's l2: 0.5752046003275173\n",
      "Iteration: 20, test_1's l2: 0.5747808324717381\n",
      "Iteration: 21, test_1's l2: 0.5742521018175533\n",
      "Iteration: 22, test_1's l2: 0.5737991071005479\n",
      "Iteration: 23, test_1's l2: 0.5733723804227979\n",
      "Iteration: 24, test_1's l2: 0.5730985403402677\n",
      "Iteration: 25, test_1's l2: 0.5725399470080286\n",
      "Iteration: 26, test_1's l2: 0.5722736604583127\n",
      "Iteration: 27, test_1's l2: 0.5720140791458682\n",
      "Iteration: 28, test_1's l2: 0.5719037024927384\n",
      "Iteration: 29, test_1's l2: 0.5716237414832455\n",
      "Iteration: 30, test_1's l2: 0.5712190388061384\n",
      "Iteration: 31, test_1's l2: 0.5709833885909759\n",
      "Iteration: 32, test_1's l2: 0.570753631329446\n",
      "Iteration: 33, test_1's l2: 0.5705231573707193\n",
      "Iteration: 34, test_1's l2: 0.5702114522695717\n",
      "Iteration: 35, test_1's l2: 0.5700056743082744\n",
      "Iteration: 36, test_1's l2: 0.569726047426111\n",
      "Iteration: 37, test_1's l2: 0.569650581932797\n",
      "Iteration: 38, test_1's l2: 0.5695250574126366\n",
      "Iteration: 39, test_1's l2: 0.5693664732658605\n",
      "Iteration: 40, test_1's l2: 0.5692889943930786\n",
      "Iteration: 41, test_1's l2: 0.5692216621098933\n",
      "Iteration: 42, test_1's l2: 0.5689082217641375\n",
      "Iteration: 43, test_1's l2: 0.5686110823170178\n",
      "Iteration: 44, test_1's l2: 0.5685083945707935\n",
      "Iteration: 45, test_1's l2: 0.5684665576995135\n",
      "Iteration: 46, test_1's l2: 0.5684256189371201\n",
      "Iteration: 47, test_1's l2: 0.5683377648702748\n",
      "Iteration: 48, test_1's l2: 0.5682090062260076\n",
      "Iteration: 49, test_1's l2: 0.5679885354254179\n",
      "Iteration: 50, test_1's l2: 0.5679472103083667\n",
      "Iteration: 51, test_1's l2: 0.5677560132560404\n",
      "Iteration: 52, test_1's l2: 0.5677020512412132\n",
      "Iteration: 53, test_1's l2: 0.5676912463712444\n",
      "Iteration: 54, test_1's l2: 0.5675173752680286\n",
      "Iteration: 55, test_1's l2: 0.5673861285895069\n",
      "Iteration: 56, test_1's l2: 0.5671510265186881\n",
      "Iteration: 57, test_1's l2: 0.5671291252115315\n",
      "Iteration: 58, test_1's l2: 0.5671136153380458\n",
      "Iteration: 59, test_1's l2: 0.5669304158716308\n",
      "Iteration: 60, test_1's l2: 0.5669189307581641\n",
      "Iteration: 61, test_1's l2: 0.5668690301321343\n",
      "Iteration: 62, test_1's l2: 0.5668499857869117\n",
      "Iteration: 63, test_1's l2: 0.566823712476227\n",
      "Iteration: 64, test_1's l2: 0.5667028351897866\n",
      "Iteration: 65, test_1's l2: 0.5667005835692813\n",
      "Iteration: 66, test_1's l2: 0.5666678315761982\n",
      "Iteration: 67, test_1's l2: 0.5665710757194332\n",
      "Iteration: 68, test_1's l2: 0.5664922097928239\n",
      "Iteration: 69, test_1's l2: 0.5664415953138618\n",
      "Iteration: 70, test_1's l2: 0.5664243088331726\n",
      "Iteration: 71, test_1's l2: 0.5663811371905009\n",
      "Iteration: 72, test_1's l2: 0.5663724531857075\n",
      "Iteration: 73, test_1's l2: 0.5662862893774419\n",
      "Iteration: 74, test_1's l2: 0.5662694322953836\n",
      "Iteration: 75, test_1's l2: 0.566267025149211\n",
      "Iteration: 76, test_1's l2: 0.5662296601870825\n",
      "Iteration: 77, test_1's l2: 0.5661852480499932\n",
      "Iteration: 78, test_1's l2: 0.5662111081155043\n",
      "Iteration: 79, test_1's l2: 0.5662462996187054\n",
      "Iteration: 80, test_1's l2: 0.5662442765582593\n",
      "Iteration: 81, test_1's l2: 0.566140243218942\n",
      "Iteration: 82, test_1's l2: 0.5660626189400247\n",
      "Iteration: 83, test_1's l2: 0.5660458211993975\n",
      "Iteration: 84, test_1's l2: 0.5660508173685697\n",
      "Iteration: 85, test_1's l2: 0.5659957059335105\n",
      "Iteration: 86, test_1's l2: 0.5659895592686015\n",
      "Iteration: 87, test_1's l2: 0.5659741314245628\n",
      "Iteration: 88, test_1's l2: 0.5659809225698761\n",
      "Iteration: 89, test_1's l2: 0.5659616429520747\n",
      "Iteration: 90, test_1's l2: 0.5659504631890389\n",
      "Iteration: 91, test_1's l2: 0.5659396888653153\n",
      "Iteration: 92, test_1's l2: 0.5659292109031797\n",
      "Iteration: 93, test_1's l2: 0.5659318655736846\n",
      "Iteration: 94, test_1's l2: 0.5659386885287684\n",
      "Iteration: 95, test_1's l2: 0.5659582194018253\n",
      "Iteration: 96, test_1's l2: 0.5659522214694381\n",
      "Iteration: 97, test_1's l2: 0.5659590442335649\n",
      "Iteration: 98, test_1's l2: 0.5659237799201455\n",
      "Iteration: 99, test_1's l2: 0.5659227578669379\n",
      "Iteration: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:53:05 Saving model...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100, test_1's l2: 0.5659455923506985\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:02:10\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:55:51 Average model value: 1.1375293\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220707 23:55:52 Average model absolute value: 1.1375303\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:07 ( 0.85 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.99 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.04 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:03 ( 0.85 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.00 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.00 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.88 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.91 μs/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@nbinclude(\"ErrorModel.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3f9ca73-b22b-4565-b492-a0bdc4a193c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220708 00:08:26 Training model...\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:24\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:11\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:01:01\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:01\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:04\u001b[39m\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "LoadError: UndefVarError: a not defined\nin expression starting at /home/kundan/Desktop/RecommenderSystem/notebooks/TrainingAlphas/Ensemble/BPR.ipynb:In[+16]:1",
     "output_type": "error",
     "traceback": [
      "LoadError: UndefVarError: a not defined\nin expression starting at /home/kundan/Desktop/RecommenderSystem/notebooks/TrainingAlphas/Ensemble/BPR.ipynb:In[+16]:1",
      "",
      "Stacktrace:",
      "  [1] add_features!(user_features::Dict{Int32, Dict{Int32, Vector{Float32}}}, alphas::Vector{String}, split::String)",
      "    @ Main ~/Desktop/RecommenderSystem/notebooks/TrainingAlphas/Ensemble/BPR.ipynb:In[+6]:2",
      "  [2] get_user_features(features::Vector{String})",
      "    @ Main ~/Desktop/RecommenderSystem/notebooks/TrainingAlphas/Ensemble/BPR.ipynb:In[+6]:15",
      "  [3] ##get_data_unmemoized",
      "    @ ~/Desktop/RecommenderSystem/notebooks/TrainingAlphas/Ensemble/BPR.ipynb:In[+9]:3 [inlined]",
      "  [4] #538",
      "    @ ~/.julia/packages/Memoize/12ANR/src/Memoize.jl:62 [inlined]",
      "  [5] get!(default::var\"#538#539\"{Vector{String}}, d::IdDict{Any, Any}, key::Any)",
      "    @ Base ./iddict.jl:178",
      "  [6] get_data",
      "    @ ~/.julia/packages/Memoize/12ANR/src/Memoize.jl:61 [inlined]",
      "  [7] train_model(hyp::Hyperparams; max_checkpoints::Int64, epochs_per_checkpoint::Int64, patience::Int64, verbose::Bool)",
      "    @ Main ~/Desktop/RecommenderSystem/notebooks/TrainingAlphas/Ensemble/BPR.ipynb:In[+11]:15",
      "  [8] train_alpha(hyp::Hyperparams, outdir::String; tune_hyperparams::Bool)",
      "    @ Main ~/Desktop/RecommenderSystem/notebooks/TrainingAlphas/Ensemble/BPR.ipynb:In[+14]:13",
      "  [9] top-level scope",
      "    @ ~/Desktop/RecommenderSystem/notebooks/TrainingAlphas/Ensemble/BPR.ipynb:In[+16]:1",
      " [10] eval",
      "    @ ./boot.jl:368 [inlined]",
      " [11] include_string(mapexpr::typeof(identity), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1281",
      " [12] include_string",
      "    @ ./loading.jl:1291 [inlined]",
      " [13] my_include_string(m::Module, s::String, path::String, prev::Nothing, softscope::Bool)",
      "    @ NBInclude ~/.julia/packages/NBInclude/MxvbF/src/NBInclude.jl:30",
      " [14] #2",
      "    @ ~/.julia/packages/NBInclude/MxvbF/src/NBInclude.jl:93 [inlined]",
      " [15] task_local_storage(body::NBInclude.var\"#2#3\"{Bool, Module, String, Nothing, String, String}, key::Symbol, val::Bool)",
      "    @ Base ./task.jl:292",
      " [16] nbinclude(m::Module, path::String; renumber::Bool, counters::UnitRange{Int64}, regex::Regex, anshook::typeof(identity), softscope::Bool)",
      "    @ NBInclude ~/.julia/packages/NBInclude/MxvbF/src/NBInclude.jl:92",
      " [17] nbinclude(m::Module, path::String)",
      "    @ NBInclude ~/.julia/packages/NBInclude/MxvbF/src/NBInclude.jl:57",
      " [18] top-level scope",
      "    @ In[7]:1",
      " [19] eval",
      "    @ ./boot.jl:368 [inlined]",
      " [20] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1281"
     ]
    }
   ],
   "source": [
    "@nbinclude(\"BPR.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65852a36-f4d8-442d-b046-4f29a4b9fd84",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-rc1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# Ensemble\n",
    "* Runs all the ensemble alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import NBInclude: @nbinclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "94933991-1dbe-45f9-9a7d-850d1c090592",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"../Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "edf2b7dc-6ec0-44f9-9f88-1df84ba11362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:01\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:06:57 alphas: [\"ExplicitUserItemBiases\", \"ExplicitItemCF\", \"NeuralExplicitMatrixFactorization\", \"NeuralExplicitItemCFUntuned\", \"NeuralExplicitAutoencoder\", \"NeuralExplicitEaseUntuned\"]\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:06:57 coefficients: Float32[0.99233574, 0.14281733, -0.058303095, 0.3529429, 0.7020718, -0.009851629]\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:01\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:01\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:08\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.02 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:07:16 validation loss: 1.3411749353738334, β: [0.9999976892375362]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:08 ( 0.86 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 (10.92 ns/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:07:29 training loss: 67.37459122582702, β: [0.9999976892375362]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.06 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:07:31 test loss: 1.350201845222005, β: [0.9999976892375362]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:08 ( 0.86 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.99 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.99 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:03 ( 0.86 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.01 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.00 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.93 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.92 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:25\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:10:12 alphas: [\"NeuralImplicitUserItemBiases\", \"NeuralImplicitMatrixFactorization\", \"NeuralImplicitItemCFUntuned\", \"NeuralImplicitAutoencoderUntuned\", \"NeuralImplicitEaseUntuned\"]\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:10:12 coefficients: Float32[6.809186f-7, 0.18537387, 0.18452036, 0.49037346, 0.13973111, 5.54689f-7]\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:17\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:15\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:14\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:14\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:15\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:15\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:01:35\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.03 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:12:24 validation loss: 5.665073070989285, β: Float32[6.1708306f-7, 0.9999994]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:12 ( 0.93 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 8.45 ns/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:12:44 training loss: 24.21860478768231, β: Float32[6.1708306f-7, 0.9999994]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.09 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:12:47 test loss: 5.65789646554726, β: Float32[6.1708306f-7, 0.9999994]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:08 ( 0.92 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.03 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.05 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:03 ( 0.92 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.04 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.09 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.92 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.93 μs/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@nbinclude(\"LinearModel.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "517ce91a-bf09-446a-8be9-a7c5bbe0c0f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:13:15 lib_lightgbm not found in system dirs, trying fallback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.069236 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3570\n",
      "[LightGBM] [Info] Number of data points in the train set: 22508916, number of used features: 14\n",
      "[LightGBM] [Info] Start training from score -0.001432\n",
      "Iteration: 1, test_1's l2: 1.3377109468283697\n",
      "Iteration: 2, test_1's l2: 1.3353943885393567\n",
      "Iteration: 3, test_1's l2: 1.3328754113862005\n",
      "Iteration: 4, test_1's l2: 1.3308310914747383\n",
      "Iteration: 5, test_1's l2: 1.3290586122922645\n",
      "Iteration: 6, test_1's l2: 1.3278227585077182\n",
      "Iteration: 7, test_1's l2: 1.3266841697983018\n",
      "Iteration: 8, test_1's l2: 1.3257815867463147\n",
      "Iteration: 9, test_1's l2: 1.324767633115169\n",
      "Iteration: 10, test_1's l2: 1.3236285691707992\n",
      "Iteration: 11, test_1's l2: 1.323046679955744\n",
      "Iteration: 12, test_1's l2: 1.3224858791755643\n",
      "Iteration: 13, test_1's l2: 1.3217291334194163\n",
      "Iteration: 14, test_1's l2: 1.3213926377473508\n",
      "Iteration: 15, test_1's l2: 1.3207126941794032\n",
      "Iteration: 16, test_1's l2: 1.3203540864903942\n",
      "Iteration: 17, test_1's l2: 1.3200543589561513\n",
      "Iteration: 18, test_1's l2: 1.3195581863383414\n",
      "Iteration: 19, test_1's l2: 1.3193012494093834\n",
      "Iteration: 20, test_1's l2: 1.3188564185598053\n",
      "Iteration: 21, test_1's l2: 1.31881223555549\n",
      "Iteration: 22, test_1's l2: 1.3184696336253277\n",
      "Iteration: 23, test_1's l2: 1.3183641606713046\n",
      "Iteration: 24, test_1's l2: 1.3181731991522576\n",
      "Iteration: 25, test_1's l2: 1.3178067593504132\n",
      "Iteration: 26, test_1's l2: 1.3175479504178915\n",
      "Iteration: 27, test_1's l2: 1.3173373994944997\n",
      "Iteration: 28, test_1's l2: 1.317235120222584\n",
      "Iteration: 29, test_1's l2: 1.317112759290323\n",
      "Iteration: 30, test_1's l2: 1.3169239738748602\n",
      "Iteration: 31, test_1's l2: 1.3166828865196976\n",
      "Iteration: 32, test_1's l2: 1.3167370583444045\n",
      "Iteration: 33, test_1's l2: 1.3166379913757573\n",
      "Iteration: 34, test_1's l2: 1.3165101960364258\n",
      "Iteration: 35, test_1's l2: 1.3163794940676325\n",
      "Iteration: 36, test_1's l2: 1.3162806871443733\n",
      "Iteration: 37, test_1's l2: 1.3162160987842328\n",
      "Iteration: 38, test_1's l2: 1.3161335111920103\n",
      "Iteration: 39, test_1's l2: 1.316046791110598\n",
      "Iteration: 40, test_1's l2: 1.3159780007573774\n",
      "Iteration: 41, test_1's l2: 1.3159900632676977\n",
      "Iteration: 42, test_1's l2: 1.3160183613622964\n",
      "Iteration: 43, test_1's l2: 1.3160092683240994\n",
      "Iteration: 44, test_1's l2: 1.315976480002948\n",
      "Iteration: 45, test_1's l2: 1.3159634334695953\n",
      "Iteration: 46, test_1's l2: 1.3159570627890387\n",
      "Iteration: 47, test_1's l2: 1.3160189051994606\n",
      "Iteration: 48, test_1's l2: 1.3158952244256519\n",
      "Iteration: 49, test_1's l2: 1.3158663795986776\n",
      "Iteration: 50, test_1's l2: 1.3157948831869712\n",
      "Iteration: 51, test_1's l2: 1.3157375523433232\n",
      "Iteration: 52, test_1's l2: 1.3156828449641529\n",
      "Iteration: 53, test_1's l2: 1.3156701986464823\n",
      "Iteration: 54, test_1's l2: 1.3155577414193524\n",
      "Iteration: 55, test_1's l2: 1.3155127983749402\n",
      "Iteration: 56, test_1's l2: 1.3154793876346236\n",
      "Iteration: 57, test_1's l2: 1.3154238901403188\n",
      "Iteration: 58, test_1's l2: 1.3153777434735483\n",
      "Iteration: 59, test_1's l2: 1.3153300487428181\n",
      "Iteration: 60, test_1's l2: 1.3153670297152014\n",
      "Iteration: 61, test_1's l2: 1.3153336540251581\n",
      "Iteration: 62, test_1's l2: 1.315250815844479\n",
      "Iteration: 63, test_1's l2: 1.3152165816907113\n",
      "Iteration: 64, test_1's l2: 1.3151975885707043\n",
      "Iteration: 65, test_1's l2: 1.3152278021995134\n",
      "Iteration: 66, test_1's l2: 1.3151101532873255\n",
      "Iteration: 67, test_1's l2: 1.3150744322566266\n",
      "Iteration: 68, test_1's l2: 1.3151536280540927\n",
      "Iteration: 69, test_1's l2: 1.3151309116597611\n",
      "Iteration: 70, test_1's l2: 1.3150767407310484\n",
      "Iteration: 71, test_1's l2: 1.3150405001295007\n",
      "Iteration: 72, test_1's l2: 1.3150004518361809\n",
      "Iteration: 73, test_1's l2: 1.3149865426121363\n",
      "Iteration: 74, test_1's l2: 1.3150000640153812\n",
      "Iteration: 75, test_1's l2: 1.3150459170573505\n",
      "Iteration: 76, test_1's l2: 1.3150410906964962\n",
      "Iteration: 77, test_1's l2: 1.3150355152504967\n",
      "Iteration: 78, test_1's l2: 1.3150383732843698\n",
      "Iteration: 79, test_1's l2: 1.3149711509146738\n",
      "Iteration: 80, test_1's l2: 1.3149334843165648\n",
      "Iteration: 81, test_1's l2: 1.314941021759296\n",
      "Iteration: 82, test_1's l2: 1.3149745618253383\n",
      "Iteration: 83, test_1's l2: 1.314977262596641\n",
      "Iteration: 84, test_1's l2: 1.314958722583118\n",
      "Iteration: 85, test_1's l2: 1.3149620596981595\n",
      "Iteration: 86, test_1's l2: 1.3149905490480882\n",
      "Iteration: 87, test_1's l2: 1.3150120830338257\n",
      "Iteration: 88, test_1's l2: 1.3150170857402488\n",
      "Iteration: 89, test_1's l2: 1.3149766212536653\n",
      "Early stopping at iteration 90, the best iteration round is 80\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:14:20 Saving model...\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:01:37\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:16:31 Average model value: 0.07228403\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:16:31 Average model absolute value: 0.20484489\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:08 ( 0.92 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.04 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.02 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:03 ( 0.92 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.06 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.06 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.92 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.72 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.06 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:17:16 validation loss: 1.2581052967159831, β: [1.0003703122283172]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:08 ( 0.93 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 (10.90 ns/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:17:28 training loss: 67.37459122582702, β: [1.0003703122283172]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.06 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:17:30 test loss: 1.3241850167141473, β: [1.0003703122283172]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:08 ( 0.94 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.02 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.04 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:03 ( 0.94 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.05 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.06 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.93 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.91 μs/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@nbinclude(\"NonlinearModel.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "765ef7e7-abf6-432e-b55d-2eea75753f32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.12 μs/it)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.844184 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4080\n",
      "[LightGBM] [Info] Number of data points in the train set: 66963121, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.102471\n",
      "Iteration: 1, test_1's l2: 0.04130566578247209\n",
      "Iteration: 2, test_1's l2: 0.03628133327630459\n",
      "Iteration: 3, test_1's l2: 0.032225694562234036\n",
      "Iteration: 4, test_1's l2: 0.0289288865684472\n",
      "Iteration: 5, test_1's l2: 0.026253211607741612\n",
      "Iteration: 6, test_1's l2: 0.024090085504428566\n",
      "Iteration: 7, test_1's l2: 0.022328964893075214\n",
      "Iteration: 8, test_1's l2: 0.020898320910708215\n",
      "Iteration: 9, test_1's l2: 0.019742433969513553\n",
      "Iteration: 10, test_1's l2: 0.019095521429314293\n",
      "Iteration: 11, test_1's l2: 0.018280479402186946\n",
      "Iteration: 12, test_1's l2: 0.017619090531475035\n",
      "Iteration: 13, test_1's l2: 0.0170830661949989\n",
      "Iteration: 14, test_1's l2: 0.0167753353318029\n",
      "Iteration: 15, test_1's l2: 0.01639735348062097\n",
      "Iteration: 16, test_1's l2: 0.016089765543446922\n",
      "Iteration: 17, test_1's l2: 0.015838886859523223\n",
      "Iteration: 18, test_1's l2: 0.015637121882290203\n",
      "Iteration: 19, test_1's l2: 0.015528896836580845\n",
      "Iteration: 20, test_1's l2: 0.015385545533146493\n",
      "Iteration: 21, test_1's l2: 0.015268780956644887\n",
      "Iteration: 22, test_1's l2: 0.015216922459352855\n",
      "Iteration: 23, test_1's l2: 0.015168916271463774\n",
      "Iteration: 24, test_1's l2: 0.015095341766126875\n",
      "Iteration: 25, test_1's l2: 0.015066030098053186\n",
      "Iteration: 26, test_1's l2: 0.015007278222090146\n",
      "Iteration: 27, test_1's l2: 0.014958474984216742\n",
      "Iteration: 28, test_1's l2: 0.014942133270267865\n",
      "Iteration: 29, test_1's l2: 0.01493009588086227\n",
      "Iteration: 30, test_1's l2: 0.014896716266911844\n",
      "Iteration: 31, test_1's l2: 0.014888432155203656\n",
      "Iteration: 32, test_1's l2: 0.01486507226287406\n",
      "Iteration: 33, test_1's l2: 0.014845930080719681\n",
      "Iteration: 34, test_1's l2: 0.01484136330900411\n",
      "Iteration: 35, test_1's l2: 0.014825171648106105\n",
      "Iteration: 36, test_1's l2: 0.014811561566316469\n",
      "Iteration: 37, test_1's l2: 0.014801627680387841\n",
      "Iteration: 38, test_1's l2: 0.014790802205115142\n",
      "Iteration: 39, test_1's l2: 0.014783979040406342\n",
      "Iteration: 40, test_1's l2: 0.01478288742404185\n",
      "Iteration: 41, test_1's l2: 0.014776451280821872\n",
      "Iteration: 42, test_1's l2: 0.01477207146753066\n",
      "Iteration: 43, test_1's l2: 0.014768717401085301\n",
      "Iteration: 44, test_1's l2: 0.014764794966497937\n",
      "Iteration: 45, test_1's l2: 0.014763367364499817\n",
      "Iteration: 46, test_1's l2: 0.014761661601708297\n",
      "Iteration: 47, test_1's l2: 0.01476107292023651\n",
      "Iteration: 48, test_1's l2: 0.014760358398568589\n",
      "Iteration: 49, test_1's l2: 0.014761369082234205\n",
      "Iteration: 50, test_1's l2: 0.014761295801563667\n",
      "Iteration: 51, test_1's l2: 0.014761585159799131\n",
      "Iteration: 52, test_1's l2: 0.014760710974598166\n",
      "Iteration: 53, test_1's l2: 0.014760382205583004\n",
      "Iteration: 54, test_1's l2: 0.014759453833060439\n",
      "Iteration: 55, test_1's l2: 0.014759955210637632\n",
      "Iteration: 56, test_1's l2: 0.014759948447882896\n",
      "Iteration: 57, test_1's l2: 0.014759367199964523\n",
      "Iteration: 58, test_1's l2: 0.014760307633560756\n",
      "Iteration: 59, test_1's l2: 0.014760555822901027\n",
      "Iteration: 60, test_1's l2: 0.014761755992451156\n",
      "Iteration: 61, test_1's l2: 0.014761939381446256\n",
      "Iteration: 62, test_1's l2: 0.014761870915369417\n",
      "Iteration: 63, test_1's l2: 0.014762528805858922\n",
      "Iteration: 64, test_1's l2: 0.014762451873932178\n",
      "Iteration: 65, test_1's l2: 0.014763299224757151\n",
      "Iteration: 66, test_1's l2: 0.014763586356414548\n",
      "Early stopping at iteration 67, the best iteration round is 57\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:22:58 Saving model...\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:37\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:30:38 Average model value: 0.041084707\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:30:39 Average model absolute value: 0.04109555\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:08 ( 0.86 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.99 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.98 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:03 ( 0.85 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.03 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.99 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.88 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.88 μs/it)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.270400 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 4080\n",
      "[LightGBM] [Info] Number of data points in the train set: 22508916, number of used features: 16\n",
      "[LightGBM] [Info] Start training from score 0.806497\n",
      "Iteration: 1, test_1's l2: 0.6304138126997461\n",
      "Iteration: 2, test_1's l2: 0.6216263482092746\n",
      "Iteration: 3, test_1's l2: 0.6144058188692458\n",
      "Iteration: 4, test_1's l2: 0.6085188636209778\n",
      "Iteration: 5, test_1's l2: 0.6035723117211023\n",
      "Iteration: 6, test_1's l2: 0.5996005404782906\n",
      "Iteration: 7, test_1's l2: 0.5962379206697548\n",
      "Iteration: 8, test_1's l2: 0.59330116369463\n",
      "Iteration: 9, test_1's l2: 0.5906217515564088\n",
      "Iteration: 10, test_1's l2: 0.5885466138543822\n",
      "Iteration: 11, test_1's l2: 0.5869014967742748\n",
      "Iteration: 12, test_1's l2: 0.5855000241633891\n",
      "Iteration: 13, test_1's l2: 0.5842607381460483\n",
      "Iteration: 14, test_1's l2: 0.583028240781846\n",
      "Iteration: 15, test_1's l2: 0.582141829394564\n",
      "Iteration: 16, test_1's l2: 0.5811949775412839\n",
      "Iteration: 17, test_1's l2: 0.5805160431480049\n",
      "Iteration: 18, test_1's l2: 0.579676643391284\n",
      "Iteration: 19, test_1's l2: 0.5790675544642294\n",
      "Iteration: 20, test_1's l2: 0.5786960902971221\n",
      "Iteration: 21, test_1's l2: 0.5782248916893884\n",
      "Iteration: 22, test_1's l2: 0.5778367016526106\n",
      "Iteration: 23, test_1's l2: 0.5773738324986533\n",
      "Iteration: 24, test_1's l2: 0.5770797005220295\n",
      "Iteration: 25, test_1's l2: 0.5767875867776588\n",
      "Iteration: 26, test_1's l2: 0.5765341496843126\n",
      "Iteration: 27, test_1's l2: 0.576170755673173\n",
      "Iteration: 28, test_1's l2: 0.5758183741302073\n",
      "Iteration: 29, test_1's l2: 0.5754861916321177\n",
      "Iteration: 30, test_1's l2: 0.5752429936827135\n",
      "Iteration: 31, test_1's l2: 0.5751021406276469\n",
      "Iteration: 32, test_1's l2: 0.5748808862514364\n",
      "Iteration: 33, test_1's l2: 0.5747189979342937\n",
      "Iteration: 34, test_1's l2: 0.5743645068724647\n",
      "Iteration: 35, test_1's l2: 0.5742136298736581\n",
      "Iteration: 36, test_1's l2: 0.5740615710586351\n",
      "Iteration: 37, test_1's l2: 0.5739958149428187\n",
      "Iteration: 38, test_1's l2: 0.5739134709327537\n",
      "Iteration: 39, test_1's l2: 0.5736566519690602\n",
      "Iteration: 40, test_1's l2: 0.5735172718194649\n",
      "Iteration: 41, test_1's l2: 0.5733272169787724\n",
      "Iteration: 42, test_1's l2: 0.573223333115913\n",
      "Iteration: 43, test_1's l2: 0.573034895564426\n",
      "Iteration: 44, test_1's l2: 0.5728351173298488\n",
      "Iteration: 45, test_1's l2: 0.5726277329896171\n",
      "Iteration: 46, test_1's l2: 0.5725281019295598\n",
      "Iteration: 47, test_1's l2: 0.5722314914119344\n",
      "Iteration: 48, test_1's l2: 0.5721094011409392\n",
      "Iteration: 49, test_1's l2: 0.5719453006663939\n",
      "Iteration: 50, test_1's l2: 0.5718936497128996\n",
      "Iteration: 51, test_1's l2: 0.5717115783578675\n",
      "Iteration: 52, test_1's l2: 0.5715888141987623\n",
      "Iteration: 53, test_1's l2: 0.5714671831759613\n",
      "Iteration: 54, test_1's l2: 0.5713754825881279\n",
      "Iteration: 55, test_1's l2: 0.5712962717462655\n",
      "Iteration: 56, test_1's l2: 0.57103968628569\n",
      "Iteration: 57, test_1's l2: 0.5709820564974389\n",
      "Iteration: 58, test_1's l2: 0.5709355240765301\n",
      "Iteration: 59, test_1's l2: 0.5707236415209952\n",
      "Iteration: 60, test_1's l2: 0.5706886685206027\n",
      "Iteration: 61, test_1's l2: 0.5705539941050078\n",
      "Iteration: 62, test_1's l2: 0.570532959431374\n",
      "Iteration: 63, test_1's l2: 0.57049069193381\n",
      "Iteration: 64, test_1's l2: 0.5704395254497973\n",
      "Iteration: 65, test_1's l2: 0.5703900769485526\n",
      "Iteration: 66, test_1's l2: 0.5703684998894001\n",
      "Iteration: 67, test_1's l2: 0.5703449870295294\n",
      "Iteration: 68, test_1's l2: 0.570297885979531\n",
      "Iteration: 69, test_1's l2: 0.5703031444306755\n",
      "Iteration: 70, test_1's l2: 0.5701975171811758\n",
      "Iteration: 71, test_1's l2: 0.5702032468091008\n",
      "Iteration: 72, test_1's l2: 0.5700911154796823\n",
      "Iteration: 73, test_1's l2: 0.5699684422265134\n",
      "Iteration: 74, test_1's l2: 0.5699311096469636\n",
      "Iteration: 75, test_1's l2: 0.5699342587489222\n",
      "Iteration: 76, test_1's l2: 0.5698210914302839\n",
      "Iteration: 77, test_1's l2: 0.5698094219931596\n",
      "Iteration: 78, test_1's l2: 0.5698125063887708\n",
      "Iteration: 79, test_1's l2: 0.5698119526021003\n",
      "Iteration: 80, test_1's l2: 0.5697941887656437\n",
      "Iteration: 81, test_1's l2: 0.5697021996825025\n",
      "Iteration: 82, test_1's l2: 0.5696600955250399\n",
      "Iteration: 83, test_1's l2: 0.569617666603608\n",
      "Iteration: 84, test_1's l2: 0.5695680853209797\n",
      "Iteration: 85, test_1's l2: 0.5695289308918294\n",
      "Iteration: 86, test_1's l2: 0.569528292076546\n",
      "Iteration: 87, test_1's l2: 0.5694709978822378\n",
      "Iteration: 88, test_1's l2: 0.5694406865423051\n",
      "Iteration: 89, test_1's l2: 0.5694601233989607\n",
      "Iteration: 90, test_1's l2: 0.5694122893477189\n",
      "Iteration: 91, test_1's l2: 0.5694254600024469\n",
      "Iteration: 92, test_1's l2: 0.5694407683694596\n",
      "Iteration: 93, test_1's l2: 0.5694494112473908\n",
      "Iteration: 94, test_1's l2: 0.5694562810249396\n",
      "Iteration: 95, test_1's l2: 0.5694760758588091\n",
      "Iteration: 96, test_1's l2: 0.569483785411032\n",
      "Iteration: 97, test_1's l2: 0.5694091708247745\n",
      "Iteration: 98, test_1's l2: 0.5693905547122003\n",
      "Iteration: 99, test_1's l2: 0.5693962927674726\n",
      "Iteration: 100, test_1's l2: 0.5694156244503487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:33:11 Saving model...\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:02:15\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:36:07 Average model value: 1.1041043\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:36:08 Average model absolute value: 1.1041056\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:08 ( 0.86 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.99 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.00 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:03 ( 0.86 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.01 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.03 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.88 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.87 μs/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@nbinclude(\"ErrorModel.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3f9ca73-b22b-4565-b492-a0bdc4a193c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:36:40 Optimizing hyperparameters...\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:25\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:11\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:01:01\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:01\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:04\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:42\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:24\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:02:29\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:48:57 Float32[0.0, 0.0] 0.11876846050337007\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:50:05 Float32[1.0, 0.0] 0.11945893656798283\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:51:40 Float32[0.0, 1.0] 0.12567927471110166\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:53:50 Float32[1.0, -1.0] 0.11843044856884308\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:56:01 Float32[1.5, -2.0] 0.12058012211651048\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 20:57:37 Float32[0.0, -1.0] 0.11861164411456124\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 21:00:23 Float32[1.0, -2.0] 0.11854029217505176\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 21:02:00 Float32[2.0, -2.0] 0.14706539192353946\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 21:03:37 Float32[0.5, -1.25] 0.1186859734196206\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 21:05:49 Float32[1.0, -1.5] 0.11818879597965433\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 21:05:49 found minimum 0.11818879597965433 at point [1.0, -1.5] after 10 function calls (ended because MAXEVAL_REACHED) and saved model at\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 21:05:49 Training model...\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 21:07:31 Trained model loss: 0.11911191337965696\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 21:07:31 Writing alpha...\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220705 21:07:32 Wrote alpha!\n"
     ]
    }
   ],
   "source": [
    "@nbinclude(\"BPR.ipynb\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-rc1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

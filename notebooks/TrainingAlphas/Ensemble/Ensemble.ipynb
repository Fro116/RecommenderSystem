{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# Ensemble\n",
    "* Runs all the ensemble alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import NBInclude: @nbinclude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edf2b7dc-6ec0-44f9-9f88-1df84ba11362",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 18:15:33 alphas: [\"ExplicitUserItemBiases\", \"ExplicitItemCF\", \"NeuralExplicitMatrixFactorization\", \"NeuralExplicitItemCFUntuned\", \"NeuralExplicitAutoencoderUntuned\"]\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 18:15:33 coefficients: Float32[1.0176827, 0.16860016, -0.029639833, 0.46684384, 0.5104295]\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:21\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.35 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 18:16:16 validation loss: 1.3584444563770786, β: [0.99999759584032]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:12 ( 1.33 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 (11.02 ns/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 18:16:33 training loss: 1.0864266849786999, β: [0.99999759584032]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.34 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 18:16:35 test loss: 1.3681797487033311, β: [0.99999759584032]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:12 ( 1.32 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.39 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.34 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:05 ( 1.32 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.36 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.35 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.98 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.98 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 18:18:29 alphas: [\"NeuralImplicitUserItemBiases\", \"NeuralImplicitMatrixFactorization\", \"NeuralImplicitItemCFUntuned\"]\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 18:18:29 coefficients: Float32[0.019830352, 0.6352052, 0.34011975, 0.0048447805]\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:16\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 1.42 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 18:19:40 validation loss: 6.266239148137566, β: Float32[6.525346f-7, 0.9999994]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:18 ( 1.40 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 8.47 ns/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 18:20:05 training loss: 5.474239612923833, β: Float32[6.525346f-7, 0.9999994]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 1.47 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 18:20:09 test loss: 6.259880538564864, β: Float32[6.525346f-7, 0.9999994]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:13 ( 1.41 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.42 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.49 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:05 ( 1.41 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.45 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.41 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.05 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.09 μs/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@nbinclude(\"LinearModel.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "517ce91a-bf09-446a-8be9-a7c5bbe0c0f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 18:20:52 lib_lightgbm not found in system dirs, trying fallback\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.061598 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 2805\n",
      "[LightGBM] [Info] Number of data points in the train set: 22508916, number of used features: 11\n",
      "[LightGBM] [Info] Start training from score 0.002064\n",
      "Iteration: 1, test_1's l2: 1.353837675750372\n",
      "Iteration: 2, test_1's l2: 1.350161602312165\n",
      "Iteration: 3, test_1's l2: 1.347144314382674\n",
      "Iteration: 4, test_1's l2: 1.344645341993565\n",
      "Iteration: 5, test_1's l2: 1.342294067792423\n",
      "Iteration: 6, test_1's l2: 1.3404735137823818\n",
      "Iteration: 7, test_1's l2: 1.33897516191795\n",
      "Iteration: 8, test_1's l2: 1.3377152814654822\n",
      "Iteration: 9, test_1's l2: 1.3364703552430675\n",
      "Iteration: 10, test_1's l2: 1.335474227062433\n",
      "Iteration: 11, test_1's l2: 1.3345422455327556\n",
      "Iteration: 12, test_1's l2: 1.3336527888957213\n",
      "Iteration: 13, test_1's l2: 1.3329848937589364\n",
      "Iteration: 14, test_1's l2: 1.3323876861491777\n",
      "Iteration: 15, test_1's l2: 1.3317842184943696\n",
      "Iteration: 16, test_1's l2: 1.3314430727381286\n",
      "Iteration: 17, test_1's l2: 1.3310142231300004\n",
      "Iteration: 18, test_1's l2: 1.3305507083797168\n",
      "Iteration: 19, test_1's l2: 1.3301315921552104\n",
      "Iteration: 20, test_1's l2: 1.329880712801208\n",
      "Iteration: 21, test_1's l2: 1.329558454916419\n",
      "Iteration: 22, test_1's l2: 1.3293015654853382\n",
      "Iteration: 23, test_1's l2: 1.3290950785300775\n",
      "Iteration: 24, test_1's l2: 1.3289066279350477\n",
      "Iteration: 25, test_1's l2: 1.3287939455160431\n",
      "Iteration: 26, test_1's l2: 1.328554305701434\n",
      "Iteration: 27, test_1's l2: 1.3284285463251049\n",
      "Iteration: 28, test_1's l2: 1.3283216552879524\n",
      "Iteration: 29, test_1's l2: 1.3281649562835702\n",
      "Iteration: 30, test_1's l2: 1.3280857917677165\n",
      "Iteration: 31, test_1's l2: 1.3280121695464833\n",
      "Iteration: 32, test_1's l2: 1.3279881802485234\n",
      "Iteration: 33, test_1's l2: 1.3278448728482106\n",
      "Iteration: 34, test_1's l2: 1.327839945948332\n",
      "Iteration: 35, test_1's l2: 1.3277729782960024\n",
      "Iteration: 36, test_1's l2: 1.3277150583720898\n",
      "Iteration: 37, test_1's l2: 1.3275579057243097\n",
      "Iteration: 38, test_1's l2: 1.3275033499628581\n",
      "Iteration: 39, test_1's l2: 1.327442146950613\n",
      "Iteration: 40, test_1's l2: 1.3272965500710592\n",
      "Iteration: 41, test_1's l2: 1.3272327094784213\n",
      "Iteration: 42, test_1's l2: 1.32718703589055\n",
      "Iteration: 43, test_1's l2: 1.3271856441859473\n",
      "Iteration: 44, test_1's l2: 1.3271445622339344\n",
      "Iteration: 45, test_1's l2: 1.3269581619220432\n",
      "Iteration: 46, test_1's l2: 1.3268979122242661\n",
      "Iteration: 47, test_1's l2: 1.3269129504252217\n",
      "Iteration: 48, test_1's l2: 1.3268660061040636\n",
      "Iteration: 49, test_1's l2: 1.3268385748241984\n",
      "Iteration: 50, test_1's l2: 1.326772089344329\n",
      "Iteration: 51, test_1's l2: 1.326787977812205\n",
      "Iteration: 52, test_1's l2: 1.3266883981774251\n",
      "Iteration: 53, test_1's l2: 1.3266932509004528\n",
      "Iteration: 54, test_1's l2: 1.326670190244562\n",
      "Iteration: 55, test_1's l2: 1.3265666580264173\n",
      "Iteration: 56, test_1's l2: 1.3265549851461567\n",
      "Iteration: 57, test_1's l2: 1.3264366428929188\n",
      "Iteration: 58, test_1's l2: 1.3264264274604003\n",
      "Iteration: 59, test_1's l2: 1.3264246373711088\n",
      "Iteration: 60, test_1's l2: 1.3264830371334904\n",
      "Iteration: 61, test_1's l2: 1.326502383892779\n",
      "Iteration: 62, test_1's l2: 1.3265200861187583\n",
      "Iteration: 63, test_1's l2: 1.3265035170970296\n",
      "Iteration: 64, test_1's l2: 1.326534315976561\n",
      "Iteration: 65, test_1's l2: 1.326598318384005\n",
      "Iteration: 66, test_1's l2: 1.326650335502646\n",
      "Iteration: 67, test_1's l2: 1.3266541976480704\n",
      "Iteration: 68, test_1's l2: 1.3266553696999666\n",
      "Early stopping at iteration 69, the best iteration round is 59\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 18:21:45 Saving model\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:04:06\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 18:27:07 Average model value: 0.056173906\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 18:27:08 Average model absolute value: 0.17983936\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:12 ( 1.34 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.36 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.36 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:05 ( 1.33 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.36 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.37 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.98 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.98 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.47 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 18:28:24 validation loss: 1.2837550266974076, β: [1.000283352101549]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:13 ( 1.43 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 (11.84 ns/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 18:28:41 training loss: 1.0385616932066548, β: [1.000283352101549]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.56 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 18:28:44 test loss: 1.3357724780327678, β: [1.000283352101549]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:13 ( 1.43 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.44 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.45 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:05 ( 1.44 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.47 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.47 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.05 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.05 μs/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@nbinclude(\"NonlinearModel.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "765ef7e7-abf6-432e-b55d-2eea75753f32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.075509 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3315\n",
      "[LightGBM] [Info] Number of data points in the train set: 22508916, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.814650\n",
      "Iteration: 1, test_1's l2: 0.6352539645496825\n",
      "Iteration: 2, test_1's l2: 0.6268879818995813\n",
      "Iteration: 3, test_1's l2: 0.6202649577945496\n",
      "Iteration: 4, test_1's l2: 0.6150349693391801\n",
      "Iteration: 5, test_1's l2: 0.6105235781655315\n",
      "Iteration: 6, test_1's l2: 0.606448398811859\n",
      "Iteration: 7, test_1's l2: 0.6030762389242275\n",
      "Iteration: 8, test_1's l2: 0.5999594271962279\n",
      "Iteration: 9, test_1's l2: 0.5976698253425081\n",
      "Iteration: 10, test_1's l2: 0.5957145474085921\n",
      "Iteration: 11, test_1's l2: 0.5940546550009584\n",
      "Iteration: 12, test_1's l2: 0.5924839468373373\n",
      "Iteration: 13, test_1's l2: 0.5912606418888857\n",
      "Iteration: 14, test_1's l2: 0.5901953703567877\n",
      "Iteration: 15, test_1's l2: 0.5893388184935457\n",
      "Iteration: 16, test_1's l2: 0.5884974627896384\n",
      "Iteration: 17, test_1's l2: 0.5877931526444713\n",
      "Iteration: 18, test_1's l2: 0.5871659750880242\n",
      "Iteration: 19, test_1's l2: 0.5866016056793801\n",
      "Iteration: 20, test_1's l2: 0.5861162299061563\n",
      "Iteration: 21, test_1's l2: 0.5856685756298681\n",
      "Iteration: 22, test_1's l2: 0.5851441835248726\n",
      "Iteration: 23, test_1's l2: 0.5847866812434961\n",
      "Iteration: 24, test_1's l2: 0.5844901609626476\n",
      "Iteration: 25, test_1's l2: 0.5842651105559988\n",
      "Iteration: 26, test_1's l2: 0.5836935214697581\n",
      "Iteration: 27, test_1's l2: 0.5833393643935161\n",
      "Iteration: 28, test_1's l2: 0.5830661772155241\n",
      "Iteration: 29, test_1's l2: 0.5827552097850732\n",
      "Iteration: 30, test_1's l2: 0.5825637412541816\n",
      "Iteration: 31, test_1's l2: 0.5823506391097764\n",
      "Iteration: 32, test_1's l2: 0.5822024132431648\n",
      "Iteration: 33, test_1's l2: 0.5819024538137032\n",
      "Iteration: 34, test_1's l2: 0.5816079718284112\n",
      "Iteration: 35, test_1's l2: 0.5813348468764282\n",
      "Iteration: 36, test_1's l2: 0.5812112953140707\n",
      "Iteration: 37, test_1's l2: 0.5809822624206787\n",
      "Iteration: 38, test_1's l2: 0.5808336163826137\n",
      "Iteration: 39, test_1's l2: 0.5806761337200855\n",
      "Iteration: 40, test_1's l2: 0.5805121887279382\n",
      "Iteration: 41, test_1's l2: 0.5803831555471717\n",
      "Iteration: 42, test_1's l2: 0.5802021260659044\n",
      "Iteration: 43, test_1's l2: 0.5800993701304429\n",
      "Iteration: 44, test_1's l2: 0.5800432810690455\n",
      "Iteration: 45, test_1's l2: 0.5798489735942561\n",
      "Iteration: 46, test_1's l2: 0.5797996021696484\n",
      "Iteration: 47, test_1's l2: 0.5796081027996445\n",
      "Iteration: 48, test_1's l2: 0.5794956453539718\n",
      "Iteration: 49, test_1's l2: 0.5794528647482424\n",
      "Iteration: 50, test_1's l2: 0.5793769116458307\n",
      "Iteration: 51, test_1's l2: 0.579370715822765\n",
      "Iteration: 52, test_1's l2: 0.5791835481986881\n",
      "Iteration: 53, test_1's l2: 0.5790084706464401\n",
      "Iteration: 54, test_1's l2: 0.5789217724398942\n",
      "Iteration: 55, test_1's l2: 0.5788349326012673\n",
      "Iteration: 56, test_1's l2: 0.5786517300904336\n",
      "Iteration: 57, test_1's l2: 0.5785479349291074\n",
      "Iteration: 58, test_1's l2: 0.578358605212126\n",
      "Iteration: 59, test_1's l2: 0.5782167634723564\n",
      "Iteration: 60, test_1's l2: 0.5781364663243597\n",
      "Iteration: 61, test_1's l2: 0.578055662233781\n",
      "Iteration: 62, test_1's l2: 0.5779376426178789\n",
      "Iteration: 63, test_1's l2: 0.5779007847324509\n",
      "Iteration: 64, test_1's l2: 0.5777343198555508\n",
      "Iteration: 65, test_1's l2: 0.5777260908578832\n",
      "Iteration: 66, test_1's l2: 0.5777374530664652\n",
      "Iteration: 67, test_1's l2: 0.5776705429762159\n",
      "Iteration: 68, test_1's l2: 0.5775688208478409\n",
      "Iteration: 69, test_1's l2: 0.5775762326704852\n",
      "Iteration: 70, test_1's l2: 0.5775726718047743\n",
      "Iteration: 71, test_1's l2: 0.5775629461576511\n",
      "Iteration: 72, test_1's l2: 0.5775269574270906\n",
      "Iteration: 73, test_1's l2: 0.5774925226301675\n",
      "Iteration: 74, test_1's l2: 0.5774734456858364\n",
      "Iteration: 75, test_1's l2: 0.5774669898290594\n",
      "Iteration: 76, test_1's l2: 0.5774446698255344\n",
      "Iteration: 77, test_1's l2: 0.5772609743199846\n",
      "Iteration: 78, test_1's l2: 0.5772853151203368\n",
      "Iteration: 79, test_1's l2: 0.5772818403291623\n",
      "Iteration: 80, test_1's l2: 0.5772943920120642\n",
      "Iteration: 81, test_1's l2: 0.5772951399546579\n",
      "Iteration: 82, test_1's l2: 0.5773643471840556\n",
      "Iteration: 83, test_1's l2: 0.577368361953701\n",
      "Iteration: 84, test_1's l2: 0.577377493934139\n",
      "Iteration: 85, test_1's l2: 0.5773809621293482\n",
      "Iteration: 86, test_1's l2: 0.5774264309934126\n",
      "Early stopping at iteration 87, the best iteration round is 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 18:30:32 Saving model\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:05:36\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 18:37:43 Average model value: 0.92416865\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 18:37:45 Average model absolute value: 0.9241687\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:13 ( 1.44 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.46 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.44 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:05 ( 1.46 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.48 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.45 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.05 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.06 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.11 μs/it)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.188362 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3315\n",
      "[LightGBM] [Info] Number of data points in the train set: 66963121, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.104162\n",
      "Iteration: 1, test_1's l2: 0.04210724560285367\n",
      "Iteration: 2, test_1's l2: 0.037187299359665776\n",
      "Iteration: 3, test_1's l2: 0.03305286348117024\n",
      "Iteration: 4, test_1's l2: 0.029686661684525037\n",
      "Iteration: 5, test_1's l2: 0.027916939851296643\n",
      "Iteration: 6, test_1's l2: 0.025534703137839995\n",
      "Iteration: 7, test_1's l2: 0.023601511989526164\n",
      "Iteration: 8, test_1's l2: 0.022027715438411023\n",
      "Iteration: 9, test_1's l2: 0.020756524240788797\n",
      "Iteration: 10, test_1's l2: 0.01971983163836431\n",
      "Iteration: 11, test_1's l2: 0.018906487403650845\n",
      "Iteration: 12, test_1's l2: 0.018214267446854917\n",
      "Iteration: 13, test_1's l2: 0.017656293301793146\n",
      "Iteration: 14, test_1's l2: 0.01720491625657941\n",
      "Iteration: 15, test_1's l2: 0.016835148933406385\n",
      "Iteration: 16, test_1's l2: 0.016533709336743488\n",
      "Iteration: 17, test_1's l2: 0.01628900044229013\n",
      "Iteration: 18, test_1's l2: 0.01617477485291654\n",
      "Iteration: 19, test_1's l2: 0.01599924050067444\n",
      "Iteration: 20, test_1's l2: 0.01585619219219645\n",
      "Iteration: 21, test_1's l2: 0.01574001356604478\n",
      "Iteration: 22, test_1's l2: 0.015689536271317008\n",
      "Iteration: 23, test_1's l2: 0.015605524093915123\n",
      "Iteration: 24, test_1's l2: 0.015537644567285317\n",
      "Iteration: 25, test_1's l2: 0.015482084000742653\n",
      "Iteration: 26, test_1's l2: 0.015461322280782543\n",
      "Iteration: 27, test_1's l2: 0.015418502952321335\n",
      "Iteration: 28, test_1's l2: 0.015404249702527115\n",
      "Iteration: 29, test_1's l2: 0.015389813851156054\n",
      "Iteration: 30, test_1's l2: 0.01535925687861062\n",
      "Iteration: 31, test_1's l2: 0.015351629024737341\n",
      "Iteration: 32, test_1's l2: 0.015328411893991001\n",
      "Iteration: 33, test_1's l2: 0.015323790727855818\n",
      "Iteration: 34, test_1's l2: 0.015305147930167637\n",
      "Iteration: 35, test_1's l2: 0.01530169795318378\n",
      "Iteration: 36, test_1's l2: 0.015286724358232912\n",
      "Iteration: 37, test_1's l2: 0.015275676890642952\n",
      "Iteration: 38, test_1's l2: 0.015275351949971155\n",
      "Iteration: 39, test_1's l2: 0.015265657067767596\n",
      "Iteration: 40, test_1's l2: 0.015259822269543019\n",
      "Iteration: 41, test_1's l2: 0.015259780594931703\n",
      "Iteration: 42, test_1's l2: 0.015258863717839409\n",
      "Iteration: 43, test_1's l2: 0.015253508908166919\n",
      "Iteration: 44, test_1's l2: 0.015248708432474747\n",
      "Iteration: 45, test_1's l2: 0.01524435444717186\n",
      "Iteration: 46, test_1's l2: 0.015242700348918005\n",
      "Iteration: 47, test_1's l2: 0.015241768061334557\n",
      "Iteration: 48, test_1's l2: 0.015239976783693666\n",
      "Iteration: 49, test_1's l2: 0.015239902224763898\n",
      "Iteration: 50, test_1's l2: 0.015238244221092814\n",
      "Iteration: 51, test_1's l2: 0.015239348307700767\n",
      "Iteration: 52, test_1's l2: 0.01523826853372395\n",
      "Iteration: 53, test_1's l2: 0.015238892155302297\n",
      "Iteration: 54, test_1's l2: 0.01523767355297712\n",
      "Iteration: 55, test_1's l2: 0.015237160013260677\n",
      "Iteration: 56, test_1's l2: 0.015237700141112505\n",
      "Iteration: 57, test_1's l2: 0.015238032988650747\n",
      "Iteration: 58, test_1's l2: 0.015238223101587959\n",
      "Iteration: 59, test_1's l2: 0.015238587378185989\n",
      "Iteration: 60, test_1's l2: 0.015238422754961992\n",
      "Iteration: 61, test_1's l2: 0.015239029358337734\n",
      "Iteration: 62, test_1's l2: 0.015240644656470619\n",
      "Iteration: 63, test_1's l2: 0.01524190379003601\n",
      "Iteration: 64, test_1's l2: 0.015243009976405287\n",
      "Early stopping at iteration 65, the best iteration round is 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 18:40:19 Saving model\n"
     ]
    }
   ],
   "source": [
    "@nbinclude(\"ErrorModel.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f9ca73-b22b-4565-b492-a0bdc4a193c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"BPR.ipynb\");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-rc1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

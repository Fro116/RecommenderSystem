{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# Bayesian Personalized Ranking Trees\n",
    "* Creates a model for pairwise classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LightGBM\n",
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"BPRBase.ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9217decf-ddb5-462c-bf63-9e868c6ffb32",
   "metadata": {},
   "source": [
    "## Lightgbm Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaabf561-dd38-46fd-93ee-a465b51d9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO move to a shared LGBM package\n",
    "\n",
    "function augment_dataset(ds, y, w)\n",
    "    LightGBM.LGBM_DatasetSetField(ds, \"label\", y)\n",
    "    LightGBM.LGBM_DatasetSetField(ds, \"weight\", w)\n",
    "    ds\n",
    "end\n",
    "\n",
    "function create_train_dataset(X, y, w, estimator)\n",
    "    augment_dataset(\n",
    "        LightGBM.LGBM_DatasetCreateFromMat(X, LightGBM.stringifyparams(estimator), false),\n",
    "        y,\n",
    "        w,\n",
    "    )\n",
    "end\n",
    "\n",
    "function create_test_dataset(X, y, w, estimator, train_ds)\n",
    "    augment_dataset(\n",
    "        LightGBM.LGBM_DatasetCreateFromMat(\n",
    "            X,\n",
    "            LightGBM.stringifyparams(estimator),\n",
    "            train_ds,\n",
    "            false,\n",
    "        ),\n",
    "        y,\n",
    "        w,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f3e679a-1818-489a-8144-7925f00f343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_pairwise_dataset(\n",
    "    split,\n",
    "    user_features,\n",
    "    training;\n",
    "    batch_size = 1024,\n",
    "    epochs = 10000,\n",
    ")\n",
    "    @info \"getting pairwise dataset\"\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    @showprogress for _ = 1:epochs\n",
    "        batch = get_batch(split, user_features, batch_size, training = training)\n",
    "        push!(Xs, batch[1][1]')\n",
    "        push!(ys, batch[1][2]')\n",
    "    end\n",
    "    X = vcat(Xs...)\n",
    "    y = vec(vcat(ys...))\n",
    "    w = copy(y)\n",
    "    w .= 1\n",
    "    X, y, w\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd36b5c4-e382-4442-acb7-41e623521076",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c43e26b6-4fd8-4772-bf0a-1ef99c8c4cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_alpha(outdir)\n",
    "    set_logging_outdir(outdir)\n",
    "    ensemble_alphas = [\n",
    "        \"Explicit\"\n",
    "        \"LinearExplicit\"\n",
    "        \"LinearImplicit\"\n",
    "        \"ErrorExplicit\"\n",
    "        \"ErrorImplicit\"\n",
    "    ]\n",
    "    all_alphas = [\n",
    "        ensemble_alphas\n",
    "        explicit_raw_alphas\n",
    "        implicit_raw_alphas\n",
    "        nondirectional_raw_alphas\n",
    "    ]\n",
    "\n",
    "    training, test, user_features = get_data(all_alphas)\n",
    "    estimator = LGBMClassification(\n",
    "        objective = \"binary\",\n",
    "        num_iterations = 1000,\n",
    "        learning_rate = 0.01,\n",
    "        early_stopping_round = 10,\n",
    "        feature_fraction = 0.8,\n",
    "        bagging_fraction = 0.9,\n",
    "        bagging_freq = 1,\n",
    "        num_leaves = 1000,\n",
    "        num_class = 1,\n",
    "        metric = [\"binary_logloss\", \"auc\"],\n",
    "    )\n",
    "    X_train, y_train, w_train = get_pairwise_dataset(training, user_features, false)\n",
    "    X_test, y_test, w_test = get_pairwise_dataset(test, user_features, false)\n",
    "\n",
    "    train_ds = create_train_dataset(X_train, y_train, w_train, estimator)\n",
    "    test_ds = create_test_dataset(X_test, y_test, w_test, estimator, train_ds)\n",
    "    fit!(estimator, train_ds, test_ds)\n",
    "    write_params(Dict(\"model\" => estimator, \"alphas\" => all_alphas), outdir)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5d8065-b752-4c3b-a67c-78505ef67454",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_alpha(\"BPRT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a211d876-0e7b-4aca-8a4d-943ccd7fd6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration: 1000, test_1's binary_logloss: 0.11233399764707044, \n",
    "# Iteration: 1000, test_1's auc: 0.992262893711801"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-rc1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

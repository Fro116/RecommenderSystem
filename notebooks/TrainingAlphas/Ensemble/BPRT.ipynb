{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# Bayesian Personalized Ranking Trees\n",
    "* Creates a model for pairwise classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: lib_lightgbm not found in system dirs, trying fallback\n",
      "└ @ LightGBM /home/kundan/.julia/packages/LightGBM/A7zVd/src/LightGBM.jl:25\n"
     ]
    }
   ],
   "source": [
    "using LightGBM\n",
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"BPRBase.ipynb\")\n",
    "@nbinclude(\"EnsembleInputs.ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9217decf-ddb5-462c-bf63-9e868c6ffb32",
   "metadata": {},
   "source": [
    "## Lightgbm Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eaabf561-dd38-46fd-93ee-a465b51d9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO move to a shared LGBM package\n",
    "\n",
    "function augment_dataset(ds, y, w)\n",
    "    LightGBM.LGBM_DatasetSetField(ds, \"label\", y)\n",
    "    LightGBM.LGBM_DatasetSetField(ds, \"weight\", w)\n",
    "    ds\n",
    "end\n",
    "\n",
    "function create_train_dataset(X, y, w, estimator)\n",
    "    augment_dataset(\n",
    "        LightGBM.LGBM_DatasetCreateFromMat(X, LightGBM.stringifyparams(estimator), false),\n",
    "        y,\n",
    "        w,\n",
    "    )\n",
    "end\n",
    "\n",
    "function create_test_dataset(X, y, w, estimator, train_ds)\n",
    "    augment_dataset(\n",
    "        LightGBM.LGBM_DatasetCreateFromMat(\n",
    "            X,\n",
    "            LightGBM.stringifyparams(estimator),\n",
    "            train_ds,\n",
    "            false,\n",
    "        ),\n",
    "        y,\n",
    "        w,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f3e679a-1818-489a-8144-7925f00f343b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_pairwise_dataset(\n",
    "    split,\n",
    "    user_features,\n",
    "    training;\n",
    "    batch_size = 1024,\n",
    "    epochs = 10000,\n",
    ")\n",
    "    @info \"getting pairwise dataset\"\n",
    "    Xs = []\n",
    "    ys = []\n",
    "    @showprogress for _ = 1:epochs\n",
    "        batch = get_batch(split, user_features, batch_size, training = training)\n",
    "        push!(Xs, cpu(batch[1][1])')\n",
    "        push!(ys, cpu(batch[1][2])')\n",
    "    end\n",
    "    X = vcat(Xs...)\n",
    "    y = vec(vcat(ys...))\n",
    "    w = copy(y)\n",
    "    w .= 1\n",
    "    X, y, w\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd36b5c4-e382-4442-acb7-41e623521076",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c43e26b6-4fd8-4772-bf0a-1ef99c8c4cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_alpha(outdir, allow_ptw)\n",
    "    set_logging_outdir(outdir)\n",
    "    alphas = [\n",
    "        # explicit_raw_alphas\n",
    "        # implicit_raw_alphas\n",
    "        # nondirectional_raw_alphas\n",
    "        [\"Explicit\", \"NonlinearImplicit\"]\n",
    "        String[]\n",
    "    ]\n",
    "    if allow_ptw\n",
    "        append!(alphas, [\"NonlinearPtw\"])\n",
    "    end\n",
    "\n",
    "    training, test, user_features = get_data(alphas, allow_ptw)\n",
    "    estimator = LGBMClassification(\n",
    "        objective = \"binary\",\n",
    "        num_iterations = 100,\n",
    "        learning_rate = 0.01,\n",
    "        early_stopping_round = 10,\n",
    "        feature_fraction = 0.8,\n",
    "        bagging_fraction = 0.9,\n",
    "        bagging_freq = 1,\n",
    "        num_leaves = 1000,\n",
    "        num_class = 1,\n",
    "        metric = [\"auc\", \"binary_logloss\"],\n",
    "    )\n",
    "    X_train, y_train, w_train = get_pairwise_dataset(training, user_features, false)\n",
    "    X_test, y_test, w_test = get_pairwise_dataset(test, user_features, false)\n",
    "\n",
    "    train_ds = create_train_dataset(X_train, y_train, w_train, estimator)\n",
    "    test_ds = create_test_dataset(X_test, y_test, w_test, estimator, train_ds)\n",
    "    fit!(estimator, train_ds, test_ds)\n",
    "    write_params(Dict(\"model\" => estimator, \"alphas\" => alphas), outdir)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c5d8065-b752-4c3b-a67c-78505ef67454",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 20:56:44 getting user features\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:01\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 20:56:46 getting test explicit alphas\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.78 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 20:56:50 getting test implicit alphas\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.70 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 20:56:51 getting test negative alphas\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:25 ( 1.44 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:01:47 ( 6.15 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:01:01\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 21:00:21 adding priorities for test explicit\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.32 μs/it)\u001b[39mm\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 21:01:25 adding priorities for test implicit\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 2.05 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 21:01:26 adding priorities for test negative\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:03:02 (10.43 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:04:52 (16.68 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 21:10:17 getting pairwise dataset\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:08:13\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 21:19:35 getting pairwise dataset\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:06:53\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5118623, number of negative: 5121377\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.012873 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1020\n",
      "[LightGBM] [Info] Number of data points in the train set: 10240000, number of used features: 4\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.499866 -> initscore=-0.000538\n",
      "[LightGBM] [Info] Start training from score -0.000538\n",
      "Iteration: 1, test_1's auc: 0.9958026099163999, \n",
      "Iteration: 1, test_1's binary_logloss: 0.6841984779872886\n",
      "Iteration: 2, test_1's auc: 0.9928208317545321, \n",
      "Iteration: 2, test_1's binary_logloss: 0.6767344414773862\n",
      "Iteration: 3, test_1's auc: 0.9948635561690041, \n",
      "Iteration: 3, test_1's binary_logloss: 0.6681087734500963\n",
      "Iteration: 4, test_1's auc: 0.9954056575146946, \n",
      "Iteration: 4, test_1's binary_logloss: 0.6596508676074182\n",
      "Iteration: 5, test_1's auc: 0.9959501719843429, \n",
      "Iteration: 5, test_1's binary_logloss: 0.6525824895205073\n",
      "Iteration: 6, test_1's auc: 0.9956286620659711, \n",
      "Iteration: 6, test_1's binary_logloss: 0.6456496529599648\n",
      "Iteration: 7, test_1's auc: 0.9957321173137217, \n",
      "Iteration: 7, test_1's binary_logloss: 0.6376206197820904\n",
      "Iteration: 8, test_1's auc: 0.9957817329525726, \n",
      "Iteration: 8, test_1's binary_logloss: 0.6297426726616906\n",
      "Iteration: 9, test_1's auc: 0.9958117617835752, \n",
      "Iteration: 9, test_1's binary_logloss: 0.6220119768404138\n",
      "Iteration: 10, test_1's auc: 0.9958315793185681, \n",
      "Iteration: 10, test_1's binary_logloss: 0.6144240931484797\n",
      "Iteration: 11, test_1's auc: 0.9959053171497377, \n",
      "Iteration: 11, test_1's binary_logloss: 0.6069727773708566\n",
      "Iteration: 12, test_1's auc: 0.9957328268585709, \n",
      "Iteration: 12, test_1's binary_logloss: 0.6007809530490187\n",
      "Iteration: 13, test_1's auc: 0.9958874046535338, \n",
      "Iteration: 13, test_1's binary_logloss: 0.5946454257471512\n",
      "Iteration: 14, test_1's auc: 0.9959382186920557, \n",
      "Iteration: 14, test_1's binary_logloss: 0.5875509474853824\n",
      "Early stopping at iteration 15, the best iteration round is 5\n"
     ]
    }
   ],
   "source": [
    "train_alpha(\"BPR.tree\", false)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5953728c-46a8-4ef8-81dc-f15a900d80fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 21:37:24 getting user features\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:01\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 21:37:26 getting test explicit alphas\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.83 μs/it)\u001b[39mm\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 21:37:30 getting test implicit alphas\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.76 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 21:37:30 getting test negative alphas\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:25 ( 1.44 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:01:43 ( 5.93 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 21:39:55 getting test ptw alphas\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.91 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:01:48\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 21:41:44 adding priorities for test explicit\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.32 μs/it)\u001b[39mm\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 21:41:45 adding priorities for test implicit\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 2.18 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 21:42:40 adding priorities for test negative\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:03:11 (10.89 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:04:17 (14.68 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 21:51:07 adding priorities for test ptw\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.05 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:00\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 21:51:08 getting pairwise dataset\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:08:51\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220827 21:59:59 getting pairwise dataset\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:07:44\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Number of positive: 5120018, number of negative: 5119982\n",
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.014958 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1530\n",
      "[LightGBM] [Info] Number of data points in the train set: 10240000, number of used features: 6\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.500002 -> initscore=0.000007\n",
      "[LightGBM] [Info] Start training from score 0.000007\n",
      "Iteration: 1, test_1's auc: 0.9778567849644422, \n",
      "Iteration: 1, test_1's binary_logloss: 0.6853845618756418\n",
      "Iteration: 2, test_1's auc: 0.9881626177427713, \n",
      "Iteration: 2, test_1's binary_logloss: 0.6773676314688329\n",
      "Iteration: 3, test_1's auc: 0.9867320878557668, \n",
      "Iteration: 3, test_1's binary_logloss: 0.6699008520025274\n",
      "Iteration: 4, test_1's auc: 0.9901060056388191, \n",
      "Iteration: 4, test_1's binary_logloss: 0.6625391474348097\n",
      "Iteration: 5, test_1's auc: 0.9905243124447334, \n",
      "Iteration: 5, test_1's binary_logloss: 0.6549500877006545\n",
      "Iteration: 6, test_1's auc: 0.991247406978075, \n",
      "Iteration: 6, test_1's binary_logloss: 0.6470878708915015\n",
      "Iteration: 7, test_1's auc: 0.9915117744358866, \n",
      "Iteration: 7, test_1's binary_logloss: 0.6401321211987944\n",
      "Iteration: 8, test_1's auc: 0.9912004949101927, \n",
      "Iteration: 8, test_1's binary_logloss: 0.6333136322057649\n",
      "Iteration: 9, test_1's auc: 0.9913090578699049, \n",
      "Iteration: 9, test_1's binary_logloss: 0.6266003585604609\n",
      "Iteration: 10, test_1's auc: 0.9916567096414858, \n",
      "Iteration: 10, test_1's binary_logloss: 0.6196419625511398\n",
      "Iteration: 11, test_1's auc: 0.9918110392155377, \n",
      "Iteration: 11, test_1's binary_logloss: 0.6128107503262901\n",
      "Iteration: 12, test_1's auc: 0.9916773666673874, \n",
      "Iteration: 12, test_1's binary_logloss: 0.6064522172805138\n",
      "Iteration: 13, test_1's auc: 0.9918319129232656, \n",
      "Iteration: 13, test_1's binary_logloss: 0.5994861489653253\n",
      "Iteration: 14, test_1's auc: 0.9918023306353622, \n",
      "Iteration: 14, test_1's binary_logloss: 0.5933386084699499\n",
      "Iteration: 15, test_1's auc: 0.9916963180282339, \n",
      "Iteration: 15, test_1's binary_logloss: 0.5873017727594655\n",
      "Iteration: 16, test_1's auc: 0.9918189982503401, \n",
      "Iteration: 16, test_1's binary_logloss: 0.5806768406017261\n",
      "Iteration: 17, test_1's auc: 0.9919030153775908, \n",
      "Iteration: 17, test_1's binary_logloss: 0.5745111716928774\n",
      "Iteration: 18, test_1's auc: 0.9917915667140335, \n",
      "Iteration: 18, test_1's binary_logloss: 0.5687820891215218\n",
      "Iteration: 19, test_1's auc: 0.9918579379952652, \n",
      "Iteration: 19, test_1's binary_logloss: 0.5628166078458826\n",
      "Iteration: 20, test_1's auc: 0.9919388727362153, \n",
      "Iteration: 20, test_1's binary_logloss: 0.556616969340381\n",
      "Iteration: 21, test_1's auc: 0.9919362917090971, \n",
      "Iteration: 21, test_1's binary_logloss: 0.5511511676626644\n",
      "Iteration: 22, test_1's auc: 0.991964058616635, \n",
      "Iteration: 22, test_1's binary_logloss: 0.5454779333725346\n",
      "Iteration: 23, test_1's auc: 0.9919020095808987, \n",
      "Iteration: 23, test_1's binary_logloss: 0.5401999362329191\n",
      "Iteration: 24, test_1's auc: 0.9919594860023698, \n",
      "Iteration: 24, test_1's binary_logloss: 0.5346905703666177\n",
      "Iteration: 25, test_1's auc: 0.9920198959935924, \n",
      "Iteration: 25, test_1's binary_logloss: 0.5289645572891879\n",
      "Iteration: 26, test_1's auc: 0.9920374810630146, \n",
      "Iteration: 26, test_1's binary_logloss: 0.5236465048595922\n",
      "Iteration: 27, test_1's auc: 0.9920697314601179, \n",
      "Iteration: 27, test_1's binary_logloss: 0.5184022696260056\n",
      "Iteration: 28, test_1's auc: 0.9921150737787602, \n",
      "Iteration: 28, test_1's binary_logloss: 0.5129448457831811\n",
      "Iteration: 29, test_1's auc: 0.9921552162170473, \n",
      "Iteration: 29, test_1's binary_logloss: 0.5075765388906205\n",
      "Iteration: 30, test_1's auc: 0.992190555151994, \n",
      "Iteration: 30, test_1's binary_logloss: 0.5022957614925244\n",
      "Iteration: 31, test_1's auc: 0.9922216803628316, \n",
      "Iteration: 31, test_1's binary_logloss: 0.49710042348965916\n",
      "Iteration: 32, test_1's auc: 0.9922354729761168, \n",
      "Iteration: 32, test_1's binary_logloss: 0.49226710361689346\n",
      "Iteration: 33, test_1's auc: 0.9922408330515575, \n",
      "Iteration: 33, test_1's binary_logloss: 0.48751544019313514\n",
      "Iteration: 34, test_1's auc: 0.9922676292045179, \n",
      "Iteration: 34, test_1's binary_logloss: 0.4825552774088627\n",
      "Iteration: 35, test_1's auc: 0.9922308887779129, \n",
      "Iteration: 35, test_1's binary_logloss: 0.4782048466772855\n",
      "Iteration: 36, test_1's auc: 0.9922348816631102, \n",
      "Iteration: 36, test_1's binary_logloss: 0.47389488278440695\n",
      "Iteration: 37, test_1's auc: 0.9921983548014567, \n",
      "Iteration: 37, test_1's binary_logloss: 0.46967161651984213\n",
      "Iteration: 38, test_1's auc: 0.9922264312982697, \n",
      "Iteration: 38, test_1's binary_logloss: 0.4649892705452452\n",
      "Iteration: 39, test_1's auc: 0.9921851675022999, \n",
      "Iteration: 39, test_1's binary_logloss: 0.4608974755936476\n",
      "Iteration: 40, test_1's auc: 0.992198335358593, \n",
      "Iteration: 40, test_1's binary_logloss: 0.4566042772369781\n",
      "Iteration: 41, test_1's auc: 0.9922066809550035, \n",
      "Iteration: 41, test_1's binary_logloss: 0.4525970570698556\n",
      "Iteration: 42, test_1's auc: 0.9922318006864929, \n",
      "Iteration: 42, test_1's binary_logloss: 0.4481768672674009\n",
      "Iteration: 43, test_1's auc: 0.9922406522785261, \n",
      "Iteration: 43, test_1's binary_logloss: 0.44407004464393396\n",
      "Early stopping at iteration 44, the best iteration round is 34\n"
     ]
    }
   ],
   "source": [
    "train_alpha(\"BPR.tree.ptw\", true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a211d876-0e7b-4aca-8a4d-943ccd7fd6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iteration: 1000, test_1's binary_logloss: 0.11105721870720313, \n",
    "# Iteration: 1000, test_1's auc: 0.9924296197751328"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-rc1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

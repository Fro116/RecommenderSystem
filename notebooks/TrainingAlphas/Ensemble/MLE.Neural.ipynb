{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# Ranking\n",
    "* This is trained to learn the partial ordering implied by each user's watches\n",
    "* Items that are watched are preferred to items that have not been watched\n",
    "* If two items have been watched, then the impression metadata determines\n",
    "  which one, if any, is liked more\n",
    "* It uses the position aware maximum likehood estimation loss  \n",
    "* The inputs to this model are features generated by other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"MLE.Base.ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44115132-0caa-40b4-a452-de56b776212d",
   "metadata": {},
   "source": [
    "## Define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d0537cf0-2141-405e-9c84-dca26f35c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@with_kw struct EnsembleFeatures <: Features\n",
    "    user_features::AbstractMatrix\n",
    "    query_features::AbstractMatrix\n",
    "    priorities::AbstractMatrix\n",
    "    user_to_indexes::Dict\n",
    "    index_to_item::Vector\n",
    "    preprocessing_data::Dict\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "479024d7-69f8-4c26-bca0-30acb5c66fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "function training_test_split(f::Features; p::Real = 0.9)\n",
    "    training = Int32[]\n",
    "    test = Int32[]\n",
    "    cutoff = num_users() * p\n",
    "    @showprogress for u in keys(f.user_to_indexes)\n",
    "        if u < cutoff\n",
    "            push!(training, u)\n",
    "        else\n",
    "            push!(test, u)\n",
    "        end\n",
    "    end\n",
    "    training, test\n",
    "end\n",
    "\n",
    "function get_inference_data(f::Features)\n",
    "    f.preprocessing_data\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54ac16df-12aa-4511-94d4-4c2219187928",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_query_features(alphas::Vector{String}, split::String, content::String)\n",
    "    @info \"getting $split $content alphas\"\n",
    "    df = get_raw_split(split, content)\n",
    "    A = Matrix{Float16}(undef, length(df.user), length(alphas))\n",
    "    @tprogress Threads.@threads for i = 1:length(alphas)\n",
    "        A[:, i] = convert.(Float16, read_raw_alpha(alphas[i], split, content).rating)\n",
    "    end\n",
    "    collect(A')\n",
    "end;\n",
    "\n",
    "function normalize(x::AbstractArray; dims = 1)\n",
    "    T = eltype(x)\n",
    "    x = convert.(Float32, x)\n",
    "    μ = mean(x, dims = dims)\n",
    "    σ = std(x, dims = dims, mean = μ, corrected = false)\n",
    "    convert.(T, (x .- μ) ./ σ), Dict(\"μ\" => μ, \"σ\" => σ)\n",
    "end\n",
    "\n",
    "function get_user_features()\n",
    "    df = get_split(\"training\", \"implicit\")\n",
    "    implicit =\n",
    "        sparse(df.item, df.user, convert.(Float16, df.rating), num_items(), num_users())\n",
    "    df = get_split(\"training\", \"explicit\")\n",
    "    explicit =\n",
    "        sparse(df.item, df.user, convert.(Float16, df.rating), num_items(), num_users())\n",
    "    vcat(implicit, explicit)\n",
    "end\n",
    "\n",
    "function get_features(alphas::Vector{String}, allow_ptw::Bool)\n",
    "    contents = all_contents\n",
    "    if !allow_ptw\n",
    "        contents = filter(x -> x != \"ptw\", contents)\n",
    "    end\n",
    "    hreduce(f; agg = hcat) = reduce(agg, f(\"test\", content) for content in contents)\n",
    "    user_features = get_user_features()\n",
    "    query_features = hreduce((split, content) -> get_query_features(alphas, split, content))\n",
    "    query_features, preprocessing_data = normalize(query_features; dims = 2)\n",
    "    priorities = hreduce(get_priorities)\n",
    "    user_to_indexes = get_user_to_indexes([(\"test\", content) for content in contents])\n",
    "    index_to_item =\n",
    "        hreduce((split, content) -> get_raw_split(split, content).item; agg = vcat)\n",
    "    EnsembleFeatures(\n",
    "        user_features = user_features,\n",
    "        query_features = query_features,\n",
    "        priorities = priorities,\n",
    "        user_to_indexes = user_to_indexes,\n",
    "        index_to_item = index_to_item,\n",
    "        preprocessing_data = preprocessing_data,\n",
    "    )\n",
    "end\n",
    "\n",
    "function get_embedding(u::Integer, q::Integer, f::Features)\n",
    "    f.user_features[:, u], [f.index_to_item[q]], f.query_features[:, q]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5a68783-a521-4742-b6fc-371e2c68d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_sample(f::Features, users::Vector, list_size::Integer)\n",
    "    comparator = (i, j) -> compare(f.priorities[:, i], f.priorities[:, j])\n",
    "    while true\n",
    "        u = rand(users)\n",
    "        idxs = f.user_to_indexes[u]\n",
    "        if length(idxs) > 1\n",
    "            list = sample(idxs, list_size; replace = false)\n",
    "            if all(f.priorities[1, i] == 0 for i in list)\n",
    "                # if all the objects are unseen, then topological_sort will fail.\n",
    "                # topological_sort takes O(N^2) time, so we use this check to\n",
    "                # fail fast in O(N) time\n",
    "                continue\n",
    "            end\n",
    "            valid = topological_sort(list, comparator)\n",
    "            if !valid\n",
    "                # fail if all objects are non-comparable\n",
    "                continue\n",
    "            end\n",
    "            embs = []\n",
    "            for q in list\n",
    "                emb = get_embedding(u, q, f)\n",
    "                if length(embs) == 0\n",
    "                    for _ = 1:length(emb)\n",
    "                        push!(embs, [])\n",
    "                    end\n",
    "                end\n",
    "                push!.(embs, emb)\n",
    "            end\n",
    "            for i = 1:length(embs)\n",
    "                if eltype(embs[i][1]) <: Integer\n",
    "                    # for inputs that will be passed into an embedding layer\n",
    "                    embs[i] = convert.(Int32, reduce(vcat, embs[i]))\n",
    "                else\n",
    "                    # for inputs that will be passed into a dense layer\n",
    "                    embs[i] = convert.(Float32, reduce(hcat, embs[i]))\n",
    "                end\n",
    "            end\n",
    "            return embs\n",
    "        end\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5b6be697-b831-472e-9c47-de3042c9cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "function build_model(hyp::Hyperparams)\n",
    "    Chain(\n",
    "        Join(\n",
    "            vcat,\n",
    "            Dense(num_items() * 2 => 32, bias = false),\n",
    "            Embedding(num_items() => 32),\n",
    "            identity,\n",
    "        ),\n",
    "        Dense(length(hyp.alphas) + 32 * 2, 64, relu),\n",
    "        Dense(64 => 32, relu),\n",
    "        Dense(32, 1),\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a616677-313b-4e3b-847d-662c703dd666",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "376e6681-572c-41a9-9b4e-08088b2bb6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hyperparams\n",
       "  allow_ptw: Bool false\n",
       "  alphas: Array{String}((19,))\n",
       "  batch_size: Int32 1024\n",
       "  l2penalty: Float32 1.0f-5\n",
       "  learning_rate: Float32 0.0003f0\n",
       "  list_size: Int32 2\n",
       "  seed: UInt64 0x0000000001348ac1\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = [\n",
    "    \"LinearExplicit\"\n",
    "    \"LinearImplicit\"\n",
    "    \"LinearPtw\"\n",
    "    \"Explicit\"\n",
    "    \"NonlinearImplicit\"\n",
    "    \"NonlinearPtw\"\n",
    "    explicit_raw_alphas\n",
    "    implicit_raw_alphas\n",
    "    ptw_raw_alphas\n",
    "    nondirectional_raw_alphas\n",
    "];\n",
    "hyp = Hyperparams(\n",
    "    allow_ptw = false,\n",
    "    alphas = alphas,\n",
    "    batch_size = 1024,\n",
    "    l2penalty = NaN,\n",
    "    learning_rate = NaN,\n",
    "    list_size = 2,\n",
    "    seed = 20220609,\n",
    ")\n",
    "hyp = create_hyperparams(hyp, [0.0f0, 0.0f0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "248d034a-3777-4530-96ad-8fe07f8bceaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_alpha(hyp, \"MLE.Neural\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98097c60-d064-4faa-9e6d-720707628fba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 0.18465150250650614 using new mle loss formulation ( -> 64 -> 32 -> 1)\n",
    "# 0.1770052581855019 using input normalization\n",
    "# going wider by 4x didn't help\n",
    "# going deeper by 2 layers didn't help\n",
    "# 0.18148092587706433 using 50% drpout make things worse\n",
    "# 0.05950891730785771 by scaling the loss function down (should be a no-op)\n",
    "# 0.056652724017389744 with double embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c704589f-19b3-410e-bc5a-ac58a13a7e1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "true"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_checkpoints::Integer = 100\n",
    "epochs_per_checkpoint::Integer = 1\n",
    "patience::Integer = 0\n",
    "verbose::Bool = true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cc957cd-b575-4b71-9fa5-123a34c239a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221124 02:30:02 Initializing model\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221124 02:30:04 Getting data\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221124 02:30:51 getting test explicit alphas\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221124 02:30:55 getting test implicit alphas\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221124 02:30:57 getting test negative alphas\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221124 02:32:04 getting test explicit priorities\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:05 ( 3.19 μs/it)\u001b[39mit)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221124 02:32:11 getting test implicit priorities\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.49 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221124 02:32:14 getting test negative priorities\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:46 ( 2.66 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 (66.35 ns/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:18 ( 1.06 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:25\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "setup_channel (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if verbose\n",
    "    @info \"Initializing model\"\n",
    "end\n",
    "opt = ADAMW(hyp.learning_rate, (0.9, 0.999), hyp.l2penalty)\n",
    "Random.seed!(hyp.seed)\n",
    "m = build_model(hyp) |> device\n",
    "best_model = m |> cpu\n",
    "ps = Flux.params(m)\n",
    "stopper = early_stopper(\n",
    "    max_iters = max_checkpoints,\n",
    "    patience = patience,\n",
    "    min_rel_improvement = 1e-3,\n",
    ")\n",
    "batchloss(x...) = position_aware_list_mle_loss(m, x)\n",
    "epoch_size = Int(round(num_users() / hyp.batch_size))\n",
    "function loginfo(x)\n",
    "    if verbose\n",
    "        @info x\n",
    "    end\n",
    "end\n",
    "\n",
    "loginfo(\"Getting data\")\n",
    "f = get_features(hyp.alphas, false)\n",
    "training_users, test_users = training_test_split(f)\n",
    "setup_channel(users) = setup_batch_channel(f, users, hyp, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ceea1cb2-0a28-42f3-b3cd-df57100f251c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training_batches = setup_channel(training_users)\n",
    "# test_batches = setup_channel(test_users)\n",
    "# @info \"Testing channels\"\n",
    "# @info size.(get_batch(training_batches))\n",
    "# @info size.(get_batch(test_batches))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "259e713c-7978-41bf-9666-74aed3627f88",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1.210589 seconds (6.11 M allocations: 344.920 MiB, 14.69% gc time, 98.52% compilation time)\n",
      "  0.032599 seconds (204.72 k allocations: 19.338 MiB, 54.93% gc time)\n",
      "  0.014125 seconds (203.99 k allocations: 19.056 MiB)\n",
      "  0.031455 seconds (204.10 k allocations: 19.913 MiB, 53.88% gc time)\n",
      "  0.013228 seconds (203.74 k allocations: 18.514 MiB)\n",
      "  0.013833 seconds (205.72 k allocations: 19.149 MiB)\n",
      "  0.028171 seconds (203.17 k allocations: 18.490 MiB, 51.90% gc time)\n",
      "  0.013380 seconds (202.92 k allocations: 19.042 MiB)\n",
      "  0.024673 seconds (203.91 k allocations: 19.305 MiB, 46.40% gc time)\n",
      "  0.013333 seconds (204.86 k allocations: 18.546 MiB)\n",
      "  0.024385 seconds (204.02 k allocations: 20.226 MiB, 45.86% gc time)\n",
      "  0.013281 seconds (205.76 k allocations: 18.801 MiB)\n",
      "  0.013086 seconds (203.28 k allocations: 18.514 MiB)\n",
      "  0.024162 seconds (204.13 k allocations: 18.932 MiB, 46.32% gc time)\n",
      "  0.013190 seconds (203.68 k allocations: 18.777 MiB)\n",
      "  0.023981 seconds (203.47 k allocations: 19.371 MiB, 46.33% gc time)\n",
      "  0.012951 seconds (202.22 k allocations: 18.967 MiB)\n",
      "  0.024257 seconds (203.04 k allocations: 18.889 MiB, 46.24% gc time)\n",
      "  0.013176 seconds (203.60 k allocations: 19.137 MiB)\n",
      "  0.024651 seconds (203.68 k allocations: 19.935 MiB, 45.77% gc time)\n",
      "  0.012892 seconds (204.70 k allocations: 18.386 MiB)\n",
      "  0.013490 seconds (204.26 k allocations: 20.139 MiB)\n",
      "  0.023931 seconds (202.87 k allocations: 19.171 MiB, 46.45% gc time)\n",
      "  0.013164 seconds (203.76 k allocations: 18.308 MiB)\n",
      "  0.023983 seconds (203.41 k allocations: 18.544 MiB, 46.74% gc time)\n",
      "  0.013103 seconds (203.44 k allocations: 18.789 MiB)\n",
      "  0.024498 seconds (203.66 k allocations: 18.655 MiB, 46.38% gc time)\n",
      "  0.012894 seconds (205.22 k allocations: 18.955 MiB)\n",
      "  0.013233 seconds (203.20 k allocations: 18.136 MiB)\n",
      "  0.024982 seconds (205.18 k allocations: 18.457 MiB, 46.31% gc time)\n",
      "  0.013378 seconds (204.24 k allocations: 18.484 MiB)\n",
      "  0.024598 seconds (203.53 k allocations: 19.346 MiB, 46.81% gc time)\n",
      "  0.013325 seconds (205.37 k allocations: 18.929 MiB)\n",
      "  0.024531 seconds (203.81 k allocations: 18.566 MiB, 46.04% gc time)\n",
      "  0.013016 seconds (204.33 k allocations: 18.756 MiB)\n",
      "  0.013188 seconds (204.06 k allocations: 18.771 MiB)\n",
      "  0.024317 seconds (204.03 k allocations: 19.581 MiB, 46.32% gc time)\n",
      "  0.013138 seconds (203.71 k allocations: 18.635 MiB)\n",
      "  0.024308 seconds (204.74 k allocations: 18.734 MiB, 46.36% gc time)\n",
      "  0.012998 seconds (202.48 k allocations: 19.284 MiB)\n",
      "  0.024522 seconds (203.31 k allocations: 20.232 MiB, 45.77% gc time)\n",
      "  0.012989 seconds (203.72 k allocations: 18.951 MiB)\n",
      "  0.013145 seconds (203.95 k allocations: 18.332 MiB)\n",
      "  0.024141 seconds (204.36 k allocations: 19.093 MiB, 46.42% gc time)\n",
      "  0.013167 seconds (203.88 k allocations: 18.850 MiB)\n",
      "  0.023884 seconds (203.44 k allocations: 18.645 MiB, 46.56% gc time)\n",
      "  0.013224 seconds (203.73 k allocations: 19.398 MiB)\n",
      "  0.024128 seconds (203.06 k allocations: 18.705 MiB, 46.56% gc time)\n",
      "  0.013302 seconds (205.24 k allocations: 18.921 MiB)\n",
      "  0.024745 seconds (204.39 k allocations: 18.982 MiB, 46.09% gc time)\n",
      "  0.012990 seconds (203.71 k allocations: 18.785 MiB)\n",
      "  0.013631 seconds (205.06 k allocations: 19.464 MiB)\n",
      "  0.025098 seconds (203.60 k allocations: 19.095 MiB, 46.78% gc time)\n",
      "  0.013144 seconds (203.55 k allocations: 18.771 MiB)\n",
      "  0.024388 seconds (204.32 k allocations: 17.932 MiB, 47.12% gc time)\n",
      "  0.013294 seconds (204.20 k allocations: 19.529 MiB)\n",
      "  0.024558 seconds (204.21 k allocations: 18.254 MiB, 46.13% gc time)\n",
      "  0.012830 seconds (204.39 k allocations: 18.918 MiB)\n",
      "  0.013306 seconds (203.75 k allocations: 20.083 MiB)\n",
      "  0.024432 seconds (204.76 k allocations: 19.268 MiB, 45.59% gc time)\n",
      "  0.013184 seconds (202.68 k allocations: 18.951 MiB)\n",
      "  0.024182 seconds (205.84 k allocations: 18.526 MiB, 46.20% gc time)\n",
      "  0.013171 seconds (204.58 k allocations: 19.084 MiB)\n",
      "  0.024775 seconds (205.12 k allocations: 18.752 MiB, 46.07% gc time)\n",
      "  0.012886 seconds (204.80 k allocations: 19.157 MiB)\n",
      "  0.013280 seconds (204.69 k allocations: 18.985 MiB)\n",
      "  0.024087 seconds (205.27 k allocations: 18.452 MiB, 46.16% gc time)\n",
      "  0.013103 seconds (204.91 k allocations: 19.076 MiB)\n",
      "  0.024097 seconds (203.03 k allocations: 18.832 MiB, 46.51% gc time)\n",
      "  0.013174 seconds (203.34 k allocations: 18.572 MiB)\n",
      "  0.024948 seconds (204.00 k allocations: 18.669 MiB, 46.91% gc time)\n",
      "  0.013155 seconds (203.63 k allocations: 19.158 MiB)\n",
      "  0.013319 seconds (202.51 k allocations: 19.186 MiB)\n",
      "  0.024445 seconds (204.48 k allocations: 19.366 MiB, 46.74% gc time)\n",
      "  0.013182 seconds (204.48 k allocations: 19.480 MiB)\n",
      "  0.024361 seconds (203.88 k allocations: 19.594 MiB, 46.02% gc time)\n",
      "  0.013249 seconds (204.30 k allocations: 19.109 MiB)\n",
      "  0.024228 seconds (204.88 k allocations: 18.810 MiB, 45.91% gc time)\n",
      "  0.013069 seconds (202.94 k allocations: 18.885 MiB)\n",
      "  0.024588 seconds (204.47 k allocations: 19.638 MiB, 45.66% gc time)\n",
      "  0.012791 seconds (204.26 k allocations: 18.366 MiB)\n",
      "  0.013097 seconds (202.88 k allocations: 19.286 MiB)\n",
      "  0.024300 seconds (205.35 k allocations: 19.036 MiB, 46.31% gc time)\n",
      "  0.012933 seconds (203.76 k allocations: 18.380 MiB)\n",
      "  0.024325 seconds (205.16 k allocations: 18.820 MiB, 46.61% gc time)\n",
      "  0.013178 seconds (203.10 k allocations: 19.493 MiB)\n",
      "  0.024558 seconds (203.93 k allocations: 19.239 MiB, 46.31% gc time)\n",
      "  0.013340 seconds (205.78 k allocations: 19.364 MiB)\n",
      "  0.013085 seconds (202.45 k allocations: 18.641 MiB)\n",
      "  0.024362 seconds (204.56 k allocations: 18.756 MiB, 46.35% gc time)\n",
      "  0.013005 seconds (203.38 k allocations: 18.237 MiB)\n",
      "  0.023913 seconds (203.83 k allocations: 18.735 MiB, 46.66% gc time)\n",
      "  0.013074 seconds (203.07 k allocations: 19.032 MiB)\n",
      "  0.024571 seconds (202.92 k allocations: 18.418 MiB, 46.71% gc time)\n",
      "  0.012950 seconds (204.67 k allocations: 18.860 MiB)\n",
      "  0.013212 seconds (203.83 k allocations: 19.494 MiB)\n",
      "  0.024014 seconds (204.39 k allocations: 19.643 MiB, 45.81% gc time)\n",
      "  0.012975 seconds (201.75 k allocations: 18.673 MiB)\n",
      "  0.023723 seconds (203.23 k allocations: 18.213 MiB, 46.52% gc time)\n",
      "  0.013272 seconds (204.31 k allocations: 19.070 MiB)\n"
     ]
    }
   ],
   "source": [
    "for _ = 1:100\n",
    "    @time batch = get_batch(f, training_users, hyp.list_size, hyp.batch_size)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0fb3eb-74f7-43c0-b8eb-d75ad68760ed",
   "metadata": {},
   "source": [
    "### "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# Ranking\n",
    "* This is trained to learn the partial ordering implied by each user's watches\n",
    "* Items that are watched are preferred to items that have not been watched\n",
    "* If two items have been watched, then the impression metadata determines\n",
    "  which one, if any, is liked more\n",
    "* It uses the position aware maximum likehood estimation loss  \n",
    "* The inputs to this model are features generated by other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"BPR.Base.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ac16df-12aa-4511-94d4-4c2219187928",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_query_features(alphas::Vector{String}, split::String, content::String)\n",
    "    @info \"getting $split $content alphas\"\n",
    "    df = get_raw_split(split, content)\n",
    "    A = Matrix{Float16}(undef, length(df.user), length(alphas))\n",
    "    @tprogress Threads.@threads for i = 1:length(alphas)\n",
    "        A[:, i] = convert.(Float16, read_raw_alpha(alphas[i], split, content).rating)\n",
    "    end\n",
    "    collect(A')\n",
    "end;\n",
    "\n",
    "function normalize(x::AbstractArray; dims = 1)\n",
    "    T = eltype(x)\n",
    "    x = convert.(Float32, x)\n",
    "    μ = mean(x, dims = dims)\n",
    "    σ = std(x, dims = dims, mean = μ, corrected = false)\n",
    "    convert.(T, (x .- μ) ./ σ), Dict(\"μ\" => μ, \"σ\" => σ)\n",
    "end\n",
    "\n",
    "function get_user_features()\n",
    "    df = get_split(\"training\", \"implicit\")\n",
    "    sparse(df.item, df.user, convert.(Float16, df.rating), num_items(), num_users())\n",
    "end\n",
    "\n",
    "function get_features(alphas::Vector{String}, allow_ptw::Bool)\n",
    "    contents = all_contents\n",
    "    if !allow_ptw\n",
    "        contents = filter(x -> x != \"ptw\", contents)\n",
    "    end\n",
    "    hreduce(f; agg = hcat) = reduce(agg, f(\"test\", content) for content in contents)\n",
    "    user_features = get_user_features()\n",
    "    query_features = hreduce((split, content) -> get_query_features(alphas, split, content))\n",
    "    query_features, preprocessing_data = normalize(query_features; dims = 2)\n",
    "    priorities = hreduce(get_priorities)\n",
    "    user_to_indexes = get_user_to_indexes([(\"test\", content) for content in contents])\n",
    "    index_to_item =\n",
    "        hreduce((split, content) -> get_raw_split(split, content).item; agg = vcat)\n",
    "    user_features,\n",
    "    query_features,\n",
    "    priorities,\n",
    "    user_to_indexes,\n",
    "    index_to_item,\n",
    "    preprocessing_data\n",
    "end\n",
    "\n",
    "function get_embedding(\n",
    "    u::Integer,\n",
    "    a::Integer,\n",
    "    q::Integer,\n",
    "    user_features::AbstractMatrix,\n",
    "    query_features::AbstractMatrix,\n",
    ")\n",
    "    user_features[:, u], [a], query_features[:, q]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6be697-b831-472e-9c47-de3042c9cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "function build_model(hyp::Hyperparams)\n",
    "    Chain(\n",
    "        Join(\n",
    "            vcat,\n",
    "            Dense(num_items() => 32, bias = false),\n",
    "            Embedding(num_items() => 32),\n",
    "            identity,\n",
    "        ),\n",
    "        Dense(length(hyp.alphas) + 32 * 2, 64, relu),\n",
    "        Dense(64 => 32, relu),\n",
    "        Dense(32, 1),\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376e6681-572c-41a9-9b4e-08088b2bb6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas = [\n",
    "    \"LinearExplicit\"\n",
    "    \"LinearImplicit\"\n",
    "    \"LinearPtw\"\n",
    "    \"Explicit\"\n",
    "    \"NonlinearImplicit\"\n",
    "    \"NonlinearPtw\"\n",
    "    explicit_raw_alphas\n",
    "    implicit_raw_alphas\n",
    "    ptw_raw_alphas\n",
    "    nondirectional_raw_alphas\n",
    "];\n",
    "hyp = Hyperparams(\n",
    "    allow_ptw = false,\n",
    "    alphas = alphas,\n",
    "    batch_size = 1024,\n",
    "    input_size = -1,\n",
    "    l2penalty = NaN,\n",
    "    learning_rate = NaN,\n",
    "    list_size = 2,\n",
    "    seed = 20220609,\n",
    ")\n",
    "hyp = create_hyperparams(hyp, [0.0f0, 0.0f0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248d034a-3777-4530-96ad-8fe07f8bceaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_alpha(hyp, \"BPR.Neural.Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98097c60-d064-4faa-9e6d-720707628fba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 0.18465150250650614 using new mle loss formulation ( -> 64 -> 32 -> 1)\n",
    "# 0.1770052581855019 using input normalization\n",
    "# going wider by 4x didn't help\n",
    "# going deeper by 2 layers didn't help\n",
    "# 0.18148092587706433 using 50% drpout make things worse\n",
    "# 0.05950891730785771 by scaling the loss function down (should be a no-op)\n",
    "# 0.056652724017389744 with double embedding"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

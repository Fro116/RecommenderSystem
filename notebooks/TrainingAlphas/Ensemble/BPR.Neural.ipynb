{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# Ranking\n",
    "* This is trained to learn the partial ordering implied by each user's watches\n",
    "* Items that are watched are preferred to items that have not been watched\n",
    "* If two items have been watched, then the impression metadata determines\n",
    "  which one, if any, is liked more\n",
    "* It uses the position aware maximum likehood estimation loss  \n",
    "* The inputs to this model are features generated by other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"BPR.Base.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54ac16df-12aa-4511-94d4-4c2219187928",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_features(alphas::Vector{String}, split::String, content::String)\n",
    "    @info \"getting $split $content alphas\"\n",
    "    df = get_raw_split(split, content)\n",
    "    A = Matrix{Float16}(undef, length(df.user), length(alphas))\n",
    "    @tprogress Threads.@threads for i = 1:length(alphas)\n",
    "        A[:, i] = convert.(Float16, read_raw_alpha(alphas[i], split, content).rating)\n",
    "    end\n",
    "    collect(A')\n",
    "end;\n",
    "\n",
    "function normalize(x::AbstractArray; dims = 1)\n",
    "    T = eltype(x)\n",
    "    x = convert.(Float32, x)\n",
    "    μ = mean(x, dims = dims)\n",
    "    σ = std(x, dims = dims, mean = μ, corrected = false)\n",
    "    convert.(T, (x .- μ) ./ σ), Dict(\"μ\" => μ, \"σ\" => σ)\n",
    "end\n",
    "\n",
    "function get_user_features()\n",
    "    df = get_split(\"training\", \"implicit\")\n",
    "    sparse(df.item, df.user, convert.(Float16, df.rating), num_items(), num_users())\n",
    "end\n",
    "\n",
    "function get_features(alphas::Vector{String}, allow_ptw::Bool)\n",
    "    contents = all_contents\n",
    "    if !allow_ptw\n",
    "        contents = filter(x -> x != \"ptw\", contents)\n",
    "    end\n",
    "    hreduce(f; agg = hcat) = reduce(agg, f(\"test\", content) for content in contents)\n",
    "    user_features = get_user_features()\n",
    "    query_features = hreduce((split, content) -> get_features(alphas, split, content))\n",
    "    query_features, preprocessing_data = normalize(query_features; dims = 2)\n",
    "    priorities = hreduce(get_priorities)\n",
    "    user_to_indexes = get_user_to_indexes([(\"test\", content) for content in contents])\n",
    "    index_to_item =\n",
    "        hreduce((split, content) -> get_raw_split(split, content).item; agg = vcat)\n",
    "    user_features,\n",
    "    query_features,\n",
    "    priorities,\n",
    "    user_to_indexes,\n",
    "    index_to_item,\n",
    "    preprocessing_data\n",
    "end\n",
    "\n",
    "function get_embedding(\n",
    "    u::Integer,\n",
    "    a::Integer,\n",
    "    q::Integer,\n",
    "    user_features::AbstractMatrix,\n",
    "    query_features::AbstractMatrix,\n",
    ")\n",
    "    user_features[:, u], [a], query_features[:, q]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b6be697-b831-472e-9c47-de3042c9cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "function build_model(hyp::Hyperparams)\n",
    "    Chain(\n",
    "        Join(\n",
    "            vcat,\n",
    "            Dense(num_items() => 32, bias = false),\n",
    "            Embedding(num_items() => 32),\n",
    "            identity,\n",
    "        ),\n",
    "        Dense(length(hyp.alphas) + 32 * 2, 64, relu),\n",
    "        Dense(64 => 32, relu),\n",
    "        Dense(32, 1),\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "376e6681-572c-41a9-9b4e-08088b2bb6a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Hyperparams\n",
       "  allow_ptw: Bool false\n",
       "  alphas: Array{String}((19,))\n",
       "  batch_size: Int32 1024\n",
       "  input_size: Int32 22724\n",
       "  l2penalty: Float32 1.0f-5\n",
       "  learning_rate: Float32 0.0003f0\n",
       "  list_size: Int32 2\n",
       "  seed: UInt64 0x0000000001348ac1\n"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alphas = [\n",
    "    \"LinearExplicit\"\n",
    "    \"LinearImplicit\"\n",
    "    \"LinearPtw\"\n",
    "    \"Explicit\"\n",
    "    \"NonlinearImplicit\"\n",
    "    \"NonlinearPtw\"\n",
    "    explicit_raw_alphas\n",
    "    implicit_raw_alphas\n",
    "    ptw_raw_alphas\n",
    "    nondirectional_raw_alphas\n",
    "];\n",
    "hyp = Hyperparams(\n",
    "    allow_ptw = false,\n",
    "    alphas = alphas,\n",
    "    batch_size = 1024,\n",
    "    input_size = -1,\n",
    "    l2penalty = NaN,\n",
    "    learning_rate = NaN,\n",
    "    list_size = 2,\n",
    "    seed = 20220609,\n",
    ")\n",
    "hyp = create_hyperparams(hyp, [0.0f0, 0.0f0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248d034a-3777-4530-96ad-8fe07f8bceaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221121 11:56:32 Training model...\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221121 11:56:32 Initializing model\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221121 11:56:33 Getting data\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221121 11:57:19 getting test explicit alphas\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221121 11:57:22 getting test implicit alphas\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221121 11:57:24 getting test negative alphas\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221121 11:58:17 getting test explicit priorities\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:04 ( 3.10 μs/it)\u001b[39mit)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221121 11:58:26 getting test implicit priorities\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.84 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221121 11:58:29 getting test negative priorities\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:44 ( 2.54 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:17 ( 0.97 μs/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221121 12:00:42 HI\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221121 12:01:00 ((22705, 2, 1024), (2, 1024), (19, 2, 1024))\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221121 12:01:01 ((22705, 2, 1024), (2, 1024), (19, 2, 1024))\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:06:08\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221121 12:07:09 Training model with initial loss 0.8120647381714489\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:07:01\u001b[39mm\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:06:07\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221121 12:20:18 loss 0.06523086232088701\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:06:24\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:06:06\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221121 12:32:50 loss 0.0625551988583644\n",
      "\u001b[32mProgress:  18%|███████▌                                 |  ETA: 0:05:09\u001b[39m"
     ]
    }
   ],
   "source": [
    "train_alpha(hyp, \"BPR.Neural.Test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98097c60-d064-4faa-9e6d-720707628fba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 0.18465150250650614 using new mle loss formulation ( -> 64 -> 32 -> 1)\n",
    "# 0.1770052581855019 using input normalization\n",
    "# going wider by 4x didn't help\n",
    "# going deeper by 2 layers didn't help\n",
    "# 0.18148092587706433 using 50% drpout make things worse\n",
    "# 0.05950891730785771 by scaling the loss function down (should be a no-op)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

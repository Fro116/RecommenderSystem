{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# Ranking\n",
    "* This is trained to learn the partial ordering implied by each user's watches\n",
    "* Items that are watched are preferred to items that have not been watched\n",
    "* If two items have been watched, then the impression metadata determines\n",
    "  which one, if any, is liked more\n",
    "* It uses a generalized form of the position aware maximum likehood estimation loss that handles posets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import CUDA\n",
    "import Flux\n",
    "import Flux: Chain, Dense, Dropout, cpu, gpu, relu, sigmoid\n",
    "import Optimisers\n",
    "import Optimisers: Adam, OptimiserChain, WeightDecay\n",
    "import NBInclude: @nbinclude\n",
    "import NLopt\n",
    "import Random\n",
    "import Setfield: @set\n",
    "import SparseArrays: AbstractSparseArray, sparse, SparseMatrixCSC, SparseVector\n",
    "import Statistics: mean, std\n",
    "import StatsBase: sample\n",
    "@nbinclude(\"../Alpha.ipynb\")\n",
    "@nbinclude(\"../Neural/Helpers/GPU.ipynb\");\n",
    "@nbinclude(\"EnsembleInputs.ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c844803-8039-40f4-9e6d-d6c32de910ec",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df06e3d4-898e-4dca-b224-d416fde35457",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstract type Features end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ced8d21-51e8-4193-b66c-2aad73ee9164",
   "metadata": {},
   "outputs": [],
   "source": [
    "@with_kw struct Hyperparams\n",
    "    alphas::Vector{String}\n",
    "    batch_size::Int32\n",
    "    embedding_size::Int32\n",
    "    holdout::Float32\n",
    "    l2penalty::Float32\n",
    "    learning_rate::Float32\n",
    "    list_size::Int32\n",
    "    seed::UInt64\n",
    "end\n",
    "\n",
    "function to_dict(x::Hyperparams)\n",
    "    Dict(string(key) => getfield(x, key) for key ∈ fieldnames(Hyperparams))\n",
    "end\n",
    "\n",
    "function Base.string(x::Hyperparams)\n",
    "    fields = [x for x in fieldnames(Hyperparams)]\n",
    "    max_field_size = maximum(length(string(k)) for k in fields)\n",
    "    ret = \"Hyperparameters:\\n\"\n",
    "    for f in fields\n",
    "        ret *= \"$(rpad(string(f), max_field_size)) => $(getfield(x, f))\\n\"\n",
    "    end\n",
    "    ret\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadbdc6d-d986-4870-a4e6-6467ac3aea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "function create_hyperparams(hyp, λ)\n",
    "    hyp = @set hyp.learning_rate = 3e-4 * 10^(-λ[1])\n",
    "    hyp = @set hyp.holdout = sigmoid(-1 + λ[2])\n",
    "    hyp = @set hyp.l2penalty = 10^(λ[3] - 5)\n",
    "    hyp\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf14fd83-b9d8-4fa9-85e0-d05f406a63d7",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f484df12-2b54-4c19-97ea-e7a87eaf566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_priority_size()\n",
    "    4\n",
    "end\n",
    "\n",
    "function get_priority(df::RatingsDataset, content::String, i::Integer)\n",
    "    # todo remove on next recrunch           \n",
    "    if content != \"negative\"\n",
    "        completion = min(max(df.completion[i], 0), 1)\n",
    "    end\n",
    "\n",
    "    if content == \"explicit\"\n",
    "        priority = Float16[1, df.rating[i], df.status[i], completion]\n",
    "    elseif content in [\"implicit\", \"ptw\"]\n",
    "        priority = Float16[1, NaN, df.status[i], completion]\n",
    "    elseif content == \"negative\"\n",
    "        priority = Float16[0, NaN, NaN, NaN]\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "    @assert length(priority) == get_priority_size()\n",
    "    priority\n",
    "end\n",
    "\n",
    "function get_priorities(split::String, task::String, content::String)\n",
    "    @info \"getting $split $task $content priorities\"\n",
    "    df = get_raw_split(split, task, content)\n",
    "    A = Matrix{Float16}(undef, get_priority_size(), length(df.user))\n",
    "    @tprogress Threads.@threads for i = 1:length(df.user)\n",
    "        A[:, i] = get_priority(df, content, i)\n",
    "    end\n",
    "    A\n",
    "end\n",
    "\n",
    "function compare(x::Number, y::Number)\n",
    "    if isnan(x) || isnan(y)\n",
    "        return NaN\n",
    "    elseif abs(x - y) < eps(eltype(x))\n",
    "        return 0\n",
    "    elseif x > y\n",
    "        return 1\n",
    "    else\n",
    "        return -1\n",
    "    end\n",
    "end\n",
    "\n",
    "function compare(x::Vector, y::Vector)\n",
    "    @assert length(x) == length(y)\n",
    "    retval = 0\n",
    "    for i = 1:length(x)\n",
    "        r = compare(x[i], y[i])\n",
    "        if isnan(r)\n",
    "            retval = NaN\n",
    "        elseif r != 0\n",
    "            return r\n",
    "        end\n",
    "    end\n",
    "    retval\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06e8394-41e5-45ee-a871-82d286036d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_user_to_indexes(split_content_pairs::Vector, task::String, include::Function)\n",
    "    u_to_xs = Dict{Int32,Vector{Int32}}(u => Int32[] for u = 1:num_users())\n",
    "    index_base::Int32 = 0\n",
    "    for (split, content) in split_content_pairs\n",
    "        df = get_raw_split(split, task, content)\n",
    "        if include(split, content)\n",
    "            # multithread by sharding on userid\n",
    "            idxs = [[[] for _ = 1:Threads.nthreads()] for _ = 1:Threads.nthreads()]\n",
    "            @tprogress Threads.@threads for i = 1:length(df.user)\n",
    "                push!(idxs[Threads.threadid()][df.user[i]%Threads.nthreads()+1], i)\n",
    "            end\n",
    "            Threads.@threads for t = 1:Threads.nthreads()\n",
    "                for idx in idxs\n",
    "                    for i in idx[t]\n",
    "                        push!(u_to_xs[df.user[i]], i + index_base)\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "        index_base += length(df.item)\n",
    "    end\n",
    "\n",
    "    # prune unused users\n",
    "    for u = 1:num_users()\n",
    "        if length(u_to_xs[u]) == 0\n",
    "            delete!(u_to_xs, u)\n",
    "        end\n",
    "    end\n",
    "    u_to_xs\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8208244b-0585-4207-83b3-f1c8b18c089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_preferences(V::Vector{Int32}, E::Function)\n",
    "    P = zeros(Int32, length(V), length(V))\n",
    "    for i = 1:length(V)\n",
    "        P[i, i] = 1\n",
    "    end\n",
    "    for i = 1:length(V)\n",
    "        for j = i+1:length(V)\n",
    "            cmp = E(V[i], V[j])\n",
    "            if cmp == 1\n",
    "                P[i, j] = 1\n",
    "            elseif cmp == -1\n",
    "                P[j, i] = 1\n",
    "            elseif cmp == 0\n",
    "                # expand ties\n",
    "                P[i, j] = 1\n",
    "                P[j, i] = 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    P\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecca61c-92a0-4f58-9e2a-a6d6671d9fc8",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef580ec-b209-42a2-b28c-4d4066a01c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "function position_aware_list_mle_loss(m, x, P)\n",
    "    # position aware list mle loss with a modifications to handle non-comparable items\n",
    "    # P is the preference relation where P[i, j] = 1 iff i is prefered to j\n",
    "\n",
    "    p = Flux.flatten(m(x))\n",
    "    p = p .- maximum(p; dims = 1)\n",
    "    q = exp.(p)\n",
    "\n",
    "    ϵ = Float32(eps(Float64))\n",
    "    N, batch_size = size(p)\n",
    "    r = ones(Float32, N) |> device\n",
    "\n",
    "    total = 0.0f0\n",
    "    for i = 1:batch_size\n",
    "        w = ((2.0f0 .^ (P[:, :, i] * r) .- 1) ./ (2^N - 1))\n",
    "        unweighted_loss = -p[:, i] + log.(P[:, :, i] * q[:, i] .+ ϵ)\n",
    "        total += sum(w .* unweighted_loss)\n",
    "    end\n",
    "    total / batch_size\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6f3c5b-3f96-4c25-b9a2-a61839f8c6c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function average_loss(m, f::Features, hyp::Hyperparams, iters::Integer)\n",
    "    loss = 0.0\n",
    "    @showprogress for _ = 1:iters\n",
    "        batch = get_batch(f, false, hyp.list_size, hyp.batch_size, hyp.holdout)\n",
    "        loss += position_aware_list_mle_loss(m, batch...)\n",
    "        device_free!(batch)\n",
    "    end\n",
    "    loss / iters\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb55068-feaf-4f29-b6e6-e2ea18451efa",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f42b26-a76f-4145-a4d7-a641980ccd15",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_epoch!(m, opt, f::Features, hyp::Hyperparams, epoch_size::Integer)\n",
    "    @showprogress for _ = 1:epoch_size\n",
    "        batch = get_batch(f, true, hyp.list_size, hyp.batch_size, hyp.holdout)\n",
    "        grads = Flux.gradient(m) do model\n",
    "            position_aware_list_mle_loss(model, batch...)\n",
    "        end        \n",
    "        device_free!(batch)\n",
    "        Flux.update!(opt, m, grads[1])        \n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000bad20-6037-4d47-8d18-18d72cd35d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trains a model with the given hyperparams and returns its validation loss\n",
    "function train_model(\n",
    "    hyp::Hyperparams,\n",
    "    task::String,\n",
    "    outdir::String;\n",
    "    max_checkpoints::Integer,\n",
    "    epochs_per_checkpoint::Integer,\n",
    "    patience::Integer,\n",
    "    verbose::Bool = true,\n",
    ")\n",
    "    if verbose\n",
    "        @info \"Initializing model\"\n",
    "    end\n",
    "    rng = Random.Xoshiro(hyp.seed)\n",
    "    Random.seed!(rand(rng, UInt64))\n",
    "    if CUDA.functional()\n",
    "        Random.seed!(CUDA.default_rng(), rand(rng, UInt64))\n",
    "        Random.seed!(CUDA.CURAND.default_rng(), rand(rng, UInt64))\n",
    "    end\n",
    "    m = build_model(hyp) |> device\n",
    "    opt = Optimisers.setup(\n",
    "        OptimiserChain(Adam(hyp.learning_rate, (0.9f0, 0.999f0)), WeightDecay(hyp.l2penalty)),\n",
    "        m,\n",
    "    )    \n",
    "    best_model = m |> cpu\n",
    "    stopper = early_stopper(\n",
    "        max_iters = max_checkpoints,\n",
    "        patience = patience,\n",
    "        min_rel_improvement = 1e-3,\n",
    "    )\n",
    "    function loginfo(x)\n",
    "        if verbose\n",
    "            @info x\n",
    "        end\n",
    "    end\n",
    "    loginfo(\"Getting data\")\n",
    "    f = get_features(hyp.alphas, task)\n",
    "    epoch_size = Int(round(length(f.user_to_indexes) / hyp.batch_size))    \n",
    "    loginfo(\"Training model...\")\n",
    "    curloss = Inf\n",
    "    losses = []\n",
    "    while (!stop!(stopper, curloss))\n",
    "        for _ = 1:epochs_per_checkpoint\n",
    "            train_epoch!(m, opt, f, hyp, epoch_size)\n",
    "        end\n",
    "        curloss = average_loss(m, f, hyp, epoch_size)\n",
    "        push!(losses, curloss)\n",
    "        if curloss == minimum(losses)\n",
    "            best_model = m |> cpu\n",
    "            write_params(\n",
    "                Dict(\n",
    "                    \"m\" => best_model,\n",
    "                    \"hyp\" => hyp,\n",
    "                    \"inference_data\" => get_inference_data(f),\n",
    "                ),\n",
    "                outdir,\n",
    "            )\n",
    "        end\n",
    "        loginfo(\"loss $curloss\")\n",
    "    end\n",
    "\n",
    "    best_model, minimum(losses), f\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd36b5c4-e382-4442-acb7-41e623521076",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd45d6f1-f2a5-4ea9-830e-c93b4c6c3395",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_alpha(hyp, task::String, outdir::String; tune_hyperparams::Bool = false)\n",
    "    set_logging_outdir(outdir)\n",
    "\n",
    "    if tune_hyperparams\n",
    "        @info \"Optimizing hyperparameters...\"\n",
    "        λ = optimize_hyperparams(hyp; max_evals = 10)\n",
    "        hyp = create_hyperparams(hyp, λ)\n",
    "    end\n",
    "\n",
    "    @info \"Training model...\"\n",
    "    m, validation_loss, f = train_model(\n",
    "        hyp,\n",
    "        task,\n",
    "        outdir;\n",
    "        max_checkpoints = 50,\n",
    "        epochs_per_checkpoint = 1,\n",
    "        patience = 2,\n",
    "    )\n",
    "    @info \"Trained model loss: $validation_loss\"\n",
    "\n",
    "    @info \"Writing alpha...\"\n",
    "    write_params(\n",
    "        Dict(\"m\" => m, \"hyp\" => hyp, \"inference_data\" => get_inference_data(f)),\n",
    "        outdir,\n",
    "    )\n",
    "    # write_alpha(\n",
    "    #     (split::String, task::String, content::String; raw_splits::Bool = true) ->\n",
    "    #         inference_model(m, hyp, f, split, task, content; raw_splits = raw_splits),\n",
    "    #     outdir;\n",
    "    #     by_split = true,\n",
    "    #     log = false,\n",
    "    # )\n",
    "    @info \"Wrote alpha!\"\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acd199c-8ffe-4cc6-814f-30406387eeff",
   "metadata": {},
   "source": [
    "## Methods to override in subclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2f9f4d-180a-4f2e-b21e-b2e2e15d00e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_features(alphas::Vector{String})\n",
    "    Base.error(\"not implemented\")\n",
    "end\n",
    "\n",
    "function build_model(hyp::Hyperparams)\n",
    "    Base.error(\"not implemented\")\n",
    "end\n",
    "\n",
    "function get_inference_data(f::Features)\n",
    "    Base.error(\"not implemented\")\n",
    "end\n",
    "\n",
    "function get_batch(\n",
    "    f::Features,\n",
    "    training::Bool,\n",
    "    list_size::Integer,\n",
    "    batch_size::Integer,\n",
    "    holdout::Float32,\n",
    ")\n",
    "    Base.error(\"not implemented\")\n",
    "end\n",
    "\n",
    "function inference_model(\n",
    "    hyp::Hyperparams,\n",
    "    f::Features,\n",
    "    split::String,\n",
    "    task::String,\n",
    "    content::String;\n",
    "    raw_splits::Bool,\n",
    ")\n",
    "    Base.error(\"not implemented\")\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# Ranking\n",
    "* This is trained to learn the partial ordering implied by each user's watches\n",
    "* Items that are watched are preferred to items that have not been watched\n",
    "* If two items have been watched, then the impression metadata determines\n",
    "  which one, if any, is liked more\n",
    "* It uses the position aware maximum likehood estimation loss  \n",
    "* The inputs to this model are features generated by other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using Flux\n",
    "\n",
    "import CUDA\n",
    "import SparseArrays: sparse\n",
    "import Statistics: mean, std\n",
    "import StatsBase: sample\n",
    "import NLopt\n",
    "import Random\n",
    "import NBInclude: @nbinclude\n",
    "import Setfield: @set\n",
    "@nbinclude(\"../Alpha.ipynb\")\n",
    "@nbinclude(\"../Neural/Helpers/GPU.ipynb\");\n",
    "@nbinclude(\"EnsembleInputs.ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c844803-8039-40f4-9e6d-d6c32de910ec",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ced8d21-51e8-4193-b66c-2aad73ee9164",
   "metadata": {},
   "outputs": [],
   "source": [
    "@with_kw struct Hyperparams\n",
    "    allow_ptw::Bool\n",
    "    alphas::Vector{String}\n",
    "    batch_size::Int32\n",
    "    input_size::Int32\n",
    "    l2penalty::Float32\n",
    "    learning_rate::Float32\n",
    "    list_size::Int32\n",
    "    seed::UInt64\n",
    "end\n",
    "\n",
    "function to_dict(x::Hyperparams)\n",
    "    Dict(string(key) => getfield(x, key) for key ∈ fieldnames(Hyperparams))\n",
    "end\n",
    "\n",
    "function Base.string(x::Hyperparams)\n",
    "    fields = [x for x in fieldnames(Hyperparams)]\n",
    "    max_field_size = maximum(length(string(k)) for k in fields)\n",
    "    ret = \"Hyperparameters:\\n\"\n",
    "    for f in fields\n",
    "        ret *= \"$(rpad(string(f), max_field_size)) => $(getfield(x, f))\\n\"\n",
    "    end\n",
    "    ret\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadbdc6d-d986-4870-a4e6-6467ac3aea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "function create_hyperparams(hyp, λ)\n",
    "    hyp = @set hyp.input_size = length(alphas) + num_items()\n",
    "    hyp = @set hyp.learning_rate = 3e-4 * 10^(-λ[1])\n",
    "    hyp = @set hyp.l2penalty = 10^(λ[2] - 5)\n",
    "    hyp\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf14fd83-b9d8-4fa9-85e0-d05f406a63d7",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f484df12-2b54-4c19-97ea-e7a87eaf566e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_priority(df::RatingsDataset, content::String, i::Integer)\n",
    "    if content == \"explicit\"\n",
    "        priority = [2, df.rating[i], df.status[i], df.completion[i]]\n",
    "    elseif content == \"implicit\"\n",
    "        priority = [2, NaN, df.status[i], df.completion[i]]\n",
    "    elseif content == \"ptw\"\n",
    "        priority = [1, NaN, NaN, NaN]\n",
    "    elseif content == \"negative\"\n",
    "        priority = [0, NaN, NaN, NaN]\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "    @assert length(priority) == get_priority_size()\n",
    "    convert.(Float16, priority)\n",
    "end\n",
    "\n",
    "function get_priority_size()\n",
    "    4\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec20c00-d18f-43fd-b18d-a63b8d46eec4",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_priorities(split::String, content::String)\n",
    "    @info \"getting $split $content priorities\"\n",
    "    df = get_raw_split(split, content)\n",
    "    A = Matrix{Float16}(undef, get_priority_size(), length(df.user))\n",
    "    @tprogress Threads.@threads for i = 1:length(df.user)\n",
    "        A[:, i] = get_priority(df, content, i)\n",
    "    end\n",
    "    A\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d06e8394-41e5-45ee-a871-82d286036d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_user_to_indexes(split_content_pairs::Vector)\n",
    "    # preallocate to avoid race conditions\n",
    "    u_to_xs = Dict{Int32,Vector{Int32}}()\n",
    "    for u = 1:num_users()\n",
    "        u_to_xs[u] = Int32[]\n",
    "    end\n",
    "\n",
    "    for (split, content) in split_content_pairs\n",
    "        df = get_raw_split(split, content)\n",
    "        # multithread by sharding on userid\n",
    "        idxs = [[[] for _ = 1:Threads.nthreads()] for _ = 1:Threads.nthreads()]\n",
    "        @tprogress Threads.@threads for i = 1:length(df.user)\n",
    "            push!(idxs[Threads.threadid()][df.user[i]%Threads.nthreads()+1], i)\n",
    "        end\n",
    "        Threads.@threads for t = 1:Threads.nthreads()\n",
    "            for idx in idxs\n",
    "                for i in idx[t]\n",
    "                    push!(u_to_xs[df.user[i]], i)\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # prune unused users\n",
    "    for u = 1:num_users()\n",
    "        if length(u_to_xs[u]) == 0\n",
    "            delete!(u_to_xs, u)\n",
    "        end\n",
    "    end\n",
    "    u_to_xs\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "192d0036-55be-4c41-b069-8a74d186a9b7",
   "metadata": {},
   "source": [
    "## Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c51820a-cc21-4c6e-b6b6-b785adedc575",
   "metadata": {},
   "outputs": [],
   "source": [
    "function compare(x::Number, y::Number)\n",
    "    if isnan(x) && isnan(y)\n",
    "        return 0\n",
    "    elseif isnan(x) || isnan(y)\n",
    "        return NaN\n",
    "    elseif x == y\n",
    "        return 0\n",
    "    elseif x > y\n",
    "        return 1\n",
    "    else\n",
    "        return -1\n",
    "    end\n",
    "end\n",
    "\n",
    "function compare(x::Vector, y::Vector)\n",
    "    @assert length(x) == length(y)\n",
    "    for i = 1:length(x)\n",
    "        r = compare(x[i], y[i])\n",
    "        if isnan(r)\n",
    "            return NaN\n",
    "        elseif r != 0\n",
    "            return r\n",
    "        end\n",
    "    end\n",
    "    0\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8208244b-0585-4207-83b3-f1c8b18c089a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function topological_sort(V::Vector, E::Function)\n",
    "    # performs a topoplogical sort to get a random permutation that's\n",
    "    # consistent with the poset implied by the graph G = (V, E)\n",
    "    T = eltype(V)\n",
    "    children = Dict{T,Set{T}}(u => Set{T}() for u in V)\n",
    "    num_parents = Dict{T,Int32}(u => 0 for u in V)\n",
    "    edges = 0\n",
    "    for u in V\n",
    "        for v in V\n",
    "            if E(u, v) == 1\n",
    "                push!(children[u], v)\n",
    "                num_parents[v] += 1\n",
    "                edges += 1\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    if edges == 0\n",
    "        return V, false\n",
    "    end\n",
    "\n",
    "    rootless = Set{T}(v for v in V if num_parents[v] == 0)\n",
    "    @assert length(rootless) > 0\n",
    "\n",
    "    toposort = T[]\n",
    "    while length(rootless) > 0\n",
    "        v = rand(rootless)\n",
    "        delete!(rootless, v)\n",
    "        push!(toposort, v)\n",
    "        for u in children[v]\n",
    "            num_parents[u] -= 1\n",
    "            @assert num_parents[u] >= 0\n",
    "            if num_parents[u] == 0\n",
    "                push!(rootless, u)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    toposort, true\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e365eb9b-2c16-4ffd-974d-1744cf6ad812",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_batch(\n",
    "    f,\n",
    "    users::Vector,\n",
    "    list_size::Integer,\n",
    "    batch_size::Integer,\n",
    ")\n",
    "    embs = []\n",
    "    for _ = 1:batch_size\n",
    "        sample = get_sample(\n",
    "            f,\n",
    "            users,\n",
    "            list_size,\n",
    "        )\n",
    "        if length(embs) == 0\n",
    "            for _ in 1:length(sample)\n",
    "                push!(embs, [])\n",
    "            end\n",
    "        end        \n",
    "        push!.(embs, sample)\n",
    "    end\n",
    "    embs\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8926dc9c-4ee2-428c-8606-4fe40e58669f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function setup_batch_channel(\n",
    "    f,\n",
    "    users::Vector,\n",
    "    hyp::Hyperparams,\n",
    "    channel_size::Integer,\n",
    ")\n",
    "    batches = Channel(channel_size)\n",
    "    for t = 1:Threads.nthreads()\n",
    "        Threads.@spawn begin\n",
    "            while true\n",
    "                try\n",
    "                    batch = get_batch(\n",
    "                        f,\n",
    "                        users,\n",
    "                        hyp.list_size,\n",
    "                        hyp.batch_size,\n",
    "                    )\n",
    "                    put!(batches, batch)\n",
    "                catch e\n",
    "                    break\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    batches\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e19f4ba-5e14-41bd-b149-04e2f57e15b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_batch(c::Channel)\n",
    "    batch = take!(c)\n",
    "    tuple((Flux.batch(device.(batch[i])) for i in 1:length(batch))...)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ecca61c-92a0-4f58-9e2a-a6d6671d9fc8",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef580ec-b209-42a2-b28c-4d4066a01c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "function position_aware_list_mle_loss(m, x)\n",
    "    p = Flux.flatten(m(x))\n",
    "\n",
    "    # for numerical stability\n",
    "    p = p .- maximum(p; dims = 1)\n",
    "    ϵ = Float32(eps(Float64))\n",
    "\n",
    "    N, batch_size = size(p)\n",
    "    C = collect(LinearAlgebra.UpperTriangular(ones(Float32, N, N))) |> device\n",
    "    w = convert.(Float32, vec(2 .^ (N:-1:1) .- 1)) ./ (2^N - 1) |> device\n",
    "    sum(w .* (-p + log.(C * exp.(p) .+ ϵ))) / batch_size\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca6f3c5b-3f96-4c25-b9a2-a61839f8c6c6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function average_loss(m, batches::Channel, iters::Integer, hyp::Hyperparams)\n",
    "    loss = 0.0\n",
    "    @showprogress for _ = 1:iters\n",
    "        loss += position_aware_list_mle_loss(m, get_batch(batches))\n",
    "    end\n",
    "    loss / iters\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb55068-feaf-4f29-b6e6-e2ea18451efa",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000bad20-6037-4d47-8d18-18d72cd35d05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# trains a model with the given hyperparams and returns its validation loss\n",
    "function train_model(\n",
    "    hyp::Hyperparams;\n",
    "    max_checkpoints::Integer = 100,\n",
    "    epochs_per_checkpoint::Integer = 10,\n",
    "    patience::Integer = 0,\n",
    "    verbose::Bool = true,\n",
    ")\n",
    "    if verbose\n",
    "        @info \"Initializing model\"\n",
    "    end\n",
    "    opt = ADAMW(hyp.learning_rate, (0.9, 0.999), hyp.l2penalty)\n",
    "    Random.seed!(hyp.seed)\n",
    "    m = build_model(hyp) |> device\n",
    "    best_model = m |> cpu\n",
    "    ps = Flux.params(m)\n",
    "    stopper = early_stopper(\n",
    "        max_iters = max_checkpoints,\n",
    "        patience = patience,\n",
    "        min_rel_improvement = 1e-3,\n",
    "    )\n",
    "    batchloss(x...) = position_aware_list_mle_loss(m, x)\n",
    "    epoch_size = Int(round(num_users() / hyp.batch_size))\n",
    "    function loginfo(x)\n",
    "        if verbose\n",
    "            @info x\n",
    "        end\n",
    "    end\n",
    "\n",
    "    loginfo(\"Getting data\")\n",
    "    f = get_features(hyp.alphas, false)\n",
    "    training_users, test_users = training_test_split(f)\n",
    "    setup_channel(users) = setup_batch_channel(\n",
    "        f,\n",
    "        users,\n",
    "        hyp,\n",
    "        64,\n",
    "    )\n",
    "    training_batches = setup_channel(training_users)\n",
    "    test_batches = setup_channel(test_users)\n",
    "    @info \"Testing channels\"\n",
    "    @info size.(get_batch(training_batches))\n",
    "    @info size.(get_batch(test_batches))\n",
    "\n",
    "\n",
    "    loginfo(\n",
    "        \"Training model with initial loss $(average_loss(m, test_batches, epoch_size, hyp))\",\n",
    "    )\n",
    "    loss = Inf\n",
    "    losses = []\n",
    "    while (!stop!(stopper, loss))\n",
    "        for _ = 1:epochs_per_checkpoint\n",
    "            @showprogress for _ = 1:epoch_size\n",
    "                Flux.train!(batchloss, ps, [get_batch(training_batches)], opt)\n",
    "            end\n",
    "        end\n",
    "\n",
    "        loss = average_loss(m, test_batches, epoch_size, hyp)\n",
    "        push!(losses, loss)\n",
    "        if loss == minimum(losses)\n",
    "            best_model = m |> cpu\n",
    "        end\n",
    "        loginfo(\"loss $loss\")\n",
    "    end\n",
    "    close(training_batches)\n",
    "    close(test_batches)\n",
    "    best_model, minimum(losses), get_inference_data(f)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4db189-a655-43dd-b93a-2d449e6a6354",
   "metadata": {},
   "source": [
    "## Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aebe789-d898-4872-b5e2-376ea1074cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function optimize_hyperparams(hyp; max_evals)\n",
    "#     function nlopt_loss(λ, grad)\n",
    "#         # nlopt internally converts to float64 because it calls a c library\n",
    "#         λ = convert.(Float32, λ)\n",
    "#         _, loss = train_model(create_hyperparams(hyp, λ))\n",
    "#         @info \"$λ $loss\"\n",
    "#         loss\n",
    "#     end\n",
    "#     opt = NLopt.Opt(:LN_NELDERMEAD, 2)\n",
    "#     opt.initial_step = 1\n",
    "#     opt.maxeval = max_evals\n",
    "#     opt.min_objective = nlopt_loss\n",
    "#     minf, λ, ret = NLopt.optimize(opt, zeros(Float32, 2))\n",
    "#     numevals = opt.numevals\n",
    "\n",
    "#     @info (\n",
    "#         \"found minimum $minf at point $λ after $numevals function calls \" *\n",
    "#         \"(ended because $ret) and saved model at\"\n",
    "#     )\n",
    "#     λ\n",
    "# end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd36b5c4-e382-4442-acb7-41e623521076",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd45d6f1-f2a5-4ea9-830e-c93b4c6c3395",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_alpha(hyp, outdir; tune_hyperparams = false)\n",
    "    set_logging_outdir(outdir)\n",
    "\n",
    "    if tune_hyperparams\n",
    "        @info \"Optimizing hyperparameters...\"\n",
    "        λ = optimize_hyperparams(hyp; max_evals = 10)\n",
    "    else\n",
    "        λ = zeros(2)\n",
    "    end\n",
    "    hyp = create_hyperparams(hyp, λ)\n",
    "\n",
    "    @info \"Training model...\"\n",
    "    m, validation_loss, inference_data =\n",
    "        train_model(hyp; max_checkpoints = 100, epochs_per_checkpoint = 1, patience = 5)\n",
    "    @info \"Trained model loss: $validation_loss\"\n",
    "\n",
    "    @info \"Writing alpha...\"\n",
    "    # TODO write the actual alpha value\n",
    "    write_params(\n",
    "        Dict(\"m\" => m, \"λ\" => λ, \"hyp\" => hyp, \"inference_data\" => inference_data),\n",
    "        outdir,\n",
    "    )\n",
    "    @info \"Wrote alpha!\"\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4acd199c-8ffe-4cc6-814f-30406387eeff",
   "metadata": {},
   "source": [
    "## Methods to override in subclasses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2f9f4d-180a-4f2e-b21e-b2e2e15d00e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_features(alphas::Vector{String}, allow_ptw::Bool)\n",
    "    Base.error(\"not implemented\")\n",
    "end\n",
    "\n",
    "function build_model(hyp::Hyperparams)\n",
    "    Base.error(\"not implemented\")\n",
    "end\n",
    "\n",
    "function get_inference_data(f)\n",
    "    Base.error(\"not implemented\")    \n",
    "end\n",
    "\n",
    "function get_sample(\n",
    "    f,\n",
    "    users::Vector,\n",
    "    list_size::Integer,\n",
    ")\n",
    "    Base.error(\"not implemented\")    \n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

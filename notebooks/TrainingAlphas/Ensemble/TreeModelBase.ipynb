{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# TreeModelBase\n",
    "* Uses LightGBM to fit a tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: lib_lightgbm found in system dirs!\n",
      "└ @ LightGBM /Users/kundan/.julia/packages/LightGBM/A7zVd/src/LightGBM.jl:28\n"
     ]
    }
   ],
   "source": [
    "using LightGBM\n",
    "\n",
    "import SparseArrays: sparse\n",
    "import Statistics: mean\n",
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"../Alpha.ipynb\");\n",
    "@nbinclude(\"EnsembleInputs.ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "add8b6e4-e53d-4f2b-9183-df18f637b182",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eaabf561-dd38-46fd-93ee-a465b51d9a7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function augment_dataset(ds, y, w)\n",
    "    LightGBM.LGBM_DatasetSetField(ds, \"label\", y)\n",
    "    LightGBM.LGBM_DatasetSetField(ds, \"weight\", w)\n",
    "    ds\n",
    "end\n",
    "\n",
    "function create_train_dataset(X, y, w, estimator)\n",
    "    augment_dataset(\n",
    "        LightGBM.LGBM_DatasetCreateFromMat(X, LightGBM.stringifyparams(estimator), false),\n",
    "        y,\n",
    "        w,\n",
    "    )\n",
    "end\n",
    "\n",
    "function create_test_dataset(X, y, w, estimator, train_ds)\n",
    "    augment_dataset(\n",
    "        LightGBM.LGBM_DatasetCreateFromMat(\n",
    "            X,\n",
    "            LightGBM.stringifyparams(estimator),\n",
    "            train_ds,\n",
    "            false,\n",
    "        ),\n",
    "        y,\n",
    "        w,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "433e3b27-07c6-4943-a3b7-037dada703b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_features(alphas, split, implicit)\n",
    "    reduce(hcat, [read_alpha(x, split, implicit).rating for x in alphas])\n",
    "end\n",
    "\n",
    "function get_data(split::String, feature_alphas, target_alphas, implicit, error_model)\n",
    "    X = get_features(feature_alphas, split, implicit)\n",
    "    if implicit\n",
    "        if error_model\n",
    "            y =\n",
    "                get_split(split, implicit).rating .*\n",
    "                get_weights(split, implicit, \"inverse\") -\n",
    "                read_alpha(target_alphas, split, implicit).rating\n",
    "            w = get_weights(split, implicit, \"inverse\")\n",
    "        else\n",
    "            @assert false\n",
    "        end\n",
    "    else\n",
    "        y =\n",
    "            get_split(split, implicit).rating -\n",
    "            read_alpha(target_alphas, split, implicit).rating\n",
    "        w = get_weights(split, implicit, \"inverse\")\n",
    "    end\n",
    "    if error_model\n",
    "        y = abs.(y)\n",
    "    end\n",
    "    training_mask = get_split(split, implicit).user .<= num_users() * 0.9\n",
    "    X_train, X_test = X[training_mask, :], X[.!training_mask, :]\n",
    "    y_train, y_test = y[training_mask], y[.!training_mask]\n",
    "    w_train, w_test = w[training_mask], w[.!training_mask]\n",
    "    X_train, X_test, y_train, y_test, w_train, w_test\n",
    "end\n",
    "\n",
    "function get_data(\n",
    "    splits::Vector{String},\n",
    "    feature_alphas,\n",
    "    target_alphas,\n",
    "    implicit,\n",
    "    error_model,\n",
    "    estimator,\n",
    ")\n",
    "    data = []\n",
    "    for split in splits\n",
    "        push!(data, get_data(split, feature_alphas, target_alphas, implicit, error_model))\n",
    "    end\n",
    "    X_train = reduce(vcat, data[n][1] for n = 1:length(data))\n",
    "    X_test = reduce(vcat, data[n][2] for n = 1:length(data))\n",
    "    y_train = reduce(vcat, data[n][3] for n = 1:length(data))\n",
    "    y_test = reduce(vcat, data[n][4] for n = 1:length(data))\n",
    "    w_train = reduce(vcat, data[n][5] for n = 1:length(data))\n",
    "    w_test = reduce(vcat, data[n][6] for n = 1:length(data))\n",
    "    train_ds = create_train_dataset(X_train, y_train, w_train, estimator)\n",
    "    test_ds = create_test_dataset(X_test, y_test, w_test, estimator, train_ds)\n",
    "    train_ds, test_ds\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c1b8c10-b11a-43de-8e22-955a07e29c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_model(\n",
    "    feature_alphas,\n",
    "    target_alphas,\n",
    "    implicit,\n",
    "    training_splits::Vector{String},\n",
    "    outdir,\n",
    "    error_model,\n",
    ")\n",
    "    set_logging_outdir(outdir)\n",
    "\n",
    "    # create lightgbm tree model\n",
    "    estimator = LGBMRegression(\n",
    "        num_iterations = 100,\n",
    "        learning_rate = 0.1,\n",
    "        early_stopping_round = 10,\n",
    "        feature_fraction = 0.8,\n",
    "        bagging_fraction = 0.9,\n",
    "        bagging_freq = 1,\n",
    "        num_leaves = 1000,\n",
    "    )\n",
    "\n",
    "    # get training data\n",
    "    train_ds, test_ds = get_data(\n",
    "        training_splits,\n",
    "        feature_alphas,\n",
    "        target_alphas,\n",
    "        implicit,\n",
    "        error_model,\n",
    "        estimator,\n",
    "    )\n",
    "\n",
    "    # train model\n",
    "    fit!(estimator, train_ds, test_ds)\n",
    "\n",
    "    # save model\n",
    "    @info \"Saving model... (this may take a while)\"\n",
    "    write_params(Dict(\"model\" => estimator, \"alphas\" => feature_alphas), outdir)\n",
    "    splits = reduce(cat, [get_split(split, implicit) for split in all_raw_splits])\n",
    "    split_features = reduce(\n",
    "        vcat,\n",
    "        [get_features(feature_alphas, split, implicit) for split in all_raw_splits],\n",
    "    )\n",
    "    preds = vec(predict(estimator, split_features))\n",
    "    sparse_preds = sparse(splits.user, splits.item, preds)\n",
    "    @info \"Average model value: $(mean(preds))\"\n",
    "    write_alpha(sparse_preds, target_alphas, implicit, outdir; log_splits = false)\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-rc1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

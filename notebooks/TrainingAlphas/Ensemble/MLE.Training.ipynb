{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# Ranking\n",
    "* This is trained to learn the partial ordering implied by each user's watches\n",
    "* Items that are watched are preferred to items that have not been watched\n",
    "* If two items have been watched, then the impression metadata determines\n",
    "  which one, if any, is liked more\n",
    "* It uses the position aware maximum likehood estimation loss  \n",
    "* The inputs to this model are features generated by other models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"MLE.Base.ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44115132-0caa-40b4-a452-de56b776212d",
   "metadata": {},
   "source": [
    "## Define Subclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0537cf0-2141-405e-9c84-dca26f35c1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "@with_kw struct TrainingFeatures <: Features\n",
    "    user_features::SparseMatrixCSC{Float32,Int32}\n",
    "    priorities::Matrix{Float16}\n",
    "\n",
    "    index_to_item::Vector{Int32}\n",
    "    index_to_training::Vector{Bool}\n",
    "    item_user_index::SparseMatrixCSC{Int32,Int32}\n",
    "\n",
    "    user_to_training_indexes::Dict{Int32,Vector{Int32}}\n",
    "    user_to_indexes::Dict{Int32,Vector{Int32}}\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479024d7-69f8-4c26-bca0-30acb5c66fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_inference_data(f::Features)\n",
    "    Dict()\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74492be9-0af2-4ff0-96a9-ab88711c2433",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_implicit_features()\n",
    "    df = get_split(\"training\", \"implicit\")\n",
    "    sparse(df.item, df.user, df.rating, num_items(), num_users())\n",
    "end\n",
    "function get_explicit_features()\n",
    "    df = get_split(\"training\", \"explicit\")\n",
    "    sparse(df.item, df.user, df.rating, num_items(), num_users())\n",
    "end\n",
    "function get_user_features()\n",
    "    vcat(get_implicit_features(), get_explicit_features())\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54ac16df-12aa-4511-94d4-4c2219187928",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_features(alphas::Vector{String}, allow_ptw::Bool)\n",
    "    @assert length(alphas) == 0\n",
    "    contents = filter(x -> x != \"negative\", all_contents)\n",
    "    if !allow_ptw\n",
    "        contents = filter(x -> x != \"ptw\", contents)\n",
    "    end\n",
    "    splits = [\"training\", \"validation\"]\n",
    "\n",
    "    user_to_training_indexes = get_user_to_indexes(\n",
    "        [(split, content) for split in splits for content in contents],\n",
    "        (split, content) -> split == \"training\",\n",
    "    )\n",
    "    user_to_indexes = get_user_to_indexes(\n",
    "        [(split, content) for split in splits for content in contents],\n",
    "        (split, content) -> true,\n",
    "    )\n",
    "\n",
    "    hreduce(f; agg = hcat) =\n",
    "        reduce(agg, f(split, content) for split in splits for content in contents)\n",
    "    user_features = get_user_features()\n",
    "    priorities = hreduce(get_priorities)\n",
    "    index_to_item =\n",
    "        hreduce((split, content) -> get_raw_split(split, content).item; agg = vcat)\n",
    "    index_to_training = hreduce(\n",
    "        (split, content) -> fill(\n",
    "            split == \"training\" ? true : false,\n",
    "            length(get_raw_split(split, content).item),\n",
    "        );\n",
    "        agg = vcat,\n",
    "    )\n",
    "\n",
    "    item_user_index = sparse(Int32[], Int32[], Int32[], num_items(), num_users())\n",
    "    idx = 1\n",
    "    for split in splits\n",
    "        @showprogress for content in contents\n",
    "            df = get_raw_split(split, content)\n",
    "            item_user_index += sparse(\n",
    "                df.item,\n",
    "                df.user,\n",
    "                collect(idx:(length(df.item)+idx-1)),\n",
    "                num_items(),\n",
    "                num_users(),\n",
    "            )\n",
    "            idx += length(df.item)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    TrainingFeatures(\n",
    "        user_features = user_features,\n",
    "        priorities = priorities,\n",
    "        index_to_item = index_to_item,\n",
    "        index_to_training = index_to_training,\n",
    "        item_user_index = item_user_index,\n",
    "        user_to_training_indexes = user_to_training_indexes,\n",
    "        user_to_indexes = user_to_indexes,\n",
    "    )\n",
    "end\n",
    "\n",
    "function get_user_embedding(u::Integer, list::Vector{Int32}, f::Features)\n",
    "    U = f.user_features[:, u]\n",
    "    for a in list\n",
    "        for i = a:num_items():length(U)\n",
    "            U[i] = 0\n",
    "        end\n",
    "    end\n",
    "    U\n",
    "end\n",
    "\n",
    "function get_item_embedding(q::Integer, f::Features)\n",
    "    q\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a68783-a521-4742-b6fc-371e2c68d5f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_priority(f::Features, u::Integer, i::Integer, training::Bool)\n",
    "    idx = f.item_user_index[i, u]\n",
    "    if (idx == 0) || (training && !f.index_to_training[idx])\n",
    "        return Float16[0, NaN, NaN, NaN]\n",
    "    end\n",
    "    f.priorities[:, idx]\n",
    "end\n",
    "\n",
    "function comparator(f::Features, u::Integer, i::Integer, j::Integer, training::Bool)\n",
    "    lhs = get_priority(f, u, i, training)\n",
    "    rhs = get_priority(f, u, j, training)\n",
    "    compare(lhs, rhs)\n",
    "end\n",
    "\n",
    "function get_sample(f::Features, training::Bool, list_size::Integer)\n",
    "    while true\n",
    "        # sample an item the user has seen\n",
    "        u = rand(1:num_users())\n",
    "        if training\n",
    "            u_to_idxs = f.user_to_training_indexes\n",
    "        else\n",
    "            u_to_idxs = f.user_to_indexes\n",
    "        end\n",
    "        if u ∉ keys(u_to_idxs)\n",
    "            continue\n",
    "        end\n",
    "        nonneg_item = f.index_to_item[rand(u_to_idxs[u])]\n",
    "        # sample random items to fill out the list\n",
    "        list = sample(Int32(1):Int32(num_items()), list_size; replace = false)\n",
    "        if nonneg_item ∉ list\n",
    "            list[1] = nonneg_item\n",
    "        end\n",
    "        # construct a random ranking that is consistent with the user's preferences\n",
    "        if !topological_sort!(list, (i, j) -> comparator(f, u, i, j, training))\n",
    "            continue\n",
    "        end\n",
    "        # batch the input features\n",
    "        u_embs = fill(get_user_embedding(u, list, f), list_size)\n",
    "        a_embs = Int32[get_item_embedding(q, f) for q in list]\n",
    "        return hcat(u_embs...), a_embs\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e37f5661-ff25-4c27-a0ce-31e73f730238",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_batch(f::Features, training::Bool, list_size::Integer, batch_size::Integer)\n",
    "    u_embs = SparseMatrixCSC{Float32,Int32}[]\n",
    "    a_embs = Vector{Int32}[]\n",
    "    for _ = 1:batch_size\n",
    "        u_emb, a_emb = get_sample(f, training, list_size)\n",
    "        push!(u_embs, u_emb)\n",
    "        push!(a_embs, a_emb)\n",
    "    end\n",
    "    hcat(u_embs...), hcat(a_embs...)\n",
    "end\n",
    "\n",
    "function get_batch(c::Channel, training::Bool, holdout::Float32)\n",
    "    u_embs, a_embs = device.(take!(c))\n",
    "    batch_size = size(a_embs)[2]\n",
    "    tsize = (size(u_embs)[1], size(u_embs)[2] ÷ batch_size, batch_size)\n",
    "    if training\n",
    "        randfn = CUDA.functional() ? CUDA.rand : rand\n",
    "        mask = randfn(num_items()) .>= holdout\n",
    "        u_embs .*= repeat(mask, size(u_embs)[1] ÷ size(mask)[1])\n",
    "    end\n",
    "    reshape(u_embs, tsize), a_embs\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b6be697-b831-472e-9c47-de3042c9cd86",
   "metadata": {},
   "outputs": [],
   "source": [
    "function build_model(hyp::Hyperparams)\n",
    "    K = 32\n",
    "    Chain(\n",
    "        Join(\n",
    "            vcat,\n",
    "            Dense(num_items() * 2 => K),\n",
    "            Embedding(num_items() => K; init = Flux.glorot_uniform),\n",
    "        ),\n",
    "        Dense(K * 2, K, relu),\n",
    "        Dense(K => K ÷ 2, relu),\n",
    "        Dense(K ÷ 2, 1),\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9dc54c2-bf92-47b1-a2ba-8cf83bc411c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "function model(\n",
    "    hyp::Hyperparams,\n",
    "    f::Features,\n",
    "    split::String,\n",
    "    content::String;\n",
    "    raw_splits = true,\n",
    ")\n",
    "    if raw_splits\n",
    "        df = get_raw_split(split, content)\n",
    "    else\n",
    "        df = get_split(split, content)\n",
    "    end\n",
    "    if split == \"training\"\n",
    "        return zeros(Float32, length(df.item))\n",
    "    end\n",
    "\n",
    "    output = Array{Float32}(undef, length(df.item))\n",
    "    @showprogress for batch in\n",
    "                      collect(Iterators.partition(1:length(df.item), hyp.batch_size))\n",
    "        u_embs = SparseVector{Float32,Int32}[]\n",
    "        a_embs = Int32[]\n",
    "        for i in batch\n",
    "            push!(u_embs, get_user_embedding(df.user[i], Int32[], f))\n",
    "            push!(a_embs, get_item_embedding(df.item[i], f))\n",
    "        end\n",
    "        U, A = device(hcat(u_embs...)), device(vcat(a_embs...))\n",
    "        output[batch] .= cpu(vec(m((U, A))))\n",
    "    end\n",
    "    output\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a616677-313b-4e3b-847d-662c703dd666",
   "metadata": {},
   "source": [
    "## Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376e6681-572c-41a9-9b4e-08088b2bb6a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hyp = Hyperparams(\n",
    "    allow_ptw = false,\n",
    "    alphas = String[],\n",
    "    batch_size = 1024,\n",
    "    holdout = NaN,\n",
    "    l2penalty = NaN,\n",
    "    learning_rate = NaN,\n",
    "    list_size = 2,\n",
    "    seed = 20220609,\n",
    ")\n",
    "hyp = create_hyperparams(hyp, Float32[0, 0, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "248d034a-3777-4530-96ad-8fe07f8bceaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_alpha(hyp, \"MLE.Training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "186e54b9-96e6-4713-94f9-55e00a41e6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.0372 with list_size = 2 and K = 32"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.2",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

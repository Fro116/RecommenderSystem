{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# ErrorModel\n",
    "* Uses LightGBM to estimate the error for a given (user, item) prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: lib_lightgbm found in system dirs!\n",
      "└ @ LightGBM /Users/kundan/.julia/packages/LightGBM/A7zVd/src/LightGBM.jl:28\n"
     ]
    }
   ],
   "source": [
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"TreeModelBase.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edf2b7dc-6ec0-44f9-9f88-1df84ba11362",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_alphas = [\"LinearExplicit\", \"LinearImplicit\"]\n",
    "nonlinear_alphas = [\"NonlinearExplicit\"]\n",
    "ensemble_alphas = [\"Explicit\"]\n",
    "all_features = [\n",
    "    explicit_raw_alphas\n",
    "    implicit_raw_alphas\n",
    "    linear_alphas\n",
    "    nonlinear_alphas\n",
    "    ensemble_alphas\n",
    "];\n",
    "error_model = true;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "517ce91a-bf09-446a-8be9-a7c5bbe0c0f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 (78.93 ns/it)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.095241 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1777\n",
      "[LightGBM] [Info] Number of data points in the train set: 22508916, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 0.850234\n",
      "Iteration: 1, test_1's l2: 0.686053493896262\n",
      "Iteration: 2, test_1's l2: 0.6796224491616033\n",
      "Iteration: 3, test_1's l2: 0.674227312567135\n",
      "Iteration: 4, test_1's l2: 0.6696473511021624\n",
      "Iteration: 5, test_1's l2: 0.6657043572482404\n",
      "Iteration: 6, test_1's l2: 0.6627822177709928\n",
      "Iteration: 7, test_1's l2: 0.6601103782120277\n",
      "Iteration: 8, test_1's l2: 0.6580241206727898\n",
      "Iteration: 9, test_1's l2: 0.6563105993899937\n",
      "Iteration: 10, test_1's l2: 0.6548803022132446\n",
      "Iteration: 11, test_1's l2: 0.6536462673358491\n",
      "Iteration: 12, test_1's l2: 0.6527191635890989\n",
      "Iteration: 13, test_1's l2: 0.6519207455055651\n",
      "Iteration: 14, test_1's l2: 0.6511923810477075\n",
      "Iteration: 15, test_1's l2: 0.6506403938795394\n",
      "Iteration: 16, test_1's l2: 0.6500616507208615\n",
      "Iteration: 17, test_1's l2: 0.6495582666380169\n",
      "Iteration: 18, test_1's l2: 0.6492265076093382\n",
      "Iteration: 19, test_1's l2: 0.6487988986465927\n",
      "Iteration: 20, test_1's l2: 0.6485188878648472\n",
      "Iteration: 21, test_1's l2: 0.6483042490715706\n",
      "Iteration: 22, test_1's l2: 0.6481782708896394\n",
      "Iteration: 23, test_1's l2: 0.6480377364057698\n",
      "Iteration: 24, test_1's l2: 0.6477660781104799\n",
      "Iteration: 25, test_1's l2: 0.6476973620839848\n",
      "Iteration: 26, test_1's l2: 0.6474525935469634\n",
      "Iteration: 27, test_1's l2: 0.6472563910051372\n",
      "Iteration: 28, test_1's l2: 0.6469994862896267\n",
      "Iteration: 29, test_1's l2: 0.6468887785637679\n",
      "Iteration: 30, test_1's l2: 0.6468668491041932\n",
      "Iteration: 31, test_1's l2: 0.6467717699409908\n",
      "Iteration: 32, test_1's l2: 0.646647227773284\n",
      "Iteration: 33, test_1's l2: 0.6465923965568116\n",
      "Iteration: 34, test_1's l2: 0.6464870504253173\n",
      "Iteration: 35, test_1's l2: 0.646494090905153\n",
      "Iteration: 36, test_1's l2: 0.6463441821859692\n",
      "Iteration: 37, test_1's l2: 0.6462031219334957\n",
      "Iteration: 38, test_1's l2: 0.6462215067035095\n",
      "Iteration: 39, test_1's l2: 0.646266471047492\n",
      "Iteration: 40, test_1's l2: 0.6462470938160007\n",
      "Iteration: 41, test_1's l2: 0.6462487345749773\n",
      "Iteration: 42, test_1's l2: 0.6461978307336874\n",
      "Iteration: 43, test_1's l2: 0.6461812970176679\n",
      "Iteration: 44, test_1's l2: 0.6461744725602578\n",
      "Iteration: 45, test_1's l2: 0.6461841909521178\n",
      "Iteration: 46, test_1's l2: 0.6461914836656185\n",
      "Iteration: 47, test_1's l2: 0.6461270008459562\n",
      "Iteration: 48, test_1's l2: 0.6460975899626045\n",
      "Iteration: 49, test_1's l2: 0.6460591846447723\n",
      "Iteration: 50, test_1's l2: 0.6460221780893624\n",
      "Iteration: 51, test_1's l2: 0.6460223789619407\n",
      "Iteration: 52, test_1's l2: 0.6460279380834131\n",
      "Iteration: 53, test_1's l2: 0.6460507220111894\n",
      "Iteration: 54, test_1's l2: 0.646042823541741\n",
      "Iteration: 55, test_1's l2: 0.6459892331476484\n",
      "Iteration: 56, test_1's l2: 0.6459751411361666\n",
      "Iteration: 57, test_1's l2: 0.6459839747314914\n",
      "Iteration: 58, test_1's l2: 0.6459821992060796\n",
      "Iteration: 59, test_1's l2: 0.645981050488445\n",
      "Iteration: 60, test_1's l2: 0.6459898749870108\n",
      "Iteration: 61, test_1's l2: 0.6459569095399924\n",
      "Iteration: 62, test_1's l2: 0.645959899721805\n",
      "Iteration: 63, test_1's l2: 0.6459694287741876\n",
      "Iteration: 64, test_1's l2: 0.6459900801421022\n",
      "Iteration: 65, test_1's l2: 0.6460041203603706\n",
      "Iteration: 66, test_1's l2: 0.6459128614102548\n",
      "Iteration: 67, test_1's l2: 0.6459372865589057\n",
      "Iteration: 68, test_1's l2: 0.6459200968396058\n",
      "Iteration: 69, test_1's l2: 0.6459430566992882\n",
      "Iteration: 70, test_1's l2: 0.6459099588062708\n",
      "Iteration: 71, test_1's l2: 0.6459161729050206\n",
      "Iteration: 72, test_1's l2: 0.6459374030922874\n",
      "Iteration: 73, test_1's l2: 0.6459330859862368\n",
      "Iteration: 74, test_1's l2: 0.6459569082147767\n",
      "Iteration: 75, test_1's l2: 0.6459638510375272\n",
      "Iteration: 76, test_1's l2: 0.6459778002266354\n",
      "Iteration: 77, test_1's l2: 0.6459667410042428\n",
      "Iteration: 78, test_1's l2: 0.6459779925291006\n",
      "Iteration: 79, test_1's l2: 0.645962326286933\n",
      "Early stopping at iteration 80, the best iteration round is 70\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220626 12:31:55 Saving model... (this may take a while)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:20 ( 0.73 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 0.74 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 0.76 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:08 ( 0.76 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.74 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.76 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 0.53 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 0.54 μs/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "train_model(all_features, [\"Explicit\"], false, [\"validation\"], \"ErrorExplicit\", true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "765ef7e7-abf6-432e-b55d-2eea75753f32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 (24.99 ns/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 (21.74 ns/it)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.281897 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1787\n",
      "[LightGBM] [Info] Number of data points in the train set: 66963121, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 0.105813\n",
      "Iteration: 1, test_1's l2: 0.04673944344522427\n",
      "Iteration: 2, test_1's l2: 0.044619940617529566\n",
      "Iteration: 3, test_1's l2: 0.0428659760514511\n",
      "Iteration: 4, test_1's l2: 0.04143028952137978\n",
      "Iteration: 5, test_1's l2: 0.04026187582128388\n",
      "Iteration: 6, test_1's l2: 0.0393202558626058\n",
      "Iteration: 7, test_1's l2: 0.03854792322434796\n",
      "Iteration: 8, test_1's l2: 0.03791600225342759\n",
      "Iteration: 9, test_1's l2: 0.03741997435014359\n",
      "Iteration: 10, test_1's l2: 0.0370003324643541\n",
      "Iteration: 11, test_1's l2: 0.036658288364376304\n",
      "Iteration: 12, test_1's l2: 0.03638928964095424\n",
      "Iteration: 13, test_1's l2: 0.036158573374389\n",
      "Iteration: 14, test_1's l2: 0.035969849226914256\n",
      "Iteration: 15, test_1's l2: 0.03581568388570838\n",
      "Iteration: 16, test_1's l2: 0.035695663218894474\n",
      "Iteration: 17, test_1's l2: 0.03559228248893903\n",
      "Iteration: 18, test_1's l2: 0.03550690786187879\n",
      "Iteration: 19, test_1's l2: 0.035439183613175905\n",
      "Iteration: 20, test_1's l2: 0.03538145138916768\n",
      "Iteration: 21, test_1's l2: 0.03533327911128633\n",
      "Iteration: 22, test_1's l2: 0.03529498954636558\n",
      "Iteration: 23, test_1's l2: 0.03526349422674533\n",
      "Iteration: 24, test_1's l2: 0.03523578369553295\n",
      "Iteration: 25, test_1's l2: 0.03521386288511144\n",
      "Iteration: 26, test_1's l2: 0.03519309171881921\n",
      "Iteration: 27, test_1's l2: 0.0351787164765327\n",
      "Iteration: 28, test_1's l2: 0.03516524850863572\n",
      "Iteration: 29, test_1's l2: 0.035153702051100126\n",
      "Iteration: 30, test_1's l2: 0.035143940435074635\n",
      "Iteration: 31, test_1's l2: 0.035136833740846966\n",
      "Iteration: 32, test_1's l2: 0.035130887955745274\n",
      "Iteration: 33, test_1's l2: 0.03512441722920474\n",
      "Iteration: 34, test_1's l2: 0.03511926273263889\n",
      "Iteration: 35, test_1's l2: 0.0351144367966475\n",
      "Iteration: 36, test_1's l2: 0.035110061668141374\n",
      "Iteration: 37, test_1's l2: 0.035106136981242805\n",
      "Iteration: 38, test_1's l2: 0.03510273177127343\n",
      "Iteration: 39, test_1's l2: 0.03510021214380647\n",
      "Iteration: 40, test_1's l2: 0.03509784989421027\n",
      "Iteration: 41, test_1's l2: 0.03509756120749154\n",
      "Iteration: 42, test_1's l2: 0.035094812712821465\n",
      "Iteration: 43, test_1's l2: 0.03509187026335579\n",
      "Iteration: 44, test_1's l2: 0.03509135718118828\n",
      "Iteration: 45, test_1's l2: 0.03508911716685114\n",
      "Iteration: 46, test_1's l2: 0.035085707902087475\n",
      "Iteration: 47, test_1's l2: 0.03508452953685077\n",
      "Iteration: 48, test_1's l2: 0.0350824614550833\n",
      "Iteration: 49, test_1's l2: 0.03508183616562989\n",
      "Iteration: 50, test_1's l2: 0.035079875047312005\n",
      "Iteration: 51, test_1's l2: 0.035079152943254886\n",
      "Iteration: 52, test_1's l2: 0.03507662773479618\n",
      "Iteration: 53, test_1's l2: 0.03507602031290839\n",
      "Iteration: 54, test_1's l2: 0.035076598363540316\n",
      "Iteration: 55, test_1's l2: 0.035076474455328306\n",
      "Iteration: 56, test_1's l2: 0.035076771992886384\n",
      "Iteration: 57, test_1's l2: 0.03507629200433286\n",
      "Iteration: 58, test_1's l2: 0.03507641917302168\n",
      "Iteration: 59, test_1's l2: 0.03507657010688781\n",
      "Iteration: 60, test_1's l2: 0.03507688717802744\n",
      "Iteration: 61, test_1's l2: 0.035076332409418\n",
      "Iteration: 62, test_1's l2: 0.0350763811055849\n",
      "Early stopping at iteration 63, the best iteration round is 53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220626 12:48:58 Saving model... (this may take a while)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:20 ( 0.72 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 0.74 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 0.74 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:08 ( 0.72 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.74 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.73 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 0.51 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 0.51 μs/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    all_features,\n",
    "    [\"LinearImplicit\"],\n",
    "    true,\n",
    "    [\"validation\", \"negative_validation\"],\n",
    "    \"ErrorImplicit\",\n",
    "    true,\n",
    ");"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-rc1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# ErrorModel\n",
    "* Uses LightGBM to estimate the error for a given (user, item) prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: lib_lightgbm not found in system dirs, trying fallback\n",
      "└ @ LightGBM /home/kundan/.julia/packages/LightGBM/A7zVd/src/LightGBM.jl:25\n"
     ]
    }
   ],
   "source": [
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"TreeModelBase.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edf2b7dc-6ec0-44f9-9f88-1df84ba11362",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_alphas = [\"LinearExplicit\", \"LinearImplicit\"]\n",
    "nonlinear_alphas = [\"NonlinearExplicit\"]\n",
    "ensemble_alphas = [\"Explicit\"]\n",
    "all_features = [\n",
    "    explicit_raw_alphas\n",
    "    implicit_raw_alphas\n",
    "    nondirectional_raw_alphas\n",
    "    linear_alphas\n",
    "    nonlinear_alphas\n",
    "    ensemble_alphas\n",
    "];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "765ef7e7-abf6-432e-b55d-2eea75753f32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.19 μs/it)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.174682 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3315\n",
      "[LightGBM] [Info] Number of data points in the train set: 66963121, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.104162\n",
      "Iteration: 1, test_1's l2: 0.042107245602853685\n",
      "Iteration: 2, test_1's l2: 0.037187299359665776\n",
      "Iteration: 3, test_1's l2: 0.03305286348117024\n",
      "Iteration: 4, test_1's l2: 0.02968666168452504\n",
      "Iteration: 5, test_1's l2: 0.02791693985129664\n",
      "Iteration: 6, test_1's l2: 0.025534703137839995\n",
      "Iteration: 7, test_1's l2: 0.02360151198952616\n",
      "Iteration: 8, test_1's l2: 0.02202771543841103\n",
      "Iteration: 9, test_1's l2: 0.020756524240788797\n",
      "Iteration: 10, test_1's l2: 0.019719831638364306\n",
      "Iteration: 11, test_1's l2: 0.018906487403650845\n",
      "Iteration: 12, test_1's l2: 0.018214267446854927\n",
      "Iteration: 13, test_1's l2: 0.017656293301793143\n",
      "Iteration: 14, test_1's l2: 0.017204916256579408\n",
      "Iteration: 15, test_1's l2: 0.016835148933406388\n",
      "Iteration: 16, test_1's l2: 0.016533709336743488\n",
      "Iteration: 17, test_1's l2: 0.01628900044229013\n",
      "Iteration: 18, test_1's l2: 0.016174774852916542\n",
      "Iteration: 19, test_1's l2: 0.01599924050067444\n",
      "Iteration: 20, test_1's l2: 0.015856192192196448\n",
      "Iteration: 21, test_1's l2: 0.01574001356604478\n",
      "Iteration: 22, test_1's l2: 0.015689536271317008\n",
      "Iteration: 23, test_1's l2: 0.015605524093915118\n",
      "Iteration: 24, test_1's l2: 0.015537644567285317\n",
      "Iteration: 25, test_1's l2: 0.01548208400074265\n",
      "Iteration: 26, test_1's l2: 0.015461322280782541\n",
      "Iteration: 27, test_1's l2: 0.015418502952321332\n",
      "Iteration: 28, test_1's l2: 0.015404249702527115\n",
      "Iteration: 29, test_1's l2: 0.015389813851156049\n",
      "Iteration: 30, test_1's l2: 0.015359256878610618\n",
      "Iteration: 31, test_1's l2: 0.01535162902473734\n",
      "Iteration: 32, test_1's l2: 0.015328411893991001\n",
      "Iteration: 33, test_1's l2: 0.015323790727855816\n",
      "Iteration: 34, test_1's l2: 0.015305147930167635\n",
      "Iteration: 35, test_1's l2: 0.015301697953183785\n",
      "Iteration: 36, test_1's l2: 0.01528672435823291\n",
      "Iteration: 37, test_1's l2: 0.015275676890642948\n",
      "Iteration: 38, test_1's l2: 0.015275351949971153\n",
      "Iteration: 39, test_1's l2: 0.015265657067767599\n",
      "Iteration: 40, test_1's l2: 0.015259822269543016\n",
      "Iteration: 41, test_1's l2: 0.015259780594931698\n",
      "Iteration: 42, test_1's l2: 0.01525886371783941\n",
      "Iteration: 43, test_1's l2: 0.015253508908166923\n",
      "Iteration: 44, test_1's l2: 0.01524870843247475\n",
      "Iteration: 45, test_1's l2: 0.01524435444717186\n",
      "Iteration: 46, test_1's l2: 0.015242700348918007\n",
      "Iteration: 47, test_1's l2: 0.015241768061334555\n",
      "Iteration: 48, test_1's l2: 0.015239976783693661\n",
      "Iteration: 49, test_1's l2: 0.015239902224763896\n",
      "Iteration: 50, test_1's l2: 0.015238244221092816\n",
      "Iteration: 51, test_1's l2: 0.015239348307700764\n",
      "Iteration: 52, test_1's l2: 0.01523826853372396\n",
      "Iteration: 53, test_1's l2: 0.015238892155302303\n",
      "Iteration: 54, test_1's l2: 0.015237673552977121\n",
      "Iteration: 55, test_1's l2: 0.015237160013260677\n",
      "Iteration: 56, test_1's l2: 0.015237700141112503\n",
      "Iteration: 57, test_1's l2: 0.015238032988650745\n",
      "Iteration: 58, test_1's l2: 0.015238223101587955\n",
      "Iteration: 59, test_1's l2: 0.015238587378185984\n",
      "Iteration: 60, test_1's l2: 0.015238422754961988\n",
      "Iteration: 61, test_1's l2: 0.01523902935833773\n",
      "Iteration: 62, test_1's l2: 0.015240644656470617\n",
      "Iteration: 63, test_1's l2: 0.015241903790036003\n",
      "Iteration: 64, test_1's l2: 0.015243009976405304\n",
      "Early stopping at iteration 65, the best iteration round is 55\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 19:34:44 Saving model\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:01:54\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 19:38:30 Average model value: 0.0647673\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 19:38:31 Average model absolute value: 0.064773984\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:12 ( 1.33 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.44 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.32 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:05 ( 1.31 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.35 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.38 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.01 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.01 μs/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    all_features,\n",
    "    [\"LinearImplicit\"],\n",
    "    true,\n",
    "    [\"validation\", \"negative_validation\"],\n",
    "    \"ErrorImplicit\",\n",
    "    true,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "517ce91a-bf09-446a-8be9-a7c5bbe0c0f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.065832 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3315\n",
      "[LightGBM] [Info] Number of data points in the train set: 22508916, number of used features: 13\n",
      "[LightGBM] [Info] Start training from score 0.814650\n",
      "Iteration: 1, test_1's l2: 0.6352539645496824\n",
      "Iteration: 2, test_1's l2: 0.6268879818995813\n",
      "Iteration: 3, test_1's l2: 0.6202649577945496\n",
      "Iteration: 4, test_1's l2: 0.6150349693391802\n",
      "Iteration: 5, test_1's l2: 0.6105235781655315\n",
      "Iteration: 6, test_1's l2: 0.6064483988118591\n",
      "Iteration: 7, test_1's l2: 0.6030762389242275\n",
      "Iteration: 8, test_1's l2: 0.599959427196228\n",
      "Iteration: 9, test_1's l2: 0.5976698253425081\n",
      "Iteration: 10, test_1's l2: 0.5957145474085922\n",
      "Iteration: 11, test_1's l2: 0.5940546550009586\n",
      "Iteration: 12, test_1's l2: 0.5924839468373374\n",
      "Iteration: 13, test_1's l2: 0.5912606418888859\n",
      "Iteration: 14, test_1's l2: 0.590195370356788\n",
      "Iteration: 15, test_1's l2: 0.5893388184935459\n",
      "Iteration: 16, test_1's l2: 0.5884974627896384\n",
      "Iteration: 17, test_1's l2: 0.5877931526444713\n",
      "Iteration: 18, test_1's l2: 0.5871659750880243\n",
      "Iteration: 19, test_1's l2: 0.5866016056793802\n",
      "Iteration: 20, test_1's l2: 0.5861162299061564\n",
      "Iteration: 21, test_1's l2: 0.5856685756298681\n",
      "Iteration: 22, test_1's l2: 0.5851441835248726\n",
      "Iteration: 23, test_1's l2: 0.5847866812434961\n",
      "Iteration: 24, test_1's l2: 0.5844901609626478\n",
      "Iteration: 25, test_1's l2: 0.584265110555999\n",
      "Iteration: 26, test_1's l2: 0.5836935214697583\n",
      "Iteration: 27, test_1's l2: 0.5833393643935162\n",
      "Iteration: 28, test_1's l2: 0.583066177215524\n",
      "Iteration: 29, test_1's l2: 0.5827552097850732\n",
      "Iteration: 30, test_1's l2: 0.5825637412541813\n",
      "Iteration: 31, test_1's l2: 0.5823506391097765\n",
      "Iteration: 32, test_1's l2: 0.5822024132431646\n",
      "Iteration: 33, test_1's l2: 0.5819024538137032\n",
      "Iteration: 34, test_1's l2: 0.5816079718284111\n",
      "Iteration: 35, test_1's l2: 0.5813348468764281\n",
      "Iteration: 36, test_1's l2: 0.5812112953140707\n",
      "Iteration: 37, test_1's l2: 0.5809822624206786\n",
      "Iteration: 38, test_1's l2: 0.5808336163826138\n",
      "Iteration: 39, test_1's l2: 0.5806761337200853\n",
      "Iteration: 40, test_1's l2: 0.5805121887279384\n",
      "Iteration: 41, test_1's l2: 0.5803831555471719\n",
      "Iteration: 42, test_1's l2: 0.5802021260659045\n",
      "Iteration: 43, test_1's l2: 0.5800993701304429\n",
      "Iteration: 44, test_1's l2: 0.5800432810690457\n",
      "Iteration: 45, test_1's l2: 0.5798489735942562\n",
      "Iteration: 46, test_1's l2: 0.5797996021696483\n",
      "Iteration: 47, test_1's l2: 0.5796081027996447\n",
      "Iteration: 48, test_1's l2: 0.5794956453539718\n",
      "Iteration: 49, test_1's l2: 0.5794528647482422\n",
      "Iteration: 50, test_1's l2: 0.5793769116458305\n",
      "Iteration: 51, test_1's l2: 0.5793707158227648\n",
      "Iteration: 52, test_1's l2: 0.5791835481986881\n",
      "Iteration: 53, test_1's l2: 0.5790084706464401\n",
      "Iteration: 54, test_1's l2: 0.5789217724398942\n",
      "Iteration: 55, test_1's l2: 0.5788349326012673\n",
      "Iteration: 56, test_1's l2: 0.5786517300904335\n",
      "Iteration: 57, test_1's l2: 0.5785479349291073\n",
      "Iteration: 58, test_1's l2: 0.5783586052121259\n",
      "Iteration: 59, test_1's l2: 0.5782167634723563\n",
      "Iteration: 60, test_1's l2: 0.5781364663243596\n",
      "Iteration: 61, test_1's l2: 0.5780556622337808\n",
      "Iteration: 62, test_1's l2: 0.5779376426178789\n",
      "Iteration: 63, test_1's l2: 0.577900784732451\n",
      "Iteration: 64, test_1's l2: 0.5777343198555508\n",
      "Iteration: 65, test_1's l2: 0.5777260908578832\n",
      "Iteration: 66, test_1's l2: 0.5777374530664651\n",
      "Iteration: 67, test_1's l2: 0.5776705429762158\n",
      "Iteration: 68, test_1's l2: 0.5775688208478409\n",
      "Iteration: 69, test_1's l2: 0.5775762326704851\n",
      "Iteration: 70, test_1's l2: 0.5775726718047741\n",
      "Iteration: 71, test_1's l2: 0.577562946157651\n",
      "Iteration: 72, test_1's l2: 0.5775269574270904\n",
      "Iteration: 73, test_1's l2: 0.5774925226301674\n",
      "Iteration: 74, test_1's l2: 0.5774734456858365\n",
      "Iteration: 75, test_1's l2: 0.5774669898290595\n",
      "Iteration: 76, test_1's l2: 0.5774446698255346\n",
      "Iteration: 77, test_1's l2: 0.5772609743199847\n",
      "Iteration: 78, test_1's l2: 0.5772853151203369\n",
      "Iteration: 79, test_1's l2: 0.5772818403291624\n",
      "Iteration: 80, test_1's l2: 0.5772943920120645\n",
      "Iteration: 81, test_1's l2: 0.5772951399546579\n",
      "Iteration: 82, test_1's l2: 0.5773643471840558\n",
      "Iteration: 83, test_1's l2: 0.5773683619537011\n",
      "Iteration: 84, test_1's l2: 0.5773774939341385\n",
      "Iteration: 85, test_1's l2: 0.5773809621293482\n",
      "Iteration: 86, test_1's l2: 0.5774264309934125\n",
      "Early stopping at iteration 87, the best iteration round is 77\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 19:40:14 Saving model\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:05:36\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 19:47:50 Average model value: 0.92416865\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220702 19:47:51 Average model absolute value: 0.9241687\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:13 ( 1.40 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.43 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.44 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:05 ( 1.40 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.48 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 1.45 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.05 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.06 μs/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "train_model(all_features, [\"Explicit\"], false, [\"validation\"], \"ErrorExplicit\", true);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-rc1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8ff8405-1d32-4ddc-94bc-da921cd4c005",
   "metadata": {},
   "source": [
    "# Item Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93389bdc-c5a6-480e-8b9a-f95084f7593d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO move to nondirectional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23d75207-5df1-4ba1-a378-f1600d38f15c",
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataFrames\n",
    "\n",
    "import CSV\n",
    "import Statistics: mean\n",
    "import StatsBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382f30c4-a143-46a4-b9cc-cbfe7a08c708",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import NBInclude: @nbinclude\n",
    "# @nbinclude(\"../Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7af73f1a-fb73-46ab-a154-8411b2714ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function fill_feature(split, implicit, transpose, user_feature)\n",
    "#     users = get_split(split, implicit; transpose = transpose).user\n",
    "#     feature = zeros(length(users))\n",
    "#     @tprogress Threads.@threads for j = 1:length(users)\n",
    "#         if users[j] <= length(user_feature)\n",
    "#             feature[j] = user_feature[users[j]]\n",
    "#         end\n",
    "#     end\n",
    "#     feature\n",
    "# end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2592d422-857b-400a-adc0-c87a41a1ac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function count_feature(split, implicit, transpose)\n",
    "#     # when transpose is true, returns the number of rated items per user\n",
    "#     # when transpose is false, return the number of rated users per item\n",
    "#     users = get_split(\"training\", implicit; transpose = transpose).user\n",
    "#     user_to_num_training_items = zeros(maximum(users), Threads.nthreads())\n",
    "#     @tprogress Threads.@threads for i = 1:length(users)\n",
    "#         user_to_num_training_items[users[i], Threads.threadid()] += 1\n",
    "#     end\n",
    "#     user_to_num_training_items = sum(user_to_num_training_items, dims = 2)\n",
    "#     fill_feature(split, implicit, transpose, user_to_num_training_items)\n",
    "# end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38e3b2e-a350-47ac-b76a-afde775e80ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function bias_feature(split, implicit, transpose)\n",
    "#     bias_param = transpose ? \"a\" : \"u\"\n",
    "#     users = get_split(\"training\", implicit; transpose = transpose).user\n",
    "#     user_bias = read_params(\"ExplicitUserItemBiases\")[bias_param]\n",
    "#     fill_feature(split, implicit, transpose, user_bias)\n",
    "# end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f424de2-a0db-4fcd-ad9c-3e744fe5cd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function std_feature(split, implicit, transpose)\n",
    "#     # get sum squared error\n",
    "#     users = get_split(\"training\", implicit; transpose = transpose).user\n",
    "#     ratings = get_split(\"training\", implicit; transpose = transpose).rating\n",
    "#     params = transpose ? [\"a\", \"u\"] : [\"u\", \"a\"]\n",
    "#     user_means =\n",
    "#         read_params(\"ExplicitUserItemBiases\")[params[1]] .+\n",
    "#         mean(read_params(\"ExplicitUserItemBiases\")[params[2]])\n",
    "#     user_to_training_std = zeros(maximum(users), Threads.nthreads())\n",
    "#     user_to_num_training_items = zeros(maximum(users), Threads.nthreads())\n",
    "#     @tprogress Threads.@threads for i = 1:length(users)\n",
    "#         u = users[i]\n",
    "#         user_to_training_std[u, Threads.threadid()] += (ratings[u] - user_means[u])^2\n",
    "#         user_to_num_training_items[u, Threads.threadid()] += 1\n",
    "#     end\n",
    "#     user_to_training_std = sum(user_to_training_std, dims = 2)\n",
    "#     user_to_num_training_items = sum(user_to_num_training_items, dims = 2)\n",
    "\n",
    "#     # transform to std\n",
    "#     @tprogress Threads.@threads for u = 1:maximum(users)\n",
    "#         if user_to_num_training_items[u] > 0\n",
    "#             user_to_training_std[u] /= user_to_num_training_items[u]\n",
    "#         end\n",
    "#     end\n",
    "#     user_to_training_std .= sqrt.(user_to_training_std)\n",
    "#     fill_feature(split, implicit, transpose, user_to_training_std)\n",
    "# end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7e46a9-25de-4db0-9e60-f3cf3f03f796",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function popularity_feature(split, implicit, transpose)\n",
    "#     # returns the average popularity of all items the user has seen\n",
    "#     users = get_split(\"training\", implicit; transpose).user\n",
    "#     items = get_split(\"training\", implicit; transpose).item\n",
    "#     item_means = read_params(\"ExplicitUserItemBiases\")[transpose ? \"u\" : \"a\"]\n",
    "#     user_to_avg_item_pop = zeros(maximum(users), Threads.nthreads())\n",
    "#     user_to_num_training_items = zeros(maximum(users), Threads.nthreads())\n",
    "#     @tprogress Threads.@threads for i = 1:length(users)\n",
    "#         u = users[i]\n",
    "#         a = items[i]\n",
    "#         user_to_avg_item_pop[u, Threads.threadid()] += item_means[a]\n",
    "#         user_to_num_training_items[u, Threads.threadid()] += 1\n",
    "#     end\n",
    "#     user_to_avg_item_pop = sum(user_to_avg_item_pop, dims = 2)\n",
    "#     user_to_num_training_items = sum(user_to_num_training_items, dims = 2)\n",
    "\n",
    "#     @tprogress Threads.@threads for u = 1:maximum(users)\n",
    "#         if user_to_num_training_items[u] > 0\n",
    "#             user_to_avg_item_pop[u] /= user_to_num_training_items[u]\n",
    "#         end\n",
    "#     end\n",
    "#     fill_feature(split, implicit, transpose, user_to_avg_item_pop)\n",
    "# end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "413fa6dc-a625-4500-ae78-e7409bc98ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "function date_to_year(x)\n",
    "    if ismissing(x)\n",
    "        return NaN\n",
    "    end\n",
    "    Dates.year(x) + Dates.month(x) / 12\n",
    "end\n",
    "\n",
    "function get_anime()\n",
    "    anime_to_uid = DataFrame(CSV.File(get_data_path(\"processed_data/anime_to_uid.csv\")))\n",
    "    anime_to_uid.uid .+= 1\n",
    "    anime = DataFrame(CSV.File(get_data_path(\"processed_data/anime.csv\"), ntasks = 1))\n",
    "    anime = innerjoin(anime_to_uid, anime, on = \"anime_id\")\n",
    "    anime.start_year = date_to_year.(anime[:, \"start_date\"])\n",
    "    anime.end_year = date_to_year.(anime[:, \"end_date\"])\n",
    "    anime\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84581a69-04f8-42c6-9317-560cbe6df78e",
   "metadata": {},
   "outputs": [],
   "source": [
    "using NBInclude\n",
    "@nbinclude(\"../Alpha.ipynb\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3dee88a-e8aa-4818-b9d5-029587162745",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_anime_column(anime_to_uid, col)\n",
    "    #TODO is there a better way of handling missing values?\n",
    "    function is_missing(x)\n",
    "        if ismissing(x)\n",
    "            return true\n",
    "        end\n",
    "        if isa(x, Real)\n",
    "            return isnan(x)\n",
    "        end\n",
    "        return x == \"NaN\"\n",
    "    end\n",
    "    default = StatsBase.mode(filter(x -> !is_missing(x), anime_to_uid[:, col]))\n",
    "    anime_to_col = fill(default, num_items())\n",
    "    for i = 1:size(anime_to_uid)[1]\n",
    "        val = anime_to_uid[i, col]\n",
    "        if !is_missing(val)\n",
    "            anime_to_col[anime_to_uid[i, \"uid\"]] = val\n",
    "        end\n",
    "    end\n",
    "    anime_to_col\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dbf15f-b2c4-4501-93d1-4805d65e70e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "function item_feature(col, out_users, out_items; categorical)\n",
    "    # subset column of interest\n",
    "    anime_to_uid = get_anime()\n",
    "    anime_to_col = get_anime_column(anime_to_uid, col)\n",
    "\n",
    "    # do a 1-hot encoding for categorical variables\n",
    "    encoding_fn = x -> anime_to_col[x]\n",
    "    ncols = 1\n",
    "    if categorical\n",
    "        encoding = sort(collect(Set(collect(anime_to_col))))\n",
    "        @debug \"$col categories: $encoding\"\n",
    "        function one_hot_encoding(item)\n",
    "            if item > length(anime_to_col)\n",
    "                return zeros(Float32, length(encoding))\n",
    "            end\n",
    "            encoding .== anime_to_col[item]\n",
    "        end\n",
    "        encoding_fn = one_hot_encoding\n",
    "        ncols = length(encoding)\n",
    "    end\n",
    "\n",
    "    feature = zeros(Float32, length(out_items), ncols)\n",
    "    @tprogress Threads.@threads for j = 1:length(out_items)\n",
    "        feature[j, :] .= encoding_fn(out_items[j])\n",
    "    end\n",
    "    feature\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "845c4228-1a83-4550-a035-0375a44eb8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of items of the same category that the user has seen\n",
    "function item_count_feature(col, training, out_users, out_items, to_category = identity;)\n",
    "    # subset column of interest\n",
    "    anime_to_uid = get_anime()\n",
    "    anime_to_uid[!, col] = to_category.(anime_to_uid[:, col])\n",
    "    anime_to_col = get_anime_column(anime_to_uid, col)\n",
    "\n",
    "    categories = sort(collect(Set(collect(anime_to_col))))\n",
    "    @debug \"$col categories: $categories\"\n",
    "    encoding(item) = findfirst(x -> x == anime_to_col[item], categories)\n",
    "\n",
    "    # get the number of items per user-category\n",
    "    users = training.user\n",
    "    items = training.item\n",
    "    user_to_num_training_items =\n",
    "        zeros(Float32, maximum(users), length(categories), Threads.nthreads())\n",
    "    @tprogress Threads.@threads for i = 1:length(users)\n",
    "        user_to_num_training_items[users[i], encoding(items[i]), Threads.threadid()] += 1\n",
    "    end\n",
    "    user_to_num_training_items = sum(user_to_num_training_items, dims = 3)\n",
    "\n",
    "    feature = zeros(Float32, length(out_items))\n",
    "    @tprogress Threads.@threads for i = 1:length(out_items)\n",
    "        feature[i] = user_to_num_training_items[out_users[i], encoding(out_items[i])]\n",
    "    end\n",
    "    feature\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f5331c-91fc-4729-8910-ca76e654f68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function parse_string_array(x)\n",
    "    # handle nested quotes\n",
    "    x = replace(x, \"' \" => \"\", \"'s \" => \"s \", \"\\\"\" => \"'\")\n",
    "    # parse as a julia array\n",
    "    eval(Meta.parse(replace(x, \"'\" => '\"')))\n",
    "end\n",
    "\n",
    "function parse_string_dict(x)\n",
    "    # handle nested quotes\n",
    "    x = replace(\n",
    "        x,\n",
    "        \"' \" => \"\",\n",
    "        \"'s \" => \"s \",\n",
    "        \"\\\"\" => \"'\",\n",
    "        \"{\" => \"Dict(\",\n",
    "        \"}\" => \")\",\n",
    "        \":\" => \"=>\",\n",
    "        \"M's\" => \"Ms\",\n",
    "        \"6'o\" => \"6o\",\n",
    "    )    # parse as a julia array\n",
    "    eval(Meta.parse(replace(x, \"'\" => '\"')))\n",
    "end\n",
    "\n",
    "function embed(tags::Vector, tag_embedding::Dict)\n",
    "    x = zeros(length(tag_embedding))\n",
    "    for i = 1:length(tags)\n",
    "        x[tag_embedding[tags[i]]] = 1\n",
    "    end\n",
    "    x\n",
    "end\n",
    "\n",
    "function get_tags(col)\n",
    "    df = get_anime()\n",
    "    tags = parse_string_array.(df[:, col])\n",
    "    tag_embedding = sort(collect(Set(reduce(vcat, tags))))\n",
    "    tag_embedding = Dict(tag_embedding[i] => i for i = 1:length(tag_embedding))\n",
    "    X = zeros(length(tag_embedding), num_items())\n",
    "    for i = 1:length(df.uid)\n",
    "        X[:, df.uid[i]] = embed(tags[i], tag_embedding)\n",
    "    end\n",
    "    X\n",
    "end\n",
    "\n",
    "function get_ids(x::Vector)\n",
    "    ids = []\n",
    "    for y in x\n",
    "        push!(ids, y[\"id\"])\n",
    "    end\n",
    "    ids\n",
    "end\n",
    "\n",
    "function get_ids(col::String)\n",
    "    df = get_anime()\n",
    "    ids = get_ids.(parse_string_dict.(df[:, col]))\n",
    "    id_embedding = sort(collect(Set(reduce(vcat, ids))))\n",
    "    id_embedding = Dict(id_embedding[i] => i for i = 1:length(id_embedding))\n",
    "    X = zeros(length(id_embedding), num_items())\n",
    "    for i = 1:length(df.uid)\n",
    "        X[:, df.uid[i]] = embed(ids[i], id_embedding)\n",
    "    end\n",
    "    X\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c987bce8-8f7c-4b91-a5fa-218440171072",
   "metadata": {},
   "outputs": [],
   "source": [
    "function normalize!(X)\n",
    "    # put X in the range [-1, 1]\n",
    "    for i = 1:size(X)[1]\n",
    "        x = X[i, :]\n",
    "        X[i, :] .= (x .- minimum(x)) ./ (maximum(x) - minimum(x) .+ eps(Float32))\n",
    "    end\n",
    "    2 .* X .- 1\n",
    "end\n",
    "\n",
    "function standardize!(X)\n",
    "    # gaussianize X\n",
    "    for i = 1:size(X)[1]\n",
    "        x = X[i, :]\n",
    "        X[i, :] .= (x .- mean(x)) ./ (std(x) .+ eps(Float32))\n",
    "    end\n",
    "    X\n",
    "end\n",
    "\n",
    "function get_neural_item_features()\n",
    "    M1 = collect(\n",
    "        hcat(\n",
    "            item_feature(\n",
    "                \"start_year\",\n",
    "                fill(1, num_items()),\n",
    "                1:num_items(),\n",
    "                categorical = false,\n",
    "            ),\n",
    "            item_feature(\n",
    "                \"end_year\",\n",
    "                fill(1, num_items()),\n",
    "                1:num_items(),\n",
    "                categorical = false,\n",
    "            ),\n",
    "            log.(\n",
    "                1 .+ item_feature(\n",
    "                    \"num_episodes\",\n",
    "                    fill(1, num_items()),\n",
    "                    1:num_items(),\n",
    "                    categorical = false,\n",
    "                ),\n",
    "            ),\n",
    "            log.(\n",
    "                1 .+ item_feature(\n",
    "                    \"average_episode_duration\",\n",
    "                    fill(1, num_items()),\n",
    "                    1:num_items(),\n",
    "                    categorical = false,\n",
    "                ),\n",
    "            ),\n",
    "        )',\n",
    "    )\n",
    "    M2 = collect(\n",
    "        hcat(\n",
    "            item_feature(\"nsfw\", fill(1, num_items()), 1:num_items(), categorical = true),\n",
    "            item_feature(\"medium\", fill(1, num_items()), 1:num_items(), categorical = true),\n",
    "            item_feature(\"source\", fill(1, num_items()), 1:num_items(), categorical = true),\n",
    "        )',\n",
    "    )\n",
    "    M3 = get_tags(\"genres\")\n",
    "    M4 = get_tags(\"tags\")\n",
    "    M5 = get_ids(\"studios\")\n",
    "    # scale non-categorical features\n",
    "    normalize!(M1)\n",
    "    (vcat(M1, M2), M3, M4, M5)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bd2033c-2a2c-4d21-9b71-7f9839c7c431",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_item_metadata_features(users::Vector, items::Vector, training::RatingsDataset)\n",
    "    round_to_multiple(x, n) = round(x / n) * n\n",
    "    function bucket_num_epiodes(x)\n",
    "        if isnan(x)\n",
    "            return x\n",
    "        end\n",
    "        if x <= 6\n",
    "            return round_to_multiple(x, 1)\n",
    "        end\n",
    "        if x <= 26\n",
    "            return round_to_multiple(x, 13)\n",
    "        end\n",
    "        if x <= 52\n",
    "            return round_to_multiple(x, 26)\n",
    "        end\n",
    "        return 100\n",
    "    end\n",
    "    hcat(\n",
    "        # # shared user/item features\n",
    "        # count_feature(split, implicit, true),\n",
    "        # count_feature(split, implicit, false),\n",
    "        # bias_feature(split, implicit, true),\n",
    "        # bias_feature(split, implicit, false),\n",
    "        # std_feature(split, implicit, true),\n",
    "        # std_feature(split, implicit, false),\n",
    "        # popularity_feature(split, implicit, true),\n",
    "        # popularity_feature(split, implicit, false),\n",
    "\n",
    "        # item only features\n",
    "        item_feature(\"start_year\", users, items, categorical = false),\n",
    "        item_feature(\"end_year\", users, items, categorical = false),\n",
    "        item_feature(\"nsfw\", users, items, categorical = true),\n",
    "        item_feature(\"medium\", users, items, categorical = true),\n",
    "        item_feature(\"num_episodes\", users, items, categorical = false),\n",
    "        item_feature(\"source\", users, items, categorical = true),\n",
    "        item_feature(\"average_episode_duration\", users, items, categorical = false),\n",
    "\n",
    "        # number of series the user has seen in each category\n",
    "        item_count_feature(\"start_year\", training, users, items, x -> round_to_multiple(x, 5)),\n",
    "        item_count_feature(\"end_year\", training, users, items, x -> round_to_multiple(x, 5)),\n",
    "        item_count_feature(\"nsfw\", training, users, items),\n",
    "        item_count_feature(\"medium\", training, users, items),\n",
    "        item_count_feature(\"num_episodes\", training, users, items, bucket_num_epiodes),\n",
    "        item_count_feature(\"source\", training, users, items),\n",
    "        item_count_feature(\n",
    "            \"average_episode_duration\",\n",
    "            training,\n",
    "            users,\n",
    "            items,\n",
    "            x -> x <= 1800 ? round_to_multiple(x, 600) : round_to_multiple(x, 1800),\n",
    "        ),\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a123b0-aa18-490d-9896-8a9761b2584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_item_metadata_features(split::String, implicit::Bool)\n",
    "    df = get_split(split, implicit)\n",
    "    training = get_split(\"training\", false)    \n",
    "    get_item_metadata_features(df.user, df.item, training)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-rc1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3758ece-9b72-47b4-ae6a-aa364e0443e3",
   "metadata": {},
   "source": [
    "# Matrix Factorization\n",
    "* Prediction is $\\tilde R = UA^T$\n",
    "* Loss fuction is $L = \\lVert (R - \\tilde R)^\\Omega \\odot W \\rVert _2^2 + \\lambda_u \\lVert U \\rVert _2^2 + \\lambda_a \\lVert A \\rVert _2^2$\n",
    "* $\\Omega$ is the set of oberved pairs $(i, j)$\n",
    "* $M^\\Omega$ is the projection of $M$ onto $\\Omega$ for any matrix $M$, that is $M_{ij}^\\Omega$ is defined to be $M_{ij}$ when $(i, j) \\in \\Omega$ and $0$ otherwise\n",
    "* $U$ is an $m x k$ matrix, $A$ is an $n x k$ matrix and $R$ is the $m x n$ ratings matrix\n",
    "* $W = w_{ij}$ is the weight for the prediction $r_{ij}$ and is modeled as a power-law in the number of items seen by $i$ and users than have seen $j$: $w_{ij} = |j' : (i, j') \\in \\Omega| ^ {\\lambda_{wu}} |i' : (i', j) \\in \\Omega| ^ {\\lambda_{wa}}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cc9334a-2287-41d6-885b-a5cca94fe263",
   "metadata": {},
   "outputs": [],
   "source": [
    "const name = \"MatrixFactorization\"\n",
    "const residual_alphas = [\"UserItemBiases\"]\n",
    "const implicit = false;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17593ac-3260-4c01-a5df-91edfcd17e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random\n",
    "using SparseArrays\n",
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e53c9e-85eb-4356-873f-df1a2efa2e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO maybe we can delete this with a newer julia version\n",
    "# Some sparse matrix operations require indices to be Int64\n",
    "@with_kw struct RatingsDataset64\n",
    "    user::Vector{Int64}\n",
    "    item::Vector{Int64}\n",
    "    rating::Vector{Float32}\n",
    "end\n",
    "\n",
    "function RatingsDataset64(x::RatingsDataset)\n",
    "    RatingsDataset64(\n",
    "        convert.(Int64, x.user),\n",
    "        convert.(Int64, x.item),\n",
    "        convert.(Float32, x.rating),\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "629b73e9-62c5-452f-ad94-e9cfafee3efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "const training = RatingsDataset64(get_split(\"training\", implicit))\n",
    "const validation = get_split(\"validation\", implicit);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f52a69-0231-4bff-8a9f-26bb16ee9f33",
   "metadata": {},
   "source": [
    "## Alternating Least Squares Algorithm\n",
    "* If $A$ is fixed then $U$ can be found by doing a regression on $A^{\\Omega_i} u_i = R^{\\Omega_i}$ with $L_2$ regularization $\\lambda_u$ and weights $W$\n",
    "* Alternating between fixing $A$ to solve $U$ and fixing $U$ to solve $A$ converges to a solution\n",
    "* $\\Omega_i = \\{(i', j) \\in \\Omega | i' = i \\}$ is projection of $\\Omega$ onto the $i$th user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9e3f1ca-34cc-48b6-8c28-7deb35939858",
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_prediction(users, items, U, A)\n",
    "    r = zeros(eltype(U), length(users))\n",
    "    @views Threads.@threads for i = 1:length(r)\n",
    "        if (users[i] <= size(U)[1]) && (items[i] <= size(A)[1])\n",
    "            r[i] = dot(U[users[i], :], A[items[i], :])\n",
    "        end\n",
    "    end\n",
    "    r\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27971b0-684c-49b5-8c12-bb6666664f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "function calc_loss(df, U, A, weights)\n",
    "    # truth = df.rating\n",
    "    # pred = make_prediction(df.user, df.item, U, A)\n",
    "    # β = (pred .* sqrt.(weights)) \\ (truth .* sqrt.(weights))\n",
    "    # loss = mse(truth, pred .* β, weights)\n",
    "    # @info \"loss: $loss β: $β\"\n",
    "    r = make_prediction(df.user, df.item, U, A)\n",
    "    loss = residualized_loss(residual_alphas, implicit, r)\n",
    "    @info \"loss: $loss\"\n",
    "    loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04463bd7-c9df-4866-b929-c6217b38e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function ridge_regression(X, y, λ)\n",
    "    (Matrix(X'X) + λ * LinearAlgebra.I(size(X)[2])) \\ Vector(X'y)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea373a98-e714-4083-8cfc-dddc4dd2c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# julia matrices are column major by default so we take adjoints to make them row major\n",
    "@memoize function sparse_csr(i, j, v, m, n)\n",
    "    sparse(j, i, v, n, m)'\n",
    "end;\n",
    "\n",
    "@memoize function gaussian_init_csr(source, K, el_type)\n",
    "    Random.seed!(20220515 * hash(source) * K)\n",
    "    (zeros(el_type, K, maximum(source)) + randn(K, maximum(source)) * K^(-1 / 4))'\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9094b8d-eea5-4ecd-b743-a7a245d3f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "function sparse_subset(A, rows)\n",
    "    # returns a sparse matrix B such that: \n",
    "    # size(B) == size(A), B[rows, :] == A[rows, :], and B[~rows, :] == 0\n",
    "    K = size(A)[2]\n",
    "    nzval = vec(A[rows, :])\n",
    "    rowval = repeat(rows, K)\n",
    "    colptr = [1 + (x - 1) * length(rows) for x = 1:K+1]\n",
    "    SparseMatrixCSC(size(A)..., colptr, rowval, nzval)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2e8700-dfa0-421a-b833-1fb40f47566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function update_users!(users, items, ratings, weights, U, A, λ_u, λ_w)\n",
    "    R = sparse_csr(users, items, ratings, size(U)[1], size(A)[1])\n",
    "    W = sparse_csr(users, items, weights, size(U)[1], size(A)[1])\n",
    "    @tprogress Threads.@threads for i = 1:size(U)[1]\n",
    "        w = expdecay.(W[i, :], λ_w / 2)\n",
    "        X = sparse_subset(A, rowvals(R[i, :])) .* w\n",
    "        y = R[i, :] .* w\n",
    "        U[i, :] = ridge_regression(X, y, λ_u)\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0371f61-27bf-4f52-b822-d060f7be01b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_model(training, validation, λ_u, λ_a, λ_wu, λ_wa, K, stop_criteria)\n",
    "    @info \"training model with parameters [$λ_u, $λ_a, $λ_wu, $λ_wa]\"\n",
    "    users, items, ratings = training.user, training.item, training.rating\n",
    "    U = copy(gaussian_init_csr(users, K, eltype(λ_u)))\n",
    "    A = copy(gaussian_init_csr(items, K, eltype(λ_a)))\n",
    "    wu = get_counts(\"training\", implicit)\n",
    "    wa = get_counts(\"training\", implicit; by_item = true)\n",
    "    function calc_losses()\n",
    "        calc_loss(validation, U, A, get_weights(\"validation\", implicit, \"inverse\"))\n",
    "    end\n",
    "\n",
    "\n",
    "    loss = Inf\n",
    "    while !stop!(stop_criteria, loss)\n",
    "        update_users!(users, items, ratings, wa, U, A, λ_u, log(λ_wa))\n",
    "        update_users!(items, users, ratings, wu, A, U, λ_a, log(λ_wu))\n",
    "        loss = calc_losses()\n",
    "    end\n",
    "    U, A, loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44f0871-3bb4-4083-8bdb-3cb53233298c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a09d0ba-09cb-48c3-84b0-d0eb57d1e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "function validation_mse(λ, K)\n",
    "    λ = exp.(λ) # ensure λ is nonnegative\n",
    "    # stop early so we can spend more computation exploring the parameter space\n",
    "    stop_criteria = early_stopper(max_iters = 10)\n",
    "    U, A, loss = train_model(training, validation, λ..., K, stop_criteria)\n",
    "    loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b672be0c-bb3c-47f5-af74-d91fbdcd55b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "function optimize_model(K)\n",
    "    # Find the best regularization hyperparameters\n",
    "    res = Optim.optimize(\n",
    "        λ -> validation_mse(λ, K),\n",
    "        randn(4),\n",
    "        Optim.LBFGS(),\n",
    "        autodiff = :forward,\n",
    "        Optim.Options(show_trace = true, extended_trace = true),\n",
    "    )\n",
    "    λ = exp.(Optim.minimizer(res))\n",
    "    @info \"The optimal λ is $λ, found in \" * repr(Optim.f_calls(res)) * \" function calls\"\n",
    "\n",
    "    # train model\n",
    "    stop_criteria =\n",
    "        early_stopper(max_iters = 100, patience = 5, min_rel_improvement = 0.0001)\n",
    "    U, A, loss = train_model(training, validation, λ..., K, stop_criteria)\n",
    "\n",
    "    # save model\n",
    "    outdir = \"$name.$K\"\n",
    "    model(users, items) = make_prediction(users, items, U, A)\n",
    "    write_predictions(model, outdir = outdir, residual_alphas = residual_alphas)\n",
    "    write_params(\n",
    "        Dict(\"U\" => U, \"A\" => A, \"λ\" => λ, \"K\" => K, \"residual_alphas\" => residual_alphas),\n",
    "        outdir = outdir,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bcd5ef-10d1-48a8-9db0-49a07f64c0a7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for K in [2^3,2^4,2^5]\n",
    "    optimize_model(K)\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3758ece-9b72-47b4-ae6a-aa364e0443e3",
   "metadata": {},
   "source": [
    "# Anime Neural Network\n",
    "* Based off of the candidate generator YouTube recommender system\n",
    "* See Section 3 of [Deep Neural Networks for YouTube Recommendations](https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf) by Covington et al."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc9334a-2287-41d6-885b-a5cca94fe263",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"ANN\";\n",
    "residual_alphas = [\"UserItemBiases\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54170f91-c85c-4207-9939-572cad4db024",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux # TODO add to readme\n",
    "import BSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17593ac-3260-4c01-a5df-91edfcd17e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "using NBInclude\n",
    "@nbinclude(\"Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69280b1f-08cb-4b16-a19a-c85ead6e1f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLAS.set_num_threads(Threads.nthreads())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08801fd4-7057-49f0-9fa7-9854d17494cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = gpu;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cc7492-35fa-4516-a4af-7ebc12dbec75",
   "metadata": {},
   "source": [
    "## train on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb458301-7baa-4bd1-88c1-bd8c9193bebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16981, 452578)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training = get_residuals(\"training\", residual_alphas);\n",
    "const validation = get_residuals(\"validation\", residual_alphas)\n",
    "# column accesses are faster than row accesses, so we make this an (item, user) matrix instead of a (user, item) matrix\n",
    "R = sparse(\n",
    "    training.item,\n",
    "    training.user,\n",
    "    convert.(Float32, training.rating),\n",
    "    maximum(training.item) + 1, # leave room for unseen users and items\n",
    "    maximum(training.user) + 1,\n",
    ");\n",
    "n_items, n_users = size(R)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce745d98-9d01-43f2-8a0d-c6bb5179abc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.44 μs/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "counts = zeros(Float32, n_users)\n",
    "@tprogress Threads.@threads for j = 1:length(training.user)\n",
    "    counts[training.user[j]] += 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f0a1aed-f31e-484f-bd54-840fd8f9ec1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_data(R, split, j)\n",
    "    # inputs are the average user's ratings for all shows (unseen shows get mapped to zero) + avg implicit ratings + heterogenous features\n",
    "    # outputs are the one-hot encoding of a heldout series that the user has seen\n",
    "    weight = max(counts[min(split.user[j], n_users)] - 1, 1)\n",
    "\n",
    "    X1 = collect(R[:, min(split.user[j], n_users)])\n",
    "    X1[min(split.item[j], n_items)] = 0\n",
    "    X1 = X1 ./ weight\n",
    "\n",
    "    X2 = copy(X1)\n",
    "    X2[X2.!=0] .= 1 / weight\n",
    "\n",
    "    Y = zeros(Float32, length(X1))\n",
    "    Y[split.item[j]] = 1\n",
    "\n",
    "    # add heterogeneous features\n",
    "    norm_weight = weight / n_items\n",
    "    X3 = [norm_weight, sqrt(norm_weight), norm_weight^2]\n",
    "    return (X1, X2, X3, Y)\n",
    "end\n",
    "\n",
    "function get_batch(R, split, block_size)\n",
    "    idxs = rand(1:length(split.rating), block_size)\n",
    "    data = [[] for j = 1:Threads.nthreads()]\n",
    "    Threads.@threads for i in idxs\n",
    "        push!(data[Threads.threadid()], get_data(R, split, i))\n",
    "    end\n",
    "    X1 = Flux.batch([data[t][i][1] for t = 1:Threads.nthreads() for i = 1:length(data[t])])\n",
    "    X2 = Flux.batch([data[t][i][2] for t = 1:Threads.nthreads() for i = 1:length(data[t])])\n",
    "    X3 = Flux.batch([data[t][i][3] for t = 1:Threads.nthreads() for i = 1:length(data[t])])\n",
    "    Y = Flux.batch([data[t][i][4] for t = 1:Threads.nthreads() for i = 1:length(data[t])])\n",
    "    [((X1, X2, X3), Y)] |> device\n",
    "end;\n",
    "\n",
    "function loss(x, y)\n",
    "    Flux.logitcrossentropy(m(x), y)\n",
    "end\n",
    "\n",
    "function evalcb(R, split)\n",
    "    losses = []\n",
    "    @showprogress for epoch = 1:100\n",
    "        push!(losses, val_loss(get_batch(R, split, 128)[1]...))\n",
    "    end\n",
    "    mean(losses)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "73ef2c54-ff66-49d1-a6a4-5b9077e969e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "function val_loss(x, y)\n",
    "    mask = (x[2] .!= 0)# zero out entries for shows you've already seen\n",
    "    prelogits = m(x)\n",
    "    prelogits[mask] .= -1e3\n",
    "    Flux.logitcrossentropy(prelogits, y)\n",
    "end\n",
    "\n",
    "function val_evalcb(R, split)\n",
    "    losses = []\n",
    "    @showprogress for epoch = 1:100\n",
    "        push!(losses, val_loss(get_batch(R, split, 128)[1]...))\n",
    "    end\n",
    "    mean(losses)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "110b7a2f-5927-4837-99f0-980bc72b5034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# see get_data for documentation on inputs, outputs\n",
    "Join(combine, paths) = Parallel(combine, paths)\n",
    "Join(combine, paths...) = Join(combine, paths)\n",
    "rating_embedding = Dense(n_items, 256, bias = false)\n",
    "implicit_embedding = Dense(n_items, 256, bias = false)\n",
    "het_embedding = Dense(3, 3, bias = false)\n",
    "m =\n",
    "    Chain(\n",
    "        Join(vcat, rating_embedding, implicit_embedding, het_embedding),\n",
    "        Dense(256 + 256 + 3, 1024, relu),    \n",
    "        Dense(1024, 512, relu),\n",
    "        Dense(512, 256, relu),\n",
    "        Dense(256, n_items),\n",
    "    ) |> device\n",
    "ps = Flux.params(m);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2068c6b4-911b-400d-89ca-f7971d8de0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss(x, y) = Flux.logitcrossentropy(m(x), y)\n",
    "opt = ADAM();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "580056a4-2187-4bda-be76-9c4a87bee43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = Inf\n",
    "patience = 5\n",
    "iters = 0\n",
    "iters_without_improvement = 0\n",
    "continue_training = true\n",
    "\n",
    "function evalcb()\n",
    "    # print losses and perform early stopping\n",
    "    @debug \"iteration: $iters\"\n",
    "    @debug \"training loss: $(evalcb(R, training))\"\n",
    "    loss = val_evalcb(R, validation)\n",
    "    @debug \"validation loss: $(loss)\"\n",
    "    if loss < best_loss\n",
    "        global best_loss = loss\n",
    "        global iters_without_improvement = 0\n",
    "        BSON.@save \"../../data/alphas/$name/model.bson\" m\n",
    "    else\n",
    "        global iters_without_improvement += 1\n",
    "        if iters_without_improvement >= patience\n",
    "            global continue_training = false\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "throttled_cb = Flux.throttle(evalcb, 60);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bda612-f8a6-4d0e-ad9a-358f8a19f06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220127 23:11:40 iteration: 0\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:06\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220127 23:11:46 training rmse: 7.370386\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:06\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220127 23:11:53 validation rmse: 7.3511214\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220127 23:12:57 iteration: 0\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:07\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220127 23:13:05 training rmse: 7.3693876\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:07\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220127 23:13:12 validation rmse: 7.3729053\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220127 23:14:12 iteration: 0\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:08\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220127 23:14:20 training rmse: 7.3237233\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:08\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220127 23:14:29 validation rmse: 7.3518467\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220127 23:15:30 iteration: 0\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:06\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220127 23:15:36 training rmse: 7.338549\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:06\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220127 23:15:43 validation rmse: 7.3386602\n"
     ]
    }
   ],
   "source": [
    "while continue_training\n",
    "    batch = get_batch(R, training, 128)\n",
    "    Flux.train!(loss, ps, batch, opt, cb = throttled_cb)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8a214c26-9661-4756-85e3-086dad9e3c32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [ Debug: 20220123 14:44:04 validation rmse: 7.43"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3758ece-9b72-47b4-ae6a-aa364e0443e3",
   "metadata": {},
   "source": [
    "# Matrix Factorization\n",
    "* Prediction is $\\tilde R = UA^T$ \n",
    "* Loss fuction is $L = \\lVert (R - \\tilde R)^\\Omega \\rVert _2^2 + \\lambda_u \\lVert U \\rVert _2^2 + \\lambda_a \\lVert A \\rVert _2^2$\n",
    "* $\\Omega$ is the set of oberved pairs $(i, j)$\n",
    "* $M^\\Omega$ is the projection of $M$ onto $\\Omega$ for any matrix $M$, that is $M_{ij}^\\Omega$ is defined to be $M_{ij}$ when $(i, j) \\in \\Omega$ and $0$ otherwise\n",
    "* $U$ is an $m x k$ matrix, $A$ is an $n x k$ matrix and $R$ is the $m x n$ ratings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc9334a-2287-41d6-885b-a5cca94fe263",
   "metadata": {},
   "outputs": [],
   "source": [
    "const name = \"MatrixFactorization\";\n",
    "const residual_alphas = [\"UserItemBiases\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54170f91-c85c-4207-9939-572cad4db024",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17593ac-3260-4c01-a5df-91edfcd17e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "using NBInclude\n",
    "@nbinclude(\"Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb458301-7baa-4bd1-88c1-bd8c9193bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "const training = RatingsDataset64(get_residuals(\"training\", residual_alphas))\n",
    "const validation = RatingsDataset64(get_residuals(\"validation\", residual_alphas));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f52a69-0231-4bff-8a9f-26bb16ee9f33",
   "metadata": {},
   "source": [
    "## Alternating Least Squares Algorithm\n",
    "* $u_{ik} = \\dfrac{\\sum_{j \\in \\Omega_i}(r_{ij} - \\tilde r_{ij} + u_{ik}a_{kj})}{\\sum_{j \\in \\Omega_i} a_j^2 + \\lambda_u}$\n",
    "* $\\Omega$ is the set of (user, item) pairs that we have ratings for\n",
    "* $\\Omega_i$ is subset of $\\Omega$ for which the user is the $i$-th user\n",
    "* Note that this equation is equivalent to solving $A^{\\Omega_i} u_i = R^{\\Omega_i}$ with $L_2$ regularization $\\lambda_u$, where $\\Omega_i = \\{(i', j) \\in \\Omega | i' = i \\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9e3f1ca-34cc-48b6-8c28-7deb35939858",
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_prediction(users, items, U, A)\n",
    "    r = zeros(eltype(U), length(users))\n",
    "    @views Threads.@threads for i = 1:length(r)\n",
    "        if (users[i] <= size(U)[1]) && (items[i] <= size(A)[1])\n",
    "            r[i] = dot(U[users[i], :], A[items[i], :])\n",
    "        end\n",
    "    end\n",
    "    r\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c27971b0-684c-49b5-8c12-bb6666664f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "function calc_loss(df, U, A)\n",
    "    truth = df.rating\n",
    "    pred = make_prediction(df.user, df.item, U, A)\n",
    "    β = pred \\ truth\n",
    "    loss = mse(truth, pred .* β)\n",
    "    @debug \"loss: $loss β: $β\"\n",
    "    loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04463bd7-c9df-4866-b929-c6217b38e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function ridge_regression(X, y, λ)\n",
    "    (Matrix(X'X) + λ * I(size(X)[2])) \\ Vector(X'y)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea373a98-e714-4083-8cfc-dddc4dd2c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# julia matrices are column major by default so we take adjoints to make them row major\n",
    "@memoize function sparse_csr(i, j, v, m, n)\n",
    "    sparse(j, i, v, n, m)'\n",
    "end;\n",
    "\n",
    "@memoize function gaussian_init_csr(source, K, el_type)\n",
    "    Random.seed!(20211204 * hash(source) * K)\n",
    "    (zeros(el_type, K, maximum(source)) + randn(K, maximum(source)) * K^(-1 / 4))'\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9094b8d-eea5-4ecd-b743-a7a245d3f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "function sparse_subset(A, rows)\n",
    "    # returns a sparse matrix B such that: \n",
    "    # size(B) == size(A), B[rows, :] == A[rows, :], and B[~rows, :] == 0\n",
    "    K = size(A)[2]\n",
    "    nzval = vec(A[rows, :])\n",
    "    rowval = repeat(rows, K)\n",
    "    colptr = [1 + (x - 1) * length(rows) for x = 1:K+1]\n",
    "    SparseMatrixCSC(size(A)..., colptr, rowval, nzval)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c2e8700-dfa0-421a-b833-1fb40f47566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function update_users!(users, items, ratings, U, A, λ_u)\n",
    "    R = sparse_csr(users, items, ratings, size(U)[1], size(A)[1])\n",
    "    @tprogress Threads.@threads for i = 1:size(U)[1]\n",
    "        X = sparse_subset(A, rowvals(R[i, :]))\n",
    "        y = R[i, :]\n",
    "        U[i, :] = ridge_regression(X, y, λ_u)\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0371f61-27bf-4f52-b822-d060f7be01b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_model(training, validation, λ_u, λ_a, K, stop_criteria)\n",
    "    @debug \"training model with parameters [$λ_u, $λ_a]\"\n",
    "    users, items, ratings = training.user, training.item, training.rating\n",
    "    U = copy(gaussian_init_csr(users, K, eltype(λ_u)))\n",
    "    A = copy(gaussian_init_csr(items, K, eltype(λ_a)))\n",
    "    calc_loss(training, U, A)\n",
    "    loss = calc_loss(validation, U, A)\n",
    "\n",
    "    while !stop!(stop_criteria, loss)\n",
    "        update_users!(users, items, ratings, U, A, λ_u)\n",
    "        update_users!(items, users, ratings, A, U, λ_a)\n",
    "        calc_loss(training, U, A)\n",
    "        loss = calc_loss(validation, U, A)\n",
    "    end\n",
    "    U, A, loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44f0871-3bb4-4083-8bdb-3cb53233298c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a09d0ba-09cb-48c3-84b0-d0eb57d1e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "function validation_mse(λ, K)\n",
    "    λ = exp.(λ) # ensure λ is nonnegative\n",
    "    # stop early so we can spend more computation exploring the parameter space\n",
    "    stop_criteria = early_stopper(max_iters = 10)\n",
    "    U, A, loss = train_model(training, validation, λ..., K, stop_criteria)\n",
    "    loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b672be0c-bb3c-47f5-af74-d91fbdcd55b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "function optimize_model(K)\n",
    "    # Find the best regularization hyperparameters\n",
    "    res = optimize(\n",
    "        λ -> validation_mse(λ, K),\n",
    "        randn(2),\n",
    "        LBFGS(),\n",
    "        autodiff = :forward,\n",
    "        Optim.Options(show_trace = true, extended_trace = true),\n",
    "    )\n",
    "    λ = exp.(Optim.minimizer(res))\n",
    "    @info \"The optimal [λ_u, λ_a] is $λ, found in \" *\n",
    "          repr(Optim.f_calls(res)) *\n",
    "          \" function calls\"\n",
    "\n",
    "    # train model\n",
    "    stop_criteria =\n",
    "        early_stopper(max_iters = 100, patience = 5, min_rel_improvement = 0.0001)\n",
    "    U, A, loss = train_model(training, validation, λ..., K, stop_criteria)\n",
    "\n",
    "    # save model\n",
    "    outdir = \"$name.$K\"\n",
    "    model(users, items) = make_prediction(users, items, U, A)\n",
    "    write_predictions(model, outdir = outdir, residual_alphas = residual_alphas)\n",
    "    write_params(\n",
    "        Dict(\"U\" => U, \"A\" => A, \"λ\" => λ, \"K\" => K, \"residual_alphas\" => residual_alphas),\n",
    "        outdir = outdir,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bcd5ef-10d1-48a8-9db0-49a07f64c0a7",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 07:00:12 training model with parameters [Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.8251864330240113,1.8251864330240113,0.0), Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(0.7666130083989544,0.0,0.7666130083989544)]\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 07:00:22 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.6473713612587806,0.0,0.0) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(-9.458627106681692e-5,0.0,0.0)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 07:00:23 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.7427761338988725,0.0,0.0) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(-0.00031870006946821514,0.0,0.0)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:02:17 ( 1.67 ms/it)\u001b[39m/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:06:04 ( 0.31  s/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 07:09:07 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.4974295591713136,0.0012119255909602265,0.0003444517153159313) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.0044104764377335,0.00037046983642813173,0.002103108606916829)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 07:09:09 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.7393452112026404,-0.00084036398217455,6.00815317440621e-6) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(0.11342732392568738,0.021160518596357376,0.00017503262895002047)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:02:11 ( 1.60 ms/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:06:03 ( 0.31  s/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 07:17:31 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.3755879458448246,-0.005120202010113187,0.00012122233191394072) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.0038027467466706,0.0003027236540481004,0.002071893245704529)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 07:17:32 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.67619567719888,-0.010297463866610164,-0.0001653596023126587) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(0.41304170977659505,0.04640528123584446,0.0014570051656350763)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:02:12 ( 1.60 ms/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:06:04 ( 0.31  s/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 07:25:56 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.308687025737508,-0.003018503590038034,1.4997182961841741e-5) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.003353712383782,0.0003953019613268123,0.0019800767800572092)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 07:25:57 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.6199064144704876,-0.01199208549142825,-0.0003915699257539677) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(0.5150916225129818,0.042322014227251535,0.002188096379974821)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:02:11 ( 1.60 ms/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:06:05 ( 0.31  s/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 07:34:21 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.276981816484575,-0.002227973732431151,-3.41418530003334e-5) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.003204387927646,0.0004749741849618421,0.0019775194916567354)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 07:34:22 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.5905210849239673,-0.01247474609041582,-0.0005735434804930286) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(0.5516822632768897,0.04083904781912976,0.0026097777354614593)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:02:11 ( 1.60 ms/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:06:05 ( 0.31  s/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 07:42:46 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.256891696783023,-0.0018119544198911873,-3.837517728519187e-5) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.0031365727171755,0.0005521830523505907,0.0019902857209783097)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 07:42:47 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.571281677822161,-0.01257980764760261,-0.0007005446041991553) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(0.5721570606705296,0.03958181886669465,0.0029234834907230786)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:02:11 ( 1.60 ms/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:06:04 ( 0.31  s/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 07:51:11 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.2430618786599925,-0.001338132109840606,6.428344920971329e-6) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.0031167708721958,0.0006320662551138953,0.0020135542182407895)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 07:51:12 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.5579031042368447,-0.0121527793151907,-0.0007612008748208791) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(0.5852825097434593,0.037803743113243936,0.0031346793570837484)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:02:12 ( 1.60 ms/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:06:05 ( 0.31  s/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 07:59:37 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.233297939780042,-0.0008534382948554505,7.690966066726648e-5) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.003132776265245,0.0007144977710465474,0.002046299915551001)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 07:59:38 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.5485803297813039,-0.011435578584999813,-0.0007841532851196692) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(0.5937013553463001,0.035719153602996455,0.0032844478415368808)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:02:11 ( 1.60 ms/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:06:05 ( 0.31  s/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 08:08:02 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.2262230931623337,-0.00045103746018643177,0.00015211173926329153) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.003175892046978,0.0007973988127039002,0.0020860288210960845)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 08:08:03 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.5420048967849893,-0.010702415645552377,-0.0008019074545919391) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(0.5990278482717014,0.03373988053067489,0.003432298331802046)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:02:12 ( 1.60 ms/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:06:04 ( 0.31  s/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 08:16:27 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.220917138615237,-0.00016684689339952578,0.0002206034766798187) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.0032381487441846,0.0008787804032527984,0.0021297347119442903)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 08:16:28 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.5372333007591665,-0.010069542811999633,-0.0008281748694121684) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(0.6024098610868519,0.03201136370787653,0.003597005766985532)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:02:11 ( 1.60 ms/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:06:04 ( 0.31  s/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 08:24:51 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.2167766352038283,1.0177592838980241e-5,0.0002766586677004654) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.0033129699761474,0.0009582980505113449,0.0021760462628258323)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 08:24:52 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.533635575902181,-0.009538844854065169,-0.0008646507076890322) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(0.6045902369965604,0.03049138222100345,0.003777185525716639)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter     Function value   Gradient norm \n",
      "     0     1.533636e+00     9.538845e-03\n",
      " * Current step size: 1.0\n",
      " * time: 0.02514505386352539\n",
      " * g(x): [-0.009538844854065169, -0.0008646507076890322]\n",
      " * x: [0.6016821368986298, -0.2657731572271953]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 08:24:54 training model with parameters [Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.8426799043494326,1.8426799043494326,0.0), Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(0.7672761475297348,0.0,0.7672761475297348)]\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 08:25:02 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.6473713612587806,0.0,0.0) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(-9.458627106681692e-5,0.0,0.0)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 08:25:03 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.7427761338988725,0.0,0.0) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(-0.00031870006946821514,0.0,0.0)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:02:11 ( 1.60 ms/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:06:03 ( 0.31  s/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 08:33:25 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.4974415181485157,0.001233058325961734,0.00034468619758291956) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.004415844467791,0.0003734435713136491,0.0021067094077613724)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 08:33:26 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.7393371901113184,-0.0008425017759594309,6.025196761588228e-6) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(0.11362959026508762,0.021216729036366205,0.00017557124744008024)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:02:12 ( 1.60 ms/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:06:03 ( 0.31  s/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 08:41:49 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.3755392327748874,-0.005115455804233272,0.00012195740918874557) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.0038074393711875,0.0003052795873263484,0.0020750161443317343)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220211 08:41:50 loss: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(1.6760972551734679,-0.01030860035308093,-0.00016536320999081366) β: Dual{ForwardDiff.Tag{var\"#24#25\"{Int64}, Float64}}(0.41348585870689913,0.04645467795356881,0.001458728010876106)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:02:11 ( 1.60 ms/it)\u001b[39m\n",
      "\u001b[32mProgress:  91%|████████████████████████▌  |  ETA: 0:00:34 ( 0.32  s/it)\u001b[39m"
     ]
    }
   ],
   "source": [
    "for K in [10, 20, 40] # TODO change this to 2^3,2^4,2^5\n",
    "    optimize_model(K)\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-beta3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

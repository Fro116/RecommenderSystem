{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3758ece-9b72-47b4-ae6a-aa364e0443e3",
   "metadata": {},
   "source": [
    "# Matrix Factorization\n",
    "* Prediction is $\\tilde R = UA^T$ \n",
    "* Loss fuction is $L = \\lVert (R - \\tilde R)^\\Omega \\rVert _2^2 + \\lambda_u \\lVert U \\rVert _2^2 + \\lambda_a \\lVert A \\rVert _2^2$\n",
    "* $\\Omega$ is the set of oberved pairs $(i, j)$\n",
    "* $M^\\Omega$ is the projection of $M$ onto $\\Omega$ for any matrix $M$, that is $M_{ij}^\\Omega$ is defined to be $M_{ij}$ when $(i, j) \\in \\Omega$ and $0$ otherwise\n",
    "* $U$ is an $m x k$ matrix, $A$ is an $n x k$ matrix and $R$ is the $m x n$ ratings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc9334a-2287-41d6-885b-a5cca94fe263",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"MatrixFactorization\";\n",
    "residual_alphas = [\"UserItemBiases\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54170f91-c85c-4207-9939-572cad4db024",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17593ac-3260-4c01-a5df-91edfcd17e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "using NBInclude\n",
    "@nbinclude(\"Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb458301-7baa-4bd1-88c1-bd8c9193bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "const training = get_residuals(\"training\", residual_alphas)\n",
    "const validation = get_residuals(\"validation\", residual_alphas);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f52a69-0231-4bff-8a9f-26bb16ee9f33",
   "metadata": {},
   "source": [
    "## Alternating Least Squares Algorithm\n",
    "* $u_{ik} = \\dfrac{\\sum_{j \\in \\Omega_i}(r_{ij} - \\tilde r_{ij} + u_{ik}a_{kj})}{\\sum_{j \\in \\Omega_i} a_j^2 + \\lambda_u}$\n",
    "* $\\Omega$ is the set of (user, item) pairs that we have ratings for\n",
    "* $\\Omega_i$ is subset of $\\Omega$ for which the user is the $i$-th user\n",
    "* Note that this equation is equivalent to solving $A^{\\Omega_i} u_i = R^{\\Omega_i}$ with $L_2$ regularization $\\lambda_u$, where $\\Omega_i = \\{(i', j) \\in \\Omega | i' = i \\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9e3f1ca-34cc-48b6-8c28-7deb35939858",
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_prediction(users, items, U, A)\n",
    "    r = zeros(eltype(U), length(users))\n",
    "    @views Threads.@threads for i = 1:length(r)\n",
    "        if (users[i] <= size(U)[1]) && (items[i] <= size(A)[1])\n",
    "            r[i] = dot(U[users[i], :], A[items[i], :])\n",
    "        end\n",
    "    end\n",
    "    r\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c27971b0-684c-49b5-8c12-bb6666664f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "function calc_loss(df, U, A)\n",
    "    truth = df.rating\n",
    "    pred = make_prediction(df.user, df.item, U, A)\n",
    "    β = pred \\ truth\n",
    "    loss = mse(truth, pred .* β)\n",
    "    @debug \"loss: $loss β: $β\"\n",
    "    loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04463bd7-c9df-4866-b929-c6217b38e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function ridge_regression(X, y, λ)\n",
    "    (Matrix(X'X) + λ * I(size(X)[2])) \\ Vector(X'y)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea373a98-e714-4083-8cfc-dddc4dd2c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# julia matrices are column major by default so we take adjoints to make them row major\n",
    "@memoize function sparse_csr(i, j, v, m, n)\n",
    "    sparse(j, i, v, n, m)'\n",
    "end;\n",
    "\n",
    "@memoize function gaussian_init_csr(source, K, el_type)\n",
    "    Random.seed!(20211204 * hash(source) * K)\n",
    "    (zeros(el_type, K, maximum(source)) + randn(K, maximum(source)) * K^(-1 / 4))'\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9094b8d-eea5-4ecd-b743-a7a245d3f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "function sparse_subset(A, rows)\n",
    "    # returns a sparse matrix B such that: \n",
    "    # size(B) == size(A), B[rows, :] == A[rows, :], and B[~rows, :] == 0\n",
    "    K = size(A)[2]\n",
    "    nzval = vec(A[rows, :])\n",
    "    rowval = repeat(rows, K)\n",
    "    colptr = [1 + (x - 1) * length(rows) for x = 1:K+1]\n",
    "    SparseMatrixCSC(size(A)..., colptr, rowval, nzval)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c2e8700-dfa0-421a-b833-1fb40f47566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function update_users!(users, items, ratings, U, A, λ_u)\n",
    "    R = sparse_csr(users, items, ratings, size(U)[1], size(A)[1])\n",
    "    @tprogress Threads.@threads for i = 1:size(U)[1]\n",
    "        X = sparse_subset(A, rowvals(R[i, :]))\n",
    "        y = R[i, :]\n",
    "        U[i, :] = ridge_regression(X, y, λ_u)\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0371f61-27bf-4f52-b822-d060f7be01b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_model(training, validation, λ_u, λ_a, K, stop_criteria)\n",
    "    @debug \"training model with parameters [$λ_u, $λ_a]\"\n",
    "    users, items, ratings = training.user, training.item, training.rating\n",
    "    U = copy(gaussian_init_csr(users, K, eltype(λ_u)))\n",
    "    A = copy(gaussian_init_csr(items, K, eltype(λ_a)))\n",
    "    calc_loss(training, U, A)\n",
    "    loss = calc_loss(validation, U, A)\n",
    "\n",
    "    while !stop!(stop_criteria, loss)\n",
    "        update_users!(users, items, ratings, U, A, λ_u)\n",
    "        update_users!(items, users, ratings, A, U, λ_a)\n",
    "        calc_loss(training, U, A)\n",
    "        loss = calc_loss(validation, U, A)\n",
    "    end\n",
    "    U, A, loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44f0871-3bb4-4083-8bdb-3cb53233298c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a09d0ba-09cb-48c3-84b0-d0eb57d1e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "function validation_mse(λ, K)\n",
    "    λ = exp.(λ) # ensure λ is nonnegative\n",
    "    # stop early so we can spend more computation exploring the parameter space\n",
    "    stop_criteria = early_stopper(max_iters = 10)\n",
    "    U, A, loss = train_model(training, validation, λ..., K, stop_criteria)\n",
    "    loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b672be0c-bb3c-47f5-af74-d91fbdcd55b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "function optimize_model(K)\n",
    "    # Find the best regularization hyperparameters\n",
    "    res = optimize(\n",
    "        λ -> validation_mse(λ, K),\n",
    "        randn(2),\n",
    "        LBFGS(),\n",
    "        autodiff = :forward,\n",
    "        Optim.Options(show_trace = true, extended_trace = true),\n",
    "    )\n",
    "    λ = exp.(Optim.minimizer(res))\n",
    "    @info \"The optimal [λ_u, λ_a] is $λ, found in \" *\n",
    "          repr(Optim.f_calls(res)) *\n",
    "          \" function calls\"\n",
    "\n",
    "    # train model\n",
    "    stop_criteria =\n",
    "        early_stopper(max_iters = 100, patience = 5, min_rel_improvement = 0.0001)\n",
    "    U, A, loss = train_model(training, validation, λ..., K, stop_criteria)\n",
    "\n",
    "    # save model\n",
    "    outdir = \"$name.$K\"\n",
    "    model(users, items) = make_prediction(users, items, U, A)\n",
    "    write_predictions(model, outdir = outdir, save_training = true)\n",
    "    write_params(\n",
    "        Dict(\"U\" => U, \"A\" => A, \"λ\" => λ, \"K\" => K, \"residual_alphas\" => residual_alphas),\n",
    "        outdir = outdir,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bcd5ef-10d1-48a8-9db0-49a07f64c0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20211229 19:35:24 training model with parameters [Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(0.9225164369247361,0.9225164369247361,0.0), Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(0.14296685505172457,0.0,0.14296685505172457)]\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20211229 19:35:29 loss: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.6739007297732638,0.0,0.0) β: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(-0.001,0.0,0.0)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20211229 19:35:30 loss: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.6981923229550528,0.0,0.0) β: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(-0.001,0.0,0.0)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:53 ( 1.89 ms/it)\u001b[39mm\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:01:37 (91.71 ms/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20211229 19:38:11 loss: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.5387685476434594,-4.7902622310245114e-5,0.000379501415091122) β: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.004369855127813,8.831596049249294e-5,0.001549196720285096)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20211229 19:38:12 loss: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.6954819918228135,-0.00043457558589552576,-5.536367865858188e-7) β: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(0.13759891022810078,0.014130153141177717,0.0005837390673051339)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:46 ( 1.66 ms/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:01:36 (91.15 ms/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20211229 19:40:39 loss: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.4169796030789952,-0.003997451081498182,-0.00021476929424898834) β: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.0029384952311253,6.28897996418773e-5,0.0013928976508575431)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20211229 19:40:39 loss: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.6200684906990916,-0.006790495146361296,-0.0008142527739223791) β: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(0.5473916195070354,0.026496887209107207,0.003960206859749645)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:47 ( 1.66 ms/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:01:36 (91.31 ms/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20211229 19:43:07 loss: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.345407442516189,-0.0032785552662425266,-0.0004313269545301179) β: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.0022590971673278,9.872600694382822e-5,0.0011726622071813186)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20211229 19:43:07 loss: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.5567087227782943,-0.00827632283813225,-0.001254218784290286) β: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(0.6432640200279165,0.022536763483941794,0.00381103293209171)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:46 ( 1.65 ms/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:01:36 (91.16 ms/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20211229 19:45:34 loss: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.3103972969014273,-0.002736737111990941,-0.0004486606736600436) β: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.0019659945821524,0.00012440271952925155,0.0010762548818372393)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20211229 19:45:35 loss: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.5224950631901446,-0.008771264289219413,-0.0013529440640470984) β: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(0.6778626589709851,0.021573324895479765,0.0035639994875108476)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:46 ( 1.65 ms/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:01:36 (90.90 ms/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20211229 19:48:01 loss: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.2899548849033002,-0.0020849700181329246,-0.00038466164861758424) β: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.0017950508247737,0.00014960472612625227,0.0010196582290165678)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20211229 19:48:02 loss: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.5015112326210602,-0.008658529200074417,-0.0013392271568057426) β: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(0.6961135453806119,0.02084957581411921,0.0034095248398095315)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:46 ( 1.65 ms/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:01:36 (91.01 ms/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20211229 19:50:29 loss: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.2772033685661885,-0.0015853820357074832,-0.00032564569574348545) β: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.0016900416805539,0.00017548936235949178,0.0009880039329907564)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20211229 19:50:30 loss: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.487806496819701,-0.008370827499756059,-0.001315101056251846) β: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(0.7075922568916505,0.020099228343877583,0.003313879907096943)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:46 ( 1.66 ms/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:01:36 (90.89 ms/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20211229 19:52:56 loss: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.268378272062608,-0.0012619620407505446,-0.0002890606174872686) β: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.0016241847246952,0.00020120446385882743,0.0009714530800032491)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20211229 19:52:57 loss: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(1.47790390814646,-0.008064925311564407,-0.0013015628423102034) β: Dual{ForwardDiff.Tag{var\"#18#19\"{Int64}, Float64}}(0.7160150245789184,0.019332000300388803,0.0032457352923563622)\n",
      "\u001b[32mProgress:  15%|████▏                      |  ETA: 0:00:41 ( 1.71 ms/it)\u001b[39m"
     ]
    }
   ],
   "source": [
    "for K in [10, 20, 40]\n",
    "    optimize_model(K)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e91df6-cca6-489a-8515-6e8e68a0b770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

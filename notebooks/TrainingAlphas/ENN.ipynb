{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3758ece-9b72-47b4-ae6a-aa364e0443e3",
   "metadata": {},
   "source": [
    "# Autoencoder Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc9334a-2287-41d6-885b-a5cca94fe263",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"ENN\";\n",
    "residual_alphas = [\"UserItemBiases\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54170f91-c85c-4207-9939-572cad4db024",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Warning: The NVIDIA driver on this system only supports up to CUDA 11.1.0.\n",
      "│ For performance reasons, it is recommended to upgrade to a driver that supports CUDA 11.2 or higher.\n",
      "└ @ CUDA C:\\Users\\kunda\\.julia\\packages\\CUDA\\nYggH\\src\\initialization.jl:70\n"
     ]
    }
   ],
   "source": [
    "using Flux # TODO add to readme\n",
    "import BSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17593ac-3260-4c01-a5df-91edfcd17e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "using NBInclude\n",
    "@nbinclude(\"Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69280b1f-08cb-4b16-a19a-c85ead6e1f25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BLAS.set_num_threads(Threads.nthreads())\n",
    "Threads.nthreads()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08801fd4-7057-49f0-9fa7-9854d17494cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = gpu;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cc7492-35fa-4516-a4af-7ebc12dbec75",
   "metadata": {},
   "source": [
    "## train on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb458301-7baa-4bd1-88c1-bd8c9193bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "training = get_residuals(\"training\", residual_alphas);\n",
    "const validation = get_residuals(\"validation\", residual_alphas)\n",
    "# column accesses are faster than row accesses, so we make this an (item, user) matrix instead of a (user, item) matrix\n",
    "R = sparse(\n",
    "    training.item,\n",
    "    training.user,\n",
    "    convert.(Float32, training.rating),\n",
    "    maximum(training.item),\n",
    "    maximum(training.user),\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fd21001b-3626-4bf2-82aa-ba04ba89df00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "evalcb (generic function with 1 method)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_data(R, split, j)\n",
    "    # inputs are the user's ratings for all shows (unseen shows get mapped to zero) + implicit ratings + heterogenous features\n",
    "    # outputs are the user's ratings for all shows (unseen shows get mapped to zero)\n",
    "    X = collect(R[:, split.user[j]])\n",
    "    X[split.item[j]] = 0\n",
    "    Y = copy(X)\n",
    "    Xr = copy(X)\n",
    "    Xr[Xr.!=0] .= 1\n",
    "    X = vcat(X, Xr)\n",
    "\n",
    "    # add heterogeneous features\n",
    "    weight = sum(X .!= 0)\n",
    "    nitems_feature = weight / size(R)[1]\n",
    "    push!(X, nitems_feature)\n",
    "    push!(X, sqrt(nitems_feature))\n",
    "    push!(X, nitems_feature^2)\n",
    "    return (X, Y)\n",
    "end\n",
    "\n",
    "function get_batch(R, split, block_size)\n",
    "    items = rand(1:length(split.rating), block_size)\n",
    "    data = [[] for j = 1:Threads.nthreads()]\n",
    "    Threads.@threads for i = 1:length(items)\n",
    "        push!(data[Threads.threadid()], get_data(R, split, items[i]))\n",
    "    end\n",
    "    X = Flux.batch([data[t][i][1] for t = 1:Threads.nthreads() for i = 1:length(data[t])])\n",
    "    Y = Flux.batch([data[t][i][2] for t = 1:Threads.nthreads() for i = 1:length(data[t])])\n",
    "    [(X, Y)] |> device\n",
    "end;\n",
    "\n",
    "function evalcb(R, split)\n",
    "    losses = []\n",
    "    @showprogress for epoch = 1:100\n",
    "        push!(losses, loss(get_batch(R, split, 128)[1]...))\n",
    "    end\n",
    "    mean(losses)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c4878a40-fa88-4f85-bcd7-0a43f1245989",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "val_evalcb (generic function with 1 method)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function get_val_data(R, split, j)\n",
    "    # inputs are the user's ratings for all shows (unseen shows get mapped to zero) + implicit ratings + heterogenous features\n",
    "    # outputs are the user's ratings for a held_out show (unseen shows get mapped to zero)\n",
    "    X = collect(R[:, split.user[j]])\n",
    "    X[split.item[j]] = 0\n",
    "    Y = zeros(eltype(X), length(X))\n",
    "    Y[split.item[j]] = split.rating[j]\n",
    "\n",
    "    Xr = copy(X)\n",
    "    Xr[Xr.!=0] .= 1\n",
    "    X = vcat(X, Xr)\n",
    "\n",
    "    # add heterogeneous features\n",
    "    weight = sum(X .!= 0)\n",
    "    nitems_feature = weight / size(R)[1]\n",
    "    push!(X, nitems_feature)\n",
    "    push!(X, sqrt(nitems_feature))\n",
    "    push!(X, nitems_feature^2)\n",
    "    return (X, Y)\n",
    "end\n",
    "\n",
    "function get_val_batch(R, split, block_size)\n",
    "    items = rand(1:length(split.rating), block_size)\n",
    "    data = [[] for j = 1:Threads.nthreads()]\n",
    "    Threads.@threads for i = 1:length(items)\n",
    "        push!(data[Threads.threadid()], get_val_data(R, split, items[i]))\n",
    "    end\n",
    "    X = Flux.batch([data[t][i][1] for t = 1:Threads.nthreads() for i = 1:length(data[t])])\n",
    "    Y = Flux.batch([data[t][i][2] for t = 1:Threads.nthreads() for i = 1:length(data[t])])\n",
    "    [(X, Y)] |> device\n",
    "end;\n",
    "\n",
    "function val_evalcb(R, split)\n",
    "    losses = []\n",
    "    @showprogress for epoch = 1:100\n",
    "        push!(losses, loss(get_val_batch(R, split, 128)[1]...))\n",
    "    end\n",
    "    mean(losses)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "110b7a2f-5927-4837-99f0-980bc72b5034",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs are the user's ratings for all shows (unseen shows get mapped to zero)\n",
    "# labels are the user's predictions for all shows\n",
    "n_items = size(R)[1]\n",
    "m =\n",
    "    Chain(\n",
    "        Dropout(0.5),\n",
    "        Dense(n_items + n_items + 3, 512, relu),\n",
    "        Dense(512, 256, relu),\n",
    "        Dense(256, 128, relu),\n",
    "        Dense(128, 256, relu),\n",
    "        Dense(256, 512, relu),\n",
    "        Dense(512, n_items),\n",
    "    ) |> device\n",
    "ps = Flux.params(m);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2068c6b4-911b-400d-89ca-f7971d8de0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "function loss(x, y)\n",
    "    mask = y .!= 0\n",
    "    Flux.mse(m(x)[mask], y[mask])\n",
    "end\n",
    "opt = ADAM();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "2be3fd86-8685-42b7-9061-d82f1a4a6064",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_loss = Inf\n",
    "patience = 1000000\n",
    "iters_without_improvement = 0\n",
    "continue_training = true\n",
    "iters = 0\n",
    "\n",
    "function evalcb()\n",
    "    # print losses and perform early stopping\n",
    "    testmode!(m)\n",
    "    @debug \"iteration: $iters\"\n",
    "    @debug \"training rmse: $(evalcb(R, training))\"\n",
    "    loss = val_evalcb(R, validation)\n",
    "    @debug \"validation rmse: $(loss)\"\n",
    "    if loss < best_loss\n",
    "        global best_loss = loss\n",
    "        global iters_without_improvement = 0\n",
    "        BSON.@save \"../../data/alphas/$name/model.bson\" m\n",
    "    else\n",
    "        global iters_without_improvement += 1\n",
    "        if iters_without_improvement >= patience\n",
    "            global continue_training = false\n",
    "        end\n",
    "    end\n",
    "    trainmode!(m)\n",
    "end\n",
    "\n",
    "throttled_cb = Flux.throttle(evalcb, 600);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bda612-f8a6-4d0e-ad9a-358f8a19f06a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220127 14:01:58 iteration: 24591\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:37\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220127 14:02:36 training rmse: 0.96169114\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:39\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220127 14:03:15 validation rmse: 1.3738708\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220127 14:13:16 iteration: 27026\n",
      "\u001b[32mProgress:  25%|███████████                              |  ETA: 0:00:15\u001b[39m"
     ]
    }
   ],
   "source": [
    "while continue_training\n",
    "    batch = get_batch(R, training, 128)\n",
    "    Flux.train!(loss, ps, batch, opt, cb = throttled_cb)\n",
    "    iters += 1\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c7870c-adda-4e3a-9358-e5dc7c3eb665",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.5",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

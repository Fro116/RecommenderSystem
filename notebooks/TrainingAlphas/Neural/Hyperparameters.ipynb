{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c030f566-08b7-46ad-9b69-182e559a9f89",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "* Contains all the information necessary to train a new model\n",
    "* A derivative free optimizer is used to find the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913177a8-b905-41a0-9a8c-922eca7c0593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import NLopt\n",
    "import Setfield: @set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abba16e9-f406-49c4-8af1-6e0afde838c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@with_kw struct Hyperparams\n",
    "    # model\n",
    "    implicit::Bool\n",
    "    input_data::String\n",
    "    input_alphas::Vector{String}\n",
    "    model::String\n",
    "    # batching\n",
    "    batch_size::Int\n",
    "    user_sampling_scheme::Union{String,Float32}\n",
    "    # optimizer\n",
    "    learning_rate::Float32\n",
    "    optimizer::String\n",
    "    # training\n",
    "    seed::UInt64\n",
    "    num_users::Int\n",
    "    # loss\n",
    "    item_weight_decay::Float32\n",
    "    regularization_params::Vector{Float32}\n",
    "    residual_alphas::Vector{String}\n",
    "    user_weight_decay::Float32\n",
    "end\n",
    "\n",
    "function to_dict(x::Hyperparams)\n",
    "    Dict(string(key) => getfield(x, key) for key ∈ fieldnames(Hyperparams))\n",
    "end\n",
    "\n",
    "function Base.string(x::Hyperparams)\n",
    "    fields = [x for x in fieldnames(Hyperparams)]\n",
    "    max_field_size = maximum(length(string(k)) for k in fields)\n",
    "    ret = \"Hyperparameters:\\n\"\n",
    "    for f in fields\n",
    "        ret *= \"$(rpad(string(f), max_field_size)) => $(getfield(x, f))\\n\"\n",
    "    end\n",
    "    ret\n",
    "end\n",
    "\n",
    "function Base.show(io::IO, x::Hyperparams)\n",
    "    print(io, string(x))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "29581f57-6a67-4433-8818-53a972d24398",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_epochs_per_checkpoint(model)\n",
    "    if model == \"user_item_biases\" || startswith(model, \"matrix_factorization\") || model == \"autoencoder\"\n",
    "        return 10\n",
    "    elseif model == \"item_based_collaborative_filtering\" || model == \"ease\"\n",
    "        return 1\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d821968a-9c72-45ec-9fc9-c305c1d2ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_subsampling_factor(model)\n",
    "    if model == \"user_item_biases\" || startswith(model, \"matrix_factorization\")\n",
    "        return 0.01\n",
    "    elseif model == model == \"autoencoder\"\n",
    "        return 0.1\n",
    "    elseif model == \"item_based_collaborative_filtering\" || model == \"ease\"\n",
    "        return 0.25\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cea999-8df9-4875-8287-89fdd2f944b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "function should_holdout_items(model)\n",
    "    if model == \"user_item_biases\" ||\n",
    "       startswith(model, \"matrix_factorization\") ||\n",
    "       model == \"item_based_collaborative_filtering\" ||\n",
    "       model == \"ease\"\n",
    "        return false\n",
    "    elseif model == \"autoencoder\"\n",
    "        return true\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5e58dc7-66d9-4cd5-ae7b-13cd1e552e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "function should_retrain_user_embeddings(model)\n",
    "    if model == \"user_item_biases\" || startswith(model, \"matrix_factorization\")\n",
    "        return true\n",
    "    elseif model == \"item_based_collaborative_filtering\" || model == \"autoencoder\" || model == \"ease\"\n",
    "        return false\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b8114a09-50dc-445e-b01d-2a285fde1040",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_optimizer(optimizer, learning_rate, regularization_params)\n",
    "    if optimizer == \"ADAM\"\n",
    "        return ADAM(learning_rate)\n",
    "    elseif optimizer == \"ADAMW\"\n",
    "        return ADAMW(learning_rate, (0.9, 0.999), regularization_params[1])\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e8716c-42fc-44d5-900c-1bca867444c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "function num_tuneable_params(model)\n",
    "    num_model_params = 3\n",
    "    if (model == \"user_item_biases\") || startswith(model, \"matrix_factorization\")\n",
    "        num_sampling_params = 0\n",
    "        num_regularization_params = 2\n",
    "    elseif model == \"item_based_collaborative_filtering\"\n",
    "        num_sampling_params = 1\n",
    "        num_regularization_params = 1\n",
    "    elseif model == \"autoencoder\"\n",
    "        num_sampling_params = 1\n",
    "        num_regularization_params = 2\n",
    "    elseif model == \"ease\"\n",
    "        num_sampling_params = 1\n",
    "        num_regularization_params = 1        \n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "    num_model_params, num_sampling_params, num_regularization_params\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76b373d-e84f-45b3-bae7-1fecb36bfde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_input_type(model, implicit)\n",
    "    if (model == \"user_item_biases\") || startswith(model, \"matrix_factorization\")\n",
    "        return \"one_hot\"\n",
    "    elseif model == \"item_based_collaborative_filtering\"\n",
    "        return \"explicit\"\n",
    "    elseif model == \"ease\"\n",
    "        if implicit\n",
    "            return \"implicit\"\n",
    "        else\n",
    "            return \"explicit\"\n",
    "        end\n",
    "    elseif model == \"autoencoder\"\n",
    "        return \"explicit_implicit\"\n",
    "    else\n",
    "        @assert false\n",
    "    end    \n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbede6be-4e33-48f1-a7a5-29d419cdbf83",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_optimizer_type(model)\n",
    "    if (model == \"user_item_biases\") || startswith(model, \"matrix_factorization\")\n",
    "        return \"ADAM\"\n",
    "    else\n",
    "        return \"ADAMW\"    \n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dadbdc6d-d986-4870-a4e6-6467ac3aea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "function create_hyperparams(hyp::Hyperparams, λ)\n",
    "    _, num_sampling_params, num_regularization_params = num_tuneable_params(hyp.model)\n",
    "    hyp = @set hyp.learning_rate = 10^(λ[1]-3)\n",
    "    hyp = @set hyp.user_weight_decay = λ[2]\n",
    "    hyp = @set hyp.item_weight_decay = λ[3]\n",
    "    if num_sampling_params == 1\n",
    "        hyp = @set hyp.user_sampling_scheme = λ[4]\n",
    "    else\n",
    "        hyp = @set hyp.user_sampling_scheme = \"constant\"\n",
    "    end\n",
    "    hyp = @set hyp.regularization_params = 10 .^ (λ[end-num_regularization_params+1:end] .- 5)\n",
    "    if should_holdout_items(hyp.model)\n",
    "        hyp.regularization_params[end] = sigmoid(λ[end])\n",
    "    end\n",
    "    hyp\n",
    "end\n",
    "\n",
    "function create_hyperparams(model::String, implicit, residual_alphas, input_alphas = [])\n",
    "    hyp = Hyperparams(\n",
    "        implicit = implicit,\n",
    "        model = model,\n",
    "        batch_size = 1024,\n",
    "        input_alphas = input_alphas,\n",
    "        input_data = get_input_type(model, implicit),\n",
    "        user_sampling_scheme = NaN32,\n",
    "        learning_rate = NaN,\n",
    "        optimizer = get_optimizer_type(model),\n",
    "        seed = 20220524,\n",
    "        num_users = num_users(),\n",
    "        item_weight_decay = NaN,\n",
    "        regularization_params = fill(NaN, num_tuneable_params(model)[end]),\n",
    "        residual_alphas = residual_alphas,\n",
    "        user_weight_decay = NaN,\n",
    "    )\n",
    "    create_hyperparams(hyp, zeros(Float32, sum(num_tuneable_params(model))))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "784a2c5a-5794-4e68-ba17-45f9c63abd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "function nlopt_optimize(\n",
    "    lossfn,\n",
    "    n;\n",
    "    max_evals = 100,\n",
    "    max_time = 86400,\n",
    "    ftol_rel = 1e-4,\n",
    "    xtol_rel = 1e-4,\n",
    ")\n",
    "    opt = NLopt.Opt(:LN_NELDERMEAD, n)\n",
    "    opt.initial_step = 1\n",
    "    opt.maxeval = max_evals\n",
    "    opt.maxtime = max_time\n",
    "    opt.ftol_rel = ftol_rel\n",
    "    opt.xtol_rel = xtol_rel\n",
    "    opt.min_objective = lossfn\n",
    "    minf, λ, ret = NLopt.optimize(opt, zeros(Float32, n))\n",
    "    numevals = opt.numevals\n",
    "    @info (\n",
    "        \"found minimum $minf at point $λ after $numevals function calls \" *\n",
    "        \"(ended because $ret)\"\n",
    "    )\n",
    "    convert.(Float32, λ)\n",
    "end;\n",
    "\n",
    "function optimize_hyperparams(hyp; max_evals)\n",
    "    function nlopt_loss(λ, grad)\n",
    "        _, _, loss = train_model(\n",
    "            create_hyperparams(hyp, convert.(Float32, λ));\n",
    "            epochs_per_checkpoint = get_epochs_per_checkpoint(hyp.model),\n",
    "            patience = 0,\n",
    "        )\n",
    "        @info \"$λ $loss\"\n",
    "        loss\n",
    "    end\n",
    "    nlopt_optimize(nlopt_loss, sum(num_tuneable_params(hyp.model)); max_evals = max_evals)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "15f261fd-937d-4141-b0ee-a71c0d892045",
   "metadata": {},
   "outputs": [],
   "source": [
    "function optimize_learning_rate(hyp, max_iters)\n",
    "    # exponentially decay the learning rate whenever we hit a plateau    \n",
    "    learning_rate_decay = exp(-1)\n",
    "    hyp = @set hyp.learning_rate /= learning_rate_decay\n",
    "    m = nothing\n",
    "    validation_loss = Inf\n",
    "    epochs = 0\n",
    "    stopper = early_stopper(patience = 0, min_rel_improvement = 1e-4, max_iters = max_iters)\n",
    "    losses = []\n",
    "    verbose = max_iters == 1 ? \"info\" : false\n",
    "\n",
    "    while !stop!(stopper, validation_loss)\n",
    "        probe_hyp = @set hyp.learning_rate *= learning_rate_decay\n",
    "        probe_m, probe_epochs, validation_loss = train_model(\n",
    "            probe_hyp;\n",
    "            max_checkpoints = 1000,\n",
    "            epochs_per_checkpoint = 1,\n",
    "            patience = get_epochs_per_checkpoint(probe_hyp.model),\n",
    "            init_model = m,\n",
    "            verbose = verbose,\n",
    "        )\n",
    "        @info \"loss: $validation_loss learning_rate: $(probe_hyp.learning_rate)\"\n",
    "        push!(losses, validation_loss)\n",
    "        if validation_loss == minimum(losses)\n",
    "            m = probe_m\n",
    "            epochs = probe_epochs\n",
    "            hyp = probe_hyp\n",
    "        end\n",
    "    end\n",
    "\n",
    "    m, epochs, minimum(losses), hyp\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-rc1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbdd719b-7f8b-491e-bafa-8aa56a9545e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Write predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd4e73e-38df-4247-953b-bbac5958cd48",
   "metadata": {},
   "outputs": [],
   "source": [
    "function evaluate(hyp::Hyperparams, m, users::Vector{Int32}, items::Vector{Int32})\n",
    "    # returns a ratings dataset of predicted ratings    \n",
    "    if hyp.output_data == \"allitems\"\n",
    "        return  evaluate_allitems(hyp, m, users, items)\n",
    "    elseif hyp.output_data == \"item\"\n",
    "        return  evaluate_item(hyp, m, users, items)\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba77e952-88a0-4402-b2e8-f4c561356515",
   "metadata": {},
   "outputs": [],
   "source": [
    "function evaluate_item(hyp::Hyperparams, m, users::Vector{Int32}, items::Vector{Int32})\n",
    "    # get model inputs\n",
    "    global G = hyp\n",
    "    m = m |> device\n",
    "    epoch = (\n",
    "        get_epoch_inputs(\n",
    "            users,\n",
    "            items,\n",
    "            G.input_data,\n",
    "            G.output_data,\n",
    "            G.implicit,\n",
    "            G.num_users,\n",
    "            G.input_alphas,\n",
    "        ),\n",
    "        nothing,\n",
    "        nothing,\n",
    "        nothing,\n",
    "    )\n",
    "    activation = G.implicit ? sigmoid : identity\n",
    "    ratings = fill(NaN32, length(out_users))\n",
    "\n",
    "    # compute predictions    \n",
    "    @showprogress for iter = 1:Int(ceil(epoch_size(epoch) / G.batch_size))\n",
    "        batch, order = get_batch(epoch, iter, G.batch_size, false)\n",
    "        alpha = activation(m(batch[1][1])) |> cpu\n",
    "        ratings[order] .= vec(alpha)\n",
    "    end\n",
    "\n",
    "    global G = nothing\n",
    "    RatingsDataset(user = users, item = items, rating = ratings)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10731233-3a58-4b55-aa5d-26424fe031b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a vector that maps a user to the list of items to predict\n",
    "function user_to_items(users::Vector, items::Vector)\n",
    "        user_to_count = zeros(Int32, num_users(), Threads.nthreads())\n",
    "        @tprogress Threads.@threads for u in users\n",
    "            user_to_count[u, Threads.threadid()] += 1\n",
    "        end\n",
    "        user_to_count = convert.(Int32, vec(sum(user_to_count, dims = 2)))\n",
    "\n",
    "        utoa = Vector{Vector{Int32}}()\n",
    "        @showprogress for u = 1:num_users()\n",
    "            push!(utoa, Vector{Int32}(undef, user_to_count[u]))\n",
    "        end\n",
    "\n",
    "        @showprogress for i = 1:length(users)\n",
    "            u = users[i]\n",
    "            a = items[i]\n",
    "            utoa[u][user_to_count[u]] = a\n",
    "            user_to_count[u] -= 1\n",
    "        end\n",
    "        utoa\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8966e09b-8e58-490d-a08a-2bce141e8eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "function evaluate_allitems(hyp::Hyperparams, m, users::Vector{Int32}, items::Vector{Int32})\n",
    "    # get model inputs\n",
    "    global G = hyp\n",
    "    m = m |> device\n",
    "    utoa = user_to_items(users, items)\n",
    "    epoch = (\n",
    "        get_epoch_inputs(\n",
    "            users,\n",
    "            items,\n",
    "            G.input_data,\n",
    "            G.output_data,\n",
    "            G.implicit,\n",
    "            G.num_users,\n",
    "            G.input_alphas,\n",
    "        ),\n",
    "        nothing,\n",
    "        nothing,\n",
    "        nothing,\n",
    "    )\n",
    "    activation = G.implicit ? softmax : identity\n",
    "    out_users = Vector{Int32}(undef, length(users))\n",
    "    out_items = Vector{Int32}(undef, length(users))\n",
    "    out_ratings = fill(NaN32, length(out_users))\n",
    "    out_idx = 1\n",
    "\n",
    "    # compute predictions    \n",
    "    @showprogress for iter = 1:Int(ceil(epoch_size(epoch) / G.batch_size))\n",
    "        batch, sampled_users = get_batch(epoch, iter, G.batch_size, false)\n",
    "        alpha = activation(m(batch[1][1])) |> cpu\n",
    "        for j = 1:length(sampled_users)\n",
    "            u = sampled_users[j]\n",
    "            if length(utoa[u]) > 0\n",
    "                item_mask = utoa[u]\n",
    "                next_idx = out_idx + length(item_mask)\n",
    "                out_users[out_idx:next_idx-1] .= u\n",
    "                out_items[out_idx:next_idx-1] = item_mask\n",
    "                out_ratings[out_idx:next_idx-1] = alpha[item_mask, j]\n",
    "                out_idx = next_idx\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    global G = nothing\n",
    "    RatingsDataset(user = out_users, item = out_items, rating = out_ratings)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d999f4-f2b4-4d71-944b-754aead7de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "function write_alpha(hyp::Hyperparams, m, outdir::String)\n",
    "    hyp = @set hyp.num_users = num_users()\n",
    "    function model(users, items)\n",
    "        p = sparse(evaluate(hyp, m, users, items))\n",
    "        r = zeros(length(users))\n",
    "        @tprogress Threads.@threads for j = 1:length(r)\n",
    "            r[j] = p[items[j], users[j]]\n",
    "        end\n",
    "        r\n",
    "    end\n",
    "    write_alpha(model, hyp.residual_alphas, hyp.implicit, outdir; log_splits=hyp.content)\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-rc1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

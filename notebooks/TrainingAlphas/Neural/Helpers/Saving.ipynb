{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbdd719b-7f8b-491e-bafa-8aa56a9545e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Write predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10731233-3a58-4b55-aa5d-26424fe031b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a vector that maps a user to the list of items to predict\n",
    "function user_to_items(users::Vector, items::Vector, medium::String)\n",
    "    user_to_count = zeros(Int32, num_users(medium), Threads.nthreads())\n",
    "    @tprogress Threads.@threads for u in users\n",
    "        user_to_count[u, Threads.threadid()] += 1\n",
    "    end\n",
    "    user_to_count = convert.(Int32, vec(sum(user_to_count, dims = 2)))\n",
    "\n",
    "    utoa = Vector{Vector{Int32}}()\n",
    "    @showprogress for u = 1:num_users(medium)\n",
    "        push!(utoa, Vector{Int32}(undef, user_to_count[u]))\n",
    "    end\n",
    "\n",
    "    @showprogress for i = 1:length(users)\n",
    "        u = users[i]\n",
    "        a = items[i]\n",
    "        utoa[u][user_to_count[u]] = a\n",
    "        user_to_count[u] -= 1\n",
    "    end\n",
    "    utoa\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8966e09b-8e58-490d-a08a-2bce141e8eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "function evaluate(hyp::Hyperparams, m, users::Vector{Int32}, items::Vector{Int32})\n",
    "    # get model inputs\n",
    "    global G = hyp\n",
    "    CUDA.math_mode!(CUDA.FAST_MATH; precision = :TensorFloat32)\n",
    "    m = m |> device\n",
    "    utoa = user_to_items(users, items, hyp.medium)\n",
    "    epoch = (\n",
    "        get_epoch_inputs(\n",
    "            G.input_data,\n",
    "            G.task,\n",
    "            G.medium,\n",
    "            G.implicit,\n",
    "            G.num_users,\n",
    "            G.input_alphas,\n",
    "        ),\n",
    "        nothing,\n",
    "        nothing,\n",
    "        nothing,\n",
    "    )\n",
    "    activation = G.implicit ? softmax : identity\n",
    "    out_users = Vector{Int32}(undef, length(users))\n",
    "    out_items = Vector{Int32}(undef, length(users))\n",
    "    out_ratings = fill(NaN32, length(out_users))\n",
    "    out_idx = 1\n",
    "\n",
    "    # compute predictions\n",
    "    N = num_users(G.medium)\n",
    "    @showprogress for iter = 1:Int(ceil(N / G.batch_size))\n",
    "        batch, sampled_users = get_batch(epoch, iter, G.batch_size, 1:N, false)\n",
    "        alpha = activation(m(batch[1])) |> cpu\n",
    "        for j = 1:length(sampled_users)\n",
    "            u = sampled_users[j]\n",
    "            if length(utoa[u]) > 0\n",
    "                item_mask = utoa[u]\n",
    "                next_idx = out_idx + length(item_mask)\n",
    "                out_users[out_idx:next_idx-1] .= u\n",
    "                out_items[out_idx:next_idx-1] = item_mask\n",
    "                out_ratings[out_idx:next_idx-1] = alpha[item_mask, j]\n",
    "                out_idx = next_idx\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    global G = nothing\n",
    "    CUDA.math_mode!(CUDA.FAST_MATH; precision = :BFloat16)\n",
    "    RatingsDataset(\n",
    "        user = out_users,\n",
    "        item = out_items,\n",
    "        rating = out_ratings,\n",
    "        medium = hyp.medium,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d999f4-f2b4-4d71-944b-754aead7de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "function write_alpha(hyp::Hyperparams, m, outdir::String)\n",
    "    hyp = @set hyp.num_users = num_users(hyp.medium)\n",
    "    test_users = union(\n",
    "        [\n",
    "            Set(get_split(\"test\", hyp.task, x, hyp.medium; fields = [:user]).user) for\n",
    "            x in ALL_CONTENTS\n",
    "        ]...,\n",
    "    )\n",
    "    master_dfs = []\n",
    "    for split in ALL_SPLITS\n",
    "        @showprogress for content in ALL_CONTENTS\n",
    "            df =\n",
    "                get_raw_split(split, hyp.task, content, hyp.medium; fields = [:user, :item])\n",
    "            if split == \"training\"\n",
    "                df = filter(df, df.user .âˆˆ (test_users,))\n",
    "            end\n",
    "            push!(master_dfs, df)\n",
    "        end\n",
    "    end\n",
    "    master_df = reduce(cat, master_dfs)\n",
    "    p = sparse(evaluate(hyp, m, master_df.user, master_df.item))\n",
    "    function model(users, items)\n",
    "        r = zeros(length(users))\n",
    "        @tprogress Threads.@threads for j = 1:length(r)\n",
    "            r[j] = p[items[j], users[j]]\n",
    "        end\n",
    "        r\n",
    "    end\n",
    "    write_alpha(\n",
    "        model,\n",
    "        hyp.medium,\n",
    "        outdir;\n",
    "        task = hyp.task,\n",
    "        log = true,\n",
    "        log_task = hyp.task,\n",
    "        log_content = hyp.content,\n",
    "        log_alphas = hyp.residual_alphas,\n",
    "    )\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0-rc2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

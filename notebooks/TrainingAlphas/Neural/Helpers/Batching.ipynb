{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a52cbc-01d6-487c-8293-702ef156698a",
   "metadata": {},
   "source": [
    "## Batching\n",
    "* Turns an epoch into minibatches\n",
    "* Each user will appear in a minibatch with a probability proportional to its sampling weight\n",
    "* There is logic to predicting masked out items within a minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f26d8e-43bc-48d0-ad0f-ef3066e58b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import StatsBase: wsample, Weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "176a1df7-d57d-4b77-8bbf-d47838e31fc2",
   "metadata": {},
   "source": [
    "### Sample users to put in a minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0286844b-273e-47be-9683-e3b213189b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_sampling_order(epoch, split::String, rng)\n",
    "    if split == \"training\"\n",
    "        weights = powerdecay(\n",
    "            get_counts(split, \"all\", G.content, G.medium; per_rating = false),\n",
    "            weighting_scheme(G.user_sampling_scheme),\n",
    "        )\n",
    "        N = epoch_size(epoch)\n",
    "        return wsample(rng, 1:N, weights[1:N], N)        \n",
    "    else\n",
    "        return collect(\n",
    "            Set(filter_users(get_split(split, G.task, G.content, G.medium), G.num_users).user),\n",
    "        )\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea29632c-edd2-436c-a103-54182bcb21a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "slice(x::Nothing, range) = nothing\n",
    "slice(x::AbstractVector, range) = x[range]\n",
    "slice(x::AbstractMatrix, range) = x[:, range]\n",
    "slice(x::Tuple, range) = slice.(x, (range,));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3288d708-5e5a-48a2-9426-57f98713580c",
   "metadata": {},
   "source": [
    "### Mask out items within a minibatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7178e2f-0f72-4359-af2d-d8933060683d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# perform emphasized denoising on each minibatch\n",
    "\n",
    "function holdout(x, mask)\n",
    "    x .* repeat(mask, size(x)[1] รท size(mask)[1])\n",
    "end\n",
    "\n",
    "function holdout(x::Tuple, mask)\n",
    "    holdout.(x, (mask,))\n",
    "end\n",
    "\n",
    "function holdout_allitems(batch, training::Bool, rng)\n",
    "    if !training\n",
    "        return batch\n",
    "    end\n",
    "    randfn = CUDA.functional() ? CUDA.rand : x -> rand(rng, x)\n",
    "    batch_size = size(batch[4])[2]\n",
    "\n",
    "    # randomly drop holdout_perc percent of items from a user's list\n",
    "    if startswith(G.model, \"universal\")\n",
    "        @assert length(G.holdout) == length(ALL_MEDIUMS)\n",
    "        media_masks = [randfn(num_items(x), batch_size) .>= p for (x, p) in zip(ALL_MEDIUMS, G.holdout)]\n",
    "        entries_to_keep = reduce(vcat, media_masks)\n",
    "        entries_to_predict = 1 .- media_masks[findfirst(x -> x == G.medium, ALL_MEDIUMS)]        \n",
    "    elseif startswith(G.model, \"autoencoder\")\n",
    "        @assert length(G.holdout) == 1        \n",
    "        entries_to_keep = randfn(num_items(G.medium), batch_size) .>= G.holdout[1]\n",
    "        entries_to_predict = 1 .- entries_to_keep\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "\n",
    "    holdout(batch[1], entries_to_keep),\n",
    "    batch[2],\n",
    "    batch[3],\n",
    "    holdout(batch[4], entries_to_predict)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c453802-5b57-4acc-b76b-246ea459cfc2",
   "metadata": {},
   "source": [
    "### Construct a minibatch from an epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f35efa-decd-42ed-bcae-f7ea7cab6a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_batch(\n",
    "    epoch,\n",
    "    iter::Int,\n",
    "    batch_size::Int,\n",
    "    sampling_order,\n",
    "    training::Bool,\n",
    "    rng = Random.GLOBAL_RNG,\n",
    ")\n",
    "    range =\n",
    "        sampling_order[(iter-1)*batch_size+1:min(iter * batch_size, length(sampling_order))]\n",
    "    process(x) = slice(x, range) |> device\n",
    "    batch = holdout_allitems(process.(epoch), training, rng)\n",
    "    (batch[1], batch[2], batch[3], batch[4]), range\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0-rc2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

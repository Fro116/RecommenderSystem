{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "826b1aac-67d5-4dec-be8b-1e6c65b4d252",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Preprocessing\n",
    "* An epoch is an efficient representation of all the models inputs, outputs, residualization, and weights\n",
    "* We generate one epoch per split and memoize them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd0b9722-a6ec-488d-a44b-d384bd1d283c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import DelimitedFiles: readdlm\n",
    "import Statistics: mean, std;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2123501e-4d50-48f2-8ad1-1e9541fc0d25",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Building blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1c39d34-3212-4131-8e1d-68021044fc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function one_hot_inputs(implicit::Bool, num_users::Int)\n",
    "    convert.(Int32, collect(1:num_users))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "685714a9-2d8c-424f-a909-cbcf50218a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function explicit_inputs(task::String, medium::String, num_users::Int, residual_alphas::Vector{String})\n",
    "    df = get_split(\"training\", task, \"explicit\", medium)\n",
    "    df = RatingsDataset(\n",
    "        user = df.user,\n",
    "        item = df.item,\n",
    "        rating = df.rating .-\n",
    "                 read_alpha(residual_alphas, \"training\", task, \"explicit\", medium, false).rating,\n",
    "        medium = medium\n",
    "    )\n",
    "    sparse(filter_users(df, num_users))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83525d6-06d4-4b02-a9c3-147592a58e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "function explicit_validity_inputs(task::String, medium::String, num_users::Int)\n",
    "    df = get_split(\"training\", task, \"explicit\", medium)\n",
    "    df = RatingsDataset(user = df.user, item = df.item, rating = fill(1, length(df.rating)), medium = medium)\n",
    "    sparse(filter_users(df, num_users))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6065f98-4065-4d0d-9800-6fd711b3f855",
   "metadata": {},
   "outputs": [],
   "source": [
    "function implicit_inputs(task::String, medium::String, num_users::Int)\n",
    "    df = get_split(\"training\", task, \"implicit\", medium)\n",
    "    sparse(filter_users(df, num_users))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89954c90-398f-4fb6-9574-f3450d61a3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function explicit_implicit_inputs(\n",
    "    task::String,\n",
    "    medium::String,\n",
    "    num_users::Int,\n",
    "    residual_alphas::Vector{String},\n",
    ")\n",
    "    vcat(\n",
    "        explicit_inputs(task, medium, num_users, residual_alphas),\n",
    "        explicit_validity_inputs(task, medium, num_users),\n",
    "        implicit_inputs(task, medium, num_users),\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d68904f-5fe1-46a0-ae56-49fd87887402",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_timestamps(task::String, medium::String, num_users::Int)\n",
    "    df = get_split(\"training\", task, \"implicit\", medium; fields = [:user, :item, :timestamp])\n",
    "    filter_users(\n",
    "        RatingsDataset(user = df.user, item = df.item, rating = df.timestamp, medium=medium),\n",
    "        num_users,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b336f2f-16af-42e4-9ab2-aa59a09fa2ab",
   "metadata": {},
   "source": [
    "### Dispatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0cd51a-8bfe-498b-9185-c0ecaeb1a9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@memoize function get_epoch_inputs(\n",
    "    input_data::String,\n",
    "    task::String,\n",
    "    medium::String,\n",
    "    implicit::Bool,\n",
    "    num_users::Int,\n",
    "    input_alphas::Vector{String},\n",
    ")\n",
    "    if input_data == \"one_hot\"\n",
    "        return one_hot_inputs(implicit, num_users)\n",
    "    elseif input_data == \"implicit\"\n",
    "        return implicit_inputs(task, medium, num_users)\n",
    "    elseif input_data == \"explicit\"\n",
    "        return explicit_inputs(task, medium, num_users, input_alphas)\n",
    "    elseif input_data == \"explicit_implicit\"\n",
    "        return explicit_implicit_inputs(task, medium, num_users, input_alphas)\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "end;\n",
    "\n",
    "@memoize LRU{Any,Any}(maxsize = 2) function get_epoch_outputs(\n",
    "    split::String,\n",
    "    task::String,\n",
    "    content::String,\n",
    "    medium::String,                \n",
    "    implicit::Bool,\n",
    "    num_users::Int,\n",
    ")\n",
    "    sparse(filter_users(get_split(split, task, content, medium), num_users))\n",
    "end\n",
    "\n",
    "@memoize LRU{Any,Any}(maxsize = 2) function get_epoch_residuals(\n",
    "    split::String,\n",
    "    task::String,\n",
    "    content::String,                \n",
    "    medium::String,   \n",
    "    residual_alphas::Vector{String},\n",
    "    implicit::Bool,\n",
    "    num_users::Int,\n",
    ")        \n",
    "    sparse(filter_users(read_alpha(residual_alphas, split, task, content, medium, implicit), num_users))\n",
    "end\n",
    "\n",
    "@memoize LRU{Any,Any}(maxsize = 2) function get_epoch_weights(\n",
    "    split::String,\n",
    "    task::String,\n",
    "    content::String,\n",
    "    medium::String,        \n",
    "    user_weight_decay::Real,\n",
    "    item_weight_decay::Real,\n",
    "    temporal_weight_decay::Real,\n",
    "    num_users::Int,\n",
    ")\n",
    "    if split == \"training\"\n",
    "        weights =\n",
    "            powerdecay(get_counts(split, task, content, medium), user_weight_decay) .*\n",
    "            powerdecay(\n",
    "                get_counts(split, task, content, medium; by_item = true),\n",
    "                item_weight_decay,\n",
    "            ) .* powerlawdecay(\n",
    "                (\n",
    "                    1 .-\n",
    "                    max.(\n",
    "                        get_split(split, task, content, medium; fields = [:timestamp]).timestamp,\n",
    "                        0.0f0,\n",
    "                    )\n",
    "                ) ./ year_in_timestamp_units(medium),\n",
    "                temporal_weight_decay,\n",
    "            )\n",
    "    else\n",
    "        weights = powerdecay(get_counts(split, task, content, medium), weighting_scheme(\"inverse\"))\n",
    "    end\n",
    "\n",
    "    df = get_split(split, task, content, medium)\n",
    "    df = filter_users(\n",
    "        RatingsDataset(user = df.user, item = df.item, rating = weights, medium=medium),\n",
    "        num_users,\n",
    "    )\n",
    "    sparse(df)\n",
    "end\n",
    "\n",
    "@memoize LRU{Any,Any}(maxsize = 2) function get_epoch_timestamps(\n",
    "    split::String,\n",
    "    task::String,\n",
    "    content::String,\n",
    "    medium::String,        \n",
    "    num_users::Int,\n",
    ")\n",
    "    sparse(get_timestamps(task, medium, num_users))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "272ebd7c-a236-4a22-b0af-17759579f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns (X, Y, Z, W) = (inputs, outputs, residualization alpha, weights)\n",
    "function get_epoch(split::String)\n",
    "    if split == \"training\"\n",
    "        task = \"all\"\n",
    "    elseif split in [\"validation\", \"test\"]\n",
    "        task = G.task\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "    X = get_epoch_inputs(\n",
    "        G.input_data,        \n",
    "        task,\n",
    "        G.medium, # TODO cross-media alpha\n",
    "        G.implicit,\n",
    "        G.num_users,\n",
    "        G.input_alphas,\n",
    "    )\n",
    "    Y = get_epoch_outputs(split, task, G.content, G.medium, G.implicit, G.num_users)\n",
    "    Z = get_epoch_residuals(\n",
    "        split,\n",
    "        task,\n",
    "        G.content,\n",
    "        G.medium, \n",
    "        G.residual_alphas,\n",
    "        G.implicit,\n",
    "        G.num_users,\n",
    "    )\n",
    "    W = get_epoch_weights(\n",
    "        split,\n",
    "        task,\n",
    "        G.content,\n",
    "        G.medium,\n",
    "        G.user_weight_decay,\n",
    "        G.item_weight_decay,\n",
    "        G.temporal_weight_decay,\n",
    "        G.num_users,\n",
    "    )\n",
    "    (X, Y, Z, W)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c74b547-2a41-4ded-93c2-d1e54a646860",
   "metadata": {},
   "source": [
    "### Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b1a9c4-cf30-4352-994f-b904d5e08371",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch_size(epoch) = size(epoch[1])[end]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0-rc2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

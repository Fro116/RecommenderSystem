{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c030f566-08b7-46ad-9b69-182e559a9f89",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "* Contains all the information necessary to train a new model\n",
    "* A derivative free optimizer is used to find the best hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913177a8-b905-41a0-9a8c-922eca7c0593",
   "metadata": {},
   "outputs": [],
   "source": [
    "import NLopt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abba16e9-f406-49c4-8af1-6e0afde838c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@with_kw struct Hyperparams\n",
    "    # model\n",
    "    model::String\n",
    "    # data\n",
    "    content::String\n",
    "    implicit::Bool\n",
    "    input_data::String\n",
    "    input_alphas::Vector{String}\n",
    "    output_data::String\n",
    "    # batching\n",
    "    batch_size::Int\n",
    "    user_sampling_scheme::Float32\n",
    "    # optimizer\n",
    "    learning_rate::Float32\n",
    "    optimizer_weight_decay::Float32\n",
    "    optimizer::String\n",
    "    # training\n",
    "    seed::UInt64\n",
    "    num_users::Int\n",
    "    holdout::Float32\n",
    "    temporal_holdout::Float32\n",
    "    # loss\n",
    "    item_weight_decay::Float32\n",
    "    residual_alphas::Vector{String}\n",
    "    temporal_weight_decay::Float32\n",
    "    user_weight_decay::Float32\n",
    "end\n",
    "\n",
    "function to_dict(x::Hyperparams)\n",
    "    Dict(string(key) => getfield(x, key) for key ∈ fieldnames(Hyperparams))\n",
    "end\n",
    "\n",
    "function Base.string(x::Hyperparams)\n",
    "    fields = [x for x in fieldnames(Hyperparams)]\n",
    "    max_field_size = maximum(length(string(k)) for k in fields)\n",
    "    ret = \"Hyperparameters:\\n\"\n",
    "    for f in fields\n",
    "        ret *= \"$(rpad(string(f), max_field_size)) => $(getfield(x, f))\\n\"\n",
    "    end\n",
    "    ret\n",
    "end\n",
    "\n",
    "function Base.show(io::IO, x::Hyperparams)\n",
    "    print(io, string(x))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29581f57-6a67-4433-8818-53a972d24398",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_epochs_per_checkpoint(model::String)\n",
    "    if startswith(model, \"item_biases\") ||\n",
    "       startswith(model, \"autoencoder\") ||\n",
    "       startswith(model, \"double_embedding\") ||\n",
    "       startswith(model, \"metadata_embedding\")\n",
    "        return 10\n",
    "    elseif startswith(model, \"item_based_collaborative_filtering\") ||\n",
    "           startswith(model, \"ease\")\n",
    "        return 1\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d821968a-9c72-45ec-9fc9-c305c1d2ba2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_subsampling_factor(model::String)\n",
    "    if startswith(model, \"item_biases\")\n",
    "        return 0.01\n",
    "    elseif startswith(model, \"autoencoder\") ||\n",
    "           startswith(model, \"double_embedding\") ||\n",
    "           startswith(model, \"metadata_embedding\")\n",
    "        return 0.10\n",
    "    elseif startswith(model, \"item_based_collaborative_filtering\") ||\n",
    "           startswith(model, \"ease\")\n",
    "        return 0.25\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28cea999-8df9-4875-8287-89fdd2f944b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "function should_holdout_items(model::String)\n",
    "    if startswith(model, \"item_biases\") ||\n",
    "       startswith(model, \"item_based_collaborative_filtering\") ||\n",
    "       startswith(model, \"ease\")\n",
    "        return false\n",
    "    elseif startswith(model, \"autoencoder\") ||\n",
    "           startswith(model, \"double_embedding\") ||\n",
    "           startswith(model, \"metadata_embedding\")\n",
    "        return true\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "end\n",
    "\n",
    "function should_temporal_batch(model::String)\n",
    "    \"temporal\" in split(model, \".\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8114a09-50dc-445e-b01d-2a285fde1040",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_optimizer(\n",
    "    optimizer::String,\n",
    "    learning_rate::Float32,\n",
    "    optimizer_weight_decay::Float32,\n",
    ")\n",
    "    if optimizer == \"ADAMW\"\n",
    "        return ADAMW(learning_rate, (0.9, 0.999), optimizer_weight_decay)\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e8716c-42fc-44d5-900c-1bca867444c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "function num_tuneable_params(model::String)\n",
    "    num_model_params = 7\n",
    "    if should_holdout_items(model)\n",
    "        num_model_params += 1\n",
    "        if should_temporal_batch(model)\n",
    "            num_model_params += 1\n",
    "        end\n",
    "    end\n",
    "    num_model_params\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a76b373d-e84f-45b3-bae7-1fecb36bfde4",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_input_data_type(model::String, implicit::Bool)\n",
    "    if startswith(model, \"item_biases\")\n",
    "        return \"one_hot\"\n",
    "    elseif startswith(model, \"item_based_collaborative_filtering\")\n",
    "        return \"explicit\"\n",
    "    elseif startswith(model, \"ease\")\n",
    "        if implicit\n",
    "            return \"implicit\"\n",
    "        else\n",
    "            return \"explicit\"\n",
    "        end\n",
    "    elseif startswith(model, \"autoencoder\")\n",
    "        return \"explicit_implicit\"\n",
    "    elseif startswith(model, \"double_embedding\")\n",
    "        return \"explicit_implicit_tuple\"\n",
    "    elseif startswith(model, \"metadata_embedding\")\n",
    "        return \"impression_metadata\"\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f758d828-8076-48c7-abc6-ab00bc38e829",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_output_data_type(model::String)\n",
    "    if startswith(model, \"item_biases\") ||\n",
    "       startswith(model, \"item_based_collaborative_filtering\") ||\n",
    "       startswith(model, \"ease\") ||\n",
    "       startswith(model, \"autoencoder\") ||\n",
    "       startswith(model, \"metadata_embedding\")\n",
    "        return \"allitems\"\n",
    "    elseif startswith(model, \"double_embedding\")\n",
    "        return \"item\"\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadbdc6d-d986-4870-a4e6-6467ac3aea23",
   "metadata": {},
   "outputs": [],
   "source": [
    "function create_hyperparams(hyp::Hyperparams, λ::Vector{Float32})\n",
    "    # normalize λ such that a step size of 1 is reasonable\n",
    "    # and so that λ=1 is a more promising direction than λ=-1\n",
    "    index = 0\n",
    "    function incr()\n",
    "        index = index + 1\n",
    "    end\n",
    "    hyp = @set hyp.learning_rate = 10^(-λ[incr()] - 3)\n",
    "    hyp = @set hyp.temporal_weight_decay = log(0.5) / log(year_in_timestamp_units() * 3 * exp(-λ[incr()]))\n",
    "    if should_holdout_items(hyp.model)\n",
    "        hyp = @set hyp.holdout = sigmoid(-λ[incr()])\n",
    "        if should_temporal_batch(hyp.model)\n",
    "            hyp = @set hyp.temporal_holdout = max(1 - exp(λ[incr()]) * year_in_timestamp_units(), eps(Float32))\n",
    "        end\n",
    "    end\n",
    "    hyp = @set hyp.user_sampling_scheme = λ[incr()]    \n",
    "    hyp = @set hyp.user_weight_decay = λ[incr()] - 1\n",
    "    hyp = @set hyp.item_weight_decay = λ[incr()]\n",
    "    hyp = @set hyp.optimizer_weight_decay = 10^(λ[incr()] - 5)\n",
    "    hyp\n",
    "end\n",
    "\n",
    "function create_hyperparams(\n",
    "    model::String,\n",
    "    content::String,\n",
    "    residual_alphas::Vector{String},\n",
    "    input_alphas::Vector{String},\n",
    ")\n",
    "    if content == \"explicit\"\n",
    "        implicit = false\n",
    "    elseif content == \"implicit\"\n",
    "        implicit = true\n",
    "    elseif content == \"ptw\"\n",
    "        implicit = true\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "    hyp = Hyperparams(\n",
    "        # model\n",
    "        model = model,\n",
    "        # data\n",
    "        content = content,\n",
    "        implicit = implicit,\n",
    "        input_data = get_input_data_type(model, implicit),\n",
    "        input_alphas = input_alphas,\n",
    "        output_data = get_output_data_type(model),\n",
    "        # batching\n",
    "        batch_size = 1024,\n",
    "        user_sampling_scheme = NaN,\n",
    "        # optimizer\n",
    "        learning_rate = NaN,\n",
    "        optimizer_weight_decay = NaN,\n",
    "        optimizer = \"ADAMW\",\n",
    "        # training\n",
    "        seed = 20220524,\n",
    "        num_users = num_users(),\n",
    "        holdout = NaN,\n",
    "        temporal_holdout = NaN,\n",
    "        # loss\n",
    "        item_weight_decay = NaN,\n",
    "        residual_alphas = residual_alphas,\n",
    "        temporal_weight_decay = NaN,\n",
    "        user_weight_decay = NaN,\n",
    "    )\n",
    "    create_hyperparams(hyp, zeros(Float32, num_tuneable_params(model)))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "784a2c5a-5794-4e68-ba17-45f9c63abd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "function nlopt_optimize(\n",
    "    lossfn,\n",
    "    n::Int;\n",
    "    max_evals::Int = 100,\n",
    "    max_time::Int = 86400,\n",
    "    ftol_rel::Real = 1e-4,\n",
    "    xtol_rel::Real = 1e-4,\n",
    ")\n",
    "    opt = NLopt.Opt(:LN_NELDERMEAD, n)\n",
    "    opt.initial_step = 1\n",
    "    opt.maxeval = max_evals\n",
    "    opt.maxtime = max_time\n",
    "    opt.ftol_rel = ftol_rel\n",
    "    opt.xtol_rel = xtol_rel\n",
    "    opt.min_objective = lossfn\n",
    "    minf, λ, ret = NLopt.optimize(opt, zeros(Float32, n))\n",
    "    numevals = opt.numevals\n",
    "    @info (\n",
    "        \"found minimum $minf at point $λ after $numevals function calls \" *\n",
    "        \"(ended because $ret)\"\n",
    "    )\n",
    "    convert.(Float32, λ)\n",
    "end;\n",
    "\n",
    "function optimize_hyperparams(hyp::Hyperparams; max_evals::Int)\n",
    "    function nlopt_loss(λ, grad)\n",
    "        _, _, loss = train_model(\n",
    "            create_hyperparams(hyp, convert.(Float32, λ));\n",
    "            epochs_per_checkpoint = get_epochs_per_checkpoint(hyp.model),\n",
    "            patience = 0,\n",
    "        )\n",
    "        @info \"$λ $loss\"\n",
    "        loss\n",
    "    end\n",
    "    nlopt_optimize(nlopt_loss, num_tuneable_params(hyp.model); max_evals = max_evals)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f261fd-937d-4141-b0ee-a71c0d892045",
   "metadata": {},
   "outputs": [],
   "source": [
    "function optimize_learning_rate(hyp::Hyperparams, max_iters::Int)\n",
    "    # exponentially decay the learning rate whenever we hit a plateau    \n",
    "    learning_rate_decay = exp(-1)\n",
    "    hyp = @set hyp.learning_rate /= learning_rate_decay\n",
    "    m = nothing\n",
    "    validation_loss = Inf\n",
    "    epochs = 0\n",
    "    stopper = early_stopper(patience = 0, min_rel_improvement = 1e-3, max_iters = max_iters)\n",
    "    losses = []\n",
    "    verbose = \"info\"\n",
    "\n",
    "    while !stop!(stopper, validation_loss)\n",
    "        probe_hyp = @set hyp.learning_rate *= learning_rate_decay\n",
    "        probe_m, probe_epochs, validation_loss = train_model(\n",
    "            probe_hyp;\n",
    "            max_checkpoints = 1000,\n",
    "            epochs_per_checkpoint = 1,\n",
    "            patience = get_epochs_per_checkpoint(probe_hyp.model),\n",
    "            init_model = m,\n",
    "            verbose = verbose,\n",
    "        )\n",
    "        @info \"loss: $validation_loss learning_rate: $(probe_hyp.learning_rate)\"\n",
    "        push!(losses, validation_loss)\n",
    "        if validation_loss == minimum(losses)\n",
    "            m = probe_m\n",
    "            epochs = probe_epochs\n",
    "            hyp = probe_hyp\n",
    "        end\n",
    "    end\n",
    "\n",
    "    m, epochs, minimum(losses), hyp\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-rc1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

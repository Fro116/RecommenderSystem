{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e701df7-0d06-4631-a382-8228a4d3a845",
   "metadata": {},
   "source": [
    "# Pretraining\n",
    "* Trains a bag-of-words model on user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd56259-4513-4297-a978-99c765532231",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "medium = \"\"\n",
    "metric = \"\"\n",
    "mode = \"\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90afc10-1ae5-4665-937e-d58a5859ac94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"../Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d60ae-6b55-4274-85b1-c0f9c9fc7545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import H5Zblosc\n",
    "import HDF5\n",
    "import JSON\n",
    "import SparseArrays: AbstractSparseArray, sparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f353ca-c0d9-4178-8329-4d38d8d4bdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = \"v1\"\n",
    "basepath = \"$medium/BagOfWords/$version\"\n",
    "name = \"$basepath/$metric\"\n",
    "set_logging_outdir(name);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bf4e32-b0d0-4a05-8a87-bf0072d98f1b",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24bd2532-2491-4533-8d24-205f9522ea13",
   "metadata": {},
   "outputs": [],
   "source": [
    "@memoize function get_rating_beta(name)\n",
    "    params = read_params(name, false)\n",
    "    params[\"β\"]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa84fbe-12fd-4f67-aa24-4b5bbb71f4fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "function get_inputs(medium::String, metric::String, holdout::Bool)\n",
    "    @info \"loading $medium $metric inputs\"\n",
    "    if metric == \"rating\"\n",
    "        alpha = \"$medium/Baseline/rating\"\n",
    "        β = get_rating_beta(alpha)\n",
    "        df = get_split(\n",
    "            \"training\",\n",
    "            metric,\n",
    "            medium,\n",
    "            [:userid, :itemid, :metric, :update_order, :updated_at],\n",
    "            alpha,\n",
    "        )\n",
    "        df.metric .= df.metric - df.alpha .* β\n",
    "    else\n",
    "        df = get_split(\n",
    "            \"training\",\n",
    "            metric,\n",
    "            medium,\n",
    "            [:userid, :itemid, :metric, :update_order, :updated_at],\n",
    "        )\n",
    "    end\n",
    "    GC.gc()\n",
    "    if holdout\n",
    "        df, _ = training_test_split(df)\n",
    "    end\n",
    "    sparse(df, medium)\n",
    "end;\n",
    "\n",
    "function get_epoch_inputs_unmemoized(holdout)\n",
    "    inputs = [\n",
    "        get_inputs(medium, metric, holdout) for metric in [\"rating\", \"watch\"] for\n",
    "        medium in ALL_MEDIUMS\n",
    "    ]\n",
    "    @info \"loaded inputs\"\n",
    "    vcat(inputs...)\n",
    "end;\n",
    "\n",
    "function get_epoch_inputs(holdout)\n",
    "    fn = get_data_path(\"alphas/all/BagOfWords/$version/inputs.$holdout.h5\")\n",
    "    if !isfile(fn)\n",
    "        mkpath(dirname(fn))\n",
    "        X = get_epoch_inputs_unmemoized(holdout)\n",
    "        d = Dict{String,Any}()\n",
    "        record_sparse_array!(d, \"inputs\", X)\n",
    "        HDF5.h5open(fn, \"w\") do file\n",
    "            for (k, v) in d\n",
    "                file[k] = v\n",
    "            end\n",
    "        end\n",
    "        return X\n",
    "    else\n",
    "        d = Dict{String,Any}()\n",
    "        HDF5.h5open(fn, \"r\") do f\n",
    "            g(x) = read(f[x])\n",
    "            return sparse(g(\"inputs_i\"), g(\"inputs_j\"), g(\"inputs_v\"), g(\"inputs_size\")...)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function record_sparse_array!(d::Dict, name::String, x::AbstractSparseArray)\n",
    "    i, j, v = SparseArrays.findnz(x)\n",
    "    d[name*\"_i\"] = i\n",
    "    d[name*\"_j\"] = j\n",
    "    d[name*\"_v\"] = v\n",
    "    d[name*\"_size\"] = [size(x)[1], num_users()]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ecb20f-066b-489c-87eb-ef0db76eea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_epoch_labels(split, metric, medium)\n",
    "    @info \"loading labels $split\"\n",
    "    if split in [\"pretrain\", \"finetune\"]\n",
    "        tsplit = \"training\"\n",
    "    elseif split == \"test\"\n",
    "        tsplit = \"test\"\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "    if metric == \"rating\"\n",
    "        alpha = \"$medium/Baseline/rating\"\n",
    "        df = get_split(\n",
    "            tsplit,\n",
    "            metric,\n",
    "            medium,\n",
    "            [:userid, :itemid, :metric, :update_order, :updated_at],\n",
    "            alpha,\n",
    "        )\n",
    "        df.metric .= df.metric - df.alpha .* get_rating_beta(alpha)\n",
    "    else\n",
    "        df = get_split(\n",
    "            tsplit,\n",
    "            metric,\n",
    "            medium,\n",
    "            [:userid, :itemid, :metric, :update_order, :updated_at],\n",
    "        )\n",
    "    end\n",
    "    if split == \"pretrain\"\n",
    "        df, _ = training_test_split(df)\n",
    "    elseif split == \"finetune\"\n",
    "        _, df = training_test_split(df)\n",
    "    elseif split == \"test\"\n",
    "        nothing\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "    sparse(df, medium)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e7f153-ac14-42a0-a974-462f257a437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_epoch_weights(\n",
    "    split::String,\n",
    "    metric::String,\n",
    "    medium::String,\n",
    "    λ_wu::Real,\n",
    "    λ_wa::Real,\n",
    "    λ_wt::Real,\n",
    ")\n",
    "    @info \"loading weights $split\"\n",
    "    GC.gc()\n",
    "    if split == \"pretrain\"\n",
    "        df = get_split(\n",
    "            \"training\",\n",
    "            metric,\n",
    "            medium,\n",
    "            [:userid, :itemid, :update_order, :updated_at],\n",
    "        )\n",
    "        df, _ = training_test_split(df)\n",
    "        weights = df.updated_at\n",
    "        @showprogress for i = 1:length(weights)\n",
    "            weights[i] = λ_wt^((1 - df.updated_at[i]) / days_in_timestamp_units(365))\n",
    "        end\n",
    "        df = @set df.update_order = []\n",
    "        df = @set df.updated_at = []\n",
    "        for (c, λ) in zip([:userid, :itemid], [λ_wu, λ_wa])\n",
    "            w = get_counts(getfield(df, c))\n",
    "            @showprogress for i = 1:length(weights)\n",
    "                weights[i] *= powerdecay(w[i], λ)\n",
    "            end\n",
    "        end\n",
    "    elseif split == \"finetune\"\n",
    "        df = get_split(\n",
    "            \"training\",\n",
    "            metric,\n",
    "            medium,\n",
    "            [:userid, :itemid, :update_order, :updated_at],\n",
    "        )\n",
    "        _, df = training_test_split(df)\n",
    "        weights = powerdecay(get_counts(df.userid), -1.0f0)\n",
    "    elseif split == \"test\"\n",
    "        df = get_split(\n",
    "            \"test\",\n",
    "            metric,\n",
    "            medium,\n",
    "            [:userid, :itemid, :update_order, :updated_at],\n",
    "        )\n",
    "        weights = powerdecay(get_counts(df.userid), -1.0f0)\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "    df = @set df.metric = weights\n",
    "    GC.gc()\n",
    "    sparse(df, medium)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106fa056-8deb-486d-9854-6e0991bc4714",
   "metadata": {},
   "source": [
    "# Disk I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163716a3-03e3-4c9a-8073-1f697518d3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function create_training_config(medium, metric)\n",
    "    Dict(\n",
    "        # model\n",
    "        \"input_sizes\" => num_items.(ALL_MEDIUMS),\n",
    "        \"output_size_index\" => findfirst(x -> x == medium, ALL_MEDIUMS),\n",
    "        \"metric\" => metric,\n",
    "        # training\n",
    "        \"user_weight_decay\" => 0.0f0,\n",
    "        \"item_weight_decay\" => 0.0f0,\n",
    "        \"temporal_weight_decay\" => 0.5f0,\n",
    "        \"mask_rate\" => 0.25,\n",
    "        # data\n",
    "        \"num_shards\" => 8,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc31c5b2-42e2-455a-bd3f-0ca4eab8cb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function setup_split(config, outdir)\n",
    "    if !isdir(outdir)\n",
    "        mkpath(outdir)\n",
    "    end\n",
    "    for x in readdir(outdir, join = true)\n",
    "        if isfile(x)\n",
    "            rm(x)\n",
    "        end\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7abb52-f79b-4e89-8611-aa1506d2808e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function save_features(X, Y, W, epoch_size, users, valid_users, filename)\n",
    "    d = Dict{String,Any}()\n",
    "    data = [X, Y, W]\n",
    "    names = [\"inputs\", \"labels\", \"weights\"]\n",
    "    for i = 1:length(names)\n",
    "        record_sparse_array!(d, names[i], data[i])\n",
    "    end\n",
    "    d[\"epoch_size\"] = epoch_size\n",
    "    d[\"users\"] = users\n",
    "    d[\"valid_users\"] = valid_users\n",
    "    HDF5.h5open(filename, \"w\") do file\n",
    "        for (k, v) in d\n",
    "            file[k, blosc = 1] = v\n",
    "        end\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617c19b7-612d-464b-a830-519ad2c4924a",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafb1e1e-1056-4e65-b90c-bdc13e86169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function save_split(split, config)\n",
    "    @info \"loading $split data\"\n",
    "    outdir = get_data_path(joinpath(\"alphas\", name, split))\n",
    "    setup_split(config, outdir)\n",
    "    users = collect(0:num_users()-1)\n",
    "    chunks = collect(\n",
    "        Iterators.partition(1:num_users(), div(num_users(), config[\"num_shards\"], RoundUp)),\n",
    "    )\n",
    "    if split == \"inference\"\n",
    "        X = get_epoch_inputs(false)\n",
    "        GC.gc()\n",
    "        Y = sparse(RatingsDataset(), medium) # unused\n",
    "        W = sparse(RatingsDataset(), medium) # unused\n",
    "        valid_users = Set{Int32}()\n",
    "        for s in [\"test\", \"negative\"]\n",
    "            for m in ALL_METRICS\n",
    "                df = get_raw_split(s, medium, [:userid], nothing)\n",
    "                valid_users = union(valid_users, Set(df.userid))\n",
    "            end\n",
    "        end\n",
    "        valid_users = sort(collect(valid_users))\n",
    "        @showprogress for i = 1:length(chunks)\n",
    "            save_features(\n",
    "                X[:, chunks[i]],\n",
    "                Y[:, chunks[i]],\n",
    "                W[:, chunks[i]],\n",
    "                length(valid_users),\n",
    "                users[chunks[i]],\n",
    "                valid_users,\n",
    "                \"$outdir/data.$i.h5\",\n",
    "            )\n",
    "        end\n",
    "    elseif split in [\"pretrain\", \"finetune\", \"test\"]\n",
    "        X = get_epoch_inputs(split != \"test\")\n",
    "        GC.gc()\n",
    "        Y = get_epoch_labels(split, metric, medium)\n",
    "        W = get_epoch_weights(\n",
    "            split,\n",
    "            metric,\n",
    "            medium,\n",
    "            config[\"user_weight_decay\"],\n",
    "            config[\"item_weight_decay\"],\n",
    "            config[\"temporal_weight_decay\"],\n",
    "        )\n",
    "        valid_users = users[vec(sum(W, dims = 1) .> 0)]\n",
    "        epoch_size = length(valid_users)\n",
    "        config[\"epoch_size_$(split)\"] = epoch_size\n",
    "        @showprogress for i = 1:length(chunks)\n",
    "            save_features(\n",
    "                X[:, chunks[i]],\n",
    "                Y[:, chunks[i]],\n",
    "                W[:, chunks[i]],\n",
    "                epoch_size,\n",
    "                users[chunks[i]],\n",
    "                valid_users,\n",
    "                \"$outdir/data.$i.h5\",\n",
    "            )\n",
    "        end\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "    @info \"done $split data\"\n",
    "end\n",
    "\n",
    "function save_splits(mode)\n",
    "    config_fn = get_data_path(joinpath(\"alphas\", name, \"config.json\"))\n",
    "    if get_settings()[\"mode\"] == \"research\"\n",
    "        if mode == \"training_dataset\"\n",
    "            splits = [\"pretrain\"]\n",
    "            config = create_training_config(medium, metric)\n",
    "        elseif mode == \"test_dataset\"\n",
    "            splits = [\"finetune\", \"test\", \"inference\"]\n",
    "            config = JSON.parsefile(config_fn)\n",
    "        else\n",
    "            @assert false\n",
    "        end\n",
    "    else\n",
    "        @assert false # TODO\n",
    "    end\n",
    "    for split in splits\n",
    "        GC.gc()\n",
    "        save_split(split, config)\n",
    "    end\n",
    "    open(config_fn, \"w\") do f\n",
    "        write(f, JSON.json(config))\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae37d3b-b4ae-454f-bb26-2e525298bc78",
   "metadata": {},
   "outputs": [],
   "source": [
    "if mode != \"train\"\n",
    "    save_splits(mode)\n",
    "    exit()\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1b6a7dd-0296-4ba8-ae2c-50d63e1f288b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if get_settings()[\"mode\"] == \"research\"\n",
    "    modes = [\"pretrain\", \"finetune\", \"inference\"]\n",
    "else\n",
    "    @assert false\n",
    "end\n",
    "for mode in modes\n",
    "    run(`python3 Pytorch.py --outdir $name --mode $mode`)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2702ca-2ae2-4f2b-861f-87c2b5dd770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [\"pretrain\", \"finetune\", \"test\", \"inference\"]\n",
    "    outdir = get_data_path(joinpath(\"alphas\", name, split))\n",
    "    rm(outdir, recursive = true)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c813f1cb-db4a-444d-8c8f-1a002c99b00e",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da0f0c-0916-4940-a3ab-0dac67765604",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = HDF5.h5open(get_data_path(joinpath(\"alphas\", name, \"predictions.h5\")), \"r\")\n",
    "predictions = read(file[\"predictions\"])\n",
    "users = read(file[\"users\"])\n",
    "close(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f101c0-fb02-400b-a229-43fa3c989953",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_index = Dict()\n",
    "for i = 1:length(users)\n",
    "    user_to_index[users[i]] = i\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce859a7-8b65-437d-8b66-4446e19a21e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero out watched items\n",
    "if metric in [\"watch\", \"plantowatch\"]\n",
    "    df = get_raw_split(\"training\", medium, [:userid, :itemid], nothing)\n",
    "    users = Set(get_raw_split(\"test\", medium, [:userid, :itemid], nothing).userid)\n",
    "    df = filter(df, df.userid .∈ (users,))\n",
    "    df = @set df.metric = ones(Float32, length(df.userid))\n",
    "    seen = sparse(df, medium)\n",
    "    for (u, index) in user_to_index\n",
    "        predictions[seen[:, u+1].nzind, index] .= 0\n",
    "        predictions[:, index] ./= sum(predictions[:, index])\n",
    "    end\n",
    "else\n",
    "    seen = nothing\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a1f04d-2780-4967-a8f4-77f8fbd437c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function model(users, items, predictions, user_to_index)\n",
    "    p = zeros(Float32, length(users))\n",
    "    @showprogress for i = 1:length(p)\n",
    "        @assert users[i] in keys(user_to_index)\n",
    "        u = user_to_index[users[i]]\n",
    "        a = items[i] + 1\n",
    "        p[i] = predictions[a, u]\n",
    "    end\n",
    "    p\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3447cfa-d1a6-4c50-8aeb-8452053bc420",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_alpha(\n",
    "    (users, items) -> model(users, items, predictions, user_to_index),\n",
    "    medium,\n",
    "    name,\n",
    "    [\"test\", \"negative\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a072cc1-6dfe-4144-befc-82dd3a87576c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [\"test\"]\n",
    "    if metric == \"rating\"\n",
    "        alphas = [\"$medium/Baseline/rating\", name]\n",
    "    else\n",
    "        alphas = [name]\n",
    "    end\n",
    "    val = compute_loss(metric, medium, alphas, split)\n",
    "    @info \"$split loss = $val\"\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e701df7-0d06-4631-a382-8228a4d3a845",
   "metadata": {},
   "source": [
    "# Pretraining\n",
    "* Trains a bag-of-words model on user data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd56259-4513-4297-a978-99c765532231",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "task = \"\"\n",
    "content = \"\"\n",
    "medium = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f353ca-c0d9-4178-8329-4d38d8d4bdd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"$medium/$task/BagOfWords/$content/v1\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90afc10-1ae5-4665-937e-d58a5859ac94",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"../Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d60ae-6b55-4274-85b1-c0f9c9fc7545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import HDF5\n",
    "import JSON\n",
    "import SparseArrays: AbstractSparseArray, sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2bf4e32-b0d0-4a05-8a87-bf0072d98f1b",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fa84fbe-12fd-4f67-aa24-4b5bbb71f4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "function explicit_inputs(task::String, medium::String, residual_alphas::Vector{String})\n",
    "    df = get_split(\"training\", task, \"explicit\", medium; fields = [:user, :item, :rating])\n",
    "    df = RatingsDataset(\n",
    "        user = df.user,\n",
    "        item = df.item,\n",
    "        rating = df.rating .-\n",
    "                 read_alpha(\n",
    "            residual_alphas,\n",
    "            \"training\",\n",
    "            task,\n",
    "            \"explicit\",\n",
    "            medium,\n",
    "            false,\n",
    "        ).rating,\n",
    "        medium = medium,\n",
    "    )\n",
    "    sparse(df)\n",
    "end;\n",
    "\n",
    "function implicit_inputs(task::String, medium::String)\n",
    "    df = get_split(\"training\", task, \"implicit\", medium; fields = [:user, :item, :rating])\n",
    "    sparse(df)\n",
    "end;\n",
    "\n",
    "function get_epoch_inputs(task::String, residual_alphas::Vector{String})\n",
    "    @assert length(residual_alphas) == length(ALL_MEDIUMS)\n",
    "    inputs = []\n",
    "    for i = 1:length(ALL_MEDIUMS)\n",
    "        push!(inputs, explicit_inputs(task, ALL_MEDIUMS[i], residual_alphas[i:i]))\n",
    "    end\n",
    "    for x in ALL_MEDIUMS\n",
    "        push!(inputs, implicit_inputs(task, x))\n",
    "    end\n",
    "    reduce(vcat, inputs)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ecb20f-066b-489c-87eb-ef0db76eea1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_residualization_alphas(content)\n",
    "    if content == \"explicit\"\n",
    "        return [\"$medium/$task/ExplicitUserItemBiases\"]\n",
    "    else\n",
    "        return String[]\n",
    "    end\n",
    "end\n",
    "\n",
    "function get_epoch_labels(split, task, content, medium)\n",
    "    Y = sparse(get_split(split, task, content, medium; fields = [:user, :item, :rating]))\n",
    "    if content == \"explicit\"\n",
    "        Z = sparse(\n",
    "            read_alpha(\n",
    "                get_residualization_alphas(content),\n",
    "                split,\n",
    "                task,\n",
    "                content,\n",
    "                medium,\n",
    "                false,\n",
    "            ),\n",
    "        )\n",
    "        Y -= Z\n",
    "    end\n",
    "    Y\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e7f153-ac14-42a0-a974-462f257a437a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_epoch_weights(\n",
    "    split::String,\n",
    "    task::String,\n",
    "    content::String,\n",
    "    medium::String,\n",
    "    user_weight_decay::Real,\n",
    "    item_weight_decay::Real,\n",
    "    temporal_weight_decay::Real,\n",
    ")\n",
    "    if split == \"training\"\n",
    "        weights =\n",
    "            powerdecay(get_counts(split, task, content, medium), user_weight_decay) .*\n",
    "            powerdecay(\n",
    "                get_counts(split, task, content, medium; by_item = true),\n",
    "                item_weight_decay,\n",
    "            ) .* powerlawdecay(\n",
    "                (\n",
    "                    1 .-\n",
    "                    max.(\n",
    "                        get_split(\n",
    "                            split,\n",
    "                            task,\n",
    "                            content,\n",
    "                            medium;\n",
    "                            fields = [:timestamp],\n",
    "                        ).timestamp,\n",
    "                        0.0f0,\n",
    "                    )\n",
    "                ) ./ year_in_timestamp_units(),\n",
    "                temporal_weight_decay,\n",
    "            )\n",
    "    else\n",
    "        weights = powerdecay(\n",
    "            get_counts(split, task, content, medium),\n",
    "            weighting_scheme(\"inverse\"),\n",
    "        )\n",
    "    end\n",
    "    df = get_split(split, task, content, medium; fields = [:user, :item])\n",
    "    df = RatingsDataset(user = df.user, item = df.item, rating = weights, medium = medium)\n",
    "    sparse(df)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106fa056-8deb-486d-9854-6e0991bc4714",
   "metadata": {},
   "source": [
    "# Disk I/O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163716a3-03e3-4c9a-8073-1f697518d3b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function create_training_config(medium, content)\n",
    "    Dict(\n",
    "        # model\n",
    "        \"input_sizes\" => num_items.(ALL_MEDIUMS),\n",
    "        \"output_size_index\" => findfirst(x -> x == medium, ALL_MEDIUMS),\n",
    "        \"content\" => content,\n",
    "        # training\n",
    "        \"user_weight_decay\" => -0.26133174,\n",
    "        \"item_weight_decay\" => 0.2260387,\n",
    "        \"temporal_weight_decay\" => 0.67891073,\n",
    "        \"mask_rate\" => 0.25762135,\n",
    "        # data\n",
    "        \"num_shards\" => 8,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc31c5b2-42e2-455a-bd3f-0ca4eab8cb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function setup_training(config, outdir)\n",
    "    if !isdir(outdir)\n",
    "        mkpath(outdir)\n",
    "    end\n",
    "    for x in readdir(outdir, join = true)\n",
    "        if isfile(x)\n",
    "            rm(x)\n",
    "        end\n",
    "    end\n",
    "    fn = joinpath(outdir, \"..\", \"config.json\")\n",
    "    open(fn * \"~\", \"w\") do f\n",
    "        write(f, JSON.json(config))\n",
    "    end\n",
    "    mv(fn * \"~\", fn, force = true)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7abb52-f79b-4e89-8611-aa1506d2808e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function save_features(X, Y, W, users, epoch_size, filename)\n",
    "    d = Dict{String,Any}()\n",
    "    data = [X, Y, W]\n",
    "    names = [\"inputs\", \"labels\", \"weights\"]\n",
    "    for i = 1:length(names)\n",
    "        record_sparse_array!(d, names[i], data[i])\n",
    "    end\n",
    "    d[\"users\"] = users\n",
    "    d[\"epoch_size\"] = epoch_size\n",
    "    counts = sum(W, dims = 1)\n",
    "    d[\"valid_users\"] = [x for x in 1:length(counts) if counts[x] > 0]\n",
    "    HDF5.h5open(filename, \"w\") do file\n",
    "        for (k, v) in d\n",
    "            write(file, k, v)\n",
    "        end\n",
    "    end\n",
    "end\n",
    "\n",
    "function record_sparse_array!(d::Dict, name::String, x::AbstractSparseArray)\n",
    "    i, j, v = SparseArrays.findnz(x)\n",
    "    d[name*\"_i\"] = i\n",
    "    d[name*\"_j\"] = j\n",
    "    d[name*\"_v\"] = v\n",
    "    d[name*\"_size\"] = [size(x)[1], size(x)[2]]\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "617c19b7-612d-464b-a830-519ad2c4924a",
   "metadata": {},
   "source": [
    "# Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9829ee8-6649-4386-a8cf-f927b23ee742",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = create_training_config(medium, content);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafb1e1e-1056-4e65-b90c-bdc13e86169d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function save_split(split)\n",
    "    @info \"loading $split data\"\n",
    "    outdir = get_data_path(joinpath(\"alphas\", name, split))\n",
    "    setup_training(config, outdir)\n",
    "    X = get_epoch_inputs(task, [\"$x/$task/ExplicitUserItemBiases\" for x in ALL_MEDIUMS])\n",
    "    if split == \"inference\"\n",
    "        Y = get_epoch_labels(\"test\", task, content, medium)\n",
    "        W = 0\n",
    "        for content in [\"implicit\", \"negative\"]\n",
    "            W =\n",
    "                get_epoch_weights(\n",
    "                    \"test\",\n",
    "                    task,\n",
    "                    content,\n",
    "                    medium,\n",
    "                    config[\"user_weight_decay\"],\n",
    "                    config[\"item_weight_decay\"],\n",
    "                    config[\"temporal_weight_decay\"],\n",
    "                ) .+ W\n",
    "        end\n",
    "        num_shards = 1\n",
    "    else\n",
    "        Y = get_epoch_labels(split, task, content, medium)\n",
    "        W = get_epoch_weights(\n",
    "            split,\n",
    "            task,\n",
    "            content,\n",
    "            medium,\n",
    "            config[\"user_weight_decay\"],\n",
    "            config[\"item_weight_decay\"],\n",
    "            config[\"temporal_weight_decay\"],\n",
    "        )\n",
    "        num_shards = config[\"num_shards\"]\n",
    "    end\n",
    "    splits =\n",
    "        collect(Iterators.partition(1:num_users(), div(num_users(), num_shards, RoundUp)))\n",
    "    for i = 1:length(splits)\n",
    "        save_features(\n",
    "            X[:, splits[i]],\n",
    "            Y[:, splits[i]],\n",
    "            W[:, splits[i]],\n",
    "            collect(splits[i]),\n",
    "            sum(sum(W, dims = 1) .> 0),\n",
    "            \"$outdir/data.$i.h5\",\n",
    "        )\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c866d658-8234-43df-8aa6-d7b66bebaa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_split.([\"training\", \"validation\", \"test\", \"inference\"]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9c24d4-6c69-4dfd-b8c5-2769fc0096d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "GC.gc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9753a51a-b134-45bb-8c7e-38adf38d0d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in [\"pretrain\", \"finetune\", \"inference\"]\n",
    "    run(`python3 Pytorch.py --outdir $name --mode $mode`)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2702ca-2ae2-4f2b-861f-87c2b5dd770c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for split in [\"training\", \"validation\", \"test\"]\n",
    "    outdir = get_data_path(joinpath(\"alphas\", name, split))\n",
    "    rm(outdir, recursive = true)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c813f1cb-db4a-444d-8c8f-1a002c99b00e",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7da0f0c-0916-4940-a3ab-0dac67765604",
   "metadata": {},
   "outputs": [],
   "source": [
    "file = HDF5.h5open(get_data_path(joinpath(\"alphas\", name, \"predictions.h5\")), \"r\")\n",
    "predictions = read(file[\"predictions\"])\n",
    "users = read(file[\"users\"])\n",
    "close(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38f101c0-fb02-400b-a229-43fa3c989953",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_to_index = Dict()\n",
    "for i = 1:length(users)\n",
    "    user_to_index[users[i]] = i\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a1f04d-2780-4967-a8f4-77f8fbd437c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that we only record predictions for test users\n",
    "function model(users, items, predictions, user_to_index)\n",
    "    ratings = zeros(Float32, length(users))\n",
    "    @showprogress for i = 1:length(ratings)\n",
    "        u = user_to_index[users[i]]\n",
    "        ratings[i] = predictions[items[i], u]\n",
    "    end\n",
    "    ratings\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df1db55a-b537-4bfe-8524-54f628717654",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_alpha(\n",
    "    (users, items) -> model(users, items, predictions, user_to_index),\n",
    "    medium,\n",
    "    name,\n",
    "    splits = [\"test\"];\n",
    "    task = task,\n",
    "    log = true,\n",
    "    log_task = task,\n",
    "    log_content = content,\n",
    "    log_alphas = get_residualization_alphas(content),\n",
    "    log_splits = [\"test\"],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

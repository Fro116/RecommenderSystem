{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8dda73-d6ce-4e69-b769-d6cd305bec8d",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "function get_wordtype_index(field::Symbol)\n",
    "    fields = [\n",
    "        :itemid,\n",
    "        :rating,\n",
    "        :updated_at,\n",
    "        :status,\n",
    "        :source,\n",
    "        :created_at,\n",
    "        :started_at,\n",
    "        :finished_at,\n",
    "        :progress,\n",
    "        :repeat_count,\n",
    "        :priority,\n",
    "        :sentiment,\n",
    "        :sentiment_score,\n",
    "        :position,\n",
    "        :userid,\n",
    "    ]\n",
    "    findfirst(x -> x == field, fields)\n",
    "end\n",
    "\n",
    "const wordtype = Tuple{\n",
    "    Int32, # itemid\n",
    "    Float32, # rating\n",
    "    Float32, # updated_at\n",
    "    Int32, # status\n",
    "    Int32, # source\n",
    "    Float32, # created_at\n",
    "    Float32, # started_at\n",
    "    Float32, # finished_at\n",
    "    Float32, # progress\n",
    "    Float32, # 1 - 1 / (repeat_count + 1)\n",
    "    Float32, # 1 - 1 / (priority + 1)\n",
    "    Int32, # sentiment\n",
    "    Float32, # sentiment_score\n",
    "    Int32, # position\n",
    "    Int32, # userid\n",
    "}\n",
    "\n",
    "extract(word, field::Symbol) = word[get_wordtype_index(field)]\n",
    "\n",
    "function replace(word, fieldname::Symbol, field)\n",
    "    pos = get_wordtype_index(fieldname)\n",
    "    (word[1:pos-1]..., field, word[pos+1:end]...)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc04890-ae17-45b0-a8be-d375ec198d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_training_data(cls_tokens, partition, users_to_finetune)\n",
    "    function get_df(medium, partition, users_to_finetune)\n",
    "        fields = [\n",
    "            :itemid,\n",
    "            :rating,\n",
    "            :updated_at,\n",
    "            :status,\n",
    "            :source,\n",
    "            :created_at,\n",
    "            :started_at,\n",
    "            :finished_at,\n",
    "            :progress,\n",
    "            :repeat_count,\n",
    "            :priority,\n",
    "            :sentiment,\n",
    "            :sentiment_score,\n",
    "            :userid,\n",
    "            :medium,\n",
    "            :update_order,\n",
    "        ]\n",
    "        df = get_raw_split(\"training\", medium, fields, nothing)\n",
    "        if !isnothing(partition)\n",
    "            df = filter(df, df.userid .% partition[2] .== partition[1])\n",
    "        end\n",
    "        if !isnothing(users_to_finetune)\n",
    "            df = filter(df, df.userid .∈ (Set(users_to_finetune),))\n",
    "            df = training_test_split(df, 1)[1]\n",
    "        end\n",
    "        itemid_offset::Int32 = 0\n",
    "        for j = 1:findfirst(x -> x == medium, ALL_MEDIUMS)-1\n",
    "            itemid_offset += num_items(ALL_MEDIUMS[j])\n",
    "        end\n",
    "        df.itemid .+= itemid_offset\n",
    "        df\n",
    "    end\n",
    "    @info \"loading training splits\"\n",
    "    dfs = [get_df(medium, partition, users_to_finetune) for medium in ALL_MEDIUMS]\n",
    "    GC.gc()\n",
    "\n",
    "    @info \"processing training splits\"\n",
    "    chunks = 128\n",
    "    sentences = Vector{Dict{Int32,Vector{wordtype}}}(undef, chunks)\n",
    "    function save_sentence(t)\n",
    "        df = reduce(cat, [filter(x, @. (x.userid % chunks) + 1 == t) for x in dfs])\n",
    "        sentences[t] = get_training_data(df, cls_tokens)\n",
    "    end\n",
    "    tforeach(save_sentence, 1:chunks, 4)\n",
    "    merge(sentences...)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad4ffdb-0bb7-409a-a6cd-478560e9466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_training_data(df::RatingsDataset, cls_tokens)\n",
    "    sentences = Dict{Int32,Vector{wordtype}}()\n",
    "    # need to sort by updated_at because we're combining multiple_media\n",
    "    order = sortperm(collect(zip(df.updated_at, -df.update_order)))\n",
    "    for idx = 1:length(order)\n",
    "        i = order[idx]\n",
    "        if df.userid[i] ∉ keys(sentences)\n",
    "            sentences[df.userid[i]] = [replace(cls_tokens, :userid, df.userid[i])]\n",
    "        end\n",
    "        word = convert(\n",
    "            wordtype,\n",
    "            (\n",
    "                df.itemid[i],\n",
    "                df.rating[i],\n",
    "                df.updated_at[i],\n",
    "                df.status[i],\n",
    "                df.source[i],\n",
    "                df.created_at[i],\n",
    "                df.started_at[i],\n",
    "                df.finished_at[i],\n",
    "                df.progress[i],\n",
    "                Float32(1 - 1 / (df.repeat_count[i] + 1)),\n",
    "                Float32(1 - 1 / (df.priority[i] + 1)),\n",
    "                df.sentiment[i],\n",
    "                df.sentiment_score[i],\n",
    "                length(sentences[df.userid[i]]) - 1,\n",
    "                df.userid[i],\n",
    "            ),\n",
    "        )\n",
    "        push!(sentences[df.userid[i]], word)\n",
    "    end\n",
    "    sentences\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764fd3fd-6b56-4a4b-af5f-d2ec2f089177",
   "metadata": {},
   "outputs": [],
   "source": [
    "function subset_sentence(sentence, max_seq_length; recent)\n",
    "    if length(sentence) <= max_seq_length\n",
    "        return sentence\n",
    "    end\n",
    "    if recent\n",
    "        # keep the rightmost entries\n",
    "        idx = length(sentence) - max_seq_length + 1\n",
    "    else\n",
    "        # take a random contiguous subset            \n",
    "        idx = rand(1:length(sentence)-max_seq_length+1)\n",
    "    end\n",
    "    sentence[idx:idx+max_seq_length-1]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7c91cf-9187-46e6-a925-bb743d9ad8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_token_ids(sentence, max_seq_length, pad_tokens, cls_tokens)\n",
    "    outputs = fill.(pad_tokens, max_seq_length)\n",
    "    @assert length(sentence) <= max_seq_length\n",
    "    function process(word, i)\n",
    "        # update the position for sentences that are longer than max_seq_len\n",
    "        if i == get_wordtype_index(:position) &&\n",
    "           extract(word, :itemid) != extract(cls_tokens, :itemid)\n",
    "            return (word[i] % max_seq_length)\n",
    "        else\n",
    "            return word[i]\n",
    "        end\n",
    "    end\n",
    "    for i = 1:length(sentence)\n",
    "        for j = 1:length(outputs)\n",
    "            outputs[j][i] = process(sentence[i], j)\n",
    "        end\n",
    "    end\n",
    "    outputs\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

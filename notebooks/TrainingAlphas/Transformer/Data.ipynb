{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8dda73-d6ce-4e69-b769-d6cd305bec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# itemid, rating, updated_at, status, position, userid\n",
    "const wordtype = Tuple{Int32,Float32,Float32,Int32,Int32,Int32}\n",
    "\n",
    "function get_wordtype_index(field::Symbol)\n",
    "    if field == :itemid\n",
    "        return 1\n",
    "    elseif field == :rating\n",
    "        return 2\n",
    "    elseif field == :updated_at\n",
    "        return 3\n",
    "    elseif field == :status\n",
    "        return 4\n",
    "    elseif field == :position\n",
    "        return 5\n",
    "    elseif field == :userid\n",
    "        return 6\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "end\n",
    "\n",
    "extract(word, field::Symbol) = word[get_wordtype_index(field)]\n",
    "\n",
    "function replace(word, fieldname::Symbol, field)\n",
    "    pos = get_wordtype_index(fieldname)\n",
    "    (word[1:pos-1]..., field, word[pos+1:end]...)\n",
    "end\n",
    "\n",
    "function encode_word(itemid, rating, updated_at, status, position, userid)\n",
    "    word = (itemid, rating, updated_at, status, position, userid)\n",
    "    convert(wordtype, word)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc04890-ae17-45b0-a8be-d375ec198d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_training_data(cls_tokens, userids = nothing)\n",
    "    function get_df(medium, userids)\n",
    "        df = get_raw_split(\n",
    "            \"training\",\n",
    "            medium,\n",
    "            [:medium, :userid, :itemid, :status, :rating, :update_order, :updated_at],\n",
    "            nothing,\n",
    "        )\n",
    "        if !isnothing(userids)\n",
    "            df = filter(df, df.userid .∈ (Set(userids),))\n",
    "        end\n",
    "        @assert ALL_MEDIUMS == [\"manga\", \"anime\"]\n",
    "        @tprogress Threads.@threads for i = 1:length(df.userid)\n",
    "            for j = 1:df.medium[i]\n",
    "                df.itemid[i] += num_items(ALL_MEDIUMS[j])\n",
    "            end\n",
    "        end\n",
    "        df\n",
    "    end\n",
    "    @info \"loading training splits\"\n",
    "    dfs = [get_df(medium, userids) for medium in ALL_MEDIUMS]\n",
    "\n",
    "    @info \"processing training splits\"\n",
    "    chunks = 128\n",
    "    sentences = Vector{Dict{Int32,Vector{wordtype}}}(undef, chunks)\n",
    "    function save_sentence(t)\n",
    "        df = reduce(cat, [filter(x, @. (x.userid % chunks) + 1 == t) for x in dfs])\n",
    "        sentences[t] = get_training_data(df, cls_tokens)\n",
    "    end\n",
    "    tforeach(save_sentence, 1:chunks, 8)\n",
    "    merge(sentences...)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad4ffdb-0bb7-409a-a6cd-478560e9466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_training_data(df::RatingsDataset, cls_tokens)\n",
    "    sentences = Dict{Int32,Vector{wordtype}}()\n",
    "    order = sortperm(collect(zip(df.updated_at, df.update_order)))\n",
    "    for idx = 1:length(order)\n",
    "        i = order[idx]\n",
    "        if df.userid[i] ∉ keys(sentences)\n",
    "            sentences[df.userid[i]] = [replace(cls_tokens, :userid, df.userid[i])]\n",
    "        end\n",
    "        word = encode_word(\n",
    "            df.itemid[i],\n",
    "            df.rating[i],\n",
    "            df.updated_at[i],\n",
    "            df.status[i],\n",
    "            length(sentences[df.userid[i]]) - 1,\n",
    "            df.userid[i],\n",
    "        )\n",
    "        push!(sentences[df.userid[i]], word)\n",
    "    end\n",
    "    sentences\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764fd3fd-6b56-4a4b-af5f-d2ec2f089177",
   "metadata": {},
   "outputs": [],
   "source": [
    "function subset_sentence(sentence, max_seq_length; recent)\n",
    "    if length(sentence) <= max_seq_length\n",
    "        return sentence\n",
    "    end\n",
    "    if recent\n",
    "        # keep the rightmost entries\n",
    "        idx = length(sentence) - max_seq_length + 1\n",
    "    else\n",
    "        # take a random contiguous subset            \n",
    "        idx = rand(1:length(sentence)-max_seq_length+1)\n",
    "    end\n",
    "    sentence[idx:idx+max_seq_length-1]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f7c91cf-9187-46e6-a925-bb743d9ad8e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_token_ids(sentence, max_seq_length, pad_tokens, cls_tokens)\n",
    "    outputs = fill.(pad_tokens, max_seq_length)\n",
    "    @assert length(sentence) <= max_seq_length\n",
    "    function process(word, i)\n",
    "        # update the position for sentences that are longer than max_seq_len\n",
    "        if i == get_wordtype_index(:position) &&\n",
    "           extract(word, :itemid) != extract(cls_tokens, :itemid)\n",
    "            return (word[i] % max_seq_length)\n",
    "        else\n",
    "            return word[i]\n",
    "        end\n",
    "    end\n",
    "    for i = 1:length(sentence)\n",
    "        for j = 1:length(outputs)\n",
    "            outputs[j][i] = process(sentence[i], j)\n",
    "        end\n",
    "    end\n",
    "    outputs\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.4",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

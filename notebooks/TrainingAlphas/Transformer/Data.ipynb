{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8dda73-d6ce-4e69-b769-d6cd305bec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# animeid, mangaid, rating, timestamp, status, completion, user, position\n",
    "const wordtype = Tuple{Int32,Int32,Float32,Float32,Int32,Float32,Int32,Int32}\n",
    "\n",
    "function get_wordtype_index(field::Symbol)\n",
    "    if field == :anime\n",
    "        return 1\n",
    "    elseif field == :manga\n",
    "        return 2       \n",
    "    elseif field == :rating\n",
    "        return 3\n",
    "    elseif field == :timestamp\n",
    "        return 4\n",
    "    elseif field == :status\n",
    "        return 5\n",
    "    elseif field == :completion\n",
    "        return 6\n",
    "    elseif field == :user\n",
    "        return 7\n",
    "    elseif field == :position\n",
    "        return 8\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "end\n",
    "\n",
    "extract(word, field::Symbol) = word[get_wordtype_index(field)]\n",
    "\n",
    "function replace(word, fieldname::Symbol, field)\n",
    "    pos = get_wordtype_index(fieldname)\n",
    "    (word[1:pos-1]..., field, word[pos+1:end]...)\n",
    "end\n",
    "\n",
    "function encode_word(\n",
    "    animeid,\n",
    "    mangaid,\n",
    "    rating,\n",
    "    timestamp,\n",
    "    status,\n",
    "    completion,\n",
    "    user,\n",
    "    position,\n",
    ")\n",
    "    word =\n",
    "        (animeid, mangaid, rating, timestamp, status, completion, user, position)\n",
    "    convert(wordtype, word)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ad4ffdb-0bb7-409a-a6cd-478560e9466e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_training_data(df::RatingsDataset, media, cls_tokens, empty_tokens)\n",
    "    function itemids(df, i)\n",
    "        if media[df.source[i]] == \"manga\"\n",
    "            return (extract(empty_tokens, :anime), df.item[i])\n",
    "        elseif media[df.source[i]] == \"anime\"\n",
    "            return (df.item[i], extract(empty_tokens, :manga))\n",
    "        else\n",
    "            @assert false\n",
    "        end\n",
    "    end    \n",
    "    \n",
    "    sentences = Dict{Int32,Vector{wordtype}}()\n",
    "    order = sortperm(df.timestamp)\n",
    "    for idx = 1:length(order)\n",
    "        i = order[idx]\n",
    "        if df.user[i] âˆ‰ keys(sentences)\n",
    "            sentences[df.user[i]] = [replace(cls_tokens, :user, df.user[i])]\n",
    "        end\n",
    "        word = encode_word(\n",
    "            itemids(df, i)...,\n",
    "            df.rating[i],\n",
    "            df.timestamp[i],\n",
    "            df.status[i],\n",
    "            df.completion[i],\n",
    "            df.user[i],\n",
    "            length(sentences[df.user[i]]),\n",
    "        )\n",
    "        push!(sentences[df.user[i]], word)\n",
    "    end\n",
    "    sentences\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc04890-ae17-45b0-a8be-d375ec198d69",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_training_data(\n",
    "    task,\n",
    "    media,\n",
    "    include_ptw,\n",
    "    cls_tokens,\n",
    "    empty_tokens;\n",
    "    explicit_baseline = nothing,\n",
    ")\n",
    "    function get_df(task, content, medium, baseline)\n",
    "        df = get_raw_split(\"training\", task, content, medium)\n",
    "        if content == \"explicit\"\n",
    "            if !isnothing(baseline)\n",
    "                Threads.@threads for i = 1:length(df.rating)\n",
    "                    df.rating[i] -=\n",
    "                        baseline[medium][\"u\"][df.user[i]] +\n",
    "                        baseline[medium][\"a\"][df.item[i]]\n",
    "                end\n",
    "            end\n",
    "        else\n",
    "            df.rating .= 11\n",
    "        end\n",
    "        df.source .= findfirst(x -> x == df.medium, media)\n",
    "        Threads.@threads for i = 1:length(df.timestamp)\n",
    "            df.timestamp[i] = universal_timestamp(df.timestamp[i], df.medium)\n",
    "        end\n",
    "        @set df.medium = \"\"\n",
    "    end\n",
    "    contents = [\"explicit\", \"implicit\"]\n",
    "    if include_ptw\n",
    "        push!(contents, \"ptw\")\n",
    "    end\n",
    "    @info \"loading training splits for $task\"\n",
    "    dfs = [\n",
    "            get_df(task, content, medium, explicit_baseline) for content in contents for\n",
    "            medium in media\n",
    "    ]\n",
    "\n",
    "    @info \"processing training splits for $task\"\n",
    "    chunks = 128\n",
    "    sentences = [Dict{Int32,Vector{wordtype}}() for _ in 1:chunks]\n",
    "    @tprogress Threads.@threads for t = 1:chunks\n",
    "        df = reduce(\n",
    "            cat,\n",
    "            [\n",
    "                 filter(x, @. (x.user % chunks) + 1 == t) for x in dfs\n",
    "            ]\n",
    "        )        \n",
    "        partition = get_training_data(\n",
    "            df,\n",
    "            media,\n",
    "            cls_tokens,\n",
    "            empty_tokens,\n",
    "        )\n",
    "        for (k, v) in partition\n",
    "            sentences[t][k] = v\n",
    "        end\n",
    "    end\n",
    "    merge(sentences...)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764fd3fd-6b56-4a4b-af5f-d2ec2f089177",
   "metadata": {},
   "outputs": [],
   "source": [
    "function subset_sentence(sentence, max_seq_length; recent, keep_first, rng)\n",
    "    if keep_first\n",
    "        # the first token is usually a cls_token that embeds user metadata\n",
    "        cls_token = sentence[1]\n",
    "        sentence = sentence[2:end]\n",
    "        max_seq_length -= 1\n",
    "    end\n",
    "    if length(sentence) > max_seq_length\n",
    "        if recent\n",
    "            # keep the rightmost entries\n",
    "            idx = length(sentence) - max_seq_length + 1\n",
    "        else\n",
    "            # take a random contiguous subset            \n",
    "            idx = rand(rng, 1:length(sentence)-max_seq_length+1)\n",
    "        end\n",
    "        sentence = sentence[idx:idx+max_seq_length-1]\n",
    "    end\n",
    "    if keep_first\n",
    "        pushfirst!(sentence, cls_token)\n",
    "    end    \n",
    "    sentence\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dda2a7-8e5b-4519-b0e9-246cb358f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function pad_sentence(sentence, max_seq_length, max_position, pad_tokens, cls_tokens)\n",
    "    outputs = fill.(pad_tokens, max_seq_length)\n",
    "    @assert length(sentence) <= max_seq_length \"$(length(sentence)) $max_seq_length\"\n",
    "    for i = 1:length(sentence)\n",
    "        for j = 1:length(outputs)\n",
    "            if j == get_wordtype_index(:position) && extract(sentence[i], :anime) != extract(cls_tokens, :anime)\n",
    "                p = (sentence[i][j] % max_position)\n",
    "                if p == 0\n",
    "                    p = max_position\n",
    "                end\n",
    "                outputs[j][i] = p\n",
    "            else\n",
    "                outputs[j][i] = sentence[i][j]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    outputs\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd56c38b-d848-416f-a028-364b4dc1a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_token_ids(sentences, max_seq_length, max_position, pad_tokens, cls_tokens)\n",
    "    padded_sentences = [\n",
    "        pad_sentence(x, max_seq_length, max_position, pad_tokens, cls_tokens) for x in sentences\n",
    "    ]\n",
    "    Tuple(hcat([x[i] for x in padded_sentences]...) for i = 1:length(pad_tokens))\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0-rc2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

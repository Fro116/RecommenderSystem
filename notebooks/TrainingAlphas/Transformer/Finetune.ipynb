{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dda7f55-4c2c-40ff-be28-c6a19829f6a0",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "source_medium = \"anime\"\n",
    "medium = \"manga\"\n",
    "task = \"temporal\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07463b45-3148-4a5a-b119-ed43d468d8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"$medium/$task/$source_medium/Transformer/\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0ab492d-c494-4117-bed2-bb7fa7e7d8d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import DataStructures: DefaultDict\n",
    "import Flux\n",
    "import Flux: cpu, gpu, LayerNorm, logsoftmax\n",
    "import NBInclude: @nbinclude\n",
    "import Random\n",
    "import SparseArrays: AbstractSparseArray, sparse\n",
    "import StatsBase: mean, sample\n",
    "@nbinclude(\"../Alpha.ipynb\")\n",
    "@nbinclude(\"Reference/CUDA.ipynb\")\n",
    "@nbinclude(\"Reference/Include.ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94ba6cc6-c7a5-49a6-83c8-208f318eba5e",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b2ecba6-e4c4-4d4f-a8c6-4a9847e7bb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kwdef struct Trainer\n",
    "    task::Any\n",
    "    # data\n",
    "    sentences::Any\n",
    "    labels::Any\n",
    "    weights::Any\n",
    "    timestamps::Any\n",
    "    source_explicit_baseline::Any\n",
    "    target_explicit_baseline::Any\n",
    "    # model\n",
    "    model::Any\n",
    "    max_seq_len::Any\n",
    "    vocab_sizes::Any\n",
    "    mask_tokens::Any\n",
    "    pad_tokens::Any\n",
    "    cls_tokens::Any\n",
    "    # training\n",
    "    minibatch_size::Any\n",
    "    batch_size::Any\n",
    "    opt::Any\n",
    "    rng::Any\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b753540-f3ec-4fda-af5d-9aaeb7d8a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_labels(task, content, pretrain, num_items)\n",
    "    if pretrain\n",
    "        df = get_split(\"training\", \"all\", content, medium)\n",
    "    else\n",
    "        df = cat(\n",
    "            get_split(\"validation\", task, content, medium),\n",
    "            get_split(\"test\", task, content, medium),\n",
    "        )\n",
    "    end\n",
    "    sparse(df.item, df.user, df.rating, num_items, num_users(medium))\n",
    "end\n",
    "\n",
    "get_labels(task, pretrain, num_items) = get_labels(task, \"implicit\", pretrain, num_items),\n",
    "get_labels(task, \"explicit\", pretrain, num_items);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fafc960-525a-421e-93d8-d92885061ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_weights(task, content, pretrain, num_items)\n",
    "    if pretrain\n",
    "        df = get_split(\"training\", \"all\", content, medium)\n",
    "        w = powerdecay(\n",
    "            get_counts(\"training\", \"all\", content, medium),\n",
    "            weighting_scheme(\"inverse\"),\n",
    "        )\n",
    "    else\n",
    "        df = cat(\n",
    "            get_split(\"validation\", task, content, medium),\n",
    "            get_split(\"test\", task, content, medium),\n",
    "        )\n",
    "        w = vcat(\n",
    "            powerdecay(\n",
    "                get_counts(\"validation\", task, content, medium),\n",
    "                weighting_scheme(\"inverse\"),\n",
    "            ),\n",
    "            powerdecay(\n",
    "                get_counts(\"test\", task, content, medium),\n",
    "                weighting_scheme(\"inverse\"),\n",
    "            ),\n",
    "        )\n",
    "    end\n",
    "    sparse(df.item, df.user, w, num_items, num_users(medium))\n",
    "end\n",
    "\n",
    "get_weights(task, pretrain, num_items) = get_weights(task, \"implicit\", pretrain, num_items),\n",
    "get_weights(task, \"explicit\", pretrain, num_items);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71cf0317-682d-49f8-8cc1-fb73bee068ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_timestamps(task, content, pretrain, num_items)\n",
    "    if pretrain\n",
    "        df = get_split(\"training\", \"all\", content, medium)\n",
    "    else\n",
    "        df = cat(\n",
    "            get_split(\"validation\", task, content, medium),\n",
    "            get_split(\"test\", task, content, medium),\n",
    "        )\n",
    "    end\n",
    "    sparse(df.item, df.user, df.timestamp, num_items, num_users(medium))\n",
    "end\n",
    "\n",
    "get_timestamps(task, pretrain, num_items) =\n",
    "    get_timestamps(task, \"implicit\", pretrain, num_items);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2eeb2a-806a-4cbf-9c2e-8bbe5c17124b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_users(rng, task, pretrain, content)\n",
    "    if pretrain\n",
    "        users = collect(Set(get_split(\"training\", \"all\", content, medium).user))\n",
    "        training_frac = 0.99\n",
    "        training = [x for x in users if x < training_frac * num_users(medium)]\n",
    "        test = [x for x in users if x >= training_frac * num_users(medium)]\n",
    "    else\n",
    "        training = collect(Set(get_split(\"validation\", task, content, medium).user))\n",
    "        test = collect(Set(get_split(\"test\", task, content, medium).user))\n",
    "    end\n",
    "    training, test\n",
    "end\n",
    "\n",
    "get_users(rng, task, pretrain) = get_users(rng, task, pretrain, \"implicit\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "307e849d-5097-4c20-8bd7-f8d8792995de",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_sentence(sentences, x, cls_tokens, explicit_baseline)\n",
    "    try\n",
    "        return copy(sentences[x])\n",
    "    catch KeyError\n",
    "        tokens = replace(cls_tokens, :user, x)\n",
    "        tokens = replace(tokens, :status, explicit_baseline[\"task\"])\n",
    "        tokens = replace(tokens, :rating, explicit_baseline[\"user_biases\"][x])\n",
    "        return [tokens]\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fa01f7-57c6-47c4-bea1-b8702ea700ad",
   "metadata": {},
   "source": [
    "# Batching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12aa0de7-d44b-4374-ace9-028e59b26f4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_batch(;\n",
    "    users,\n",
    "    training,\n",
    "    task,\n",
    "    sentences,\n",
    "    labels,\n",
    "    weights,\n",
    "    timestamps,\n",
    "    max_seq_len,\n",
    "    vocab_sizes,\n",
    "    mask_tokens,\n",
    "    pad_tokens,\n",
    "    cls_tokens,\n",
    "    explicit_baseline,\n",
    "    rng,\n",
    ")\n",
    "    sentences = [get_sentence(sentences, x, cls_tokens, explicit_baseline) for x in users]\n",
    "    processed_sentences = eltype(values(sentences))[]\n",
    "    batch_positions = Tuple{Int32,Int32}[]\n",
    "    output_labels = map(x -> x[:, users], labels)\n",
    "    output_weights = map(x -> x[:, users], weights)\n",
    "\n",
    "    for i::Int32 = 1:length(sentences)\n",
    "        s = sentences[i]\n",
    "        if task == \"random\"\n",
    "            s = subset_sentence(\n",
    "                s,\n",
    "                max_seq_len - 1;\n",
    "                recent = false,\n",
    "                keep_first = true,\n",
    "                rng = rng,\n",
    "            )\n",
    "            masked_word = mask_tokens\n",
    "        elseif task in [\"temporal\"]\n",
    "            s = subset_sentence(\n",
    "                s,\n",
    "                max_seq_len - 1;\n",
    "                recent = true,\n",
    "                keep_first = true,\n",
    "                rng = rng,\n",
    "            )\n",
    "            masked_word = replace(mask_tokens, :timestamp, 1)\n",
    "        elseif task in [\"temporal_causal\"]\n",
    "            s = subset_sentence(\n",
    "                s,\n",
    "                max_seq_len - 1;\n",
    "                recent = true,\n",
    "                keep_first = true,\n",
    "                rng = rng,\n",
    "            )\n",
    "            masked_word = replace(mask_tokens, :timestamp, 1)\n",
    "            masked_word = replace(masked_word, :position, length(s))\n",
    "        else\n",
    "            @assert false\n",
    "        end\n",
    "        push!(s, masked_word)\n",
    "        push!(batch_positions, (Int32(length(s)), i))\n",
    "        push!(processed_sentences, s)\n",
    "    end\n",
    "\n",
    "    inputs =\n",
    "        get_inputs(processed_sentences, max_seq_len, vocab_sizes, pad_tokens, cls_tokens)\n",
    "    (inputs..., output_labels, output_weights, batch_positions)\n",
    "end\n",
    "\n",
    "get_batch(users, training::Bool, t::Trainer) = get_batch(\n",
    "    users = users,\n",
    "    training = training,\n",
    "    task = t.task,\n",
    "    sentences = t.sentences,\n",
    "    labels = t.labels,\n",
    "    weights = t.weights,\n",
    "    timestamps = t.timestamps,\n",
    "    max_seq_len = t.max_seq_len,\n",
    "    vocab_sizes = t.vocab_sizes,\n",
    "    mask_tokens = t.mask_tokens,\n",
    "    pad_tokens = t.pad_tokens,\n",
    "    cls_tokens = t.cls_tokens,\n",
    "    explicit_baseline = t.source_explicit_baseline,\n",
    "    rng = t.rng,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0f3c260-0e44-418e-9577-95c55d5ce566",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_inputs(sentences, max_seq_len, vocab_sizes, pad_tokens, cls_tokens)\n",
    "    # dynamically pad to the largest sequence length\n",
    "    seq_len = min(maximum(length.(sentences)), max_seq_len)\n",
    "\n",
    "    # get tokenized sentences\n",
    "    tokens = get_token_ids(\n",
    "        sentences,\n",
    "        seq_len,\n",
    "        extract(vocab_sizes, :position),\n",
    "        pad_tokens,\n",
    "        cls_tokens,\n",
    "    )\n",
    "\n",
    "    # don't attend to padding tokens\n",
    "    attention_mask = reshape(\n",
    "        convert.(Float32, extract(tokens, :item) .!= extract(pad_tokens, :item)),\n",
    "        (1, seq_len, length(sentences)),\n",
    "    )\n",
    "    attention_mask = attention_mask .* permutedims(attention_mask, (2, 1, 3))\n",
    "\n",
    "    tokens, attention_mask\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b370ea21-04af-456f-b3e0-351be33c861e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device(x) = gpu(x)\n",
    "device(x::AbstractSparseArray) = CUDA.functional() ? CUDA.CuArray(gpu(x)) : collect(x)\n",
    "function device(x::Tuple)\n",
    "    (\n",
    "        device(x[1][1]),\n",
    "        device(x[1][2]),\n",
    "        device(x[1][3]),\n",
    "        device(x[1][4]),\n",
    "        device(x[1][5]),\n",
    "        nothing,\n",
    "        device(x[1][7]),\n",
    "    ),\n",
    "    device(x[2]),\n",
    "    device.(x[3]),\n",
    "    device.(x[4]),\n",
    "    device(x[5])\n",
    "end\n",
    "\n",
    "CUDA.unsafe_free!(::Nothing) = nothing\n",
    "\n",
    "function device_free!(x)\n",
    "    if !CUDA.functional()\n",
    "        return\n",
    "    end\n",
    "    CUDA.unsafe_free!.(x[1])\n",
    "    CUDA.unsafe_free!(x[2])\n",
    "    CUDA.unsafe_free!.(x[3])\n",
    "    CUDA.unsafe_free!.(x[4])\n",
    "    CUDA.unsafe_free!(x[5])\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7e3cac-dc1c-465a-bdf0-f5d10307e61d",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adcb70cb-968b-41fa-b049-9bf3a24480ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "function output_embedding(model, batch)\n",
    "    tokens, attention_mask, _, _, batch_positions = batch\n",
    "    X = model.embed(\n",
    "        item = extract(tokens, :item),\n",
    "        rating = extract(tokens, :rating),\n",
    "        timestamp = extract(tokens, :timestamp),\n",
    "        status = extract(tokens, :status),\n",
    "        completion = extract(tokens, :completion),\n",
    "        position = extract(tokens, :position),\n",
    "    )\n",
    "    X = model.transformers(X, attention_mask)\n",
    "    X = gather(X, batch_positions)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20554889-80a5-4a09-bc5e-f13b9d713e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function lm_preds(model, batch)\n",
    "    X = output_embedding(model, batch)\n",
    "    item_preds =\n",
    "        transpose(model.classifier.item.decoder) * model.classifier.item.transform(X) .+\n",
    "        model.classifier.item.output_bias.b\n",
    "    rating_preds = model.classifier.rating.transform(X)\n",
    "    item_preds, rating_preds\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc2a10f-bcc9-41c1-9a7d-5a20d6056383",
   "metadata": {},
   "outputs": [],
   "source": [
    "function lm_losses(model, batch)\n",
    "    item_preds, rating_preds = lm_preds(model, batch)\n",
    "    labels = batch[3]\n",
    "    weights = batch[4]\n",
    "\n",
    "    if sum(weights[1]) > 0\n",
    "        item_loss =\n",
    "            -sum(labels[1] .* weights[1] .* logsoftmax(item_preds)) / sum(weights[1])\n",
    "    else\n",
    "        item_loss = 0.0f0\n",
    "    end\n",
    "    if sum(weights[2]) > 0\n",
    "        rating_loss = sum((rating_preds - labels[2]) .^ 2 .* weights[2]) / sum(weights[2])\n",
    "    else\n",
    "        rating_loss = 0.0f0\n",
    "    end\n",
    "\n",
    "    item_loss, rating_loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cea0e5c-2d02-4b74-8636-653b806fe9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function evaluate_losses(users, t::Trainer)\n",
    "#     losses = zeros(2)\n",
    "#     loss_weights = zeros(2)\n",
    "#     user_batches = collect(Iterators.partition(users, t.batch_size))\n",
    "#     @showprogress for user_batch in user_batches\n",
    "#         batch = get_batch(user_batch, false, t) |> device\n",
    "#         weights = sum.(batch[4])\n",
    "#         loss_weights .+= weights\n",
    "#         losses .+= lm_losses(t.model, batch) .* weights\n",
    "#         batch |> device_free!\n",
    "#     end\n",
    "#     losses = losses ./ loss_weights\n",
    "#     Dict(\"Item Crossentropy Loss\" => losses[1], \"Rating MSE Loss\" => losses[2])\n",
    "# end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7543ac0-ead9-424e-ae79-eb66f34cfef4",
   "metadata": {},
   "outputs": [],
   "source": [
    "function lm_correlation_losses(model, batch)\n",
    "    item_preds, rating_preds = lm_preds(model, batch)\n",
    "    labels = batch[3]\n",
    "    weights = batch[4]\n",
    "    if sum(weights[1]) > 0\n",
    "        item_loss = -sum(labels[1] .* weights[1] .* logsoftmax(item_preds))\n",
    "    else\n",
    "        item_loss = 0.0f0\n",
    "    end\n",
    "    if sum(weights[2]) > 0\n",
    "        r1_loss = sum((rating_preds - labels[2]) .^ 2 .* weights[2])\n",
    "        r0_loss = sum((0 .* rating_preds - labels[2]) .^ 2 .* weights[2])\n",
    "        r_n1_loss = sum((-1 .* rating_preds - labels[2]) .^ 2 .* weights[2])\n",
    "    else\n",
    "        r1_loss = 0.0f0\n",
    "        r0_loss = 0.0f0\n",
    "        r_n1_loss = 0.0f0\n",
    "    end\n",
    "    item_loss, r1_loss, r0_loss, r_n1_loss\n",
    "end;\n",
    "\n",
    "function evaluate_losses(users, t::Trainer)\n",
    "    losses = zeros(4)\n",
    "    loss_weights = zeros(2)\n",
    "    user_batches = collect(Iterators.partition(users, t.batch_size))\n",
    "    @showprogress for user_batch in user_batches\n",
    "        batch = get_batch(user_batch, false, t) |> device\n",
    "        weights = sum.(batch[4])\n",
    "        loss_weights .+= weights\n",
    "        losses .+= lm_correlation_losses(t.model, batch)\n",
    "        batch |> device_free!\n",
    "    end\n",
    "    i_loss = losses[1] / loss_weights[1]\n",
    "    # get the correlation loss by finding the minimum of the rating loss quadratic    \n",
    "    r1_loss = losses[2] / loss_weights[2]\n",
    "    r0_loss = losses[3] / loss_weights[2]\n",
    "    r_n1_loss = losses[4] / loss_weights[2]\n",
    "    a = (r1_loss + r_n1_loss) / 2 - r0_loss\n",
    "    b = (r1_loss - r_n1_loss) / 2\n",
    "    c = r0_loss\n",
    "    r_loss = c - b^2 / (4 * a)\n",
    "    Dict(\n",
    "        \"Item Crossentropy Loss\" => i_loss,\n",
    "        \"Correlation MSE Loss\" => r_loss,\n",
    "        \"Rating MSE Loss\" => r1_loss,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27317bbc-7e8c-4a81-9c54-34a4ccffd603",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc47f8f3-2380-4d7c-a83e-38ea1867cee1",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_epoch!(users, t::Trainer)\n",
    "    users = Random.shuffle(t.rng, users)\n",
    "    user_batches = collect(Iterators.partition(users, t.batch_size))\n",
    "    losses = []\n",
    "    @showprogress for user_batch in user_batches\n",
    "        minibatches = collect(Iterators.partition(user_batch, t.minibatch_size))\n",
    "        total_grads = nothing\n",
    "        for minibatch in minibatches\n",
    "            batch = get_batch(minibatch, true, t) |> device\n",
    "            loss, grads = Flux.withgradient(t.model) do m\n",
    "                sum(lm_losses(m, batch))\n",
    "            end\n",
    "            total_grads = tuplesum(total_grads, grads[1])\n",
    "            push!(losses, loss)\n",
    "            batch |> device_free!\n",
    "        end\n",
    "        total_grads = tupledivide(total_grads, length(minibatches))\n",
    "        Flux.update!(t.opt, t.model, total_grads)\n",
    "    end\n",
    "    mean(losses)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b22acc9f-a168-4afe-ad5a-a6be2f9dbe45",
   "metadata": {},
   "outputs": [],
   "source": [
    "function checkpoint(\n",
    "    users,\n",
    "    t::Trainer,\n",
    "    training_loss,\n",
    "    epoch,\n",
    "    source_checkpoint,\n",
    "    target_checkpoint,\n",
    "    name,\n",
    ")\n",
    "    @info \"evaluating metrics\"\n",
    "    metrics = evaluate_losses(users, t)\n",
    "    metrics[\"training_loss\"] = training_loss\n",
    "    write_params(\n",
    "        Dict(\n",
    "            \"m\" => t.model |> cpu,\n",
    "            \"epoch\" => epoch,\n",
    "            \"metrics\" => metrics,\n",
    "            \"source_checkpoint\" => source_checkpoint,\n",
    "            \"target_checkpoint\" => target_checkpoint,\n",
    "        ),\n",
    "        \"$name/checkpoints/$epoch\",\n",
    "    )\n",
    "    @info \"saving model after $epoch epochs with metrics $metrics\"\n",
    "    metrics\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e32d86b2-9354-4297-bcfa-b7e75f08c137",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fefbbcc-3c00-42bf-8a1c-352e06dc9881",
   "metadata": {},
   "outputs": [],
   "source": [
    "function create_cross_media_model(source_checkpoint, target_checkpoint)\n",
    "    m = read_params(source_checkpoint)[\"m\"]\n",
    "    n = read_params(target_checkpoint)[\"m\"]\n",
    "    item_cls = (\n",
    "        transform = n.classifier.item.transform,\n",
    "        output_bias = n.classifier.item.output_bias,\n",
    "        decoder = n.embed.embeddings.item.embedding,\n",
    "    )\n",
    "    rating_cls = n.classifier.rating\n",
    "    clf = (item = item_cls, rating = rating_cls)\n",
    "    TransformerModel(m.embed, m.transformers, clf)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93c853ae-56bb-4de2-9653-000555115925",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_explicit_baseline(medium)\n",
    "    explicit_baseline = read_params(\"$medium/$task/ExplicitUserItemBiases\")\n",
    "    explicit_baseline[\"user_biases\"] = DefaultDict(\n",
    "        mean(explicit_baseline[\"u\"]),\n",
    "        Dict(keys(explicit_baseline[\"u\"]) .=> explicit_baseline[\"u\"]),\n",
    "    )\n",
    "    explicit_baseline[\"item_biases\"] = DefaultDict(\n",
    "        mean(explicit_baseline[\"a\"]),\n",
    "        Dict(keys(explicit_baseline[\"a\"]) .=> explicit_baseline[\"a\"]),\n",
    "    )\n",
    "    explicit_baseline[\"task\"] = findfirst(x -> x == task, ALL_TASKS)\n",
    "    explicit_baseline\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "757625cc-b732-4687-89e8-6f287c462a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "function load_input_data(t::Trainer, source_checkpoint)\n",
    "    config = read_params(source_checkpoint)[\"training_config\"]\n",
    "    use_ptw = config[\"include_ptw_impressions\"]\n",
    "    sentences = reduce(\n",
    "        merge,\n",
    "        [\n",
    "            get_training_data(task, source_medium, use_ptw, config[\"cls_tokens\"]) for\n",
    "            task in ALL_TASKS\n",
    "        ],\n",
    "    )\n",
    "    t = @set t.sentences = sentences\n",
    "    GC.gc()\n",
    "\n",
    "    # demean inputs\n",
    "    @tprogress Threads.@threads for u in collect(keys(t.sentences))\n",
    "        for i = 1:length(t.sentences[u])\n",
    "            tokens = t.sentences[u][i]\n",
    "            has_explicit_rating =\n",
    "                (extract(tokens, :rating) .< extract(t.vocab_sizes, :rating))\n",
    "            if has_explicit_rating\n",
    "                blp =\n",
    "                    t.source_explicit_baseline[\"user_biases\"][u] +\n",
    "                    t.source_explicit_baseline[\"item_biases\"][extract(tokens, :item)]\n",
    "                demeaned_rating = extract(tokens, :rating) - blp\n",
    "                t.sentences[u][i] = replace(tokens, :rating, demeaned_rating)\n",
    "            end\n",
    "            if extract(tokens, :item) == extract(t.cls_tokens, :item)\n",
    "                tokens = replace(tokens, :status, t.source_explicit_baseline[\"task\"])\n",
    "                tokens =\n",
    "                    replace(tokens, :rating, t.source_explicit_baseline[\"user_biases\"][u])\n",
    "                t.sentences[u][i] = tokens\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    t\n",
    "end\n",
    "\n",
    "function load_output_data(t::Trainer, source_checkpoint, pretrain)\n",
    "    N = size(t.model.classifier.item.decoder)[2]\n",
    "    t = @set t.labels = get_labels(t.task, pretrain, N)\n",
    "    t = @set t.weights = get_weights(t.task, pretrain, N)\n",
    "    t = @set t.timestamps = get_timestamps(t.task, pretrain, N)\n",
    "\n",
    "    # demean outputs\n",
    "    @tprogress Threads.@threads for (a, u, _) in\n",
    "                                    collect(zip(SparseArrays.findnz(t.labels[2])...))\n",
    "        t.labels[2][a, u] -=\n",
    "            t.target_explicit_baseline[\"user_biases\"][u] +\n",
    "            t.target_explicit_baseline[\"item_biases\"][a]\n",
    "    end\n",
    "    training, validation = get_users(t.rng, t.task, pretrain)\n",
    "    t, training, validation\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20a0ac00-9e5d-491c-b5a0-f15a340ff23f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function load_pretrained_model(source_checkpoint, target_checkpoint, task)\n",
    "    model = create_cross_media_model(source_checkpoint, target_checkpoint) |> gpu\n",
    "    source_params = read_params(source_checkpoint)\n",
    "    config = source_params[\"training_config\"]\n",
    "    t = Trainer(\n",
    "        # finetuning domain\n",
    "        task = task,\n",
    "        # data\n",
    "        sentences = nothing, #sentences,\n",
    "        labels = nothing, #labels,\n",
    "        weights = nothing, #weights,\n",
    "        timestamps = nothing, #timestamps,\n",
    "        source_explicit_baseline = get_explicit_baseline(source_medium),\n",
    "        target_explicit_baseline = get_explicit_baseline(medium),\n",
    "        # model\n",
    "        model = model,\n",
    "        max_seq_len = config[\"max_sequence_length\"],\n",
    "        vocab_sizes = config[\"base_vocab_sizes\"],\n",
    "        mask_tokens = config[\"mask_tokens\"],\n",
    "        pad_tokens = config[\"pad_tokens\"],\n",
    "        cls_tokens = config[\"cls_tokens\"],\n",
    "        # training\n",
    "        minibatch_size = config[\"minibatch_size\"],\n",
    "        batch_size = config[\"batch_size\"],\n",
    "        opt = nothing,\n",
    "        rng = Random.Xoshiro(20230102),\n",
    "    )\n",
    "    load_input_data(t, source_checkpoint)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2724548d-cf46-4897-b865-0bdcf56b304b",
   "metadata": {},
   "source": [
    "# Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce95bcf4-aa02-4971-920e-a748f11a7331",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_pretrain_checkpoint(medium, tag)\n",
    "    pretrain_dir = \"$medium/all/Transformer/$tag/checkpoints/\"\n",
    "    pretrain_epoch = sort(parse.(Int, readdir(get_data_path(\"alphas/$pretrain_dir\"))))[end]\n",
    "    pretrain_checkpoint = joinpath(pretrain_dir, string(pretrain_epoch))\n",
    "    @info \"using pretrained model from $pretrain_checkpoint\"\n",
    "    pretrain_checkpoint\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc5b0c71-0dff-42d3-b0dc-3d9da3af65c3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "source_checkpoint = get_pretrain_checkpoint(source_medium, \"v9\")\n",
    "target_checkpoint = get_pretrain_checkpoint(medium, \"v9\")\n",
    "trainer = load_pretrained_model(source_checkpoint, target_checkpoint, task);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94638170-e922-4851-924e-244c802f0723",
   "metadata": {},
   "source": [
    "# Optionally pretrain model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d698f0-7e4c-4c12-97b3-06f79d9143e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_embeddings(users, t::Trainer)\n",
    "    embedding = zeros(Float32, size(t.model.classifier.item.decoder)[1], length(users))\n",
    "    @showprogress for minibatch in\n",
    "                      collect(Iterators.partition(1:length(users), t.minibatch_size))\n",
    "        batch = get_batch(users[minibatch], false, t) |> device\n",
    "        y = output_embedding(t.model, batch) |> cpu\n",
    "        batch |> device_free!\n",
    "        embedding[:, minibatch] = y\n",
    "    end\n",
    "    embedding\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c2a753-f571-4e3c-9e72-7b35ef33ef0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function pretrain_epoch!(users, embeddings, t::Trainer)\n",
    "    losses = []\n",
    "    @showprogress for minibatch in collect(\n",
    "        Iterators.partition(Random.shuffle(1:length(users)), t.minibatch_size),\n",
    "    )\n",
    "        X = embeddings[:, minibatch] |> device\n",
    "        y = device.(z[:, users[minibatch]] for z in t.labels)\n",
    "        w = device.(z[:, users[minibatch]] for z in t.weights)\n",
    "        tloss, grads = Flux.withgradient(t.model.classifier) do m\n",
    "            rating_preds = m.rating.transform(X)\n",
    "            item_preds =\n",
    "                transpose(m.item.decoder) * m.item.transform(X) .+ m.item.output_bias.b\n",
    "            iloss = -sum(y[1] .* w[1] .* logsoftmax(item_preds)) / sum(w[1])\n",
    "            rloss = sum((rating_preds - y[2]) .^ 2 .* w[2]) / sum(w[2])\n",
    "            iloss + rloss\n",
    "        end\n",
    "        Flux.update!(t.opt, t.model.classifier, grads[1])\n",
    "        push!(losses, tloss)\n",
    "        CUDA.unsafe_free!(X)\n",
    "        CUDA.unsafe_free!.(y)\n",
    "        CUDA.unsafe_free!.(w)\n",
    "    end\n",
    "    mean(losses)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3b7e5e6-d97e-4674-9347-23341e710744",
   "metadata": {},
   "outputs": [],
   "source": [
    "function pretrain_loss!(users, embeddings, t::Trainer)\n",
    "    i_losses = []\n",
    "    i_weight = 0.0f0\n",
    "    r1_losses = []\n",
    "    r0_losses = []\n",
    "    r_n1_losses = []\n",
    "    r_weight = 0.0f0\n",
    "    @showprogress for minibatch in\n",
    "                      collect(Iterators.partition(1:length(users), t.minibatch_size))\n",
    "        X = embeddings[:, minibatch] |> device\n",
    "        y = device.(z[:, users[minibatch]] for z in t.labels)\n",
    "        w = device.(z[:, users[minibatch]] for z in t.weights)\n",
    "\n",
    "        m = trainer.model.classifier\n",
    "        rating_preds = m.rating.transform(X)\n",
    "        item_preds = transpose(m.item.decoder) * m.item.transform(X) .+ m.item.output_bias.b\n",
    "        iloss = -sum(y[1] .* w[1] .* logsoftmax(item_preds))\n",
    "        i_weight += sum(w[1])\n",
    "        r1_loss = sum((1 .* rating_preds - y[2]) .^ 2 .* w[2])\n",
    "        r0_loss = sum((0 .* rating_preds - y[2]) .^ 2 .* w[2])\n",
    "        r_n1_loss = sum((-1 .* rating_preds - y[2]) .^ 2 .* w[2])\n",
    "        r_weight += sum(w[2])\n",
    "\n",
    "        push!(i_losses, iloss)\n",
    "        push!(r1_losses, r1_loss)\n",
    "        push!(r0_losses, r0_loss)\n",
    "        push!(r_n1_losses, r_n1_loss)\n",
    "\n",
    "        CUDA.unsafe_free!(X)\n",
    "        CUDA.unsafe_free!.(y)\n",
    "        CUDA.unsafe_free!.(w)\n",
    "    end\n",
    "\n",
    "    i_loss = sum(i_losses) / i_weight\n",
    "    # get the correlation loss by finding the minimum of the rating loss quadratic    \n",
    "    r1 = sum(r1_losses) / r_weight\n",
    "    r0 = sum(r0_losses) / r_weight\n",
    "    r_n1 = sum(r_n1_losses) / r_weight\n",
    "    a = (r1 + r_n1) / 2 - r0\n",
    "    b = (r1 - r_n1) / 2\n",
    "    c = r0\n",
    "    r_loss = c - b^2 / (4 * a)\n",
    "    i_loss, r_loss, r1\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7431852-71e9-4d18-b8aa-c3cdf79e8930",
   "metadata": {},
   "outputs": [],
   "source": [
    "function pretrain_model!(t::Trainer)\n",
    "    t, training, validation = load_output_data(t, source_checkpoint, true)\n",
    "    training_embeddings = get_embeddings(training, t)\n",
    "    validation_embeddings = get_embeddings(validation, t)\n",
    "\n",
    "    lr = 1e-4\n",
    "    t = @set t.opt = Optimisers.setup(\n",
    "        OptimiserChain(Adam(lr, (0.9f0, 0.999f0)), WeightDecay(lr * 1f-2)),\n",
    "        t.model.classifier,\n",
    "    )\n",
    "\n",
    "    stopper = early_stopper(max_iters = 10, patience = 0)\n",
    "    test_loss = Inf\n",
    "    best_model = nothing\n",
    "    while (!stop!(stopper, test_loss))\n",
    "        best_model = t.model |> cpu\n",
    "        training_loss = pretrain_epoch!(training, training_embeddings, t)\n",
    "        item_loss, corr_loss, rating_loss =\n",
    "            pretrain_loss!(validation, validation_embeddings, t)\n",
    "        test_loss = item_loss + corr_loss\n",
    "        @info \"$training_loss $item_loss $corr_loss $rating_loss\"\n",
    "    end\n",
    "    t = @set t.model = best_model |> gpu\n",
    "    write_params(\n",
    "        Dict(\"m\" => t.model |> cpu, \"epoch\" => stopper.iters, \"loss\" => stopper.loss),\n",
    "        \"$name/checkpoints/pretrain\",\n",
    "    )\n",
    "    t\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c9787a-3b64-4b72-85ce-1e2df5c54053",
   "metadata": {},
   "outputs": [],
   "source": [
    "if source_medium != medium\n",
    "    trainer = pretrain_model!(trainer)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09179457-f478-42ab-a9d5-6145196d7514",
   "metadata": {},
   "source": [
    "# Finetune model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3d3a024-f460-4036-b42b-a43c8db62119",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer, training, validation = load_output_data(trainer, source_checkpoint, false);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5faf9605-b5c9-4f9e-a123-b676f99dd0d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-5\n",
    "opt = Optimisers.setup(\n",
    "    OptimiserChain(Adam(lr, (0.9f0, 0.999f0)), WeightDecay(lr * 1f-2)),\n",
    "    trainer.model,\n",
    ")\n",
    "trainer = @set trainer.opt = opt;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5caad534-15d7-4909-bce7-825c283099e9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "stopper = early_stopper(max_iters = 100, patience = 0)\n",
    "test_loss = Inf\n",
    "best_model = nothing\n",
    "while (!stop!(stopper, test_loss))\n",
    "    best_model = trainer.model |> cpu\n",
    "    training_loss = train_epoch!(training, trainer)\n",
    "    metrics = checkpoint(\n",
    "        validation,\n",
    "        trainer,\n",
    "        training_loss,\n",
    "        stopper.iters,\n",
    "        source_checkpoint,\n",
    "        target_checkpoint,\n",
    "        name,\n",
    "    )\n",
    "    test_loss = metrics[\"Item Crossentropy Loss\"] + metrics[\"Rating MSE Loss\"]\n",
    "end;\n",
    "trainer = @set trainer.model = best_model |> gpu;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf158b9-d63c-4efb-921b-555add5a607d",
   "metadata": {},
   "source": [
    "# Save predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faebdc6c-7441-4eb5-859a-56bc9e461e36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a vector that maps a user to the list of items to predict\n",
    "function user_to_items(users::Vector, items::Vector)\n",
    "    user_to_count = zeros(Int32, num_users(medium), Threads.nthreads())\n",
    "    @tprogress Threads.@threads for u in users\n",
    "        user_to_count[u, Threads.threadid()] += 1\n",
    "    end\n",
    "    user_to_count = convert.(Int32, vec(sum(user_to_count, dims = 2)))\n",
    "\n",
    "    utoa = Vector{Vector{Int32}}()\n",
    "    @showprogress for u = 1:num_users(medium)\n",
    "        push!(utoa, Vector{Int32}(undef, user_to_count[u]))\n",
    "    end\n",
    "\n",
    "    @showprogress for i = 1:length(users)\n",
    "        u = users[i]\n",
    "        a = items[i]\n",
    "        utoa[u][user_to_count[u]] = a\n",
    "        user_to_count[u] -= 1\n",
    "    end\n",
    "    utoa\n",
    "end\n",
    "\n",
    "function evaluate_model(users, items, t::Trainer)\n",
    "    CUDA.math_mode!(CUDA.FAST_MATH; precision = :TensorFloat32)\n",
    "    utoa = user_to_items(users, items)\n",
    "    out_users = Vector{Int32}(undef, length(users))\n",
    "    out_items = Vector{Int32}(undef, length(users))\n",
    "    out_implicit_ratings = fill(NaN32, length(out_users))\n",
    "    out_explicit_ratings = fill(NaN32, length(out_users))\n",
    "    out_idx = 1\n",
    "\n",
    "    # compute predictions    \n",
    "    user_batches = collect(Iterators.partition(Set(users), t.minibatch_size))\n",
    "    @showprogress for sampled_users in Set(user_batches)\n",
    "        batch = get_batch(sampled_users, false, t) |> device\n",
    "        item_preds, rating_preds = lm_preds(t.model, batch)\n",
    "        item_preds = softmax(item_preds) |> cpu\n",
    "        rating_preds = rating_preds |> cpu\n",
    "        for j = 1:length(sampled_users)\n",
    "            u = sampled_users[j]\n",
    "            if length(utoa[u]) > 0\n",
    "                item_mask = utoa[u]\n",
    "                next_idx = out_idx + length(item_mask)\n",
    "                out_users[out_idx:next_idx-1] .= u\n",
    "                out_items[out_idx:next_idx-1] = item_mask\n",
    "                out_implicit_ratings[out_idx:next_idx-1] = item_preds[item_mask, j]\n",
    "                out_explicit_ratings[out_idx:next_idx-1] = rating_preds[item_mask, j]\n",
    "                out_idx = next_idx\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    CUDA.math_mode!(CUDA.FAST_MATH; precision = :BFloat16)\n",
    "    RatingsDataset(\n",
    "        user = out_users,\n",
    "        item = out_items,\n",
    "        rating = out_implicit_ratings,\n",
    "        medium = medium,\n",
    "    ),\n",
    "    RatingsDataset(\n",
    "        user = out_users,\n",
    "        item = out_items,\n",
    "        rating = out_explicit_ratings,\n",
    "        medium = medium,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f674970-6330-416d-ac48-046d60865ba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "function write_alpha(t::Trainer, outdir::String, task::String)\n",
    "    master_dfs = []\n",
    "    @showprogress for split in ALL_SPLITS\n",
    "        for content in ALL_CONTENTS\n",
    "            push!(\n",
    "                master_dfs,\n",
    "                get_raw_split(split, task, content, medium; fields = [:user, :item]),\n",
    "            )\n",
    "        end\n",
    "    end\n",
    "    master_df = reduce(cat, master_dfs)\n",
    "    imp_p, exp_p = sparse.(evaluate_model(master_df.user, master_df.item, trainer))\n",
    "    function model(content, p, users, items)\n",
    "        r = zeros(length(users))\n",
    "        @tprogress Threads.@threads for j = 1:length(r)\n",
    "            r[j] = p[items[j], users[j]]\n",
    "            if content == \"explicit\"\n",
    "                blp =\n",
    "                    t.target_explicit_baseline[\"user_biases\"][users[j]] +\n",
    "                    t.target_explicit_baseline[\"item_biases\"][items[j]]\n",
    "                r[j] += blp\n",
    "            end\n",
    "        end\n",
    "        r\n",
    "    end\n",
    "    for (content, p) in [(\"implicit\", imp_p), (\"explicit\", exp_p)]\n",
    "        write_alpha(\n",
    "            (users, items) -> model(content, p, users, items),\n",
    "            medium,\n",
    "            \"$outdir/$content\";\n",
    "            task = task,\n",
    "            log = true,\n",
    "            log_task = task,\n",
    "            log_content = content,\n",
    "            log_alphas = String[],\n",
    "        )\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6969ef30-d148-4d7e-ab8f-73f0e82e28a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_alpha(trainer, name, task)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0-rc2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

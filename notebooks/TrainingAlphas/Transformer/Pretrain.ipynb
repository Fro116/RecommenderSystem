{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9ffa83-ba30-4d94-aa0a-827dd82eb7b0",
   "metadata": {},
   "source": [
    "# Pretrains a tranformer encoder model on watch histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c8376-2d03-4c69-a07d-0ba71801ec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"all/Transformer/test\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90afc10-1ae5-4665-937e-d58a5859ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"../Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3184e0c-d01a-4b83-aa3f-7908fc378b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import CUDA\n",
    "import Flux\n",
    "import Flux: Chain, Dense, Dropout, LayerNorm, cpu, gelu, gpu, logsoftmax\n",
    "import Flux.NNlib: gather\n",
    "import Functors: @functor\n",
    "import Optimisers\n",
    "import Optimisers: OptimiserChain, Adam, WeightDecay\n",
    "import ParameterSchedulers\n",
    "import ParameterSchedulers: Sequence, Triangle, Shifted, Stateful\n",
    "import Random\n",
    "import StatsBase: mean, sample\n",
    "import Transformers: Bert, Positionwise, TransformerModel\n",
    "import Transformers.Basic: CompositeEmbedding, Embed, PositionEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b924da24-7c19-45a8-bed0-de97e886c818",
   "metadata": {},
   "source": [
    "# Tokenize training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1390be71-9ece-4b82-a6c7-d4eb41d3c3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "function encode_word(item, rating, timestamp, status, completion, user)\n",
    "    if timestamp == -1\n",
    "        ts = 1\n",
    "    else\n",
    "        date = timestamp_to_date(timestamp)\n",
    "        year = Dates.value(Dates.Year(date)) - 2004\n",
    "        season = div(Dates.value(Dates.Month(date)) - 1, 4) + 1\n",
    "        ts = 1 + year * 4 + season\n",
    "    end\n",
    "    r = Int32(round(rating)) + 1\n",
    "    c = Int32(round(10 * completion)) + 1\n",
    "    word = (item, r, ts, status, c, user)\n",
    "    convert.(Int32, word)\n",
    "end\n",
    "\n",
    "function get_training_data(task, include_ptw; show_progress_bar = false)\n",
    "    function get_df(task, content)\n",
    "        df = get_raw_split(\"training\", task, content)\n",
    "        if content != \"explicit\"\n",
    "            df.rating .= 11\n",
    "        end\n",
    "        df\n",
    "    end\n",
    "\n",
    "    contents = [\"explicit\", \"implicit\"]\n",
    "    if include_ptw\n",
    "        push!(contents, \"ptw\")\n",
    "    end\n",
    "    sentences = Dict{Int32,Vector{NTuple{6,Int32}}}()\n",
    "    df = reduce(cat, [get_df(task, content) for content in contents])\n",
    "    order = sortperm(df.timestamp)\n",
    "    p = ProgressMeter.Progress(length(order); enabled = show_progress_bar, showspeed = true)\n",
    "    for idx = 1:length(order)\n",
    "        i = order[idx]\n",
    "        if df.user[i] ∉ keys(sentences)\n",
    "            sentences[df.user[i]] = NTuple{6,Int32}[]\n",
    "        end\n",
    "        word = encode_word(\n",
    "            df.item[i],\n",
    "            df.rating[i],\n",
    "            df.timestamp[i],\n",
    "            df.status[i],\n",
    "            df.completion[i],\n",
    "            df.user[i],\n",
    "        )\n",
    "        push!(sentences[df.user[i]], word)\n",
    "        ProgressMeter.next!(p)\n",
    "    end\n",
    "    ProgressMeter.finish!(p)\n",
    "    [sentences[k] for k in keys(sentences)]\n",
    "end;\n",
    "\n",
    "function get_training_data(include_ptw)\n",
    "    sentences = Vector{Vector{Vector{NTuple{6,Int32}}}}(undef, length(ALL_TASKS))\n",
    "    # only print progress bars for one thread\n",
    "    show_progress_thread = Threads.Atomic{Int}(0)\n",
    "    Threads.@threads for i = 1:length(ALL_TASKS)\n",
    "        Threads.atomic_cas!(show_progress_thread, 0, Threads.threadid())\n",
    "        sentences[i] = get_training_data(\n",
    "            ALL_TASKS[i],\n",
    "            include_ptw;\n",
    "            show_progress_bar = show_progress_thread[] == Threads.threadid(),\n",
    "        )\n",
    "    end\n",
    "    vcat(sentences...)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8227aee2-8a2f-4932-bae2-38c951404415",
   "metadata": {},
   "outputs": [],
   "source": [
    "function pad_sentence(sentence, max_seq_length, cls_tokens, pad_tokens; rng)\n",
    "    outputs = fill.(pad_tokens, max_seq_length)\n",
    "    for i = 1:length(outputs)\n",
    "        outputs[i][1] = cls_tokens[i]\n",
    "    end\n",
    "    seq_len = max_seq_length - 1\n",
    "    if length(sentence) > seq_len\n",
    "        # take a random contiguous subset\n",
    "        idx = rand(rng, 1:length(sentence)-seq_len+1)\n",
    "        sentence = sentence[idx:idx+seq_len-1]\n",
    "    end\n",
    "    for i = 1:length(sentence)\n",
    "        for j = 1:length(outputs)\n",
    "            outputs[j][1+i] = sentence[i][j]\n",
    "        end\n",
    "    end\n",
    "    outputs\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703ab7e5-b47f-42e7-a117-522a8d165b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_token_ids(sentences, max_seq_length, cls_tokens, pad_tokens; rng)\n",
    "    padded_sentences = [\n",
    "        pad_sentence(x, max_seq_length, cls_tokens, pad_tokens; rng = rng) for\n",
    "        x in sentences\n",
    "    ]\n",
    "    Tuple(hcat([x[i] for x in padded_sentences]...) for i = 1:length(cls_tokens))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dddc8746-8e2a-4a38-a0d3-5e1ff4b01c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "function validate_tokenization(sentences, vocab_sizes)\n",
    "    sharded_vocab_values =\n",
    "        [[Set() for _ = 1:length(vocab_sizes)] for t = 1:Threads.nthreads()]\n",
    "    @tprogress Threads.@threads for i = 1:length(sentences)\n",
    "        for word in sentences[i]\n",
    "            @assert all((word .>= 1) .&& (word .<= vocab_sizes)) word\n",
    "            for j = 1:length(word)\n",
    "                push!(sharded_vocab_values[Threads.threadid()][j], word[j])\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    vocab_values = [Set() for _ = 1:length(vocab_sizes)]\n",
    "    @showprogress for t = 1:Threads.nthreads()\n",
    "        for i = 1:length(vocab_sizes)\n",
    "            union!(vocab_values[i], sharded_vocab_values[t][i])\n",
    "        end\n",
    "    end\n",
    "\n",
    "    coverage = [length(vocab_values[i]) / vocab_sizes[i] for i = 1:length(vocab_sizes)]\n",
    "    @info \"Vocab values $(vocab_sizes)\"\n",
    "    @info \"Minimum observed vocab values $(minimum.(vocab_values))\"\n",
    "    @info \"Maximum observed vocab values $(maximum.(vocab_values))\"\n",
    "    @info \"Coverage $coverage\"\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d345ae8-f437-480c-add6-7b16e0f050c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "function prune(sentences, invalid_word_fn)\n",
    "    pruned_sentences = []\n",
    "    @showprogress for i = 1:length(sentences)\n",
    "        sentence = Vector{eltype(sentences[i])}()\n",
    "        for word in sentences[i]\n",
    "            if !invalid_word_fn(word)\n",
    "                push!(sentence, word)\n",
    "            end\n",
    "        end\n",
    "        if length(sentence) > 0\n",
    "            push!(pruned_sentences, sentence)\n",
    "        end\n",
    "    end\n",
    "    pruned_sentences\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0594317f-813d-4f10-856c-a7df127e146f",
   "metadata": {},
   "source": [
    "# Create minibatches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b524c73-58a0-4c31-9ff0-48f81eb0fa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_batch(\n",
    "    sentences;\n",
    "    max_seq_len,\n",
    "    vocab_sizes,\n",
    "    cls_tokens,\n",
    "    pad_tokens,\n",
    "    mask_tokens,\n",
    "    rng,\n",
    "    training,\n",
    ")\n",
    "    # dynamically pad to the largest sequence length\n",
    "    seq_len = min(maximum(length.(sentences)) + 1, max_seq_len)\n",
    "\n",
    "    # get tokenized sentences\n",
    "    tokens = get_token_ids(sentences, seq_len, cls_tokens, pad_tokens; rng = rng)\n",
    "\n",
    "    # don't attend to padding tokens\n",
    "    attention_mask = reshape(\n",
    "        convert.(Float32, tokens[1] .!= pad_tokens[1]),\n",
    "        (1, seq_len, length(sentences)),\n",
    "    )\n",
    "\n",
    "    # apply BERT masking\n",
    "    masked_token_positions = (Tuple{Int32,Int32}[], Tuple{Int32,Int32}[])\n",
    "    labels = (Tuple{Int32,Int32}[], Float32[])\n",
    "    userids = (Int32[], Int32[])\n",
    "    for b::Int32 = 1:length(sentences)\n",
    "        seq_len = Int(sum(attention_mask[:, :, b]))\n",
    "        for i::Int32 = 1:seq_len\n",
    "            mask_item = rand(rng) < 0.15\n",
    "            mask_rating = rand(rng) < 0.15\n",
    "\n",
    "            if mask_item && (tokens[1][i, b] .<= vocab_sizes[1])\n",
    "                push!(labels[1], (tokens[1][i, b], Int32(length(labels[1]) + 1)))\n",
    "                push!(userids[1], tokens[6][i, b])\n",
    "                for j in [2, 4, 5]\n",
    "                    # when predicting masked items, dont use rating, status or completion metadata\n",
    "                    tokens[j][i, b] = mask_tokens[j]\n",
    "                end\n",
    "                r = training ? rand(rng) : 0.0\n",
    "                if r < 0.8\n",
    "                    tokens[1][i, b] = mask_tokens[1]\n",
    "                elseif r < 0.9\n",
    "                    tokens[1][i, b] = rand(1:vocab_sizes[1])\n",
    "                end\n",
    "                push!(masked_token_positions[1], (i, b))\n",
    "            end\n",
    "\n",
    "            if mask_rating && !mask_item && (tokens[2][i, b] .< vocab_sizes[2])\n",
    "                # only try to predict explicit ratings\n",
    "                push!(labels[2], tokens[2][i, b])\n",
    "                push!(userids[2], tokens[6][i, b])\n",
    "                for j in [4, 5]\n",
    "                    # when predicting masked ratings, dont use status or completion metadata\n",
    "                    tokens[j][i, b] = mask_tokens[j]\n",
    "                end\n",
    "                r = training ? rand(rng) : 0.0\n",
    "                if r < 0.8\n",
    "                    tokens[2][i, b] = mask_tokens[2]\n",
    "                elseif r < 0.9\n",
    "                    tokens[2][i, b] = rand(1:vocab_sizes[2])\n",
    "                end\n",
    "                push!(masked_token_positions[2], (i, b))\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    processed_labels = (labels[1], convert.(Float32, collect(labels[2]')))\n",
    "    processed_weights = (uids_to_weights(userids[1]), collect(uids_to_weights(userids[2])'))\n",
    "    if training && !training_config[\"user_weighted_training\"]\n",
    "        processed_weights[1] .= 1\n",
    "        processed_weights[2] .= 1\n",
    "    end\n",
    "\n",
    "    tokens, attention_mask, masked_token_positions, processed_labels, processed_weights\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "284f2d32-a313-4e0b-a650-0fc049e90e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "function uids_to_weights(uids)\n",
    "    uid_to_count = Dict(i => 0 for i in uids)\n",
    "    for i in uids\n",
    "        uid_to_count[i] += 1\n",
    "    end\n",
    "    weights = zeros(Float32, length(uids))\n",
    "    for i = 1:length(uids)\n",
    "        weights[i] = 1 / uid_to_count[uids[i]]\n",
    "    end\n",
    "    weights\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ed0909-a7b0-4b54-ae7b-20dd5b9b789b",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_batch(sentences, training_config, rng, training) = get_batch(\n",
    "    sentences;\n",
    "    max_seq_len = training_config[\"max_sequence_length\"],\n",
    "    vocab_sizes = training_config[\"base_vocab_sizes\"],\n",
    "    cls_tokens = training_config[\"cls_tokens\"],\n",
    "    pad_tokens = training_config[\"pad_tokens\"],\n",
    "    mask_tokens = training_config[\"mask_tokens\"],\n",
    "    rng = rng,\n",
    "    training = training,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0deae8-f55a-4293-8ebb-84011b487f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "function shuffle_training_data(\n",
    "    rng,\n",
    "    sentences,\n",
    "    line_by_line,\n",
    "    max_sequence_length,\n",
    "    max_document_length,\n",
    "    pad_tokens,\n",
    ")\n",
    "    order = Random.shuffle(rng, 1:length(sentences))\n",
    "    if line_by_line\n",
    "        return sentences[order]\n",
    "    end\n",
    "    max_sequence_length = max_sequence_length - 1 # leave room for CLS token \n",
    "    max_document_length = max_document_length - 1\n",
    "    S = eltype(sentences)\n",
    "    W = eltype(sentences[1])\n",
    "\n",
    "    # concatenate all tokens\n",
    "    tokens = Vector{W}()\n",
    "    @showprogress for i in order\n",
    "        sentence = sentences[i]\n",
    "        if length(sentence) > max_document_length\n",
    "            idx = rand(rng, 1:length(sentence)-max_document_length+1)\n",
    "            sentence = sentence[idx:idx+max_document_length-1]\n",
    "        end\n",
    "        for token in sentence\n",
    "            push!(tokens, token)\n",
    "        end\n",
    "        if i != order[end]\n",
    "            push!(tokens, pad_tokens)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    # patition tokens into minibatches\n",
    "    batched_sentences = Vector{S}()\n",
    "    sentence = Vector{W}()\n",
    "    @showprogress for token in tokens\n",
    "        push!(sentence, token)\n",
    "        if length(sentence) == max_sequence_length\n",
    "            push!(batched_sentences, sentence)\n",
    "            sentence = Vector{W}()\n",
    "        end\n",
    "    end\n",
    "    if length(sentence) > 0\n",
    "        push!(batched_sentences, sentence)\n",
    "    end\n",
    "    batched_sentences\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d198f46-71be-48b6-a6b8-cb728894eed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function device(batch)\n",
    "    gpu.(batch[1]), gpu(batch[2]), gpu.(batch[3]), gpu.(batch[4]), gpu.(batch[5])\n",
    "end\n",
    "\n",
    "function device_free!(batch)\n",
    "    if !CUDA.functional()\n",
    "        return\n",
    "    end\n",
    "    CUDA.unsafe_free!.(batch[1])\n",
    "    CUDA.unsafe_free!(batch[2])\n",
    "    CUDA.unsafe_free!(batch[4][2])\n",
    "    CUDA.unsafe_free!.(batch[5])\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59101cfb-147f-491b-b48a-e942ddbae8b3",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58089cb-f5b9-4f7f-80d0-053f0e3d11b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A layer that adds a 1-D vector to the input\n",
    "struct BiasLayer\n",
    "    b::Any\n",
    "end\n",
    "BiasLayer(n::Integer; init = zeros) = BiasLayer(init(Float32, n))\n",
    "(m::BiasLayer)(x) = x .+ m.b\n",
    "@functor BiasLayer;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffb8b2af-44c4-4c6c-a35a-987e7d6b1406",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pe::PositionEmbedding)(x::AbstractArray{X}) where {X<:Integer} = pe(size(x, 1));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888e8ee3-c369-41c8-ba85-267e2757d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "function create_bert(config)\n",
    "    bert = Bert(\n",
    "        config[\"hidden_size\"],\n",
    "        config[\"num_attention_heads\"],\n",
    "        config[\"intermediate_size\"],\n",
    "        config[\"num_hidden_layers\"];\n",
    "        act = config[\"hidden_act\"],\n",
    "        pdrop = config[\"hidden_dropout_prob\"],\n",
    "        attn_pdrop = config[\"attention_probs_dropout_prob\"],\n",
    "    )\n",
    "\n",
    "    create_embedding(hidden_size, vocab_size) = Embed(Int(hidden_size), Int(vocab_size))\n",
    "    item_emb = create_embedding(config[\"hidden_size\"], config[\"vocab_sizes\"][1])\n",
    "    rating_emb = create_embedding(config[\"hidden_size\"], config[\"vocab_sizes\"][2])\n",
    "    timestamp_emb = create_embedding(config[\"hidden_size\"], config[\"vocab_sizes\"][3])\n",
    "    status_emb = create_embedding(config[\"hidden_size\"], config[\"vocab_sizes\"][4])\n",
    "    completion_emb = create_embedding(config[\"hidden_size\"], config[\"vocab_sizes\"][5])\n",
    "\n",
    "    position_emb = PositionEmbedding(\n",
    "        config[\"hidden_size\"],\n",
    "        config[\"max_sequence_length\"];\n",
    "        trainable = true,\n",
    "    )\n",
    "\n",
    "    emb_post = Positionwise(\n",
    "        LayerNorm(config[\"hidden_size\"]),\n",
    "        Dropout(config[\"hidden_dropout_prob\"]),\n",
    "    )\n",
    "\n",
    "    emb = CompositeEmbedding(\n",
    "        item = item_emb,\n",
    "        rating = rating_emb,\n",
    "        timestamp = timestamp_emb,\n",
    "        status = status_emb,\n",
    "        position = position_emb,\n",
    "        postprocessor = emb_post,\n",
    "    )\n",
    "\n",
    "    item_cls = (\n",
    "        transform = Chain(\n",
    "            Dense(config[\"hidden_size\"], config[\"hidden_size\"], config[\"hidden_act\"]),\n",
    "            LayerNorm(config[\"hidden_size\"]),\n",
    "        ),\n",
    "        output_bias = BiasLayer(config[\"vocab_sizes\"][1]),\n",
    "    )\n",
    "    rating_cls = Dense(config[\"hidden_size\"], 1)\n",
    "    clf = (item = item_cls, rating = rating_cls)\n",
    "\n",
    "    TransformerModel(emb, bert, clf)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fc3c56-2786-4752-befc-e9f241ae0f08",
   "metadata": {},
   "source": [
    "# Loss metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca77b1-83ef-4a11-ab46-aad27f8adc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "function masklm_losses(model, batch)\n",
    "    tokens, attention_mask, masked_token_positions, masked_token_labels, weights = batch\n",
    "    X = model.embed(\n",
    "        item = tokens[1],\n",
    "        rating = tokens[2],\n",
    "        timestamp = tokens[3],\n",
    "        status = tokens[4],\n",
    "        completion = tokens[5],\n",
    "        position = tokens[1],\n",
    "    )\n",
    "    X = model.transformers(X, attention_mask)\n",
    "\n",
    "    if length(masked_token_labels[1]) > 0\n",
    "        item_pred = logsoftmax(\n",
    "            transpose(model.embed.embeddings.item.embedding) *\n",
    "            model.classifier.item.transform(gather(X, masked_token_positions[1])) .+\n",
    "            model.classifier.item.output_bias.b,\n",
    "        )\n",
    "        item_loss =\n",
    "            -sum(gather(item_pred, masked_token_labels[1]) .* weights[1]) / sum(weights[1])\n",
    "    else\n",
    "        item_loss = 0.0f0\n",
    "    end\n",
    "\n",
    "    if length(masked_token_labels[2]) > 0\n",
    "        rating_pred = model.classifier.rating(gather(X, masked_token_positions[2]))\n",
    "        rating_loss =\n",
    "            sum((rating_pred - masked_token_labels[2]) .^ 2 .* weights[2]) / sum(weights[2])\n",
    "    else\n",
    "        rating_loss = 0.0f0\n",
    "    end\n",
    "\n",
    "    item_loss, rating_loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eca42c-7356-49c2-8cbf-5baf86dec544",
   "metadata": {},
   "outputs": [],
   "source": [
    "function evaluate_metrics(model, sentences, training_config; rng)\n",
    "    sumtotals = [0.0, 0.0]\n",
    "    Random.shuffle!(rng, sentences)\n",
    "    sentence_batches =\n",
    "        collect(Iterators.partition(sentences, training_config[\"batch_size\"]))\n",
    "    @showprogress for sbatch in sentence_batches\n",
    "        batch = get_batch(sbatch, training_config, rng, false) |> device\n",
    "        sumtotals .+= masklm_losses(model, batch)\n",
    "        device_free!(batch)\n",
    "    end\n",
    "    totals = sumtotals ./ length(sentence_batches)\n",
    "    Dict(\"Item Crossentropy Loss\" => totals[1], \"Rating MSE Loss\" => totals[2])\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb18c7a-64c9-4817-888b-3866fbff4ec6",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f13b747-89de-4f87-83b6-d03804ce5a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Trainer\n",
    "    model::Any\n",
    "    opt::Any\n",
    "    lr_schedule::Any\n",
    "    training_config::Any\n",
    "    model_config::Any\n",
    "    rng::Any\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab906ead-ee90-4e1e-bc2d-af9b7313f996",
   "metadata": {},
   "outputs": [],
   "source": [
    "function schedule_learning_rate!(opt, lr_schedule)\n",
    "    lr = Float32(ParameterSchedulers.next!(lr_schedule))\n",
    "    Optimisers.adjust!(opt, eta = lr, gamma = lr * 1f-2)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8da27fc-de44-4142-bc8f-00b1dedebedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "tuplesum(a::Nothing, b::Nothing) = nothing\n",
    "tuplesum(a::Nothing, b) = b\n",
    "tuplesum(a, b::Nothing) = a\n",
    "function tuplesum(a::NamedTuple, b::NamedTuple)\n",
    "    fields = fieldnames(typeof(a))\n",
    "    NamedTuple{fields}(tuplesum(a[k], b[k]) for k in fields)\n",
    "end\n",
    "tuplesum(a::Tuple, b::Tuple) = Tuple(tuplesum(a[k], b[k]) for k = 1:length(a))\n",
    "tuplesum(a, b) = a .+ b;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4c0fd3-6beb-47fb-95d2-94fb1d5cdb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_epoch!(t::Trainer, sentences)\n",
    "    sentences = shuffle_training_data(\n",
    "        t.rng,\n",
    "        sentences,\n",
    "        t.training_config[\"line_by_line\"],\n",
    "        t.training_config[\"max_sequence_length\"],\n",
    "        t.training_config[\"max_document_length\"],\n",
    "        t.training_config[\"pad_tokens\"],\n",
    "    )\n",
    "    sentence_batches = collect(\n",
    "        Iterators.partition(\n",
    "            sentences,\n",
    "            t.training_config[\"gradient_accumulation_batch_size\"],\n",
    "        ),\n",
    "    )\n",
    "    @showprogress for sbatch in sentence_batches\n",
    "        minibatches = collect(Iterators.partition(sbatch, t.training_config[\"batch_size\"]))\n",
    "        schedule_learning_rate!(t.opt, t.lr_schedule)\n",
    "        total_grads = nothing\n",
    "        for minibatch in minibatches\n",
    "            batch = get_batch(minibatch, t.training_config, rng, true) |> device\n",
    "            grads = Flux.gradient(t.model) do m\n",
    "                sum(masklm_losses(m, batch))\n",
    "            end\n",
    "            total_grads = tuplesum(total_grads, grads)\n",
    "            batch |> device_free!\n",
    "        end\n",
    "        Flux.update!(t.opt, t.model, total_grads[1])\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f95adc-4281-4fb4-a126-957bd5431e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function checkpoint(t::Trainer, sentences, epoch, outdir)\n",
    "    @info \"evaluating metrics\"\n",
    "    metrics = evaluate_metrics(t.model, sentences, t.training_config; rng = t.rng)\n",
    "    write_params(\n",
    "        Dict(\n",
    "            \"m\" => t.model |> cpu,\n",
    "            \"opt\" => t.opt |> cpu,\n",
    "            \"lr_schedule\" => t.lr_schedule,\n",
    "            \"epoch\" => epoch,\n",
    "            \"metrics\" => metrics,\n",
    "            \"training_config\" => t.training_config,\n",
    "            \"model_config\" => t.model_config,\n",
    "            \"rng\" => t.rng,\n",
    "        ),\n",
    "        \"$name/checkpoints/$epoch\",\n",
    "    )\n",
    "    @info \"saving model after $epoch epochs with metrics $metrics\"\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50183c75-f670-425e-b08e-c72efe4e8988",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805ac800-38d2-4ed9-9963-05c176baef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function set_rngs(seed)\n",
    "    rng = Random.Xoshiro(seed)\n",
    "    Random.seed!(rand(rng, UInt64))\n",
    "    if CUDA.functional()\n",
    "        Random.seed!(CUDA.default_rng(), rand(rng, UInt64))\n",
    "        Random.seed!(CUDA.CURAND.default_rng(), rand(rng, UInt64))\n",
    "    end\n",
    "    rng\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ed260a-b454-4690-ab8f-15ba4d686b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_sentences(rng, training_config)\n",
    "    sentences = get_training_data(training_config[\"include_ptw_impressions\"])\n",
    "    Random.shuffle!(rng, sentences)\n",
    "    cutoff = Int(round(0.95 * length(sentences)))\n",
    "    is_ptw(word) = word[4] == 1\n",
    "    training = sentences[1:cutoff]\n",
    "    validation = prune(sentences[cutoff+1:end], is_ptw)\n",
    "    if training_config[\"line_by_line\"]\n",
    "        training_config[\"iters_per_epoch\"] = length(training)\n",
    "    else\n",
    "        # this is an approximation\n",
    "        total_tokens =\n",
    "            sum(min.(length.(training), training_config[\"max_document_length\"])) +\n",
    "            length(training) - 1\n",
    "        training_config[\"iters_per_epoch\"] =\n",
    "            Int(ceil(total_tokens / (training_config[\"max_sequence_length\"] - 1)))\n",
    "    end\n",
    "    training, validation\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affb67b6-dabb-4db8-841d-c7ebf43f4a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function create_training_config()\n",
    "    base_vocab_sizes =\n",
    "        convert.(\n",
    "            Int32,\n",
    "            (\n",
    "                num_items(),\n",
    "                12,\n",
    "                (Dates.value(Dates.Year(Dates.today())) - 2004 + 1) * 4 + 1,\n",
    "                5,\n",
    "                11,\n",
    "                num_users(),\n",
    "            ),\n",
    "        )\n",
    "    Dict(\n",
    "        \"base_vocab_sizes\" => base_vocab_sizes,\n",
    "        \"cls_tokens\" => base_vocab_sizes .+ Int32(1),\n",
    "        \"pad_tokens\" => base_vocab_sizes .+ Int32(2),\n",
    "        \"mask_tokens\" => base_vocab_sizes .+ Int32(3),\n",
    "        \"sep_tokens\" => base_vocab_sizes .+ Int32(4),\n",
    "        \"vocab_sizes\" => base_vocab_sizes .+ Int32(4),\n",
    "        \"batch_size\" => 16,\n",
    "        \"gradient_accumulation_batch_size\" => 16,\n",
    "        \"max_sequence_length\" => 512,\n",
    "        \"num_epochs\" => 8,\n",
    "        \"include_ptw_impressions\" => false,\n",
    "        \"line_by_line\" => false,\n",
    "        \"max_document_length\" => 512, # controls document subsampling when not in line by line mode\n",
    "        \"user_weighted_training\" => false,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7d3212-578e-4eb1-bfc5-04b33b4c1830",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function LinearWarmupSchedule(lr, iters)\n",
    "    warmup_steps = Int(round(iters * 0.06))\n",
    "    remaining_steps = iters - warmup_steps\n",
    "    Stateful(\n",
    "        Sequence(\n",
    "            Triangle(λ0 = 0.0f0, λ1 = lr, period = 2 * warmup_steps) => warmup_steps,\n",
    "            Shifted(\n",
    "                Triangle(λ0 = 0.0f0, λ1 = lr, period = 2 * remaining_steps),\n",
    "                remaining_steps,\n",
    "            ) => remaining_steps,\n",
    "        ),\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5545bdf1-5fad-4de2-bbc8-dbcf63da3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "function create_model_config(layers, hidden_size, training_config)\n",
    "    # follows the recipe in Section 5 of [Well-Read Students Learn Better: On the \n",
    "    # Importance of Pre-training Compact Models](https://arxiv.org/pdf/1908.08962.pdf)\n",
    "    Dict(\n",
    "        \"attention_probs_dropout_prob\" => 0.1,\n",
    "        \"hidden_act\" => gelu,\n",
    "        \"num_hidden_layers\" => layers,\n",
    "        \"hidden_size\" => hidden_size,\n",
    "        \"max_sequence_length\" => training_config[\"max_sequence_length\"],\n",
    "        \"vocab_sizes\" => training_config[\"vocab_sizes\"],\n",
    "        \"num_attention_heads\" => Int(hidden_size / 64),\n",
    "        \"hidden_dropout_prob\" => 0.1,\n",
    "        \"intermediate_size\" => hidden_size * 4,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d14633c-55e0-4044-8429-705b4f005bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "function load_from_checkpoint(training_config, epoch::Integer, rng)\n",
    "    params = read_params(\"$name/checkpoints/$epoch\")\n",
    "    model = params[\"m\"] |> gpu\n",
    "    @assert training_config == params[\"training_config\"]\n",
    "    model_config = params[\"model_config\"]\n",
    "    opt = params[\"opt\"] |> gpu\n",
    "    lr_schedule = params[\"lr_schedule\"]\n",
    "    rng = params[\"rng\"]\n",
    "    Trainer(model, opt, lr_schedule, training_config, model_config, rng), epoch + 1\n",
    "end\n",
    "\n",
    "function load_from_checkpoint(training_config, ::Nothing, rng)\n",
    "    model_config = create_model_config(4, 512, training_config)\n",
    "    model = create_bert(model_config) |> gpu\n",
    "    opt = Optimisers.setup(\n",
    "        OptimiserChain(Adam(1f-4, (0.9f0, 0.999f0)), WeightDecay(1f-6)),\n",
    "        model,\n",
    "    )\n",
    "    max_batches = Int(\n",
    "        round(\n",
    "            training_config[\"num_epochs\"] * training_config[\"iters_per_epoch\"] /\n",
    "            training_config[\"gradient_accumulation_batch_size\"],\n",
    "        ),\n",
    "    )\n",
    "    lr_schedule = LinearWarmupSchedule(1f-4, max_batches)\n",
    "    Trainer(model, opt, lr_schedule, training_config, model_config, rng), 1\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106fa056-8deb-486d-9854-6e0991bc4714",
   "metadata": {},
   "source": [
    "# Actually Train Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2969e640-d857-474e-b015-bbb11892d09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng = set_rngs(20221221)\n",
    "training_config = create_training_config();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cd4b56-48d2-4d45-bdab-27eecaac3f3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_sentences, validation_sentences = get_sentences(rng, training_config)\n",
    "validate_tokenization(\n",
    "    [training_sentences; validation_sentences],\n",
    "    training_config[\"base_vocab_sizes\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e68ceb9-83ed-440f-a7f8-418db715a45f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "trainer, starting_epoch = load_from_checkpoint(training_config, nothing, rng);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcaa87cf-eb30-44d5-9d9c-3d8c05af400e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "@info \"Training model with $(sum(length, Flux.params(trainer.model))) total parameters\"\n",
    "@info \"Embedding parameters: $(sum(length, Flux.params(trainer.model.embed)))\"\n",
    "@info \"Transformer parameters: $(sum(length, Flux.params(trainer.model.transformers)))\"\n",
    "@info \"Classifier parameters: $(sum(length, Flux.params(trainer.model.classifier)))\"\n",
    "@info \"Training config $(trainer.training_config)\"\n",
    "@info \"Model config $(trainer.model_config)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08f53316-15c6-47c3-ad77-416099102f89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch = starting_epoch:100\n",
    "    train_epoch!(trainer, training_sentences)    \n",
    "    checkpoint(trainer, validation_sentences, epoch, name)        \n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

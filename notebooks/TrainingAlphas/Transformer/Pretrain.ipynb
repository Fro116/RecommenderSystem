{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9ffa83-ba30-4d94-aa0a-827dd82eb7b0",
   "metadata": {},
   "source": [
    "# Pretrains a tranformer encoder model on watch histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c8376-2d03-4c69-a07d-0ba71801ec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"all/Transformer/small\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90afc10-1ae5-4665-937e-d58a5859ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"../Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3184e0c-d01a-4b83-aa3f-7908fc378b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Transformers\n",
    "using Transformers.Basic\n",
    "import CUDA\n",
    "import Random\n",
    "import StatsBase: mean, sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b924da24-7c19-45a8-bed0-de97e886c818",
   "metadata": {},
   "source": [
    "# Tokenize training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1390be71-9ece-4b82-a6c7-d4eb41d3c3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "function encode_word(item, rating, timestamp, status)\n",
    "    if timestamp == -1\n",
    "        ts = 1\n",
    "    else\n",
    "        ts = Int32(round(timestamp / year_in_timestamp_units())) + 2\n",
    "    end\n",
    "    r = Int32(round(rating)) + 1\n",
    "    word = (item, r, ts, status)\n",
    "    convert.(Int32, word)\n",
    "end\n",
    "\n",
    "function get_training_data()\n",
    "    function get_df(task, content)\n",
    "        df = get_raw_split(\"training\", task, content)\n",
    "        if content == \"implicit\"\n",
    "            df.rating .= 11\n",
    "        end\n",
    "        df\n",
    "    end\n",
    "\n",
    "    sentences = Dict{Int32,Vector{NTuple{4,Int32}}}()\n",
    "    for task in ALL_TASKS\n",
    "        df = cat(get_df(task, \"explicit\"), get_df(task, \"implicit\"))\n",
    "        order = sortperm(df.timestamp)\n",
    "        @showprogress for idx = 1:length(order)\n",
    "            i = order[idx]\n",
    "            if df.user[i] âˆ‰ keys(sentences)\n",
    "                sentences[df.user[i]] = NTuple{4,Int32}[]\n",
    "            end\n",
    "            word = encode_word(df.item[i], df.rating[i], df.timestamp[i], df.status[i])\n",
    "            push!(sentences[df.user[i]], word)\n",
    "        end\n",
    "    end\n",
    "    [sentences[k] for k in keys(sentences)]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8227aee2-8a2f-4932-bae2-38c951404415",
   "metadata": {},
   "outputs": [],
   "source": [
    "function pad_sentence(sentence, max_seq_length, cls_tokens, pad_tokens; rng)\n",
    "    outputs = fill.(pad_tokens, max_seq_length)\n",
    "    for i = 1:length(outputs)\n",
    "        outputs[i][1] = cls_tokens[i]\n",
    "    end\n",
    "    seq_len = max_seq_length - 1\n",
    "    if length(sentence) > seq_len\n",
    "        # take a random contiguous subset\n",
    "        idx = rand(rng, 1:length(sentence)-seq_len+1)\n",
    "        sentence = sentence[idx:idx+seq_len-1]\n",
    "    end\n",
    "    for i = 1:length(sentence)\n",
    "        for j = 1:length(outputs)\n",
    "            outputs[j][1+i] = sentence[i][j]\n",
    "        end\n",
    "    end\n",
    "    outputs\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703ab7e5-b47f-42e7-a117-522a8d165b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_token_ids(sentences, max_seq_length, cls_tokens, pad_tokens; rng)\n",
    "    padded_sentences = [\n",
    "        pad_sentence(x, max_seq_length, cls_tokens, pad_tokens; rng = rng) for\n",
    "        x in sentences\n",
    "    ]\n",
    "    Tuple(hcat([x[i] for x in padded_sentences]...) for i = 1:length(cls_tokens))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b524c73-58a0-4c31-9ff0-48f81eb0fa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_batch(\n",
    "    sentences;\n",
    "    max_seq_len,\n",
    "    vocab_sizes,\n",
    "    cls_tokens,\n",
    "    pad_tokens,\n",
    "    mask_tokens,\n",
    "    rng,\n",
    "    training,\n",
    ")\n",
    "    # dynamically pad to the largest sequence length\n",
    "    seq_len = min(maximum(length.(sentences)) + 1, max_seq_len)\n",
    "\n",
    "    # get tokenized sentences\n",
    "    tokens = get_token_ids(sentences, seq_len, cls_tokens, pad_tokens; rng = rng)\n",
    "\n",
    "    # don't attend to padding tokens\n",
    "    attention_mask = reshape(\n",
    "        convert.(Float32, tokens[1] .!= pad_tokens[1]),\n",
    "        (1, seq_len, length(sentences)),\n",
    "    )\n",
    "\n",
    "    # apply BERT masking\n",
    "    masked_token_positions = ([], [])\n",
    "    labels = ([], [])\n",
    "    for b = 1:length(sentences)\n",
    "        seq_len = Int(sum(attention_mask[:, :, b]))\n",
    "        for i = 2:seq_len\n",
    "            mask_item = rand(rng) < 0.15\n",
    "            mask_rating = rand(rng) < 0.15\n",
    "\n",
    "            if mask_item\n",
    "                push!(labels[1], (tokens[1][i, b], length(labels[1]) + 1))\n",
    "                for j in [2, 4]\n",
    "                    # when predicting masked items, dont use rating or status metadata\n",
    "                    tokens[j][i, b] = mask_tokens[j]\n",
    "                end\n",
    "                r = training ? rand(rng) : 0.0\n",
    "                if r < 0.8\n",
    "                    tokens[1][i, b] = mask_tokens[1]\n",
    "                elseif r < 0.9\n",
    "                    tokens[1][i, b] = rand(1:vocab_sizes[1])\n",
    "                end\n",
    "                push!(masked_token_positions[1], (i, b))\n",
    "            end\n",
    "\n",
    "            if mask_rating && !mask_item && (tokens[2][i, b] != vocab_sizes[2])\n",
    "                # only try to predict explicit ratings\n",
    "                push!(labels[2], tokens[2][i, b])\n",
    "                for j in [4]\n",
    "                    # when predicting masked ratings, dont use status metadata\n",
    "                    tokens[j][i, b] = mask_tokens[j]\n",
    "                end\n",
    "                r = training ? rand(rng) : 0.0\n",
    "                if r < 0.8\n",
    "                    tokens[2][i, b] = mask_tokens[2]\n",
    "                elseif r < 0.9\n",
    "                    tokens[2][i, b] = rand(1:vocab_sizes[2])\n",
    "                end\n",
    "                push!(masked_token_positions[2], (i, b))\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    processed_labels = (labels[1], convert.(Float32, collect(labels[2]')))\n",
    "\n",
    "    tokens, attention_mask, masked_token_positions, processed_labels\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edda391-cb1f-4b4a-ba59-09b825782342",
   "metadata": {},
   "outputs": [],
   "source": [
    "function device(batch)\n",
    "    gpu.(batch[1]), gpu(batch[2]), gpu.(batch[3]), gpu.(batch[4])\n",
    "end\n",
    "\n",
    "function device_free!(batch)\n",
    "    if !CUDA.functional()\n",
    "        return\n",
    "    end\n",
    "    CUDA.unsafe_free!.(batch[1])\n",
    "    CUDA.unsafe_free!(batch[2])\n",
    "    CUDA.unsafe_free!(batch[4][2])\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59101cfb-147f-491b-b48a-e942ddbae8b3",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e58089cb-f5b9-4f7f-80d0-053f0e3d11b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A layer that adds a 1-D vector to the input\n",
    "struct BiasLayer\n",
    "    b::Any\n",
    "end\n",
    "BiasLayer(n::Integer; init = zeros) = BiasLayer(init(Float32, n))\n",
    "(m::BiasLayer)(x) = x .+ m.b\n",
    "Flux.@functor BiasLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888e8ee3-c369-41c8-ba85-267e2757d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "function create_bert(config)\n",
    "    bert = Bert(\n",
    "        config[\"hidden_size\"],\n",
    "        config[\"num_attention_heads\"],\n",
    "        config[\"intermediate_size\"],\n",
    "        config[\"num_hidden_layers\"];\n",
    "        act = config[\"hidden_act\"],\n",
    "        pdrop = config[\"hidden_dropout_prob\"],\n",
    "        attn_pdrop = config[\"attention_probs_dropout_prob\"],\n",
    "    )\n",
    "\n",
    "    item_emb = Embed(config[\"hidden_size\"], config[\"vocab_sizes\"][1])\n",
    "    rating_emb = Embed(config[\"hidden_size\"], config[\"vocab_sizes\"][2])\n",
    "    timestamp_emb = Embed(config[\"hidden_size\"], config[\"vocab_sizes\"][3])\n",
    "    status_emb = Embed(config[\"hidden_size\"], config[\"vocab_sizes\"][4])\n",
    "\n",
    "    position_emb = PositionEmbedding(\n",
    "        config[\"hidden_size\"],\n",
    "        config[\"max_sequence_length\"];\n",
    "        trainable = true,\n",
    "    )\n",
    "\n",
    "    emb_post = Positionwise(\n",
    "        LayerNorm(config[\"hidden_size\"]),\n",
    "        Dropout(config[\"hidden_dropout_prob\"]),\n",
    "    )\n",
    "\n",
    "    emb = CompositeEmbedding(\n",
    "        item = item_emb,\n",
    "        rating = rating_emb,\n",
    "        timestamp = timestamp_emb,\n",
    "        status = status_emb,\n",
    "        position = position_emb,\n",
    "        postprocessor = emb_post,\n",
    "    )\n",
    "\n",
    "    item_cls = (\n",
    "        transform = Chain(\n",
    "            Dense(config[\"hidden_size\"], config[\"hidden_size\"], config[\"hidden_act\"]),\n",
    "            LayerNorm(config[\"hidden_size\"]),\n",
    "        ),\n",
    "        output_bias = BiasLayer(config[\"vocab_sizes\"][1]),\n",
    "    )\n",
    "    rating_cls = Dense(config[\"hidden_size\"], 1)\n",
    "    clf = (item = item_cls, rating = rating_cls)\n",
    "\n",
    "    TransformerModel(emb, bert, clf)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceff79e-2b50-45bb-b89f-4de58c1794a7",
   "metadata": {},
   "source": [
    "# Loss metrics and training utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ca77b1-83ef-4a11-ab46-aad27f8adc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "function masklm_losses(model, batch)\n",
    "    tokens, attention_mask, masked_token_positions, masked_token_labels = batch\n",
    "    X = model.embed(\n",
    "        item = tokens[1],\n",
    "        rating = tokens[2],\n",
    "        timestamp = tokens[3],\n",
    "        status = tokens[4],\n",
    "        position = tokens[1],\n",
    "    )\n",
    "    X = model.transformers(X, attention_mask)\n",
    "\n",
    "    if length(masked_token_labels[1]) > 0\n",
    "        item_pred = logsoftmax(\n",
    "            transpose(model.embed.embeddings.item.embedding) *\n",
    "            model.classifier.item.transform(gather(X, masked_token_positions[1])) .+\n",
    "            model.classifier.item.output_bias.b,\n",
    "        )\n",
    "        item_loss = -mean(gather(item_pred, masked_token_labels[1]))\n",
    "    else\n",
    "        item_loss = 0.0f0\n",
    "    end\n",
    "\n",
    "    if length(masked_token_labels[2]) > 0\n",
    "        rating_pred = model.classifier.rating(gather(X, masked_token_positions[2]))\n",
    "        rating_loss = mean((rating_pred - masked_token_labels[2]) .^ 2)\n",
    "    else\n",
    "        rating_loss = 0.0f0\n",
    "    end\n",
    "\n",
    "    item_loss, rating_loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eca42c-7356-49c2-8cbf-5baf86dec544",
   "metadata": {},
   "outputs": [],
   "source": [
    "function evaluate_metrics(model, sentences, training_config; rng)\n",
    "    sumtotals = [0.0, 0.0]\n",
    "    Random.shuffle!(rng, sentences)\n",
    "    sentence_batches =\n",
    "        collect(Iterators.partition(sentences, training_config[\"batch_size\"]))\n",
    "    @showprogress for sbatch in sentence_batches\n",
    "        batch =\n",
    "            get_batch(\n",
    "                sbatch;\n",
    "                max_seq_len = training_config[\"max_sequence_length\"],\n",
    "                vocab_sizes = training_config[\"vocab_sizes\"],\n",
    "                cls_tokens = training_config[\"cls_tokens\"],\n",
    "                pad_tokens = training_config[\"pad_tokens\"],\n",
    "                mask_tokens = training_config[\"mask_tokens\"],\n",
    "                rng = rng,\n",
    "                training = false,\n",
    "            ) |> device\n",
    "        sumtotals .+= masklm_losses(model, batch)\n",
    "        device_free!(batch)\n",
    "    end\n",
    "    totals = sumtotals ./ length(sentence_batches)\n",
    "    Dict(\"Item Crossentropy Loss\" => totals[1], \"Rating MSE Loss\" => totals[2])\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11599f78-e9c1-48ac-905a-778dc5196d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_epoch!(model, opt, sentences, training_config; rng)\n",
    "    ps = Flux.params(model)\n",
    "    Random.shuffle!(rng, sentences)\n",
    "    sentence_batches =\n",
    "        collect(Iterators.partition(sentences, training_config[\"batch_size\"]))\n",
    "    @showprogress for sbatch in sentence_batches\n",
    "        batch =\n",
    "            get_batch(\n",
    "                sbatch;\n",
    "                max_seq_len = training_config[\"max_sequence_length\"],\n",
    "                vocab_sizes = training_config[\"vocab_sizes\"],\n",
    "                cls_tokens = training_config[\"cls_tokens\"],\n",
    "                pad_tokens = training_config[\"pad_tokens\"],\n",
    "                mask_tokens = training_config[\"mask_tokens\"],\n",
    "                rng = rng,\n",
    "                training = true,\n",
    "            ) |> device\n",
    "        grads = Flux.gradient(ps) do\n",
    "            sum(masklm_losses(model, batch))\n",
    "        end\n",
    "        Flux.Optimise.update!(opt, ps, grads)\n",
    "        device_free!(batch)\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853e8f81-f292-4cac-8c51-9fca12fc4eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function checkpoint(\n",
    "    model,\n",
    "    opt,\n",
    "    sentences,\n",
    "    training_config,\n",
    "    model_config,\n",
    "    epoch;\n",
    "    rng,\n",
    "    outdir,\n",
    ")\n",
    "    @info \"evaluating metrics\"\n",
    "    metrics = evaluate_metrics(model, sentences, training_config; rng = rng)\n",
    "    write_params(\n",
    "        Dict(\n",
    "            \"m\" => cpu(model),\n",
    "            \"opt\" => opt,\n",
    "            \"epoch\" => epoch,\n",
    "            \"metrics\" => metrics,\n",
    "            \"training_config\" => training_config,\n",
    "            \"model_config\" => model_config,\n",
    "        ),\n",
    "        \"$name/checkpoints/$epoch\",\n",
    "    )\n",
    "    @info \"saving model after $epoch epochs with metrics $metrics\"\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003c6f05-765d-42fd-9793-075ece765284",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805ac800-38d2-4ed9-9963-05c176baef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function set_rngs(seed)\n",
    "    rng = Random.Xoshiro(seed)\n",
    "    Random.seed!(rand(rng, UInt64))\n",
    "    if CUDA.functional()\n",
    "        Random.seed!(CUDA.default_rng(), rand(rng, UInt64))\n",
    "        Random.seed!(CUDA.CURAND.default_rng(), rand(rng, UInt64))\n",
    "    end\n",
    "    rng\n",
    "end\n",
    "\n",
    "rng = set_rngs(20221221);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6629bd-de28-48fb-842f-4a0d132f5d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences = get_training_data()\n",
    "Random.shuffle!(rng, sentences)\n",
    "cutoff = Int(round(0.95 * length(sentences)))\n",
    "training_sentences = sentences[1:cutoff]\n",
    "validation_sentences = sentences[cutoff+1:end];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4c94fc-f731-4bc9-8e7f-8af2e7693d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_vocab_sizes =\n",
    "    convert.(Int32, (num_items(), 12, Int(ceil(1 / year_in_timestamp_units())) + 2, 5))\n",
    "training_config = Dict(\n",
    "    \"base_vocab_sizes\" => base_vocab_sizes,\n",
    "    \"cls_tokens\" => base_vocab_sizes .+ 1,\n",
    "    \"pad_tokens\" => base_vocab_sizes .+ 2,\n",
    "    \"mask_tokens\" => base_vocab_sizes .+ 3,\n",
    "    \"sep_tokens\" => base_vocab_sizes .+ 4,\n",
    "    \"vocab_sizes\" => base_vocab_sizes .+ 4,\n",
    "    \"batch_size\" => 128,\n",
    "    \"max_sequence_length\" => 512,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ed5c2b-6543-42c9-a8c5-8b3b7b31d0e4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# check that vocab sizes are correct\n",
    "@tprogress Threads.@threads for i = 1:length(sentences)\n",
    "    for word in sentences[i]\n",
    "        @assert all((word .>= 1) .&& (word .<= base_vocab_sizes)) word\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ddbc3-30a6-4281-985b-5b62fd2d1acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "function create_model_config(layers, hidden_size, training_config)\n",
    "    # follows the recipe in Section 5 of [Well-Read Students Learn Better: On the \n",
    "    # Importance of Pre-training Compact Models](https://arxiv.org/pdf/1908.08962.pdf)\n",
    "    Dict(\n",
    "        \"attention_probs_dropout_prob\" => 0.1,\n",
    "        \"hidden_act\" => gelu,\n",
    "        \"num_hidden_layers\" => layers,\n",
    "        \"hidden_size\" => hidden_size,\n",
    "        \"max_sequence_length\" => training_config[\"max_sequence_length\"],\n",
    "        \"vocab_sizes\" => training_config[\"vocab_sizes\"],\n",
    "        \"num_attention_heads\" => Int(hidden_size / 64),\n",
    "        \"hidden_dropout_prob\" => 0.1,\n",
    "        \"intermediate_size\" => hidden_size * 4,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5a3e39-57a2-4734-b19b-f0260c695c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function load_from_checkpoint(::Nothing)\n",
    "    # todo schedule learning rate warmup and decay\n",
    "    opt = ADAMW(1e-4, (0.9, 0.999), 1e-4 * 0.01)\n",
    "    model_config = create_model_config(4, 512, training_config)\n",
    "    ryouko = create_bert(model_config) |> gpu\n",
    "    ryouko, opt, model_config, 0\n",
    "end\n",
    "\n",
    "function load_from_checkpoint(epoch::Integer)\n",
    "    params = read_params(\"$name/checkpoints/$epoch\")\n",
    "    ryouko = params[\"m\"] |> gpu\n",
    "    opt = params[\"opt\"]\n",
    "    model_config = params[\"model_config\"]\n",
    "    ryouko, opt, model_config, epoch\n",
    "end\n",
    "\n",
    "ryouko, opt, model_config, start_epoch = load_from_checkpoint(nothing);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec648853-aed9-4173-980d-a9adb0a2966c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@info \"Training model with $(sum(length, Flux.params(ryouko))) parameters\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fddb24-071b-4898-8874-7b95e41871e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for epoch = start_epoch:100\n",
    "    checkpoint(ryouko, opt, validation_sentences, training_config, model_config, epoch; rng=rng, outdir=name)\n",
    "    train_epoch!(ryouko, opt, training_sentences, training_config; rng=rng)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

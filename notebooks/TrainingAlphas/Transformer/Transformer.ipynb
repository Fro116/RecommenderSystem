{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec9e3dd-c524-405d-a797-18f33b7c08af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import CUDA\n",
    "import Flux\n",
    "import Flux: Chain, Dense, Dropout, LayerNorm, cpu, gelu, gpu, logsoftmax\n",
    "import Flux.NNlib: gather\n",
    "import Functors: @functor\n",
    "import Optimisers\n",
    "import Optimisers: OptimiserChain, Adam, WeightDecay\n",
    "import ParameterSchedulers\n",
    "import ParameterSchedulers: Sequence, Triangle, Shifted, Stateful\n",
    "import Random\n",
    "import StatsBase: mean, sample\n",
    "import Transformers: Bert, Positionwise, TransformerModel\n",
    "import Transformers.Basic: CompositeEmbedding, Embed, PositionEmbedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ad5e3d-1b8e-4599-9dae-100fa69a398c",
   "metadata": {},
   "source": [
    "# Model Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928e184d-512f-4638-bd73-97c88d62e79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A layer that adds a 1-D vector to the input\n",
    "struct BiasLayer\n",
    "    b::Any\n",
    "end\n",
    "BiasLayer(n::Integer; init = zeros) = BiasLayer(init(Float32, n))\n",
    "(m::BiasLayer)(x) = x .+ m.b\n",
    "@functor BiasLayer;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1560541-3e42-4305-bd31-841a27365742",
   "metadata": {},
   "outputs": [],
   "source": [
    "(pe::PositionEmbedding)(x::AbstractArray{X}) where {X<:Integer} = pe(size(x, 1));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968aac9b-c224-47f3-af4a-b3aec74d1197",
   "metadata": {},
   "source": [
    "# Data Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24fe0b7-abea-44e9-86e1-551b10887071",
   "metadata": {},
   "outputs": [],
   "source": [
    "function encode_word(item, rating, timestamp, status, completion, user)\n",
    "    if timestamp == -1\n",
    "        ts = 1\n",
    "    else\n",
    "        date = timestamp_to_date(timestamp)\n",
    "        year = Dates.value(Dates.Year(date)) - 2004\n",
    "        season = div(Dates.value(Dates.Month(date)) - 1, 4) + 1\n",
    "        ts = 1 + year * 4 + season\n",
    "    end\n",
    "    r = Int32(round(rating)) + 1\n",
    "    c = Int32(round(10 * completion)) + 1\n",
    "    word = (item, r, ts, status, c, user)\n",
    "    convert.(Int32, word)\n",
    "end\n",
    "\n",
    "function get_training_data(task, include_ptw; show_progress_bar = false)\n",
    "    function get_df(task, content)\n",
    "        df = get_raw_split(\"training\", task, content)\n",
    "        if content != \"explicit\"\n",
    "            df.rating .= 11\n",
    "        end\n",
    "        df\n",
    "    end\n",
    "\n",
    "    contents = [\"explicit\", \"implicit\"]\n",
    "    if include_ptw\n",
    "        push!(contents, \"ptw\")\n",
    "    end\n",
    "    sentences = Dict{Int32,Vector{NTuple{6,Int32}}}()\n",
    "    df = reduce(cat, [get_df(task, content) for content in contents])\n",
    "    order = sortperm(df.timestamp)\n",
    "    p = ProgressMeter.Progress(length(order); enabled = show_progress_bar, showspeed = true)\n",
    "    for idx = 1:length(order)\n",
    "        i = order[idx]\n",
    "        if df.user[i] âˆ‰ keys(sentences)\n",
    "            sentences[df.user[i]] = NTuple{6,Int32}[]\n",
    "        end\n",
    "        word = encode_word(\n",
    "            df.item[i],\n",
    "            df.rating[i],\n",
    "            df.timestamp[i],\n",
    "            df.status[i],\n",
    "            df.completion[i],\n",
    "            df.user[i],\n",
    "        )\n",
    "        push!(sentences[df.user[i]], word)\n",
    "        ProgressMeter.next!(p)\n",
    "    end\n",
    "    ProgressMeter.finish!(p)\n",
    "    sentences\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0dee12-3522-4229-9a06-599065e9876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function pad_sentence(sentence, max_seq_length, cls_tokens, pad_tokens; rng)\n",
    "    outputs = fill.(pad_tokens, max_seq_length)\n",
    "    for i = 1:length(outputs)\n",
    "        outputs[i][1] = cls_tokens[i]\n",
    "    end\n",
    "    seq_len = max_seq_length - 1\n",
    "    if length(sentence) > seq_len\n",
    "        # take a random contiguous subset\n",
    "        idx = rand(rng, 1:length(sentence)-seq_len+1)\n",
    "        sentence = sentence[idx:idx+seq_len-1]\n",
    "    end\n",
    "    for i = 1:length(sentence)\n",
    "        for j = 1:length(outputs)\n",
    "            outputs[j][1+i] = sentence[i][j]\n",
    "        end\n",
    "    end\n",
    "    outputs\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03e6636-5847-4eb1-8b9b-ffcceda9f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_token_ids(sentences, max_seq_length, cls_tokens, pad_tokens; rng)\n",
    "    padded_sentences = [\n",
    "        pad_sentence(x, max_seq_length, cls_tokens, pad_tokens; rng = rng) for\n",
    "        x in sentences\n",
    "    ]\n",
    "    Tuple(hcat([x[i] for x in padded_sentences]...) for i = 1:length(cls_tokens))\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dec9e3dd-c524-405d-a797-18f33b7c08af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import CUDA\n",
    "import Flux\n",
    "import Flux: Chain, Dense, Dropout, LayerNorm, cpu, gelu, gpu, logsoftmax\n",
    "import Flux.NNlib: gather\n",
    "import Functors: @functor\n",
    "import NNlibCUDA\n",
    "import Optimisers\n",
    "import Optimisers: Adam, OptimiserChain, WeightDecay\n",
    "import ParameterSchedulers\n",
    "import ParameterSchedulers: Sequence, Triangle, Shifted, Stateful\n",
    "import Random\n",
    "import StatsBase: mean, sample\n",
    "import Transformers: Bert, Positionwise, TransformerModel\n",
    "import Transformers.Basic: AbstractEmbed, CompositeEmbedding, Embed, Transformer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722355ff-67aa-45f9-aa7a-22df5b509382",
   "metadata": {},
   "source": [
    "# CUDA Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07027490-db68-424b-8d5f-86ab829b3211",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUDA.math_mode!(CUDA.FAST_MATH; precision = :BFloat16)\n",
    "NNlibCUDA.softmaxalgo() = NNlibCUDA.CUDNN_SOFTMAX_ACCURATE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad73e835-a25e-4bcf-8560-9df24f7276ae",
   "metadata": {},
   "source": [
    "# Transformer Architecture Overrides"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85eeeeba-83eb-43a5-b764-6c459719c586",
   "metadata": {},
   "outputs": [],
   "source": [
    "function (bert::Bert)(x::T, mask) where {T}\n",
    "    e = bert.drop(x)\n",
    "    t, _ = bert.ts(e, mask)\n",
    "    t\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddef1e88-8a6e-4fcc-ab7d-e7d3c8156265",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do pre layer normalization\n",
    "function (t::Transformer)(\n",
    "    x::A,\n",
    "    mask = nothing,\n",
    ") where {T,N,A<:AbstractArray{T,N}}\n",
    "    dropout = t.drop\n",
    "    a = t.mhn(x)\n",
    "    a = t.mh(a, a, a; mask = mask)\n",
    "    a = dropout(a)\n",
    "    res_a = x + a\n",
    "    pwffn = t.pwn(res_a)\n",
    "    pwffn = t.pw(pwffn)\n",
    "    pwffn = dropout(pwffn)\n",
    "    res_pwffn = res_a + pwffn\n",
    "    res_pwffn\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ad5e3d-1b8e-4599-9dae-100fa69a398c",
   "metadata": {},
   "source": [
    "# Model Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928e184d-512f-4638-bd73-97c88d62e79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct BiasLayer\n",
    "    b::Any\n",
    "end\n",
    "BiasLayer(n::Integer; init = zeros) = BiasLayer(init(Float32, n))\n",
    "(m::BiasLayer)(x) = x .+ m.b\n",
    "@functor BiasLayer;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e226881a-8a9c-44d2-a947-85d0ece2e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct ContinuousEmbed <: AbstractEmbed{Float32}\n",
    "    embedding::Any\n",
    "end\n",
    "@functor ContinuousEmbed\n",
    "ContinuousEmbed(hidden_size::Int) = ContinuousEmbed(\n",
    "    Chain(\n",
    "        Dense(1, div(hidden_size, 64), gelu),\n",
    "        Dense(div(hidden_size, 64), hidden_size),\n",
    "    ),\n",
    ")\n",
    "(e::ContinuousEmbed)(x) = e.embedding(reshape(x, (1, size(x)...)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c896748f-3732-4b3b-b5a9-4397d040cdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "function tuplesum(a::NamedTuple, b::NamedTuple)\n",
    "    fields = fieldnames(typeof(a))\n",
    "    NamedTuple{fields}(tuplesum(a[k], b[k]) for k in fields)\n",
    "end\n",
    "tuplesum(a::Tuple, b::Tuple) = Tuple(tuplesum(a[k], b[k]) for k = 1:length(a))\n",
    "tuplesum(a::Nothing, b) = b\n",
    "tuplesum(a, b) = a + b;\n",
    "\n",
    "function tupledivide(a::NamedTuple, d)\n",
    "    fields = fieldnames(typeof(a))\n",
    "    NamedTuple{fields}(tupledivide(a[k], d) for k in fields)\n",
    "end\n",
    "tupledivide(a::Tuple, d) = Tuple(tupledivide(a[k], d) for k = 1:length(a))\n",
    "tupledivide(a::Nothing, d) = nothing\n",
    "tupledivide(a, d) = a ./ d;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968aac9b-c224-47f3-af4a-b3aec74d1197",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "914f8396-3c67-439e-bfc6-77926bf2424b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO named tuples\n",
    "# item, rating, timestamp, status, completion, user, position\n",
    "const word_type = Tuple{Int32, Float32, Float32, Int32, Float32, Int32, Int32}\n",
    "replace_user(word::word_type, user::Int32) = (word[1:5]..., user, word[7])\n",
    "replace_position(word::word_type, position::Int32) = (word[1:6]..., position)\n",
    "replace_timestamp(word, timestamp) = (word[1:2]..., timestamp, word[4:end]...)\n",
    "is_ptw(word::word_type) = word[4] == 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f24fe0b7-abea-44e9-86e1-551b10887071",
   "metadata": {},
   "outputs": [],
   "source": [
    "function encode_word(item, rating, timestamp, status, completion, user, position)\n",
    "    word = (item, rating, timestamp, status, completion, user, position)\n",
    "    convert(word_type, word)\n",
    "end\n",
    "\n",
    "function get_training_data(task, include_ptw, cls_tokens; show_progress_bar = false)\n",
    "    function get_df(task, content)\n",
    "        df = get_raw_split(\"training\", task, content)\n",
    "        if content != \"explicit\"\n",
    "            df.rating .= 11\n",
    "        end\n",
    "        df\n",
    "    end\n",
    "\n",
    "    contents = [\"explicit\", \"implicit\"]\n",
    "    if include_ptw\n",
    "        push!(contents, \"ptw\")\n",
    "    end\n",
    "    sentences = Dict{Int32,Vector{word_type}}()\n",
    "    df = reduce(cat, [get_df(task, content) for content in contents])\n",
    "    order = sortperm(df.timestamp)\n",
    "    p = ProgressMeter.Progress(length(order); enabled = show_progress_bar, showspeed = true)\n",
    "    for idx = 1:length(order)\n",
    "        i = order[idx]\n",
    "        if df.user[i] âˆ‰ keys(sentences)\n",
    "            sentences[df.user[i]] = [replace_user(cls_tokens, df.user[i])]\n",
    "        end\n",
    "        word = encode_word(\n",
    "            df.item[i],\n",
    "            df.rating[i],\n",
    "            df.timestamp[i],\n",
    "            df.status[i],\n",
    "            df.completion[i],\n",
    "            df.user[i],\n",
    "            length(sentences[df.user[i]]),\n",
    "        )\n",
    "        push!(sentences[df.user[i]], word)\n",
    "        ProgressMeter.next!(p)\n",
    "    end\n",
    "    ProgressMeter.finish!(p)\n",
    "    sentences\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cae57da-8caa-4e94-a4be-f34b172680ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "function subset_sentence(sentence, max_seq_length; recent, rng)\n",
    "    if length(sentence) > max_seq_length\n",
    "        if recent\n",
    "            # keep the rightmost entries\n",
    "            idx = length(sentence)-max_seq_length+1\n",
    "        else\n",
    "            # take a random contiguous subset            \n",
    "            idx = rand(rng, 1:length(sentence)-max_seq_length+1)\n",
    "        end\n",
    "        sentence = sentence[idx:idx+max_seq_length-1]\n",
    "    end\n",
    "    sentence\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee0dee12-3522-4229-9a06-599065e9876d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function pad_sentence(sentence, max_seq_length, max_position, pad_tokens, cls_tokens; rng)\n",
    "    outputs = fill.(pad_tokens, max_seq_length)\n",
    "    sentence = subset_sentence(sentence, max_seq_length; recent = false, rng = rng)\n",
    "    for i = 1:length(sentence)\n",
    "        for j = 1:length(outputs)\n",
    "            if j == 7 && sentence[i][1] != cls_tokens[1]\n",
    "                p = (sentence[i][j] % max_position)\n",
    "                if p == 0\n",
    "                    p = 1\n",
    "                end\n",
    "                outputs[j][i] = p\n",
    "            else\n",
    "                outputs[j][i] = sentence[i][j]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    outputs\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03e6636-5847-4eb1-8b9b-ffcceda9f9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_token_ids(sentences, max_seq_length, max_position, pad_tokens, cls_tokens; rng)\n",
    "    padded_sentences = [\n",
    "        pad_sentence(x, max_seq_length, max_position, pad_tokens, cls_tokens; rng = rng) for x in sentences\n",
    "    ]\n",
    "    Tuple(hcat([x[i] for x in padded_sentences]...) for i = 1:length(pad_tokens))\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

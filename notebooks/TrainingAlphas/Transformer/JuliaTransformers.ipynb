{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "327c8376-2d03-4c69-a07d-0ba71801ec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"all/Transformer\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d90afc10-1ae5-4665-937e-d58a5859ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"../Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3184e0c-d01a-4b83-aa3f-7908fc378b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: method definition for CuArray at /home/kundan/.julia/packages/PrimitiveOneHot/M7M4C/src/gpu.jl:29 declares type variable A but does not use it.\n",
      "WARNING: method definition for CuArray at /home/kundan/.julia/packages/PrimitiveOneHot/M7M4C/src/gpu.jl:29 declares type variable N+1 but does not use it.\n",
      "WARNING: method definition for CuArray at /home/kundan/.julia/packages/PrimitiveOneHot/M7M4C/src/gpu.jl:29 declares type variable K but does not use it.\n"
     ]
    }
   ],
   "source": [
    "using Flux\n",
    "using Transformers\n",
    "using Transformers.Basic\n",
    "import CUDA\n",
    "import Random\n",
    "import StatsBase: mean, sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b924da24-7c19-45a8-bed0-de97e886c818",
   "metadata": {},
   "source": [
    "# Tokenize training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1390be71-9ece-4b82-a6c7-d4eb41d3c3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_training_data()\n",
    "    function get_df(task, content)\n",
    "        df = get_raw_split(\"training\", task, content)\n",
    "        if content == \"implicit\"\n",
    "            df.rating .= 11\n",
    "        end\n",
    "        df\n",
    "    end\n",
    "\n",
    "    sentences = Dict{Int32,Vector{Tuple{Int32,Int32,Int32,Int32}}}()\n",
    "    for task in ALL_TASKS\n",
    "        df = cat(get_df(task, \"explicit\"), get_df(task, \"implicit\"))\n",
    "        order = sortperm(df.timestamp)\n",
    "        @showprogress for idx = 1:length(order)\n",
    "            i = order[idx]\n",
    "            if df.user[i] ∉ keys(sentences)\n",
    "                sentences[df.user[i]] = Int32[]\n",
    "            end\n",
    "            if df.timestamp[i] == -1\n",
    "                ts = 1\n",
    "            else\n",
    "                ts = Int32(round(df.timestamp[i] / year_in_timestamp_units())) + 2\n",
    "            end\n",
    "            r = Int32(round(df.rating[i])) + 1\n",
    "            word = convert.(Int32, (df.item[i], r, ts, df.status[i]))\n",
    "            push!(sentences[df.user[i]], word)\n",
    "        end\n",
    "    end\n",
    "    [sentences[k] for k in keys(sentences)]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8227aee2-8a2f-4932-bae2-38c951404415",
   "metadata": {},
   "outputs": [],
   "source": [
    "function pad_sentence(sentence, max_seq_length, cls_tokens, pad_tokens; rng)\n",
    "    outputs = fill.(pad_tokens, max_seq_length)\n",
    "    for i = 1:length(outputs)\n",
    "        outputs[i][1] = cls_tokens[i]\n",
    "    end\n",
    "    seq_len = max_seq_length - 1\n",
    "    if length(sentence) > seq_len\n",
    "        # take a random contiguous subset\n",
    "        idx = rand(rng, 1:length(sentence)-seq_len)\n",
    "        sentence = sentence[idx:idx+seq_len-1]\n",
    "    end\n",
    "    for i = 1:length(sentence)\n",
    "        for j = 1:length(outputs)\n",
    "            outputs[j][1+i] = sentence[i][j]\n",
    "        end\n",
    "    end\n",
    "    outputs\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "703ab7e5-b47f-42e7-a117-522a8d165b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_token_ids(sentences, max_seq_length, cls_tokens, pad_tokens; rng)\n",
    "    padded_sentences = [\n",
    "        pad_sentence(x, max_seq_length, cls_tokens, pad_tokens; rng = rng) for\n",
    "        x in sentences\n",
    "    ]\n",
    "    Tuple(hcat([x[i] for x in padded_sentences]...) for i = 1:length(cls_tokens))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9b524c73-58a0-4c31-9ff0-48f81eb0fa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_batch(\n",
    "    sentences;\n",
    "    max_seq_len,\n",
    "    vocab_sizes,\n",
    "    cls_tokens,\n",
    "    pad_tokens,\n",
    "    mask_tokens,\n",
    "    rng,\n",
    "    training,\n",
    ")\n",
    "    # dynamically pad to the largest sequence length\n",
    "    seq_len = min(maximum(length.(sentences)) + 1, max_seq_len)\n",
    "\n",
    "    # get tokenized sentences\n",
    "    tokens = get_token_ids(sentences, seq_len, cls_tokens, pad_tokens; rng = rng)\n",
    "\n",
    "    # don't attend to padding tokens\n",
    "    attention_mask = reshape(\n",
    "        convert.(Float32, tokens[1] .!= pad_tokens[1]),\n",
    "        (1, seq_len, length(sentences)),\n",
    "    )\n",
    "\n",
    "    # apply BERT masking\n",
    "    masked_token_positions = ([], [])\n",
    "    labels = ([], [])\n",
    "    for b = 1:length(sentences)\n",
    "        seq_len = Int(sum(attention_mask[:, :, b]))\n",
    "        for i = 2:seq_len\n",
    "            mask_item = rand(rng) < 0.15\n",
    "            mask_rating = rand(rng) < 0.15\n",
    "\n",
    "            if mask_item\n",
    "                push!(labels[1], (tokens[1][i, b], length(labels[1]) + 1))\n",
    "                for j in [2, 4]\n",
    "                    # when predicting masked items, dont use rating or status metadata\n",
    "                    tokens[j][i, b] = mask_tokens[j]\n",
    "                end\n",
    "                r = training ? rand(rng) : 0.0\n",
    "                if r < 0.8\n",
    "                    tokens[1][i, b] = mask_tokens[1]\n",
    "                elseif r < 0.9\n",
    "                    tokens[1][i, b] = rand(1:vocab_sizes[1])\n",
    "                end\n",
    "                push!(masked_token_positions[1], (i, b))\n",
    "            end\n",
    "\n",
    "            if mask_rating && !mask_item && (tokens[2][i, b] != vocab_sizes[2])\n",
    "                # only try to predict explicit ratings\n",
    "                push!(labels[2], tokens[2][i, b])\n",
    "                for j in [4]\n",
    "                    # when predicting masked ratings, dont use status metadata\n",
    "                    tokens[j][i, b] = mask_tokens[j]\n",
    "                end\n",
    "                r = training ? rand(rng) : 0.0\n",
    "                if r < 0.8\n",
    "                    tokens[2][i, b] = mask_tokens[2]\n",
    "                elseif r < 0.9\n",
    "                    tokens[2][i, b] = rand(1:vocab_sizes[2])\n",
    "                end\n",
    "                push!(masked_token_positions[2], (i, b))\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    processed_labels = (labels[1], convert.(Float32, collect(labels[2]')))\n",
    "\n",
    "    tokens, attention_mask, masked_token_positions, processed_labels\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4edda391-cb1f-4b4a-ba59-09b825782342",
   "metadata": {},
   "outputs": [],
   "source": [
    "function device(batch)\n",
    "    gpu.(batch[1]), gpu(batch[2]), gpu.(batch[3]), gpu.(batch[4])\n",
    "end\n",
    "\n",
    "function device_free!(batch)\n",
    "    if !CUDA.functional()\n",
    "        return\n",
    "    end\n",
    "    CUDA.unsafe_free!.(batch[1])\n",
    "    CUDA.unsafe_free!(batch[2])\n",
    "    CUDA.unsafe_free!(batch[4][2])\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59101cfb-147f-491b-b48a-e942ddbae8b3",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e58089cb-f5b9-4f7f-80d0-053f0e3d11b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A layer that adds a 1-D vector to the input\n",
    "struct BiasLayer\n",
    "    b::Any\n",
    "end\n",
    "BiasLayer(n::Integer; init = zeros) = BiasLayer(init(Float32, n))\n",
    "(m::BiasLayer)(x) = x .+ m.b\n",
    "Flux.@functor BiasLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "888e8ee3-c369-41c8-ba85-267e2757d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "function create_bert(config)\n",
    "    bert = Bert(\n",
    "        config[\"hidden_size\"],\n",
    "        config[\"num_attention_heads\"],\n",
    "        config[\"intermediate_size\"],\n",
    "        config[\"num_hidden_layers\"];\n",
    "        act = config[\"hidden_act\"],\n",
    "        pdrop = config[\"hidden_dropout_prob\"],\n",
    "        attn_pdrop = config[\"attention_probs_dropout_prob\"],\n",
    "    )\n",
    "\n",
    "    item_emb = Embed(config[\"hidden_size\"], config[\"vocab_sizes\"][1])\n",
    "    rating_emb = Embed(config[\"hidden_size\"], config[\"vocab_sizes\"][2])\n",
    "    timestamp_emb = Embed(config[\"hidden_size\"], config[\"vocab_sizes\"][3])\n",
    "    status_emb = Embed(config[\"hidden_size\"], config[\"vocab_sizes\"][4])\n",
    "\n",
    "    position_emb = PositionEmbedding(\n",
    "        config[\"hidden_size\"],\n",
    "        config[\"max_sequence_length\"];\n",
    "        trainable = true,\n",
    "    )\n",
    "\n",
    "    emb_post = Positionwise(\n",
    "        LayerNorm(config[\"hidden_size\"]),\n",
    "        Dropout(config[\"hidden_dropout_prob\"]),\n",
    "    )\n",
    "\n",
    "    emb = CompositeEmbedding(\n",
    "        item = item_emb,\n",
    "        rating = rating_emb,\n",
    "        timestamp = timestamp_emb,\n",
    "        status = status_emb,\n",
    "        position = position_emb,\n",
    "        postprocessor = emb_post,\n",
    "    )\n",
    "\n",
    "    item_cls = (\n",
    "        transform = Chain(\n",
    "            Dense(config[\"hidden_size\"], config[\"hidden_size\"], config[\"hidden_act\"]),\n",
    "            LayerNorm(config[\"hidden_size\"]),\n",
    "        ),\n",
    "        output_bias = BiasLayer(config[\"vocab_sizes\"][1]),\n",
    "    )\n",
    "    rating_cls = Dense(config[\"hidden_size\"], 1)\n",
    "    clf = (item = item_cls, rating = rating_cls)\n",
    "\n",
    "    TransformerModel(emb, bert, clf)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceff79e-2b50-45bb-b89f-4de58c1794a7",
   "metadata": {},
   "source": [
    "# Loss metrics and training utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e4ca77b1-83ef-4a11-ab46-aad27f8adc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "function masklm_losses(model, batch)\n",
    "    tokens, attention_mask, masked_token_positions, masked_token_labels = batch\n",
    "    X = model.embed(\n",
    "        item = tokens[1],\n",
    "        rating = tokens[2],\n",
    "        timestamp = tokens[3],\n",
    "        status = tokens[4],\n",
    "        position = tokens[1],\n",
    "    )\n",
    "    X = model.transformers(X, attention_mask)\n",
    "\n",
    "    if length(masked_token_labels[1]) > 0\n",
    "        item_pred = logsoftmax(\n",
    "            transpose(model.embed.embeddings.item.embedding) *\n",
    "            model.classifier.item.transform(gather(X, masked_token_positions[1])) .+\n",
    "            model.classifier.item.output_bias.b,\n",
    "        )\n",
    "        item_loss = -mean(gather(item_pred, masked_token_labels[1]))\n",
    "    else\n",
    "        item_loss = 0.0f0\n",
    "    end\n",
    "\n",
    "    if length(masked_token_labels[2]) > 0\n",
    "        rating_pred = model.classifier.rating(gather(X, masked_token_positions[2]))\n",
    "        rating_loss = mean((rating_pred - masked_token_labels[2]) .^ 2)\n",
    "    else\n",
    "        rating_loss = 0.0f0\n",
    "    end\n",
    "\n",
    "    item_loss, rating_loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b1eca42c-7356-49c2-8cbf-5baf86dec544",
   "metadata": {},
   "outputs": [],
   "source": [
    "function evaluate_metrics(model, sentences, training_config; rng = Random.GLOBAL_RNG)\n",
    "    sumtotals = [0.0, 0.0]\n",
    "    Random.shuffle!(rng, sentences)\n",
    "    sentence_batches =\n",
    "        collect(Iterators.partition(sentences, training_config[\"batch_size\"]))\n",
    "    @showprogress for sbatch in sentence_batches\n",
    "        batch =\n",
    "            get_batch(\n",
    "                sbatch;\n",
    "                max_seq_len = training_config[\"max_sequence_length\"],\n",
    "                vocab_sizes = training_config[\"vocab_sizes\"],\n",
    "                cls_tokens = training_config[\"cls_tokens\"],\n",
    "                pad_tokens = training_config[\"pad_tokens\"],\n",
    "                mask_tokens = training_config[\"mask_tokens\"],\n",
    "                rng = rng,\n",
    "                training = false,\n",
    "            ) |> device\n",
    "        sumtotals .+= masklm_losses(model, batch)\n",
    "        device_free!(batch)\n",
    "    end\n",
    "    totals = sumtotals ./ length(sentence_batches)\n",
    "    Dict(\"Item Crossentropy Loss\" => totals[1], \"Rating MSE Loss\" => totals[2])\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11599f78-e9c1-48ac-905a-778dc5196d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_epoch!(model, opt, sentences, training_config; rng = Random.GLOBAL_RNG)\n",
    "    ps = Flux.params(model)\n",
    "    Random.shuffle!(rng, sentences)\n",
    "    sentence_batches =\n",
    "        collect(Iterators.partition(sentences, training_config[\"batch_size\"]))\n",
    "    @showprogress for sbatch in sentence_batches\n",
    "        batch =\n",
    "            get_batch(\n",
    "                sbatch;\n",
    "                max_seq_len = training_config[\"max_sequence_length\"],\n",
    "                vocab_sizes = training_config[\"vocab_sizes\"],\n",
    "                cls_tokens = training_config[\"cls_tokens\"],\n",
    "                pad_tokens = training_config[\"pad_tokens\"],\n",
    "                mask_tokens = training_config[\"mask_tokens\"],\n",
    "                rng = rng,\n",
    "                training = true,\n",
    "            ) |> device\n",
    "        grads = Flux.gradient(ps) do\n",
    "            sum(masklm_losses(model, batch))\n",
    "        end\n",
    "        Flux.Optimise.update!(opt, ps, grads)\n",
    "        device_free!(batch)\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "853e8f81-f292-4cac-8c51-9fca12fc4eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function checkpoint(model, opt, sentences, training_config, epochs)\n",
    "    @info \"evaluating metrics\"\n",
    "    metrics = evaluate_metrics(model, sentences, training_config)\n",
    "    write_params(\n",
    "        Dict(\"m\" => cpu(model), \"opt\" => opt, \"epochs\" => epochs, \"metrics\" => metrics),\n",
    "        \"all/Transformer/checkpoints/$epochs\",\n",
    "    )\n",
    "    @info \"saving model after $epochs epochs with metrics $metrics\"\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "003c6f05-765d-42fd-9793-075ece765284",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ae6629bd-de28-48fb-842f-4a0d132f5d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:04:34\u001b[39m[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:06:22\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:06:03\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "Random.seed!(20221221);\n",
    "sentences = get_training_data()\n",
    "Random.shuffle!(sentences)\n",
    "cutoff = Int(round(0.95 * length(sentences)))\n",
    "training_sentences = sentences[1:cutoff]\n",
    "validation_sentences = sentences[cutoff+1:end];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fb4c94fc-f731-4bc9-8e7f-8af2e7693d73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:53 ( 0.26 ms/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "base_vocab_sizes =\n",
    "    convert.(Int32, (num_items(), 12, Int(ceil(1 / year_in_timestamp_units())) + 2, 5))\n",
    "training_config = Dict(\n",
    "    \"base_vocab_sizes\" => base_vocab_sizes,\n",
    "    \"cls_tokens\" => base_vocab_sizes .+ 1,\n",
    "    \"pad_tokens\" => base_vocab_sizes .+ 2,\n",
    "    \"mask_tokens\" => base_vocab_sizes .+ 3,\n",
    "    \"sep_tokens\" => base_vocab_sizes .+ 4,\n",
    "    \"vocab_sizes\" => base_vocab_sizes .+ 4,\n",
    "    \"batch_size\" => 8,\n",
    "    \"max_sequence_length\" => 512,\n",
    ")\n",
    "\n",
    "@tprogress Threads.@threads for i = 1:length(sentences)\n",
    "    for word in sentences[i]\n",
    "        @assert all((word .>= 1) .&& (word .<= base_vocab_sizes)) word\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d26ddbc3-30a6-4281-985b-5b62fd2d1acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 768\n",
    "ryouko_config = Dict(\n",
    "    \"attention_probs_dropout_prob\" => 0.1,\n",
    "    \"hidden_act\" => gelu,\n",
    "    \"num_hidden_layers\" => 2, # reduce the number of hidden layer for faster training\n",
    "    \"hidden_size\" => hidden_size,\n",
    "    \"max_sequence_length\" => training_config[\"max_sequence_length\"],\n",
    "    \"vocab_sizes\" => training_config[\"vocab_sizes\"],\n",
    "    \"num_attention_heads\" => 12,\n",
    "    \"hidden_dropout_prob\" => 0.1,\n",
    "    \"intermediate_size\" => hidden_size * 4,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17dce734-75a0-41c4-8dd7-5da2d2730774",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ADAMW(1e-4, (0.9, 0.999), 1e-4 * 0.01); # defaults taken from the BERT paper\n",
    "# todo learning rate scheduling warmup and decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "98fdd3f2-2dfe-40d5-b486-a4db32124937",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ryouko = create_bert(ryouko_config) |> gpu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "34fddb24-071b-4898-8874-7b95e41871e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for epoch = 1:100\n",
    "#     try\n",
    "#         checkpoint(ryouko, validation_sentences, training_config, epoch)\n",
    "#         train_epoch!(ryouko, opt, training_sentences, training_config)\n",
    "#     catch e\n",
    "#         @info \"ERROR\"\n",
    "#         @info e\n",
    "#         break\n",
    "#     end\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ea3a9e0-9f40-4940-b758-73799ca1fee3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TransformerModel{Bert}(\n",
       "  embed = CompositeEmbedding(item = Embed(scale=1.0, 768), rating = Embed(scale=1.0, 768), timestamp = Embed(scale=1.0, 768), status = Embed(scale=1.0, 768), position = PositionEmbedding(768, max_len=512), postprocessor = Positionwise(LayerNorm(768), Dropout(0.1))),\n",
       "  transformers = Bert(layers=2, head=12, head_size=64, pwffn_size=3072, size=768),\n",
       "  classifier = \n",
       "    (\n",
       "      item => (\n",
       "        transform => Chain(Dense(768 => 768, gelu), LayerNorm(768))\n",
       "        output_bias => BiasLayer(Float32[-2.1193697, -0.6147034, -1.1719619, -11.99434, -11.237145, -11.471468, -3.7455504, -0.19069843, -10.465175, -5.015273  …  -1.4274297, -11.424993, -10.704592, -0.5465343, -8.628784, -11.403357, -14.5366335, -10.88559, -8.82391, -12.489019])\n",
       "      )\n",
       "      rating => Dense(768 => 1)\n",
       "    )\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ryouko = read_params(\"all/Transformer/checkpoints/3.old\")[\"m\"] |> gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548e8bdd-e09a-4492-a07a-fe7e4e6263ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221222 03:58:04 evaluating metrics\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:05:45\u001b[39mm:56\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20221222 04:03:55 saving model after 3 epochs with metrics Dict(\"Item Crossentropy Loss\" => 4.506548199941086, \"Rating MSE Loss\" => 1.4360239562858914)\n",
      "\u001b[32mProgress:  37%|███████████████▏                         |  ETA: 4:26:53\u001b[39mm26\u001b[39mmIOPub message rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_msg_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n",
      "\u001b[32mProgress:  39%|████████████████▏                        |  ETA: 4:17:15\u001b[39m"
     ]
    }
   ],
   "source": [
    "for epoch = 3:100\n",
    "        checkpoint(ryouko, opt, validation_sentences, training_config, epoch)\n",
    "        train_epoch!(ryouko, opt, training_sentences, training_config)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eb1dec-adec-4a02-8fce-25e7dfa055c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

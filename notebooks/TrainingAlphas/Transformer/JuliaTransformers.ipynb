{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90afc10-1ae5-4665-937e-d58a5859ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"../Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3184e0c-d01a-4b83-aa3f-7908fc378b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Transformers\n",
    "using Transformers.Basic\n",
    "import CUDA\n",
    "import Random: shuffle!\n",
    "import StatsBase: mean, sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b924da24-7c19-45a8-bed0-de97e886c818",
   "metadata": {},
   "source": [
    "# Tokenize training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e62123a-b88b-47fd-932d-5532210755d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "const BASE_VOCAB_SIZE = num_items()\n",
    "const CLS_TOKEN = num_items() + 1\n",
    "const PAD_TOKEN = num_items() + 2\n",
    "const MASK_TOKEN = num_items() + 3\n",
    "const VOCAB_SIZE = num_items() + 3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1390be71-9ece-4b82-a6c7-d4eb41d3c3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_training_data()\n",
    "    sentences = Dict{Int32,Vector{Int32}}()\n",
    "    for task in ALL_TASKS\n",
    "        df = get_split(\"training\", task, \"implicit\")\n",
    "        @showprogress for i = 1:length(df.user)\n",
    "            if df.user[i] âˆ‰ keys(sentences)\n",
    "                sentences[df.user[i]] = Int32[]\n",
    "            end\n",
    "            push!(sentences[df.user[i]], df.item[i])\n",
    "        end\n",
    "    end\n",
    "    [sentences[k] for k in keys(sentences)]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8227aee2-8a2f-4932-bae2-38c951404415",
   "metadata": {},
   "outputs": [],
   "source": [
    "function pad_sentence(sentence, max_seq_length, cls_token, pad_token)\n",
    "    output = fill(pad_token, max_seq_length)\n",
    "    output[1] = cls_token\n",
    "    seq_len = max_seq_length - 1\n",
    "    if length(sentence) > seq_len\n",
    "        # take a random contiguous subset\n",
    "        idx = rand(1:length(sentence)-seq_len)\n",
    "        sentence = sentence[idx:idx+seq_len-1]\n",
    "    end\n",
    "    output[2:1+length(sentence)] .= sentence\n",
    "    output\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "703ab7e5-b47f-42e7-a117-522a8d165b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_token_ids(sentences, max_seq_length, batch_size, cls_token, pad_token)\n",
    "    hcat(\n",
    "        [\n",
    "            pad_sentence(rand(sentences), max_seq_length, cls_token, pad_token) for\n",
    "            _ = 1:batch_size\n",
    "        ]...,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b524c73-58a0-4c31-9ff0-48f81eb0fa0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_batch(\n",
    "    sentences,\n",
    "    max_seq_len,\n",
    "    batch_size;\n",
    "    vocab_size = BASE_VOCAB_SIZE,\n",
    "    cls_token = CLS_TOKEN,\n",
    "    pad_token = PAD_TOKEN,\n",
    "    mask_token = MASK_TOKEN,\n",
    ")\n",
    "    # get tokenized sentences\n",
    "    tokens = get_token_ids(sentences, max_seq_len, batch_size, cls_token, pad_token)\n",
    "\n",
    "    # don't attend to padding tokens\n",
    "    attention_mask =\n",
    "        reshape(convert.(Float32, tokens .!= PAD_TOKEN), (1, max_seq_len, batch_size))\n",
    "\n",
    "    # apply BERT masking\n",
    "    masked_token_positions = []\n",
    "    labels = []\n",
    "    for b = 1:batch_size\n",
    "        seq_len = Int(sum(attention_mask[:, :, b]))\n",
    "        nsamples = seq_len * 0.15\n",
    "        nsamples = Int(floor(nsamples) + (rand() < nsamples - floor(nsamples)))\n",
    "        mask_samples = sample(1:seq_len, nsamples, replace = false)\n",
    "        for m in mask_samples\n",
    "            push!(labels, (tokens[m, b], length(labels) + 1))\n",
    "            r = rand(Float32)\n",
    "            if r < 0.8\n",
    "                # replace with <mask>\n",
    "                tokens[m, b] = mask_token\n",
    "            elseif r < 0.9\n",
    "                # replace with <random>                \n",
    "                tokens[m, b] = rand(1:vocab_size)\n",
    "            else\n",
    "                # keep token unchanged\n",
    "                nothing\n",
    "            end\n",
    "            push!(masked_token_positions, (m, b))\n",
    "        end\n",
    "    end\n",
    "\n",
    "    if length(labels) == 0\n",
    "        return get_batch(\n",
    "            sentences,\n",
    "            max_seq_len,\n",
    "            batch_size;\n",
    "            vocab_size = vocab_size,\n",
    "            cls_token = cls_token,\n",
    "            pad_token = pad_token,\n",
    "            mask_token = mask_token,\n",
    "        )\n",
    "    end\n",
    "\n",
    "    tokens, attention_mask, masked_token_positions, labels\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edda391-cb1f-4b4a-ba59-09b825782342",
   "metadata": {},
   "outputs": [],
   "source": [
    "function device(batch)\n",
    "    gpu(batch[1]), gpu(batch[2]), gpu(batch[3]), gpu(batch[4])\n",
    "end\n",
    "\n",
    "function device_free!(batch)\n",
    "    if !CUDA.functional()\n",
    "        return\n",
    "    end\n",
    "    CUDA.unsafe_free!(batch[1])\n",
    "    CUDA.unsafe_free!(batch[2])\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59101cfb-147f-491b-b48a-e942ddbae8b3",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d26ddbc3-30a6-4281-985b-5b62fd2d1acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "const config = Dict(\n",
    "    \"attention_probs_dropout_prob\" => 0.1,\n",
    "    \"hidden_act\" => gelu,\n",
    "    \"num_hidden_layers\" => 6, # halving the number of hidden layers\n",
    "    \"hidden_size\" => 768,\n",
    "    \"max_sequence_length\" => 512,\n",
    "    \"vocab_size\" => VOCAB_SIZE,\n",
    "    \"num_attention_heads\" => 12,\n",
    "    \"hidden_dropout_prob\" => 0.1,\n",
    "    \"intermediate_size\" => 3072,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888e8ee3-c369-41c8-ba85-267e2757d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "function create_bert(config)\n",
    "    bert = Bert(\n",
    "        config[\"hidden_size\"],\n",
    "        config[\"num_attention_heads\"],\n",
    "        config[\"intermediate_size\"],\n",
    "        config[\"num_hidden_layers\"];\n",
    "        act = config[\"hidden_act\"],\n",
    "        pdrop = config[\"hidden_dropout_prob\"],\n",
    "        attn_pdrop = config[\"attention_probs_dropout_prob\"],\n",
    "    )\n",
    "\n",
    "    tok_emb = Embed(config[\"hidden_size\"], config[\"vocab_size\"])\n",
    "\n",
    "    posi_emb = PositionEmbedding(\n",
    "        config[\"hidden_size\"],\n",
    "        config[\"max_sequence_length\"];\n",
    "        trainable = true,\n",
    "    )\n",
    "\n",
    "    emb_post = Positionwise(\n",
    "        LayerNorm(config[\"hidden_size\"]),\n",
    "        Dropout(config[\"hidden_dropout_prob\"]),\n",
    "    )\n",
    "\n",
    "    cls = Positionwise(Dense(config[\"hidden_size\"], config[\"vocab_size\"]), logsoftmax)\n",
    "\n",
    "    emb = CompositeEmbedding(tok = tok_emb, pe = posi_emb, postprocessor = emb_post)\n",
    "    clf = (cls = cls)\n",
    "\n",
    "    TransformerModel(emb, bert, clf)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ceff79e-2b50-45bb-b89f-4de58c1794a7",
   "metadata": {},
   "source": [
    "# Loss metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5ed839-0fc4-4675-8336-6672586afcbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "function masklm_loss(model, batch)\n",
    "    tokens, attention_mask, masked_token_positions, masked_token_labels = batch\n",
    "    X = model.embed(tok = tokens, pe = tokens)\n",
    "    X = model.transformers(X, attention_mask)\n",
    "    X = model.classifier(gather(X, masked_token_positions))\n",
    "    -mean(gather(X, masked_token_labels))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eca42c-7356-49c2-8cbf-5baf86dec544",
   "metadata": {},
   "outputs": [],
   "source": [
    "function accuracy(model, batch)\n",
    "    tokens, attention_mask, masked_token_positions, masked_token_labels = batch\n",
    "    X = model.embed(tok = tokens, pe = tokens)\n",
    "    X = model.transformers(X, attention_mask)\n",
    "    X = model.classifier(gather(X, masked_token_positions))\n",
    "    mislabel_count =\n",
    "        sum(X .> reshape(gather(X, masked_token_labels), (1, size(X)[2])), dims = 1)\n",
    "    sum(mislabel_count .== 0), length(mislabel_count)\n",
    "end\n",
    "\n",
    "function accuracy(model, sentences, max_seq_length, batch_size)\n",
    "    totals = [0, 0]\n",
    "    @showprogress for i = 1:Int(ceil(length(sentences) / batch_size))\n",
    "        batch = get_batch(sentences, max_seq_length, batch_size) |> device\n",
    "        totals .+= accuracy(model, batch)\n",
    "        device_free!(batch)\n",
    "    end\n",
    "    totals[1] / totals[2]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11599f78-e9c1-48ac-905a-778dc5196d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_epoch!(model, opt, sentences, max_seq_length, batch_size, iters)\n",
    "    ps = Flux.params(model)\n",
    "    batchloss(batch) = masklm_loss(model, batch)\n",
    "    @showprogress for i = 1:iters\n",
    "        batch = get_batch(sentences, max_seq_length, batch_size) |> device\n",
    "        Flux.train!(batchloss, ps, [(batch,)], opt)\n",
    "        device_free!(batch)\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "853e8f81-f292-4cac-8c51-9fca12fc4eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function checkpoint(model, sentences, max_seq_length, batch_size, iters)\n",
    "    write_params(Dict(\"m\" => cpu(model), \"iters\" => iters), \"Transformer/$iters\")\n",
    "    acc = accuracy(model, sentences, max_seq_length, batch_size)\n",
    "    @info \"saving model after $iters iters with accuracy $acc\"\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6629bd-de28-48fb-842f-4a0d132f5d1d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sentences = get_training_data()\n",
    "shuffle!(sentences)\n",
    "cutoff = Int(round(0.95 * length(sentences)))\n",
    "training_sentences = sentences[1:cutoff]\n",
    "validation_sentences = sentences[cutoff+1:end];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae20697-5ec6-4e77-a830-706976496c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_seq_length = config[\"max_sequence_length\"]\n",
    "batch_size = 8\n",
    "checkpoint_iters = 20000;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fdd3f2-2dfe-40d5-b486-a4db32124937",
   "metadata": {},
   "outputs": [],
   "source": [
    "ryouko = create_bert(config) |> gpu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17dce734-75a0-41c4-8dd7-5da2d2730774",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ADAMW(1e-4, (0.9, 0.999), 1e-4 * 0.01) # defaults taken from the BERT paper\n",
    "# todo learning rate scheduling decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34fddb24-071b-4898-8874-7b95e41871e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "iters = 0\n",
    "while true\n",
    "    train_epoch!(ryouko, opt, training_sentences, max_seq_length, batch_size, checkpoint_iters)\n",
    "    iters += checkpoint_iters\n",
    "    checkpoint(ryouko, validation_sentences, max_seq_length, batch_size, iters)\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

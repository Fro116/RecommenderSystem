{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "da9ffa83-ba30-4d94-aa0a-827dd82eb7b0",
   "metadata": {},
   "source": [
    "# Pretrains a tranformer encoder model on watch histories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af186e89-ad33-424f-8937-f8b49db34774",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "datapath = \"alphas/all/Transformer/v0\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "327c8376-2d03-4c69-a07d-0ba71801ec0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"all/Transformer/v21\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d90afc10-1ae5-4665-937e-d58a5859ac94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"../Alpha.ipynb\")\n",
    "@nbinclude(\"Reference/CUDA.ipynb\")\n",
    "@nbinclude(\"Reference/Include.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "567d60ae-6b55-4274-85b1-c0f9c9fc7545",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Flux\n",
    "import Flux: cpu, gpu, LayerNorm, logsoftmax\n",
    "import JSON\n",
    "import HDF5\n",
    "import Random\n",
    "import StatsBase: mean, sample"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "002401ce-b05d-411b-8583-0d7fe34893e3",
   "metadata": {},
   "source": [
    "# Structs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f13b747-89de-4f87-83b6-d03804ce5a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Trainer\n",
    "    model::Any\n",
    "    opt::Any\n",
    "    weightdecay::Any\n",
    "    lr_schedule::Any\n",
    "    training_config::Any\n",
    "    model_config::Any\n",
    "    rng::Any\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c46dc8a-7814-448c-a54f-051ab5ecdab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "function device(x::NamedTuple)\n",
    "    fields = fieldnames(typeof(x))\n",
    "    NamedTuple{fields}(gpu(x[k]) for k in fields)\n",
    "end\n",
    "\n",
    "function device(batch)\n",
    "    gpu.(batch[1]),\n",
    "    gpu(batch[2]),\n",
    "    device(batch[3]),\n",
    "    device(batch[4]),\n",
    "    device(batch[5]),\n",
    "    device(batch[6])\n",
    "end\n",
    "\n",
    "CUDA.unsafe_free!(::Nothing) = nothing\n",
    "device_free!(x) = CUDA.unsafe_free!(x)\n",
    "function device_free!(x::NamedTuple)\n",
    "    fields = fieldnames(typeof(x))\n",
    "    for f in fields\n",
    "        device_free!(x[f])\n",
    "    end\n",
    "end\n",
    "function device_free!(batch::Tuple)\n",
    "    if !CUDA.functional()\n",
    "        return\n",
    "    end\n",
    "    CUDA.unsafe_free!.(batch[1])\n",
    "    CUDA.unsafe_free!(batch[2])\n",
    "    device_free!(batch[3])\n",
    "    device_free!(batch[4])\n",
    "    device_free!(batch[5])\n",
    "    device_free!(batch[6])\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59101cfb-147f-491b-b48a-e942ddbae8b3",
   "metadata": {},
   "source": [
    "# Create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888e8ee3-c369-41c8-ba85-267e2757d140",
   "metadata": {},
   "outputs": [],
   "source": [
    "function create_bert(config)\n",
    "    bert = Bert(\n",
    "        hidden_size = config[\"hidden_size\"],\n",
    "        num_attention_heads = config[\"num_attention_heads\"],\n",
    "        intermediate_size = config[\"intermediate_size\"],\n",
    "        num_layers = config[\"num_hidden_layers\"];\n",
    "        activation_fn = config[\"hidden_act\"],\n",
    "        dropout = config[\"dropout\"],\n",
    "        attention_dropout = config[\"attention_dropout\"],\n",
    "    )\n",
    "\n",
    "    anime_emb = DiscreteEmbed(config[\"hidden_size\"], extract(config[\"vocab_sizes\"], :anime))\n",
    "    manga_emb = DiscreteEmbed(config[\"hidden_size\"], extract(config[\"vocab_sizes\"], :manga))\n",
    "    rating_emb = ContinuousEmbed(config[\"hidden_size\"])\n",
    "    timestamp_emb = ContinuousEmbed(config[\"hidden_size\"])\n",
    "    status_emb =\n",
    "        DiscreteEmbed(config[\"hidden_size\"], extract(config[\"vocab_sizes\"], :status))\n",
    "    completion_emb = ContinuousEmbed(config[\"hidden_size\"])\n",
    "    position_emb =\n",
    "        DiscreteEmbed(config[\"hidden_size\"], extract(config[\"vocab_sizes\"], :position))\n",
    "    emb_post = Chain(LayerNorm(config[\"hidden_size\"]), Dropout(config[\"dropout\"]))\n",
    "    emb = CompositeEmbedding(\n",
    "        anime = anime_emb,\n",
    "        manga = manga_emb,\n",
    "        rating = rating_emb,\n",
    "        timestamp = timestamp_emb,\n",
    "        status = status_emb,\n",
    "        completion = completion_emb,\n",
    "        position = position_emb,\n",
    "        postprocessor = emb_post,\n",
    "    )\n",
    "\n",
    "    clf = (\n",
    "        anime = (\n",
    "            item = Dense(config[\"hidden_size\"], extract(config[\"vocab_sizes\"], :anime)),\n",
    "            rating = Dense(config[\"hidden_size\"], extract(config[\"vocab_sizes\"], :anime)),\n",
    "        ),\n",
    "        manga = (\n",
    "            item = Dense(config[\"hidden_size\"], extract(config[\"vocab_sizes\"], :manga)),\n",
    "            rating = Dense(config[\"hidden_size\"], extract(config[\"vocab_sizes\"], :manga)),\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    TransformerModel(emb, bert, clf)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3fc3c56-2786-4752-befc-e9f241ae0f08",
   "metadata": {},
   "source": [
    "# Loss metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32348a0a-b6ef-4944-a28f-6b9bc038296a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function masklm_losses(model, batch)\n",
    "    tokens, attention_mask, batch_positions, item_positions, labels, weights = batch\n",
    "    X = model.embed(\n",
    "        anime = extract(tokens, :anime),\n",
    "        manga = extract(tokens, :manga),\n",
    "        rating = extract(tokens, :rating),\n",
    "        timestamp = extract(tokens, :timestamp),\n",
    "        status = extract(tokens, :status),\n",
    "        completion = extract(tokens, :completion),\n",
    "        position = extract(tokens, :position),\n",
    "    )\n",
    "    X = model.transformers(X, attention_mask)\n",
    "\n",
    "    if length(item_positions[:anime][:item]) > 0\n",
    "        anime_item_pred = logsoftmax(\n",
    "            model.classifier.anime.item(gather(X, batch_positions[:anime][:item])),\n",
    "        )\n",
    "        anime_item_loss =\n",
    "            -(\n",
    "                weights[:anime][:item]' *\n",
    "                gather(anime_item_pred, item_positions[:anime][:item])\n",
    "            ) / sum(weights[:anime][:item])\n",
    "    else\n",
    "        anime_item_loss = 0.0f0\n",
    "    end\n",
    "    if length(item_positions[:anime][:rating]) > 0\n",
    "        anime_rating_pred =\n",
    "            model.classifier.anime.rating(gather(X, batch_positions[:anime][:rating]))\n",
    "        anime_rating_loss =\n",
    "            (\n",
    "                weights[:anime][:rating]' *\n",
    "                (\n",
    "                    gather(anime_rating_pred, item_positions[:anime][:rating]) -\n",
    "                    labels[:anime][:rating]\n",
    "                ) .^ 2\n",
    "            ) / sum(weights[:anime][:rating])\n",
    "    else\n",
    "        anime_rating_loss = 0.0f0\n",
    "    end\n",
    "\n",
    "    if length(item_positions[:manga][:item]) > 0\n",
    "        manga_item_pred = logsoftmax(\n",
    "            model.classifier.manga.item(gather(X, batch_positions[:manga][:item])),\n",
    "        )\n",
    "        manga_item_loss =\n",
    "            -(\n",
    "                weights[:manga][:item]' *\n",
    "                gather(manga_item_pred, item_positions[:manga][:item])\n",
    "            ) / sum(weights[:manga][:item])\n",
    "    else\n",
    "        manga_item_loss = 0.0f0\n",
    "    end\n",
    "    if length(item_positions[:manga][:rating]) > 0\n",
    "        manga_rating_pred =\n",
    "            model.classifier.manga.rating(gather(X, batch_positions[:manga][:rating]))\n",
    "        manga_rating_loss =\n",
    "            (\n",
    "                weights[:manga][:rating]' *\n",
    "                (\n",
    "                    gather(manga_rating_pred, item_positions[:manga][:rating]) -\n",
    "                    labels[:manga][:rating]\n",
    "                ) .^ 2\n",
    "            ) / sum(weights[:manga][:rating])\n",
    "    else\n",
    "        manga_rating_loss = 0.0f0\n",
    "    end\n",
    "\n",
    "    anime_item_loss, anime_rating_loss, manga_item_loss, manga_rating_loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1ea8ec-0cca-4b5f-a918-5de29732674b",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a046086b-93b8-4216-b391-15ea04d4dea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Dataloader\n",
    "    embeds::Any\n",
    "    positions::Any\n",
    "    labels::Any\n",
    "    weights::Any\n",
    "end\n",
    "\n",
    "function Dataloader(filename::String)\n",
    "    f = HDF5.h5open(filename, \"r\")\n",
    "    embeds = [\n",
    "        HDF5.read(f, x) for x in [\n",
    "            \"anime\",\n",
    "            \"manga\",\n",
    "            \"rating\",\n",
    "            \"timestamp\",\n",
    "            \"status\",\n",
    "            \"completion\",\n",
    "            \"user\",\n",
    "            \"position\",\n",
    "        ]\n",
    "    ]\n",
    "    positions = [\n",
    "        HDF5.read(f, \"positions_$(medium)_$(task)\") for medium in [\"anime\", \"manga\"] for\n",
    "        task in [\"item\", \"rating\"]\n",
    "    ]\n",
    "    labels = [\n",
    "        HDF5.read(f, \"labels_$(medium)_$(task)\") for medium in [\"anime\", \"manga\"] for\n",
    "        task in [\"item\", \"rating\"]\n",
    "    ]\n",
    "    weights = [\n",
    "        HDF5.read(f, \"weights_$(medium)_$(task)\") for medium in [\"anime\", \"manga\"] for\n",
    "        task in [\"item\", \"rating\"]\n",
    "    ]\n",
    "    Dataloader(embeds, positions, labels, weights)\n",
    "end\n",
    "\n",
    "Base.length(d::Dataloader) = size(d.embeds[1])[2];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "234e8c8c-3b04-462d-8ca7-55efe48bdaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_dataloader(outdir, split, batch_size, num_workers)\n",
    "    # find the next data shard\n",
    "    dataloader_file = joinpath(outdir, \"training\", \"dataloader.$split\")\n",
    "    if isfile(dataloader_file)\n",
    "        open(dataloader_file, \"r\") do f\n",
    "            worker = parse(Int, readline(f))\n",
    "        end\n",
    "    else\n",
    "        worker = 0\n",
    "    end\n",
    "    worker = (worker + 1) % num_workers\n",
    "    if worker == 0\n",
    "        worker = num_workers\n",
    "    end\n",
    "\n",
    "    # wait for the data shard to be written\n",
    "    completion_file = joinpath(outdir, \"training\", \"$split.$worker.h5.complete\")\n",
    "    while !isfile(completion_file)\n",
    "        sleep(1)\n",
    "    end\n",
    "\n",
    "    # read the data shard\n",
    "    data_file = completion_file[1:end-length(\".complete\")]\n",
    "    dataloader = Dataloader(data_file)\n",
    "\n",
    "    # sync and update disk\n",
    "    open(dataloader_file, \"w\") do f\n",
    "        write(f, \"$worker\")\n",
    "    end\n",
    "    rm(completion_file)\n",
    "    rm(data_file)\n",
    "    return dataloader\n",
    "end;\n",
    "\n",
    "get_dataloader(split, config) =\n",
    "    get_dataloader(get_data_path(datapath), split, config[\"batch_size\"], 4);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "255154d8-d026-4015-8066-9b737a61c5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_batch(d::Dataloader, batch_size, i)\n",
    "    idx = (batch_size*(i-1)+1):min(batch_size * i, length(d))\n",
    "    tokens = Tuple(d.embeds[j][:, idx] for j = 1:length(fieldnames(wordtype)))\n",
    "\n",
    "    mask = extract(tokens, :user)\n",
    "    s, b = size(mask)\n",
    "    attention_mask = reshape(mask, (1, s, b)) .== reshape(mask, (s, 1, b))\n",
    "\n",
    "    batch_positions = (\n",
    "        anime = (item = Tuple{Int32,Int32}[], rating = Tuple{Int32,Int32}[]),\n",
    "        manga = (item = Tuple{Int32,Int32}[], rating = Tuple{Int32,Int32}[]),\n",
    "    )\n",
    "    taskidx = 0\n",
    "    for medium in [:anime, :manga]\n",
    "        for task in [:item, :rating]\n",
    "            taskidx += 1\n",
    "            w = @view d.weights[taskidx][:, idx]\n",
    "            for b::Int32 = 1:b\n",
    "                for i::Int32 = 1:s\n",
    "                    if w[i, b] != 0\n",
    "                        push!(batch_positions[medium][task], (i, b))\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    item_positions = (\n",
    "        anime = (item = Tuple{Int32,Int32}[], rating = Tuple{Int32,Int32}[]),\n",
    "        manga = (item = Tuple{Int32,Int32}[], rating = Tuple{Int32,Int32}[]),\n",
    "    )\n",
    "    taskidx = 0\n",
    "    for medium in [:anime, :manga]\n",
    "        for task in [:item, :rating]\n",
    "            taskidx += 1\n",
    "            p = @view d.positions[taskidx][:, idx]\n",
    "            w = @view d.weights[taskidx][:, idx]\n",
    "            for b::Int32 = 1:b\n",
    "                for i::Int32 = 1:s\n",
    "                    if w[i, b] != 0\n",
    "                        push!(\n",
    "                            item_positions[medium][task],\n",
    "                            (p[i, b], Int32(length(item_positions[medium][task]) + 1)),\n",
    "                        )\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    labels = (\n",
    "        anime = (item = Int32[], rating = Float32[]),\n",
    "        manga = (item = Int32[], rating = Float32[]),\n",
    "    )\n",
    "    taskidx = 0\n",
    "    for medium in [:anime, :manga]\n",
    "        for task in [:item, :rating]\n",
    "            taskidx += 1\n",
    "            l = @view d.labels[taskidx][:, idx]\n",
    "            w = @view d.weights[taskidx][:, idx]\n",
    "            for b::Int32 = 1:b\n",
    "                for i::Int32 = 1:s\n",
    "                    if w[i, b] != 0\n",
    "                        push!(labels[medium][task], l[i, b])\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    weights = (\n",
    "        anime = (item = Float32[], rating = Float32[]),\n",
    "        manga = (item = Float32[], rating = Float32[]),\n",
    "    )\n",
    "    taskidx = 0\n",
    "    for medium in [:anime, :manga]\n",
    "        for task in [:item, :rating]\n",
    "            taskidx += 1\n",
    "            w = @view d.weights[taskidx][:, idx]\n",
    "            for b::Int32 = 1:b\n",
    "                for i::Int32 = 1:s\n",
    "                    if w[i, b] != 0\n",
    "                        push!(weights[medium][task], w[i, b])\n",
    "                    end\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    tokens, attention_mask, batch_positions, item_positions, labels, weights\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cda28b15-2a31-44c2-b725-273aed86d412",
   "metadata": {},
   "outputs": [],
   "source": [
    "function read_json(file)\n",
    "    open(file, \"r\") do f\n",
    "        return JSON.parse(read(f, String))\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb18c7a-64c9-4817-888b-3866fbff4ec6",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c4c0fd3-6beb-47fb-95d2-94fb1d5cdb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_epoch!(t::Trainer)\n",
    "    losses = 0.0f0\n",
    "    steps = 0\n",
    "    remaining_tokens = t.training_config[\"tokens_per_epoch\"]\n",
    "    batch_size = t.training_config[\"batch_size\"]\n",
    "    p = ProgressMeter.Progress(remaining_tokens)\n",
    "    while remaining_tokens > 0\n",
    "        dataloader = get_dataloader(\"training\", t.training_config)\n",
    "        for i = 1:div(length(dataloader), batch_size, RoundUp)\n",
    "            schedule_learning_rate!(\n",
    "                t.opt,\n",
    "                t.weightdecay,\n",
    "                t.lr_schedule,\n",
    "                t.training_config[\"weight_decay\"],\n",
    "            )\n",
    "            batch = get_batch(dataloader, batch_size, i) |> device\n",
    "            num_tokens = size(batch[1][1])[1] * size(batch[1][1])[2]\n",
    "            tloss, grads = Flux.withgradient(t.model) do m\n",
    "                sum(masklm_losses(m, batch))\n",
    "            end\n",
    "            batch |> device_free!\n",
    "            losses += tloss\n",
    "            steps += 1\n",
    "            Flux.update!(t.opt, t.model, grads[1])\n",
    "            Flux.update!(t.weightdecay, t.model, grads[1])\n",
    "            remaining_tokens -= num_tokens\n",
    "            ProgressMeter.next!(p; step = num_tokens)\n",
    "            if remaining_tokens < 0\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    ProgressMeter.finish!(p)\n",
    "    losses / steps\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1eca42c-7356-49c2-8cbf-5baf86dec544",
   "metadata": {},
   "outputs": [],
   "source": [
    "function evaluate_metrics(t::Trainer)\n",
    "    losses = zeros(Float32, 4)\n",
    "    weights = zeros(Float32, 4)\n",
    "    remaining_sentences = t.training_config[\"num_validation_sentences\"]\n",
    "    batch_size = t.training_config[\"batch_size\"]\n",
    "    p = ProgressMeter.Progress(remaining_sentences)\n",
    "    while remaining_sentences > 0\n",
    "        dataloader = get_dataloader(\"validation\", t.training_config)\n",
    "        for i = 1:div(length(dataloader), batch_size, RoundUp)\n",
    "            batch = get_batch(dataloader, batch_size, i) |> device\n",
    "            w =\n",
    "                sum.([\n",
    "                    batch[6][:anime][:item],\n",
    "                    batch[6][:anime][:rating],\n",
    "                    batch[6][:manga][:item],\n",
    "                    batch[6][:manga][:rating],\n",
    "                ])\n",
    "            losses .+= masklm_losses(t.model, batch) .* w\n",
    "            weights .+= w\n",
    "            num_sentences = size(batch[1][1])[2]\n",
    "            device_free!(batch)\n",
    "            remaining_sentences -= num_sentences\n",
    "            ProgressMeter.next!(p; step = num_sentences)\n",
    "            if remaining_sentences < 0\n",
    "                break\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    ProgressMeter.finish!(p)\n",
    "    names = [\n",
    "        \"Anime Crossentropy Loss\",\n",
    "        \"Anime Rating Loss\",\n",
    "        \"Manga Crossentropy Loss\",\n",
    "        \"Manga Rating Loss\",\n",
    "    ]\n",
    "    Dict(names .=> losses ./ weights)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f95adc-4281-4fb4-a126-957bd5431e9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function checkpoint(t::Trainer, training_loss, epoch, name)\n",
    "    @info \"evaluating metrics\"\n",
    "    metrics = evaluate_metrics(t)\n",
    "    metrics[\"Validation Loss\"] = sum(values(metrics))\n",
    "    metrics[\"Training Loss\"] = training_loss\n",
    "    write_params(\n",
    "        Dict(\n",
    "            \"m\" => t.model |> cpu,\n",
    "            \"opt\" => t.opt |> cpu,\n",
    "            \"weightdecay\" => t.weightdecay |> cpu,\n",
    "            \"lr_schedule\" => t.lr_schedule,\n",
    "            \"epoch\" => epoch,\n",
    "            \"metrics\" => metrics,\n",
    "            \"training_config\" => t.training_config,\n",
    "            \"model_config\" => t.model_config,\n",
    "            \"rng\" => t.rng,\n",
    "        ),\n",
    "        \"$name/checkpoints/$epoch\",\n",
    "    )\n",
    "    @info \"saving model after $epoch epochs with metrics $metrics\"\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50183c75-f670-425e-b08e-c72efe4e8988",
   "metadata": {},
   "source": [
    "# Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "805ac800-38d2-4ed9-9963-05c176baef7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function set_rngs(seed)\n",
    "    rng = Random.Xoshiro(seed)\n",
    "    Random.seed!(rand(rng, UInt64))\n",
    "    if CUDA.functional()\n",
    "        Random.seed!(CUDA.default_rng(), rand(rng, UInt64))\n",
    "        Random.seed!(CUDA.CURAND.default_rng(), rand(rng, UInt64))\n",
    "    end\n",
    "    rng\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affb67b6-dabb-4db8-841d-c7ebf43f4a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function create_training_config()\n",
    "    media = [\"anime\", \"manga\"]\n",
    "    base_vocab_sizes = (\n",
    "        Int32(num_items(\"anime\")),\n",
    "        Int32(num_items(\"manga\")),\n",
    "        Float32(11),\n",
    "        Float32(1),\n",
    "        Int32(5),\n",
    "        Float32(1),\n",
    "        Int32(maximum(num_users(x) for x in media)),\n",
    "        Int32(512),\n",
    "    )\n",
    "    d = Dict(\n",
    "        # tokenization\n",
    "        \"base_vocab_sizes\" => base_vocab_sizes,\n",
    "        \"vocab_sizes\" => base_vocab_sizes .+ Int32(4),\n",
    "        # training\n",
    "        \"batch_size\" => 16,\n",
    "        \"peak_learning_rate\" => 3f-4,\n",
    "        \"weight_decay\" => 1f-2,\n",
    "        # data\n",
    "        \"media\" => media,\n",
    "        \"num_epochs\" => 1,\n",
    "        # model\n",
    "        \"num_layers\" => 4,\n",
    "        \"hidden_size\" => 512,\n",
    "        \"max_sequence_length\" => extract(base_vocab_sizes, :position),\n",
    "    )\n",
    "    d\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5545bdf1-5fad-4de2-bbc8-dbcf63da3c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "function create_model_config(training_config)\n",
    "    # follows the recipe in Section 5 of [Well-Read Students Learn Better: On the \n",
    "    # Importance of Pre-training Compact Models](https://arxiv.org/pdf/1908.08962.pdf)\n",
    "    Dict(\n",
    "        \"attention_dropout\" => 0.1,\n",
    "        \"hidden_act\" => gelu,\n",
    "        \"num_hidden_layers\" => training_config[\"num_layers\"],\n",
    "        \"hidden_size\" => training_config[\"hidden_size\"],\n",
    "        \"max_sequence_length\" => training_config[\"max_sequence_length\"],\n",
    "        \"vocab_sizes\" => training_config[\"vocab_sizes\"],\n",
    "        \"num_attention_heads\" => Int(training_config[\"hidden_size\"] / 64),\n",
    "        \"dropout\" => 0.1,\n",
    "        \"intermediate_size\" => training_config[\"hidden_size\"] * 4,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d14633c-55e0-4044-8429-705b4f005bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "function load_from_checkpoint(training_config, rng)\n",
    "    model_config = create_model_config(training_config)\n",
    "    model = create_bert(model_config) |> gpu\n",
    "    lr = Float32(config[\"peak_learning_rate\"])\n",
    "    wd = Float32(config[\"weight_decay\"])\n",
    "    opt = Optimisers.setup(Adam(lr, (0.9f0, 0.999f0)), model)\n",
    "    weightdecay = Optimisers.setup(PureWeightDecay(lr * wd), model)\n",
    "    initialize_weight_decay!(weightdecay, model)\n",
    "    lr_schedule = get_lr_schedule(config)\n",
    "    Trainer(model, opt, weightdecay, lr_schedule, training_config, model_config, rng)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106fa056-8deb-486d-9854-6e0991bc4714",
   "metadata": {},
   "source": [
    "# Actually Train Model!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2969e640-d857-474e-b015-bbb11892d09c",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_checkpoint = nothing\n",
    "config_epoch = nothing\n",
    "config_rng = set_rngs(20221221)\n",
    "config = create_training_config();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77d1318-d5f4-4311-831f-e3f16c422cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_config = read_json(joinpath(get_data_path(datapath), \"training\", \"config.json\"))\n",
    "config[\"tokens_per_epoch\"] = data_config[\"tokens_per_epoch\"]\n",
    "config[\"num_validation_sentences\"] = data_config[\"num_validation_sentences\"]\n",
    "config[\"iters_per_epoch\"] =\n",
    "    Int(ceil(config[\"tokens_per_epoch\"] / config[\"max_sequence_length\"]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a065c25-75b0-4e7b-a48d-7d27dcd0c64c",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = load_from_checkpoint(config, config_rng)\n",
    "@info \"Num epochs: $(config[\"num_epochs\"])\"\n",
    "@info \"Training model with $(sum(length, Flux.params(trainer.model))) total parameters\"\n",
    "@info \"Embedding parameters: $(sum(length, Flux.params(trainer.model.embed)))\"\n",
    "@info \"Transformer parameters: $(sum(length, Flux.params(trainer.model.transformers)))\"\n",
    "@info \"Classifier parameters: $(sum(length, Flux.params(trainer.model.classifier)))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb98bbf0-dae0-431e-a75c-b7c01343be9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "training_loss = Inf\n",
    "for i = 1:trainer.training_config[\"num_epochs\"]\n",
    "    GC.gc()\n",
    "    training_loss = train_epoch!(trainer)\n",
    "    checkpoint(trainer, training_loss, i, name)\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0-rc2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

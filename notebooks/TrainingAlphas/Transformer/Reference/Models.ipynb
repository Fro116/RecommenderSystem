{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cd34ac1-7a93-4fd7-b470-f37067a1a2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Flux: Chain, Dense, Dropout, gelu\n",
    "import Flux.NNlib: gather\n",
    "import Functors: @functor\n",
    "import NeuralAttentionlib: GenericAttenMask\n",
    "import Transformers: Transformer, Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207af3a8-ae0b-4c24-ab60-50175a47ba7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct Bert{T,D}\n",
    "    transformers::T\n",
    "    dropout::D\n",
    "end\n",
    "\n",
    "@functor Bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae5caee-c992-4ff9-9e1a-31d20c37d321",
   "metadata": {},
   "outputs": [],
   "source": [
    "function Bert(;\n",
    "    hidden_size,\n",
    "    num_attention_heads,\n",
    "    intermediate_size,\n",
    "    num_layers,\n",
    "    activation_fn = gelu,\n",
    "    dropout = 0.1,\n",
    "    attention_dropout = 0.1,\n",
    ")\n",
    "    ts = Transformer(\n",
    "        Layers.PreNormTransformerBlock,\n",
    "        num_layers,\n",
    "        activation_fn,\n",
    "        num_attention_heads,\n",
    "        hidden_size,\n",
    "        div(hidden_size, num_attention_heads),\n",
    "        intermediate_size,\n",
    "        attention_dropout = attention_dropout,\n",
    "        dropout = dropout,\n",
    "        return_score = false,\n",
    "    )\n",
    "    Bert(ts, Dropout(dropout))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4c1191-0aca-44bd-878c-c263e4ea2185",
   "metadata": {},
   "outputs": [],
   "source": [
    "function (bert::Bert)(x::T, mask) where {T}\n",
    "    e = bert.dropout(x)\n",
    "    y = bert.transformers((hidden_state = x, attention_mask = GenericAttenMask(mask)))\n",
    "    y.hidden_state\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "928e184d-512f-4638-bd73-97c88d62e79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct BiasLayer\n",
    "    b::Any\n",
    "end\n",
    "BiasLayer(n::Integer; init = zeros) = BiasLayer(init(Float32, n))\n",
    "(m::BiasLayer)(x) = x .+ m.b\n",
    "@functor BiasLayer;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45275a04-585b-413f-9f57-0e714076e52b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for use with the WeightDecayNobias optimizer\n",
    "# function mark_embedding_matrix(hidden_size)\n",
    "#     if hidden_size % 2 == 0\n",
    "#         return hidden_size + 1\n",
    "#     else\n",
    "#         return hidden_size\n",
    "#     end\n",
    "# end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16992d69-daaa-47b2-87ce-f8620615e28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct DiscreteEmbed <: AbstractEmbed{Float32}\n",
    "    embedding::Any\n",
    "end\n",
    "@functor DiscreteEmbed\n",
    "Base.size(e::DiscreteEmbed, s...) = size(e.embedding, s...)\n",
    "DiscreteEmbed(size, vocab_size; init=randn) = DiscreteEmbed(init(Float32, Int32(size), Int32(vocab_size)))\n",
    "(e::DiscreteEmbed)(x) = gather(e.embedding, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e226881a-8a9c-44d2-a947-85d0ece2e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "struct ContinuousEmbed <: AbstractEmbed{Float32}\n",
    "    embedding::Any\n",
    "end\n",
    "@functor ContinuousEmbed\n",
    "function ContinuousEmbed(hidden_size::Int) \n",
    "    embed_size = div(hidden_size, 64)\n",
    "    ContinuousEmbed(\n",
    "        Chain(Dense(1, embed_size, gelu), Dense(embed_size, hidden_size)),\n",
    "    )\n",
    "end\n",
    "(e::ContinuousEmbed)(x) = e.embedding(reshape(x, (1, size(x)...)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

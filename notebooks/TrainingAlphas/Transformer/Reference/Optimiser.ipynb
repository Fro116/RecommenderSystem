{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4314d5be-9cf0-4f39-904c-b297f2d7b6fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Optimisers\n",
    "import Optimisers: Adam, OptimiserChain, WeightDecay\n",
    "import ParameterSchedulers\n",
    "import ParameterSchedulers: Sequence, Triangle, Shifted, Stateful"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328eddd2-0fb7-4956-9ca4-df8a4a90d1c8",
   "metadata": {},
   "source": [
    "# Learning rate schedules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecc7b25-2c8d-491a-ad13-ebf7c8e02fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "function schedule_learning_rate!(opt, lr_schedule, weight_decay)\n",
    "    lr = Float32(ParameterSchedulers.next!(lr_schedule))\n",
    "    Optimisers.adjust!(opt, eta = lr, gamma = lr * weight_decay)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12eb28a-053a-4448-b34a-dbb62551f43c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function LinearWarmupSchedule(lr, iters, warmup_perc)\n",
    "    warmup_steps = Int(round(iters * warmup_perc))\n",
    "    remaining_steps = iters - warmup_steps\n",
    "    Stateful(\n",
    "        Sequence(\n",
    "            Triangle(λ0 = 0.0f0, λ1 = lr, period = 2 * warmup_steps) => warmup_steps,\n",
    "            Shifted(\n",
    "                Triangle(λ0 = 0.0f0, λ1 = lr, period = 2 * remaining_steps),\n",
    "                remaining_steps,\n",
    "            ) => remaining_steps,\n",
    "        ),\n",
    "    )\n",
    "end\n",
    "\n",
    "function get_lr_schedule(config; num_epochs = nothing, peak_learning_rate = nothing)\n",
    "    if isnothing(peak_learning_rate)\n",
    "        lr = Float32(config[\"peak_learning_rate\"])\n",
    "    else\n",
    "        lr = peak_learning_rate\n",
    "    end\n",
    "    if isnothing(num_epochs)\n",
    "        num_epochs = config[\"num_epochs\"]\n",
    "    end\n",
    "    max_batches = Int(round(num_epochs * config[\"iters_per_epoch\"] / config[\"batch_size\"]))\n",
    "    LinearWarmupSchedule(lr, max_batches, 0.06)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54d0c8d-dd7c-491e-bd1f-2d0c9def45de",
   "metadata": {},
   "outputs": [],
   "source": [
    "function current(iter::ParameterSchedulers.Stateful)\n",
    "    return iter.schedule(iter.state)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69d5916b-9662-44a2-9f03-86c75635a1f1",
   "metadata": {},
   "source": [
    "# Gradient accumulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0a7a635-406e-4dcc-96bb-f4d894442bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function tuplesum(a::NamedTuple, b::NamedTuple)\n",
    "    fields = fieldnames(typeof(a))\n",
    "    NamedTuple{fields}(tuplesum(a[k], b[k]) for k in fields)\n",
    "end\n",
    "tuplesum(a::Tuple, b::Tuple) = Tuple(tuplesum(a[k], b[k]) for k = 1:length(a))\n",
    "tuplesum(a::Nothing, b) = b\n",
    "tuplesum(a, b) = a + b;\n",
    "\n",
    "function tupledivide(a::NamedTuple, d)\n",
    "    fields = fieldnames(typeof(a))\n",
    "    NamedTuple{fields}(tupledivide(a[k], d) for k in fields)\n",
    "end\n",
    "tupledivide(a::Tuple, d) = Tuple(tupledivide(a[k], d) for k = 1:length(a))\n",
    "tupledivide(a::Nothing, d) = nothing\n",
    "tupledivide(a, d) = a ./ d;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0392893a-4141-4aac-b836-004a0cdf491c",
   "metadata": {},
   "source": [
    "# Optimisers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03107eec-c852-48d3-a1f1-be1f49f709c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight decay, but on on bias terms, embedding layers, layer norms, etc.\n",
    "struct WeightDecayNobias{T} <: Optimisers.AbstractRule\n",
    "  gamma::T\n",
    "end\n",
    "Optimisers.init(o::WeightDecayNobias, x::AbstractArray) = nothing\n",
    "function Optimisers.apply!(o::WeightDecayNobias, state, x, dx)\n",
    "    if should_weight_decay(o, x)\n",
    "        dx′ = Optimisers.@lazy dx + o.gamma * x\n",
    "    else\n",
    "        dx′ = Optimisers.@lazy dx\n",
    "    end\n",
    "    return state, dx′\n",
    "end\n",
    "function should_weight_decay(o::WeightDecayNobias, x)\n",
    "    nontrivial_dims = 0 \n",
    "    has_odd_size = false\n",
    "    has_power_of_two_size = false\n",
    "    for d in size(x)\n",
    "        if d > 1\n",
    "            nontrivial_dims += 1\n",
    "            if d % 2 != 0\n",
    "                has_odd_size = true\n",
    "            end\n",
    "            if ispow2(d)\n",
    "                has_power_of_two_size = true\n",
    "            end\n",
    "        end \n",
    "    end\n",
    "    is_embedding_matrix = has_power_of_two_size && has_odd_size && (length(size(x)) == 2)\n",
    "    return !is_embedding_matrix && (nontrivial_dims > 1)\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

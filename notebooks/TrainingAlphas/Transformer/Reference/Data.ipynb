{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8dda73-d6ce-4e69-b769-d6cd305bec8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# item, rating, timestamp, status, completion, user, position\n",
    "const wordtype = Tuple{Int32,Float32,Float32,Int32,Float32,Int32,Int32}\n",
    "\n",
    "function get_wordtype_index(field::Symbol)\n",
    "    if field == :item\n",
    "        return 1\n",
    "    elseif field == :rating\n",
    "        return 2\n",
    "    elseif field == :timestamp\n",
    "        return 3\n",
    "    elseif field == :status\n",
    "        return 4\n",
    "    elseif field == :completion\n",
    "        return 5\n",
    "    elseif field == :user\n",
    "        return 6\n",
    "    elseif field == :position\n",
    "        return 7\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "end\n",
    "\n",
    "extract(word, field::Symbol) = word[get_wordtype_index(field)]\n",
    "\n",
    "function replace(word, fieldname::Symbol, field)\n",
    "    pos = get_wordtype_index(fieldname)\n",
    "    (word[1:pos-1]..., field, word[pos+1:end]...)\n",
    "end\n",
    "\n",
    "function encode_word(\n",
    "    item,\n",
    "    rating,\n",
    "    timestamp,\n",
    "    status,\n",
    "    completion,\n",
    "    user,\n",
    "    position,\n",
    ")\n",
    "    word =\n",
    "        (item, rating, timestamp, status, completion, user, position)\n",
    "    convert(wordtype, word)\n",
    "end\n",
    "\n",
    "is_ptw(word::wordtype) = extract(word, :status) == 1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "239a239a-13cb-470b-93b3-ff91979b4ee2",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_training_data(task, medium, include_ptw, cls_tokens; show_progress_bar = true)\n",
    "    function get_df(task, content, medium)\n",
    "        df = get_raw_split(\"training\", task, content, medium)\n",
    "        if content != \"explicit\"\n",
    "            df.rating .= 11\n",
    "        end\n",
    "        df\n",
    "    end\n",
    "\n",
    "    contents = [\"explicit\", \"implicit\"]\n",
    "    if include_ptw\n",
    "        push!(contents, \"ptw\")\n",
    "    end\n",
    "    sentences = Dict{Int32,Vector{wordtype}}()\n",
    "    df = reduce(cat, [get_df(task, content, medium) for content in contents])\n",
    "    order = sortperm(df.timestamp)\n",
    "    p = ProgressMeter.Progress(length(order); enabled = show_progress_bar, showspeed = true)\n",
    "    for idx = 1:length(order)\n",
    "        i = order[idx]\n",
    "        if df.user[i] âˆ‰ keys(sentences)\n",
    "            sentences[df.user[i]] = [replace(cls_tokens, :user, df.user[i])]\n",
    "        end\n",
    "        word = encode_word(\n",
    "            df.item[i],\n",
    "            df.rating[i],\n",
    "            df.timestamp[i],\n",
    "            df.status[i],\n",
    "            df.completion[i],\n",
    "            df.user[i],\n",
    "            length(sentences[df.user[i]]),\n",
    "        )\n",
    "        push!(sentences[df.user[i]], word)\n",
    "        ProgressMeter.next!(p)\n",
    "    end\n",
    "    ProgressMeter.finish!(p)\n",
    "    sentences\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02084c17-25e4-4e0e-88bf-18534166293d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function get_training_data(task, include_ptw, cls_tokens)\n",
    "#     @info \"loading training splits for $task\"\n",
    "#     function get_df(task, content)\n",
    "#         df = get_raw_split(\"training\", task, content)\n",
    "#         if content != \"explicit\"\n",
    "#             df.rating .= 11\n",
    "#         end\n",
    "#         df\n",
    "#     end\n",
    "#     contents = [\"explicit\", \"implicit\"]\n",
    "#     if include_ptw\n",
    "#         push!(contents, \"ptw\")\n",
    "#     end\n",
    "#     df = reduce(cat, [get_df(task, content) for content in contents])\n",
    "\n",
    "#     # shard the users across threads\n",
    "#     sharded_users = [[Int32[] for _ = 1:Threads.nthreads()] for _ = 1:Threads.nthreads()]\n",
    "#     sharded_timestamps =\n",
    "#         [[Float32[] for _ = 1:Threads.nthreads()] for _ = 1:Threads.nthreads()]\n",
    "#     @tprogress Threads.@threads for i = 1:length(df.user)\n",
    "#         key = (df.user[i] % Threads.nthreads()) + 1\n",
    "#         push!(sharded_users[Threads.threadid()][key], i)\n",
    "#         push!(sharded_timestamps[Threads.threadid()][key], df.timestamp[i])\n",
    "#     end\n",
    "#     users = Vector{Vector{Int32}}(undef, Threads.nthreads())\n",
    "#     timestamps = Vector{Vector{Float32}}(undef, Threads.nthreads())\n",
    "#     Threads.@threads for t = 1:Threads.nthreads()\n",
    "#         users[t] = reduce(vcat, [sharded_users[s][t] for s = 1:Threads.nthreads()])\n",
    "#         timestamps[t] =\n",
    "#             reduce(vcat, [sharded_timestamps[s][t] for s = 1:Threads.nthreads()])\n",
    "#     end\n",
    "#     users = [x for x in users if length(x) > 0]\n",
    "#     timestamps = [x for x in timestamps if length(x) > 0]\n",
    "\n",
    "#     @info \"constructing watch histories for $task\"\n",
    "#     sentences = Dict{Int32,Vector{wordtype}}(i => [] for i = 1:num_users())\n",
    "#     p = ProgressMeter.Progress(length(users[1]); showspeed = true)\n",
    "#     Threads.@threads for t = 1:length(users)\n",
    "#         order = users[t][sortperm(timestamps[t])]\n",
    "#         for i in order\n",
    "#             if length(sentences[df.user[i]]) == 0\n",
    "#                 sentences[df.user[i]] = [replace(cls_tokens, :user, df.user[i])]\n",
    "#             end\n",
    "#             word = encode_word(\n",
    "#                 df.item[i],\n",
    "#                 df.rating[i],\n",
    "#                 df.timestamp[i],\n",
    "#                 df.status[i],\n",
    "#                 df.completion[i],\n",
    "#                 df.user[i],\n",
    "#                 length(sentences[df.user[i]]),\n",
    "#             )\n",
    "#             push!(sentences[df.user[i]], word)\n",
    "#             if t == 1\n",
    "#                 ProgressMeter.next!(p)\n",
    "#             end\n",
    "#         end\n",
    "#     end\n",
    "#     ProgressMeter.finish!(p)\n",
    "#     Dict(k => v for (k, v) in sentences if length(v) > 0)\n",
    "# end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764fd3fd-6b56-4a4b-af5f-d2ec2f089177",
   "metadata": {},
   "outputs": [],
   "source": [
    "function subset_sentence(sentence, max_seq_length; recent, rng)\n",
    "    if length(sentence) > max_seq_length\n",
    "        if recent\n",
    "            # keep the rightmost entries\n",
    "            idx = length(sentence) - max_seq_length + 1\n",
    "        else\n",
    "            # take a random contiguous subset            \n",
    "            idx = rand(rng, 1:length(sentence)-max_seq_length+1)\n",
    "        end\n",
    "        sentence = sentence[idx:idx+max_seq_length-1]\n",
    "    end\n",
    "    sentence\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1dda2a7-8e5b-4519-b0e9-246cb358f8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function pad_sentence(sentence, max_seq_length, max_position, pad_tokens, cls_tokens; rng)\n",
    "    outputs = fill.(pad_tokens, max_seq_length)\n",
    "    sentence = subset_sentence(sentence, max_seq_length; recent = false, rng = rng)\n",
    "    for i = 1:length(sentence)\n",
    "        for j = 1:length(outputs)\n",
    "            if j == get_wordtype_index(:position) && extract(sentence[i], :item) != extract(cls_tokens, :item)\n",
    "                p = (sentence[i][j] % max_position)\n",
    "                if p == 0\n",
    "                    p = max_position\n",
    "                end\n",
    "                outputs[j][i] = p\n",
    "            else\n",
    "                outputs[j][i] = sentence[i][j]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    outputs\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd56c38b-d848-416f-a028-364b4dc1a99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_token_ids(sentences, max_seq_length, max_position, pad_tokens, cls_tokens; rng)\n",
    "    padded_sentences = [\n",
    "        pad_sentence(x, max_seq_length, max_position, pad_tokens, cls_tokens; rng = rng) for x in sentences\n",
    "    ]\n",
    "    Tuple(hcat([x[i] for x in padded_sentences]...) for i = 1:length(pad_tokens))\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.0-rc2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3758ece-9b72-47b4-ae6a-aa364e0443e3",
   "metadata": {},
   "source": [
    "# Item Collaborative Filtering\n",
    "* This notebook implements both item-based and user-based collaborative filtering\n",
    "* Prediction is $\\tilde r_{ij} = \\dfrac{\\sum_{k \\in N(j)} w_{kj}^{\\lambda_w}r_{ik}^{\\lambda_r}}{\\sum_{k \\in N(j)} w_{kj}^{\\lambda_w} + \\lambda}$ for item-based collaborative filtering\n",
    "* $r_{ij}$ is the rating for user $i$ and item $j$\n",
    "* $w_{kj}$ is the similarity between items $j$ and $k$\n",
    "* $N(j)$ is the largest $K$ sorted by $w_{kj}$\n",
    "* $\\lambda_w, \\lambda_r, \\lambda$ are regularization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc9334a-2287-41d6-885b-a5cca94fe263",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"ItemCollaborativeFiltering\";\n",
    "residual_alphas = [];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b7fbc147-91d6-4427-bf7a-2d2b6aa06694",
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra\n",
    "using Memoize\n",
    "using SparseArrays\n",
    "# TODO upstream imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "66f0ae4d-aa14-446f-b7d1-6e092aca4afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo improve interface for running residualizations in a circular manner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d17593ac-3260-4c01-a5df-91edfcd17e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "using NBInclude\n",
    "@nbinclude(\"Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff8e524-e8f8-48bd-9ca7-c28a05a122b8",
   "metadata": {},
   "source": [
    "## Determine the neighborhoods for each user and item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9572dd9-db8e-4b1c-83ca-cacc666325f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_correlation_matrix_outdir(residual_alphas)\n",
    "    # if the matrix is already stored on disk, return its filepath\n",
    "    # otherwise, regenerate the matrix and store it to disk\n",
    "    outdir = \"$name/$(hash(residual_alphas))\"\n",
    "    if ispath(\"../../data/alphas/$outdir\")\n",
    "        return outdir\n",
    "    end\n",
    "\n",
    "    training = get_residuals(\"training\", residual_alphas)\n",
    "    R = sparse(\n",
    "        training.user,\n",
    "        training.item,\n",
    "        training.rating,\n",
    "        maximum(training.user),\n",
    "        maximum(training.item),\n",
    "    )\n",
    "    S = zeros(maximum(training.item), maximum(training.item))\n",
    "\n",
    "    norms = map(norm, eachslice(R, dims = 2))\n",
    "    norms[norms.==0] .= 1 # prevent division by 0\n",
    "    @tprogress Threads.@threads for i = 1:size(S)[1]\n",
    "        S[:, i] = vec(R[:, i]' * R) ./ norms ./ norms[i]\n",
    "    end\n",
    "\n",
    "    write_params(Dict(\"S\" => S), outdir = outdir)\n",
    "    outdir\n",
    "end;\n",
    "\n",
    "function read_similarity_matrix(outdir)\n",
    "    read_params(outdir)[\"S\"]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cd34115c-51b5-4af1-908d-4322a46d5918",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_abs_neighborhood(item, S, K)\n",
    "    weights = S[:, item]\n",
    "    K = Int(min(K, length(weights) - 1))\n",
    "    # skip the most correlated item because it's always itself\n",
    "    order = partialsortperm(abs.(weights), 2:K+1, rev = true)\n",
    "    order, weights[order]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00ebb580-b942-4113-8d60-78a83042d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "# each prediction is just the weighted sum of all items in the neighborhood\n",
    "# we apply regularization terms to decay the weights, ratings, and final prediction\n",
    "function make_prediction(item, users, R, get_neighborhood, λ)\n",
    "    items, weights = get_neighborhood(item)\n",
    "    decay(x, a) = x != 0 ? sign(x) * abs(x)^a : 0\n",
    "    weights = decay.(weights, λ[1])\n",
    "    predictions = zeros(eltype(weights), length(users))\n",
    "    weight_sum = zeros(eltype(weights), length(users))\n",
    "    for u = 1:length(users)\n",
    "        for (i, weight) in zip(items, weights)\n",
    "            if R[users[u], i] != 0\n",
    "                predictions[u] += weight * decay(R[users[u], i], λ[2])\n",
    "                weight_sum[u] += abs(weight)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    for u = 1:length(users)\n",
    "        if weight_sum[u] + λ[3] != 0\n",
    "            predictions[u] /= (weight_sum[u] + λ[3])\n",
    "        end\n",
    "    end\n",
    "    predictions\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5214736f-516e-4d6f-8f0b-92171355ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "function collaborative_filtering(training, inference, get_neighborhood, λ)\n",
    "    R = sparse(\n",
    "        training.user,\n",
    "        training.item,\n",
    "        training.rating,\n",
    "        maximum(training.user),\n",
    "        maximum(training.item),\n",
    "    )\n",
    "\n",
    "    preds = zeros(eltype(λ), length(inference.rating), Threads.nthreads())\n",
    "    @tprogress Threads.@threads for item in collect(Set(inference.item))\n",
    "        mask = inference.item .== item\n",
    "        preds[mask, Threads.threadid()] =\n",
    "            make_prediction(item, inference.user[mask], R, get_neighborhood, λ)\n",
    "    end\n",
    "\n",
    "    vec(sum(preds, dims = 2))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c815cbbe-7300-4c9d-9163-4e554a9752e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "Base.@kwdef mutable struct cf_params\n",
    "    name::Any\n",
    "    training_residuals::Any\n",
    "    validation_residuals::Any\n",
    "    neighborhood_type::Any\n",
    "    S::Any # the similarity matrix\n",
    "    K::Any # the neighborhood size\n",
    "    λ::Vector{Float64} = [1.0, 1.0, 0.0] # [weight_decay, rating_decay, prediction_decay]\n",
    "end;\n",
    "\n",
    "to_dict(x::T) where {T} = Dict(string(fn) => getfield(x, fn) for fn ∈ fieldnames(T));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0c00b2aa-a40c-4374-9631-9918f0f55968",
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup hyperparameters\n",
    "downcast_to_int(x) = isinteger(x) ? Int(x) : x\n",
    "item_cf_params = [[\n",
    "        cf_params(\n",
    "            name = \"ItemCF.$K\",\n",
    "            training_residuals = [\"UserItemBiases\"],\n",
    "            validation_residuals = [\"UserItemBiases\"],\n",
    "            neighborhood_type = \"abs\",\n",
    "            S = get_correlation_matrix_outdir([\"UserItemBiases\"]),\n",
    "            K = K,\n",
    "            λ = [1.0, 1.0, 0.0],\n",
    "        ) for K in downcast_to_int.([2^4, 2^6, 2^8, 2^10])\n",
    "    ];\n",
    "];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cf908b-4b56-412a-9765-c13021874f41",
   "metadata": {},
   "source": [
    "## Item based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "904a3cc2-c5e7-4e1b-810a-b3616c4d1b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_training(residual_alphas)\n",
    "    get_residuals(\"training\", residual_alphas)\n",
    "end\n",
    "\n",
    "function get_validation(residual_alphas)\n",
    "    get_residuals(\"validation\", residual_alphas)\n",
    "end\n",
    "\n",
    "function get_inference()\n",
    "    training = get_split(\"training\")\n",
    "    validation = get_split(\"validation\")\n",
    "    test = get_split(\"test\")\n",
    "    RatingsDataset(\n",
    "        user = [training.user; validation.user; test.user],\n",
    "        item = [training.item; validation.item; test.item],\n",
    "        rating = fill(0.0, length(training.rating) + length(validation.item) + length(test.item)),\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1842d509-9377-4b28-9fe9-9212da6183d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress:   1%|▎                          |  ETA: 2:58:00 ( 2.71  s/it)\u001b[39m"
     ]
    }
   ],
   "source": [
    "for param in item_cf_params\n",
    "    # unpack parameters\n",
    "    training = get_training(param.training_residuals)\n",
    "    validation = get_validation(param.validation_residuals)\n",
    "    item_ratings = sparse(\n",
    "        training.user,\n",
    "        training.item,\n",
    "        training.rating,\n",
    "        maximum(training.user),\n",
    "        maximum(training.item),\n",
    "    )\n",
    "    S = read_similarity_matrix(param.S)\n",
    "    K = param.K\n",
    "    neighborhood_types = Dict(\"abs\" => get_abs_neighborhood)\n",
    "    neighborhoods = i -> neighborhood_types[param.neighborhood_type](i, S, K)\n",
    "\n",
    "    # optimize hyperparameters\n",
    "    function validation_mse(λ)\n",
    "        pred = collaborative_filtering(training, validation, neighborhoods, λ)\n",
    "        truth = validation.rating\n",
    "        β = pred \\ truth\n",
    "        loss = mse(truth, pred .* β)\n",
    "        @debug \"loss: $loss β: $β: λ $λ\"\n",
    "        loss\n",
    "    end\n",
    "    res = optimize(\n",
    "        validation_mse,\n",
    "        param.λ,\n",
    "        LBFGS(),\n",
    "        autodiff = :forward,\n",
    "        Optim.Options(show_trace = true, extended_trace = true),\n",
    "    )\n",
    "    param.λ = Optim.minimizer(res)\n",
    "\n",
    "    # save predictions\n",
    "    inference = get_inference()\n",
    "    preds = collaborative_filtering(training, inference, neighborhoods, param.λ)\n",
    "    sparse_preds = sparse(inference.user, inference.item, preds)\n",
    "    function model(users, items, predictions)\n",
    "        result = zeros(length(users))\n",
    "        for i = 1:length(users)\n",
    "            if users[i] <= size(predictions)[1] && items[i] <= size(predictions)[2]\n",
    "                result[i] = predictions[users[i], items[i]]\n",
    "            end\n",
    "        end\n",
    "        result\n",
    "    end\n",
    "    write_predictions(\n",
    "        (users, items) -> model(users, items, sparse_preds),\n",
    "        outdir = param.name,\n",
    "        residual_alphas = param.validation_residuals,\n",
    "        save_training=true,\n",
    "    )\n",
    "    write_params(to_dict(param), outdir = param.name)\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fd8e95-6d93-4604-bea3-43053993a8a7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

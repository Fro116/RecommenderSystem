{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba949471-e864-4ebf-b949-7772e87b6057",
   "metadata": {},
   "source": [
    "# Common utitities for all alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f693eb8-9aab-4305-a6ee-17e885f3f24d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "using CSV\n",
    "using DataFrames\n",
    "using Dates\n",
    "using FileIO\n",
    "using Flux\n",
    "using JLD2\n",
    "using JupyterFormatter\n",
    "using LinearAlgebra\n",
    "using LoggingExtras\n",
    "using Memoize\n",
    "using Optim\n",
    "using Parameters\n",
    "using ProgressMeter\n",
    "using SparseArrays\n",
    "using Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52c3be3-c7d8-4a18-8d83-f82a0858380a",
   "metadata": {},
   "source": [
    "# General utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d03d88-f3cc-45ed-bdf9-ef33b7021a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO upstream this into the ProgressMeter\n",
    "macro tprogress(expr)\n",
    "    # let the @progress macro work with Threads.@threads\n",
    "    loop = expr\n",
    "    if loop.head == :macrocall && loop.args[1] == :(Threads.var\"@threads\")\n",
    "        loop = loop.args[end]\n",
    "    end\n",
    "    \n",
    "    p = gensym()    \n",
    "    r = loop.args[1].args[end]\n",
    "    ex = quote\n",
    "        n = Int(round(length($(esc(r))) / Threads.nthreads()))\n",
    "        global $p = Progress(n; showspeed=true)\n",
    "        $(esc(expr))\n",
    "        finish!($p)\n",
    "    end\n",
    "    \n",
    "    update = quote\n",
    "        if Threads.threadid() == 1\n",
    "            next!($p)\n",
    "        end\n",
    "    end\n",
    "    push!(loop.args[end].args, update)    \n",
    "    \n",
    "    ex    \n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b70f5-bfbf-4975-8125-2e96a962e0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "enable_autoformat();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd43cb7-3f58-412d-b8fd-9fefe907e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefer Julia multithreading to BLAS multithreading\n",
    "BLAS.set_num_threads(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48c27994-a711-4e6f-9c8d-2363f01344e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss functions\n",
    "function wmean(x, w)\n",
    "    sum(x .* w) / sum(w)\n",
    "end\n",
    "\n",
    "function equal_weight(x)\n",
    "    ones(eltype(x), length(x))\n",
    "end\n",
    "\n",
    "function mse(truth, pred, weights)\n",
    "    wmean((truth .- pred) .^ 2, weights)\n",
    "end\n",
    "\n",
    "function mse(truth, pred)\n",
    "    mse(truth, pred, equal_weight(truth))\n",
    "end\n",
    "\n",
    "function rmse(truth, pred, weights)\n",
    "    sqrt(mse(truth, pred, weights))\n",
    "end\n",
    "\n",
    "function rmse(truth, pred)\n",
    "    rmse(truth, pred, equal_weight(truth))\n",
    "end\n",
    "\n",
    "function mae(truth, pred, weights)\n",
    "    wmean(abs.(truth .- pred), weights)\n",
    "end\n",
    "\n",
    "function mae(truth, pred)\n",
    "    mae(truth, pred, equal_weight(truth))\n",
    "end\n",
    "\n",
    "function r2(truth, pred, weights)\n",
    "    1 - mse(truth, pred, weights) / mse(truth, mean(truth), weights)\n",
    "end\n",
    "\n",
    "function r2(truth, pred)\n",
    "    r2(truth, pred, equal_weight(truth))\n",
    "end\n",
    "\n",
    "function sparse_crossentropy(p, weights, ϵ = 1e-16)\n",
    "    # cross entropy loss where we are given the probabilities for every true label \n",
    "    -wmean(log.(clamp.(p, ϵ, Inf)), weights)\n",
    "end;\n",
    "\n",
    "function sparse_crossentropy(p, ϵ = 1e-16)\n",
    "    sparse_crossentropy(p, equal_weight(p), ϵ)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1ad5e6a-7ccb-4886-b500-e57b86cb9e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop training if the parameters have converged\n",
    "@with_kw mutable struct convergence_stopper\n",
    "    tolerance::AbstractFloat\n",
    "    max_iters = Inf\n",
    "    params::AbstractVector\n",
    "    prev_params::AbstractVector\n",
    "    iters = 0\n",
    "end\n",
    "\n",
    "function convergence_stopper(tolerance; max_iters=Inf)\n",
    "    convergence_stopper(tolerance = tolerance, max_iters=max_iters, params = [], prev_params = [])\n",
    "end\n",
    "\n",
    "function stop!(x::convergence_stopper, params)\n",
    "    x.iters += 1\n",
    "    if x.iters > x.max_iters\n",
    "        return true\n",
    "    end\n",
    "\n",
    "    if x.iters == 1\n",
    "        x.params = deepcopy(params)\n",
    "        return false\n",
    "    end\n",
    "\n",
    "    function maxabs(a)\n",
    "        maximum(abs.(a))\n",
    "    end\n",
    "\n",
    "    x.prev_params = deepcopy(x.params)\n",
    "    x.params = deepcopy(params)\n",
    "    maximum(maxabs.(x.params - x.prev_params)) < x.tolerance\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84f68e28-f0aa-4fa6-a423-10b12953a5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop training if the loss function has stopped decreasing\n",
    "@with_kw mutable struct early_stopper\n",
    "    max_iters = Inf\n",
    "    patience = Inf\n",
    "    min_rel_improvement = 0\n",
    "    iters = 0\n",
    "    iters_without_improvement = 0\n",
    "    loss = NaN\n",
    "end\n",
    "\n",
    "function stop!(x::early_stopper, loss)\n",
    "    x.iters += 1\n",
    "    if x.iters > x.max_iters\n",
    "        return true\n",
    "    end\n",
    "    \n",
    "    if x.iters == 1\n",
    "        x.loss = loss\n",
    "        return false\n",
    "    end\n",
    "\n",
    "    if loss < x.loss * (1 - x.min_rel_improvement)\n",
    "        x.loss = loss\n",
    "        x.iters_without_improvement = 0\n",
    "    else\n",
    "        x.iters_without_improvement += 1\n",
    "    end\n",
    "    x.iters_without_improvement > x.patience\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2411a5e8-1398-4d8a-a64c-c50a5e39b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger that flushes after every log statement\n",
    "struct FlushLogger <: AbstractLogger\n",
    "    logger::ConsoleLogger\n",
    "end\n",
    "\n",
    "function FlushLogger(logger::AbstractLogger)\n",
    "    FlushLogger(logger)\n",
    "end\n",
    "\n",
    "function Logging.handle_message(logger::FlushLogger, args...; kwargs...)\n",
    "    Logging.handle_message(logger.logger, args...; kwargs...)\n",
    "    flush(logger.logger.stream)\n",
    "end\n",
    "\n",
    "Logging.shouldlog(logger::FlushLogger, arg...) = Logging.shouldlog(logger.logger, arg...)\n",
    "Logging.min_enabled_level(logger::FlushLogger) = Logging.min_enabled_level(logger.logger)\n",
    "Logging.catch_exceptions(logger::FlushLogger) = Logging.catch_exceptions(logger.logger)\n",
    "\n",
    "function logging_meta_formatter(level, _module, group, id, file, line)\n",
    "    prefix_color = (\n",
    "        level < Logging.Info ? 4 : level < Logging.Warn ? 6 : level < Logging.Error ? 3 : 1\n",
    "    )\n",
    "    prefix = (level == Logging.Warn ? \"Warning\" : string(level)) * ':'\n",
    "    prefix_color, prefix, \"\"\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310957e5-891f-4797-879f-0084e8560b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log to file and stdout at the same time\n",
    "function redirect_logging(outdir)\n",
    "    date_format = \"yyyymmdd HH:MM:SS\"\n",
    "    timestamp_logger(logger) =\n",
    "        TransformerLogger(logger) do log\n",
    "            merge(log, (; message = \"$(Dates.format(now(), date_format)) $(log.message)\"))\n",
    "        end\n",
    "\n",
    "    outdir = mkpath(outdir)\n",
    "    global_logger(\n",
    "        TeeLogger(\n",
    "            FlushLogger(\n",
    "                ConsoleLogger(\n",
    "                    stderr,\n",
    "                    Logging.Info;\n",
    "                    meta_formatter = logging_meta_formatter,\n",
    "                ),\n",
    "            ) |> timestamp_logger,\n",
    "            FlushLogger(\n",
    "                ConsoleLogger(\n",
    "                    open(\"$(outdir)/log\", write = true),\n",
    "                    Logging.Info;\n",
    "                    meta_formatter = logging_meta_formatter,\n",
    "                ),\n",
    "            ) |> timestamp_logger,\n",
    "        ),\n",
    "    )\n",
    "end;\n",
    "\n",
    "redirect_logging(\"../../data/alphas/$name\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9bcd93-0801-4944-9e44-b2b25cc16934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A custom split layer for Flux\n",
    "struct Split{T}\n",
    "    paths::T\n",
    "end\n",
    "Split(paths...) = Split(paths)\n",
    "Flux.@functor Split\n",
    "(m::Split)(x::AbstractArray) = map(f -> f(x), m.paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064f7f66-bef4-477f-b8c0-96f8a65cc9d3",
   "metadata": {},
   "source": [
    "# Alpha specific utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39d7a7e-403e-4104-b2a8-f5c48da9c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@with_kw struct RatingsDataset\n",
    "    user::Vector{Int32}\n",
    "    item::Vector{Int32}\n",
    "    rating::Vector{Float32}\n",
    "end;\n",
    "\n",
    "function Base.adjoint(x::RatingsDataset)\n",
    "    RatingsDataset(x.item, x.user, x.rating)\n",
    "end;\n",
    "\n",
    "function get_split(split)\n",
    "    @assert split in [\"training\", \"validation\", \"test\", \"implicit\", \"implicit_training\"]\n",
    "    file = \"../../data/splits/splits.jld2\"\n",
    "    load(file, split)\n",
    "end;\n",
    "\n",
    "function get_split(split, transpose)\n",
    "    df = get_split(split)\n",
    "    return transpose ? df' : df\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "816ee316-9b8c-4cfe-b671-d79ddfcc90f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some sparse matrix operations require indices to be Int64\n",
    "@with_kw struct RatingsDataset64\n",
    "    user::Vector{Int64}\n",
    "    item::Vector{Int64}\n",
    "    rating::Vector{Float32}\n",
    "end;\n",
    "\n",
    "function RatingsDataset64(x::RatingsDataset)\n",
    "    RatingsDataset64(\n",
    "        convert.(Int64, x.user),\n",
    "        convert.(Int64, x.item),\n",
    "        convert.(Float32, x.rating),\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "410b8c50-92ac-4369-9b08-1c8b85f8058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function Base.cat(x::RatingsDataset, y::RatingsDataset)\n",
    "    RatingsDataset([x.user; y.user], [x.item; y.item], [x.rating; y.rating])\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ddd8e-1c8c-49b0-97ef-848107f4af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "@memoize function num_items()\n",
    "    df = DataFrame(CSV.File(\"../../data/processed_data/anime_to_uid.csv\"))\n",
    "    length(df.uid)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40dc66eb-9870-4d4c-bff8-5f5a1b46a18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_alpha(alpha, split)\n",
    "    @assert split in [\"training\", \"validation\", \"test\"]\n",
    "    file = \"../../data/alphas/$(alpha)/predictions.jld2\"\n",
    "    load(file, split)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3435b41-3aaa-4fd6-a4eb-b04338c3f16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function weighting_scheme(x, scheme::Number)\n",
    "    return x == 0 ? zero(eltype(scheme)) : x^scheme\n",
    "end;\n",
    "\n",
    "function weighting_scheme(scheme::String)\n",
    "    if scheme == \"linear\"\n",
    "        return 1\n",
    "    elseif scheme == \"constant\"\n",
    "        return 0\n",
    "    elseif scheme == \"inverse\"\n",
    "        return -1\n",
    "    else\n",
    "        @assert false\n",
    "        return 0\n",
    "    end\n",
    "end;\n",
    "\n",
    "function get_counts(split)\n",
    "    counts = zeros(eltype(split.rating), maximum(split.user), Threads.nthreads())\n",
    "    @tprogress Threads.@threads for i = 1:length(split.rating)\n",
    "        counts[split.user[i], Threads.threadid()] += 1\n",
    "    end\n",
    "    sum(counts, dims = 2)    \n",
    "end\n",
    "\n",
    "function get_weights(split, scheme::Number; per_rating=false, by_item=false)\n",
    "    split = get_split(split, by_item)\n",
    "    counts = get_counts(split)\n",
    "    \n",
    "    if per_rating\n",
    "       return weighting_scheme.(vec(counts), scheme)\n",
    "    end\n",
    "\n",
    "    outtype = eltype(scheme) <: Number ? eltype(scheme) : eltype(counts)\n",
    "    weights = zeros(outtype, length(split.user))\n",
    "    Threads.@threads for i = 1:length(weights)\n",
    "        weights[i] = weighting_scheme(counts[split.user[i]], scheme)\n",
    "    end\n",
    "    weights\n",
    "end\n",
    "\n",
    "@memoize function get_weights(split, scheme::String)\n",
    "    el_type = eltype(get_split(split).rating)\n",
    "    get_weights(split, convert(el_type, weighting_scheme(scheme)))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea33e3e7-ba24-4f51-937a-2469c71b9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "@memoize function get_residual_beta(alphas)\n",
    "    # train a linear model on the validation set\n",
    "    split = \"validation\"\n",
    "    y = get_split(split).rating\n",
    "    X = zeros(length(y), length(alphas))\n",
    "    @tprogress Threads.@threads for j = 1:length(alphas)\n",
    "        X[:, j] = get_alpha(alphas[j], split).rating\n",
    "    end\n",
    "    \n",
    "    # weight each user equally\n",
    "    weights_sqrt = sqrt.(get_weights(split, \"inverse\"))\n",
    "    (X .* weights_sqrt) \\ (y .* weights_sqrt)\n",
    "end\n",
    "\n",
    "function get_residuals(split, alphas)\n",
    "    # residualize out the linear model\n",
    "    β = get_residual_beta(alphas)\n",
    "    df = get_split(split)\n",
    "    ratings = df.rating\n",
    "    @showprogress for j = 1:length(alphas)\n",
    "        ratings -= β[j] * get_alpha(alphas[j], split).rating\n",
    "    end\n",
    "    RatingsDataset(df.user, df.item, ratings)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a717beaf-8ded-4f72-b6d9-c15f4b929ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "function write_predictions(model; outdir = name, residual_alphas, implicit = false)\n",
    "    splits_to_save = [\"training\", \"validation\", \"test\"]\n",
    "    if implicit\n",
    "        # the implicit predictions for the training set are not \n",
    "        # worth storing because we don't use them for residualization\n",
    "        splits_to_save = splits_to_save[2:end]\n",
    "    end\n",
    "    # don't cheat by peeking at the test set\n",
    "    splits_to_log = splits_to_save[1:end-1]\n",
    "\n",
    "    predictions = Dict()\n",
    "    for split in splits_to_save\n",
    "        df = get_residuals(split, residual_alphas)\n",
    "        pred = model(df.user, df.item)\n",
    "        if split in splits_to_log\n",
    "            if !implicit\n",
    "                truth = df.rating\n",
    "                β = pred \\ truth\n",
    "                @info \"$(split) set: RMSE $(rmse(truth, β*pred)) \" *\n",
    "                      \"MAE $(mae(truth, β*pred)) R2 $(r2(truth, β*pred))\"\n",
    "                weights = get_weights(split, \"inverse\")\n",
    "                β = (pred .* sqrt.(weights)) \\ (truth .* sqrt.(weights))\n",
    "                @info \"$(split) set weighted-loss: RMSE $(rmse(truth, β*pred, weights)) \" *\n",
    "                      \"MAE $(mae(truth, β*pred, weights)) R2 $(r2(truth, β*pred, weights))\"                \n",
    "            else\n",
    "                @info \"$(split) set: Cross-Entropy loss $(sparse_crossentropy(pred))\"\n",
    "                weights = get_weights(split, \"inverse\")\n",
    "                @info \"$(split) set weighted-loss: Cross-Entropy loss $(sparse_crossentropy(pred, weights))\"                \n",
    "            end\n",
    "        end\n",
    "        predictions[split] = RatingsDataset(df.user, df.item, pred)\n",
    "    end\n",
    "\n",
    "    outdir = mkpath(\"../../data/alphas/$outdir\")\n",
    "    save(\"$outdir/predictions.jld2\", predictions)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5237f49-f24d-43e1-9698-7358d22e7c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function write_params(params; outdir = name)\n",
    "    outdir = mkpath(\"../../data/alphas/$outdir\")\n",
    "    save(\"$outdir/params.jld2\", params)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8175e09e-f7e8-47c1-a183-64931366b9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "function read_params(alpha)\n",
    "    load(\"../../data/alphas/$alpha/params.jld2\")\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

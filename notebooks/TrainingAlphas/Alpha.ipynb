{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba949471-e864-4ebf-b949-7772e87b6057",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Helper functions for training alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f693eb8-9aab-4305-a6ee-17e885f3f24d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T10:14:16.883",
     "iopub.status.busy": "2023-11-15T10:14:16.625",
     "iopub.status.idle": "2023-11-15T10:14:18.421",
     "shell.execute_reply": "2023-11-15T10:14:18.383"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import CSV\n",
    "import DataFrames: DataFrame\n",
    "import JLD2\n",
    "import Memoize: @memoize\n",
    "import NBInclude: @nbinclude\n",
    "import NNlib: softmax\n",
    "import Optim\n",
    "import ProgressMeter: @showprogress\n",
    "import Setfield\n",
    "import Setfield: @set\n",
    "import SparseArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd094a91-95a1-4007-a3c6-748cda48f03d",
   "metadata": {},
   "source": [
    "## General utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd9bcd93-0801-4944-9e44-b2b25cc16934",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T10:14:18.552",
     "iopub.status.busy": "2023-11-15T10:14:18.421",
     "iopub.status.idle": "2023-11-15T10:14:18.823",
     "shell.execute_reply": "2023-11-15T10:14:18.823"
    }
   },
   "outputs": [],
   "source": [
    "@nbinclude(\"AlphaUtils.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9d0e0457-b3a2-4283-a855-efd59838d397",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T10:14:18.868",
     "iopub.status.busy": "2023-11-15T10:14:18.823",
     "iopub.status.idle": "2023-11-15T10:14:23.856",
     "shell.execute_reply": "2023-11-15T10:14:23.856"
    }
   },
   "outputs": [],
   "source": [
    "function get_data_path(file)\n",
    "    path = pwd()\n",
    "    while basename(path) != \"notebooks\"\n",
    "        path = dirname(path)\n",
    "    end\n",
    "    path = dirname(path)\n",
    "    \"$path/data/$file\"\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "94fef655-3bf2-494b-870c-96e1b027335e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T10:14:23.856",
     "iopub.status.busy": "2023-11-15T10:14:23.856",
     "iopub.status.idle": "2023-11-15T10:14:23.983",
     "shell.execute_reply": "2023-11-15T10:14:23.983"
    }
   },
   "outputs": [],
   "source": [
    "function set_logging_outdir(name)\n",
    "    redirect_logging(get_data_path(\"alphas/$name\"); overwrite = false)\n",
    "end\n",
    "if @isdefined name\n",
    "    set_logging_outdir(name)\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a27bef3-23dd-49fb-b313-1317cc9f1151",
   "metadata": {},
   "source": [
    "## Static data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca2ddd8e-1c8c-49b0-97ef-848107f4af49",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T10:14:23.983",
     "iopub.status.busy": "2023-11-15T10:14:23.983",
     "iopub.status.idle": "2023-11-15T10:14:24.259",
     "shell.execute_reply": "2023-11-15T10:14:24.259"
    }
   },
   "outputs": [],
   "source": [
    "@memoize function num_users()\n",
    "    df = DataFrame(CSV.File(get_data_path(\"processed_data/username_to_uid.csv\")))\n",
    "    length(df.uid)\n",
    "end\n",
    "\n",
    "@memoize function num_items(medium)\n",
    "    df = DataFrame(CSV.File(get_data_path(\"processed_data/$(medium)_to_uid.csv\")))\n",
    "    length(df.uid)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d8c06fef-9c4a-47bb-91c6-58533ae37d92",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T10:14:24.260",
     "iopub.status.busy": "2023-11-15T10:14:24.259",
     "iopub.status.idle": "2023-11-15T10:14:24.896",
     "shell.execute_reply": "2023-11-15T10:14:24.895"
    }
   },
   "outputs": [],
   "source": [
    "@memoize function get_timestamp_encodings()\n",
    "    function parse_line(file::IO, field::String, format::Type = Int)\n",
    "        line = readline(file)\n",
    "        fields = split(strip(line), \",\")\n",
    "        @assert length(fields) == 2\n",
    "        @assert fields[1] == field\n",
    "        parse(format, fields[2])\n",
    "    end\n",
    "\n",
    "    open(get_data_path(\"processed_data/timestamps.csv\")) do f\n",
    "        return parse_line(f, \"min_timestamp\"), parse_line(f, \"max_timestamp\")\n",
    "    end\n",
    "end\n",
    "\n",
    "\n",
    "@memoize function day_in_timestamp_units()\n",
    "    min_timestamp, max_timestamp = get_timestamp_encodings()\n",
    "    seconds_in_day = 24 * 60 * 60\n",
    "    return seconds_in_day / Float64(max_timestamp - min_timestamp)\n",
    "end\n",
    "\n",
    "function timestamp_to_unix(ts)\n",
    "    @assert ts > 0\n",
    "    min_timestamp, max_timestamp = get_timestamp_encodings()\n",
    "    unix_time = Int64(round(ts * (max_timestamp - min_timestamp) + min_timestamp))\n",
    "end\n",
    "\n",
    "function unix_to_timestamp(unix_time)\n",
    "    min_timestamp, max_timestamp = get_timestamp_encodings()\n",
    "    ts = (unix_time - min_timestamp) / (max_timestamp - min_timestamp)\n",
    "    convert(Float32, ts)\n",
    "end\n",
    "\n",
    "function timestamp_to_date(ts)\n",
    "    Dates.unix2datetime(timestamp_to_unix(ts))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "35db7d1e-31e1-44a8-b68b-3a1348309088",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T10:14:24.896",
     "iopub.status.busy": "2023-11-15T10:14:24.896",
     "iopub.status.idle": "2023-11-15T10:14:24.896",
     "shell.execute_reply": "2023-11-15T10:14:24.896"
    }
   },
   "outputs": [],
   "source": [
    "function get_status(status::Symbol)\n",
    "    status_encoding = Dict(\n",
    "        :rewatching => 7,\n",
    "        :completed => 6,\n",
    "        :watching => 5,\n",
    "        :plan_to_watch => 4,\n",
    "        :on_hold => 3,\n",
    "        :dropped => 2,\n",
    "        :wont_watch => 1,\n",
    "        :none => 0,\n",
    "    )\n",
    "    status_encoding[status]\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a83f090-19d7-4ed6-8828-09a195527cf3",
   "metadata": {},
   "source": [
    "## Reading and writing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f39d7a7e-403e-4104-b2a8-f5c48da9c7cc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T10:14:24.896",
     "iopub.status.busy": "2023-11-15T10:14:24.896",
     "iopub.status.idle": "2023-11-15T10:14:25.086",
     "shell.execute_reply": "2023-11-15T10:14:25.086"
    }
   },
   "outputs": [],
   "source": [
    "@kwdef struct RatingsDataset\n",
    "    source::Vector{Int32} = []\n",
    "    medium::Vector{Int32} = []\n",
    "    userid::Vector{Int32} = []\n",
    "    itemid::Vector{Int32} = []\n",
    "    status::Vector{Int32} = []\n",
    "    rating::Vector{Float32} = []\n",
    "    update_order::Vector{Int32} = []\n",
    "    updated_at::Vector{Float32} = []\n",
    "    created_at::Vector{Float32} = []\n",
    "    started_at::Vector{Float32} = []\n",
    "    finished_at::Vector{Float32} = []\n",
    "    progress::Vector{Float32} = []\n",
    "    repeat_count::Vector{Int32} = []\n",
    "    priority::Vector{Float32} = []\n",
    "    sentiment::Vector{Int32} = []\n",
    "    sentiment_score::Vector{Float32} = []\n",
    "    owned::Vector{Float32} = []\n",
    "    metric::Vector{Float32} = []\n",
    "end;\n",
    "\n",
    "# append two datasets\n",
    "function Base.cat(x::RatingsDataset, y::RatingsDataset)\n",
    "    # argument validation\n",
    "    x_is_nonempty = false\n",
    "    y_is_nonempty = false\n",
    "    for field in fieldnames(RatingsDataset)\n",
    "        if field in [:medium]\n",
    "            @assert getfield(x, field) == getfield(y, field)\n",
    "            continue\n",
    "        end\n",
    "        if length(getfield(x, field)) != 0\n",
    "            x_is_nonempty = true\n",
    "        end\n",
    "        if length(getfield(y, field)) != 0\n",
    "            y_is_nonempty = true\n",
    "        end\n",
    "    end\n",
    "    if x_is_nonempty && y_is_nonempty\n",
    "        for field in fieldnames(RatingsDataset)\n",
    "            a = length(getfield(x, field)) != 0\n",
    "            b = length(getfield(y, field)) != 0\n",
    "            @assert a == b \"cat: missing field $field\"\n",
    "        end\n",
    "    end\n",
    "\n",
    "    RatingsDataset(\n",
    "        [vcat(getfield(x, c), getfield(y, c)) for c in fieldnames(RatingsDataset)]...,\n",
    "    )\n",
    "end\n",
    "\n",
    "function Base.filter(x::RatingsDataset, mask::BitVector)\n",
    "    filter_array(a) = length(a) > 0 ? a[mask] : []\n",
    "    RatingsDataset([filter_array(getfield(x, c)) for c in fieldnames(RatingsDataset)]...)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a31d149f-b583-49db-8fd5-403affba7f12",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T10:14:25.086",
     "iopub.status.busy": "2023-11-15T10:14:25.086",
     "iopub.status.idle": "2023-11-15T10:14:25.087",
     "shell.execute_reply": "2023-11-15T10:14:25.087"
    }
   },
   "outputs": [],
   "source": [
    "function SparseArrays.sparse(x::RatingsDataset)\n",
    "    SparseArrays.sparse(x.item, x.user, x.metric, num_items(x.medium), num_users())\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a973d23-548c-4cf3-8012-a013b1a30813",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T10:14:25.087",
     "iopub.status.busy": "2023-11-15T10:14:25.087",
     "iopub.status.idle": "2023-11-15T10:14:25.087",
     "shell.execute_reply": "2023-11-15T10:14:25.087"
    }
   },
   "outputs": [],
   "source": [
    "const ALL_SPLITS = [\"training\", \"validation\", \"test\", \"negative\"]\n",
    "const ALL_METRICS = [\"rating\", \"watch\", \"plantowatch\", \"drop\"]\n",
    "const ALL_MEDIUMS = [\"manga\", \"anime\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b365d5fa-6a8b-4468-af42-4c87a54017b0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T10:15:55.142",
     "iopub.status.busy": "2023-11-15T10:15:55.142",
     "iopub.status.idle": "2023-11-15T10:15:55.147",
     "shell.execute_reply": "2023-11-15T10:15:55.147"
    }
   },
   "outputs": [],
   "source": [
    "function get_split(split::String, metric::String, medium::String, fields::Vector{Symbol})\n",
    "    validargs = split in ALL_SPLITS && metric in ALL_METRICS && medium in ALL_MEDIUMS\n",
    "    @assert validargs \"($split, $metric, $medium) ∉ (split, metric, medium)\"\n",
    "\n",
    "    extrafields = Dict(\n",
    "        \"rating\" => [:rating],\n",
    "        \"watch\" => [:status],\n",
    "        \"plantowatch\" => [:status],\n",
    "        \"drop\" => [:status],\n",
    "    )\n",
    "    fetch = union(Set(fields), Set(extrafields[metric]))\n",
    "    delete!(fetch, :metric)\n",
    "    df = get_raw_split(split, medium, collect(fetch))\n",
    "\n",
    "    if metric == \"rating\"\n",
    "        df = filter(df, df.rating .!= 0)\n",
    "        df = @set df.metric = copy(df.rating)\n",
    "    elseif metric == \"watch\"\n",
    "        df = filter(df, df.status .> get_status(:wont_watch))\n",
    "        df = @set df.metric = ones(Float32, length(df.status))\n",
    "    elseif metric == \"plantowatch\"\n",
    "        df = filter(df, df.status .== get_status(:plan_to_watch))\n",
    "        df = @set df.metric = ones(Float32, length(df.status))\n",
    "    elseif metric == \"drop\"\n",
    "        df = filter(\n",
    "            df,\n",
    "            (df.status .> get_status(:wont_watch)) .&&\n",
    "            (df.status .!= get_status(:plan_to_watch)),\n",
    "        )\n",
    "        df = @set df.metric = zeros(Float32, length(df.status))\n",
    "        for i = 1:length(df.status)\n",
    "            if df.status[i] <= get_status(:dropped)\n",
    "                df.metric[i] = 1\n",
    "            end\n",
    "        end\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "\n",
    "    # clear any columns you are not interested in\n",
    "    for f in fieldnames(RatingsDataset)\n",
    "        if f ∉ fields\n",
    "            df = Setfield.set(df, Setfield.PropertyLens{f}(), [])\n",
    "        end\n",
    "    end\n",
    "    df\n",
    "end\n",
    "\n",
    "function get_raw_split(split::String, medium::String, fields::Vector{Symbol})\n",
    "    file = get_data_path(\"splits/$(split).$(medium).jld2\")\n",
    "    data = JLD2.load(file, String.(fields)...)\n",
    "    df = RatingsDataset()\n",
    "    for i = 1:length(fields)\n",
    "        df = Setfield.set(df, Setfield.PropertyLens{fields[i]}(), data[i])\n",
    "    end\n",
    "    df\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "34e757e4-d21f-450d-a18f-568483f95224",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T10:14:27.956",
     "iopub.status.busy": "2023-11-15T10:14:27.956",
     "iopub.status.idle": "2023-11-15T10:14:27.958",
     "shell.execute_reply": "2023-11-15T10:14:27.958"
    }
   },
   "outputs": [],
   "source": [
    "function write_alpha(\n",
    "    model::Function,\n",
    "    medium::String,\n",
    "    outdir::String;\n",
    "    splits::Vector{String},\n",
    ")\n",
    "    alpha = Dict()\n",
    "    for split in splits\n",
    "        df = get_raw_split(split, medium, [:user, :item])\n",
    "        x = model(df.user, df.item)\n",
    "        @assert length(x) == length(df.user)\n",
    "        alpha[\"$split.$medium\"] = RatingsDataset(metric = x)\n",
    "    end\n",
    "    outdir = mkpath(get_data_path(\"alphas/$outdir\"))\n",
    "    JLD2.save(\"$outdir/alpha.jld2\", alpha; compress = true)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0180a286-438d-4342-932f-95c2d00f2726",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T10:14:27.958",
     "iopub.status.busy": "2023-11-15T10:14:27.958",
     "iopub.status.idle": "2023-11-15T10:14:27.959",
     "shell.execute_reply": "2023-11-15T10:14:27.959"
    }
   },
   "outputs": [],
   "source": [
    "function read_alpha(alpha::String, split::String, metric::String, medium::String)\n",
    "    file = get_data_path(\"alphas/$(alpha)/alpha.jld2\")\n",
    "    a = JLD2.load(file, \"$split.$medium\")\n",
    "    df = get_split(split, task, content, medium; fields = [:user, :item])\n",
    "    @assert length(df.user) == length(a.metric)\n",
    "    @set df.metric = a\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e5237f49-f24d-43e1-9698-7358d22e7c1b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T10:14:27.959",
     "iopub.status.busy": "2023-11-15T10:14:27.959",
     "iopub.status.idle": "2023-11-15T10:14:27.960",
     "shell.execute_reply": "2023-11-15T10:14:27.960"
    }
   },
   "outputs": [],
   "source": [
    "function write_params(params, outdir)\n",
    "    outdir = mkpath(get_data_path(\"alphas/$outdir\"))\n",
    "    JLD2.save(\"$outdir/params.jld2\", params)\n",
    "end\n",
    "\n",
    "function read_params(alpha)\n",
    "    JLD2.load(get_data_path(\"alphas/$alpha/params.jld2\"))\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae092e05-ff2f-4f0a-b6fd-fd39b78930b4",
   "metadata": {},
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ea33e3e7-ba24-4f51-937a-2469c71b9c22",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T10:14:27.960",
     "iopub.status.busy": "2023-11-15T10:14:27.960",
     "iopub.status.idle": "2023-11-15T10:14:27.963",
     "shell.execute_reply": "2023-11-15T10:14:27.963"
    }
   },
   "outputs": [],
   "source": [
    "function weighted_loss(x, y, w, lossfn)\n",
    "    sum(lossfn(x, y) .* w) / sum(w)\n",
    "end\n",
    "\n",
    "function weighted_loss_multithreaded(x, y, w, lossfn)\n",
    "    @assert false \"multithreaded loss is deprecated\"\n",
    "    # a = zeros(eltype(x), Threads.nthreads())\n",
    "    # b = zeros(eltype(w), Threads.nthreads())\n",
    "    # Threads.@threads :static for _ = 1:Threads.nthreads()\n",
    "    #     range = thread_range(length(x))\n",
    "    #     # Base.sum uses pairwise summation which is important for accuracy\n",
    "    #     @views weight = sum(w[range])\n",
    "    #     @views a[Threads.threadid()] = sum(lossfn(x[range], y[range]) .* w[range])\n",
    "    #     b[Threads.threadid()] = weight\n",
    "    # end\n",
    "    # sum(a) / sum(b)\n",
    "end\n",
    "\n",
    "function loss(x, y, w, metric; multithreaded = false)\n",
    "    if metric == \"rating\"\n",
    "        lossfn = (x, y) -> (x - y) .^ 2\n",
    "    elseif metric in [\"watch\", \"plantowatch\"]\n",
    "        lossfn = (x, y) -> -y .* log.(x)\n",
    "    elseif metric == \"drop\"\n",
    "        lossfn = (x, y) -> -(y .* log.(x) + (1 .- y) .* log.(1 .- x))\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "    if multithreaded\n",
    "        evaluator = weighted_loss_multithreaded\n",
    "    else\n",
    "        evaluator = weighted_loss\n",
    "    end\n",
    "    evaluator(x, y, w, lossfn)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef4e10c3-a442-471d-85f8-2632077b73f7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T10:14:27.963",
     "iopub.status.busy": "2023-11-15T10:14:27.963",
     "iopub.status.idle": "2023-11-15T10:14:27.965",
     "shell.execute_reply": "2023-11-15T10:14:27.964"
    }
   },
   "outputs": [],
   "source": [
    "# find β s.t. loss(X * β, y, w) is minimized\n",
    "function regress(X, y, w, metric)\n",
    "    if metric == \"rating\"\n",
    "        Xw = (X .* sqrt.(w))\n",
    "        yw = (y .* sqrt.(w))\n",
    "        # prevent singular matrix\n",
    "        λ = convert(eltype(y), 1f-9) * LinearAlgebra.I(size(Xw)[2])\n",
    "        β = (Xw'Xw + λ) \\ Xw'yw\n",
    "    elseif metric in [\"watch\", \"plantowatch\", \"drop\"]\n",
    "        β = softmax(\n",
    "            Optim.minimizer(\n",
    "                Optim.optimize(\n",
    "                    β -> loss(X * softmax(β), y, w, metric),\n",
    "                    fill(0.0f0, size(X)[2]),\n",
    "                    Optim.LBFGS(),\n",
    "                    autodiff = :forward,\n",
    "                    Optim.Options(g_tol = 1e-6, iterations = 100),\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "    X * β, β\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1169cf5d-1319-4cee-a5bc-53e4085201a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53027e8d-f9c3-4ffc-a8c2-6a97609e2388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb77d32-d1a1-4e25-adba-d063b4b290bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "af54ef89-2778-4329-bbab-f4cde92b2c31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T10:14:27.965",
     "iopub.status.busy": "2023-11-15T10:14:27.965",
     "iopub.status.idle": "2023-11-15T10:14:27.965",
     "shell.execute_reply": "2023-11-15T10:14:27.965"
    }
   },
   "outputs": [],
   "source": [
    "# function get_split(\n",
    "#     split::String,\n",
    "#     task::String,\n",
    "#     content::String,\n",
    "#     medium::String;\n",
    "#     transpose::Bool = false,\n",
    "#     fields::Union{Nothing,Vector{Symbol}} = nothing,\n",
    "# )\n",
    "#     raw_split(split, task, content, medium) =\n",
    "#         get_raw_split(split, task, content, medium; fields = fields)\n",
    "#     if content == \"explicit\"\n",
    "#         df = raw_split(split, task, content, medium)\n",
    "#     elseif content == \"implicit\"\n",
    "#         df = cat(\n",
    "#             raw_split(split, task, \"explicit\", medium),\n",
    "#             raw_split(split, task, \"implicit\", medium),\n",
    "#         )\n",
    "#         df.rating .= 1\n",
    "#     elseif content == \"ptw\"\n",
    "#         df = raw_split(split, task, content, medium)\n",
    "#         df.rating .= 1\n",
    "#     elseif content == \"negative\"\n",
    "#         df = raw_split(split, task, content, medium)\n",
    "#         N = length(get_raw_split(split, task, content, medium; fields = [:user]).user)\n",
    "#         df = @set df.rating = fill(0.0f0, N)\n",
    "#     else\n",
    "#         @assert false\n",
    "#     end\n",
    "#     transpose ? df' : df\n",
    "# end\n",
    "\n",
    "# function get_raw_split(\n",
    "#     split::String,\n",
    "#     task::String,\n",
    "#     content::String,\n",
    "#     medium::String;\n",
    "#     fields::Union{Nothing,Vector{Symbol}} = nothing,\n",
    "# )\n",
    "#     if task == \"all\"\n",
    "#         return reduce(\n",
    "#             cat,\n",
    "#             [\n",
    "#                 get_raw_split(split, task, content, medium; fields = fields) for\n",
    "#                 task in ALL_TASKS\n",
    "#             ],\n",
    "#         )\n",
    "#     end\n",
    "#     @assert split in ALL_SPLITS &&\n",
    "#             content in ALL_CONTENTS &&\n",
    "#             task in ALL_TASKS &&\n",
    "#             medium in ALL_MEDIUMS \"($split $content $task $medium)\"\n",
    "#     if split != \"test\" && content == \"negative\"\n",
    "#         return RatingsDataset(medium = medium)\n",
    "#     end\n",
    "#     file = get_data_path(\"splits/$(content).$(task).$(split).$(medium).jld2\")\n",
    "#     df = JLD2.load(file, \"dataset\")\n",
    "#     # clear any columns you are not interested in\n",
    "#     if !isnothing(fields)\n",
    "#         for f in fieldnames(RatingsDataset)\n",
    "#             if f ∉ fields && f ∉ [:medium]\n",
    "#                 df = Setfield.set(df, Setfield.PropertyLens{f}(), [])\n",
    "#             end\n",
    "#         end\n",
    "#     end\n",
    "#     df\n",
    "# end\n",
    "\n",
    "# const ALL_SPLITS = [\"training\", \"validation\", \"test\"]\n",
    "# const ALL_CONTENTS = [\"explicit\", \"implicit\", \"ptw\", \"negative\"]\n",
    "# const ALL_TASKS = [\"temporal_causal\"]\n",
    "# const ALL_MEDIUMS = [\"manga\", \"anime\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a717beaf-8ded-4f72-b6d9-c15f4b929ce6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T10:14:27.965",
     "iopub.status.busy": "2023-11-15T10:14:27.965",
     "iopub.status.idle": "2023-11-15T10:14:27.965",
     "shell.execute_reply": "2023-11-15T10:14:27.965"
    }
   },
   "outputs": [],
   "source": [
    "# function log_split_loss(\n",
    "#     model,\n",
    "#     alphas::Vector{String},\n",
    "#     task::String,\n",
    "#     content::String,\n",
    "#     medium::String,\n",
    "#     implicit::Bool,\n",
    "#     splits_to_log::Vector{String};\n",
    "#     by_split = false,\n",
    "# )\n",
    "#     β = nothing\n",
    "#     for split in splits_to_log\n",
    "#         if by_split\n",
    "#             x = model(split, task, content, medium; raw_splits = false)\n",
    "#         else\n",
    "#             df = get_split(split, task, content, medium; fields = [:user, :item])\n",
    "#             x = model(df.user, df.item)\n",
    "#         end\n",
    "#         @assert length(x) ==\n",
    "#                 length(get_split(split, task, content, medium; fields = [:user]).user)\n",
    "#         if isnothing(β)\n",
    "#             @assert split == \"validation\" || splits_to_log == [\"test\"]\n",
    "#             _, β = regress(alphas, split, task, content, medium, implicit, x)\n",
    "#         end\n",
    "#         @info \"$split loss: $(residualized_loss(alphas, task, content, medium, implicit, x, β, split)), β: $β\"\n",
    "#     end\n",
    "# end\n",
    "\n",
    "# function write_alpha(\n",
    "#     model::Function,\n",
    "#     medium::String,\n",
    "#     outdir::String;\n",
    "#     task::String = \"all\",\n",
    "#     splits::Vector{String} = ALL_SPLITS, # TODO make this a required arg\n",
    "#     by_split::Bool = false,\n",
    "#     log::Bool = true,\n",
    "#     log_task::Union{String,Nothing} = nothing,\n",
    "#     log_content::Union{String,Nothing} = nothing,\n",
    "#     log_alphas::Vector{String} = String[],\n",
    "#     log_splits::Vector{String} = [\"validation\", \"test\"],\n",
    "# )\n",
    "#     if log\n",
    "#         if log_content == \"explicit\"\n",
    "#             implicit = false\n",
    "#         elseif log_content in [\"implicit\", \"ptw\"]\n",
    "#             implicit = true\n",
    "#         else\n",
    "#             @assert false\n",
    "#         end\n",
    "#         log_split_loss(\n",
    "#             model,\n",
    "#             log_alphas,\n",
    "#             log_task,\n",
    "#             log_content,\n",
    "#             medium,\n",
    "#             implicit,\n",
    "#             log_splits;\n",
    "#             by_split = by_split,\n",
    "#         )\n",
    "#     else\n",
    "#         @info \"not logging split losses\"\n",
    "#     end\n",
    "\n",
    "#     tasks = task == \"all\" ? ALL_TASKS : [task]\n",
    "#     predictions = Dict()\n",
    "#     for split in splits\n",
    "#         for content in ALL_CONTENTS\n",
    "#             for task in tasks\n",
    "#                 if by_split\n",
    "#                     x = model(split, task, content, medium; raw_splits = true)\n",
    "#                 else\n",
    "#                     df =\n",
    "#                         get_raw_split(split, task, content, medium; fields = [:user, :item])\n",
    "#                     x = model(df.user, df.item)\n",
    "#                 end\n",
    "#                 @assert length(x) == length(\n",
    "#                     get_raw_split(split, task, content, medium; fields = [:user]).user,\n",
    "#                 )\n",
    "#                 predictions[\"$content.$task.$split.$medium\"] =\n",
    "#                     RatingsDataset(rating = x, medium = medium)\n",
    "#             end\n",
    "#         end\n",
    "#     end\n",
    "\n",
    "#     outdir = mkpath(get_data_path(\"alphas/$outdir\"))\n",
    "#     JLD2.save(\"$outdir/predictions.jld2\", predictions)\n",
    "# end\n",
    "\n",
    "# function read_raw_alpha_impl(\n",
    "#     alpha::String,\n",
    "#     split::String,\n",
    "#     task::String,\n",
    "#     content::String,\n",
    "#     medium::String,\n",
    "# )\n",
    "#     file = get_data_path(\"alphas/$(alpha)/predictions.jld2\")\n",
    "#     JLD2.load(file, \"$content.$task.$split.$medium\")\n",
    "# end\n",
    "\n",
    "\n",
    "# function read_raw_alpha(\n",
    "#     alpha::String,\n",
    "#     split::String,\n",
    "#     task::String,\n",
    "#     content::String,\n",
    "#     medium::String,\n",
    "# )\n",
    "#     # allow read_raw_alpha to be overridden by hiding the implementation\n",
    "#     if task == \"all\"\n",
    "#         return reduce(\n",
    "#             cat,\n",
    "#             [read_raw_alpha(alpha, split, task, content, medium) for task in ALL_TASKS],\n",
    "#         )\n",
    "#     end\n",
    "#     @assert split in ALL_SPLITS &&\n",
    "#             content in ALL_CONTENTS &&\n",
    "#             task in ALL_TASKS &&\n",
    "#             medium in ALL_MEDIUMS \"($split $content $task $medium)\"\n",
    "#     read_raw_alpha_impl(alpha, split, task, content, medium)\n",
    "# end\n",
    "\n",
    "# function read_alpha(\n",
    "#     alpha::String,\n",
    "#     split::String,\n",
    "#     task::String,\n",
    "#     content::String,\n",
    "#     medium::String,\n",
    "# )\n",
    "#     if content == \"explicit\"\n",
    "#         p = read_raw_alpha(alpha, split, task, content, medium)\n",
    "#     elseif content == \"implicit\"\n",
    "#         p = cat(\n",
    "#             read_raw_alpha(alpha, split, task, \"explicit\", medium),\n",
    "#             read_raw_alpha(alpha, split, task, \"implicit\", medium),\n",
    "#         )\n",
    "#     elseif content == \"ptw\"\n",
    "#         p = read_raw_alpha(alpha, split, task, \"ptw\", medium)\n",
    "#     elseif content == \"negative\"\n",
    "#         p = read_raw_alpha(alpha, split, task, content, medium)\n",
    "#     else\n",
    "#         @assert false\n",
    "#     end\n",
    "#     df = get_split(split, task, content, medium; fields = [:user, :item])\n",
    "#     @assert length(df.user) == length(p.rating)\n",
    "#     RatingsDataset(user = df.user, item = df.item, rating = p.rating, medium = medium)\n",
    "# end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d03bdb-6e21-4f41-b7d1-f52f143320da",
   "metadata": {},
   "source": [
    "## Weight decays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a3435b41-3aaa-4fd6-a4eb-b04338c3f16c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T10:14:27.965",
     "iopub.status.busy": "2023-11-15T10:14:27.965",
     "iopub.status.idle": "2023-11-15T10:14:27.966",
     "shell.execute_reply": "2023-11-15T10:14:27.966"
    }
   },
   "outputs": [],
   "source": [
    "# function powerdecay(x, a)\n",
    "#     x == 0 ? zero(eltype(a)) : sign(x) * abs(x)^a\n",
    "# end\n",
    "\n",
    "# function powerdecay(x::Vector, a)\n",
    "#     y = Array{eltype(a)}(undef, length(x))\n",
    "#     Threads.@threads for i = 1:length(x)\n",
    "#         @inbounds y[i] = powerdecay(x[i], a)\n",
    "#     end\n",
    "#     y\n",
    "# end\n",
    "\n",
    "# function powerlawdecay(x, a)\n",
    "#     a^x\n",
    "# end\n",
    "\n",
    "# function powerlawdecay(x::Vector, a)\n",
    "#     a .^ x\n",
    "# end\n",
    "\n",
    "# function weighting_scheme(scheme::Number)\n",
    "#     scheme\n",
    "# end\n",
    "\n",
    "# function weighting_scheme(scheme::String)\n",
    "#     if scheme == \"constant\"\n",
    "#         return 0.0f0\n",
    "#     elseif scheme == \"inverse\"\n",
    "#         return -1.0f0\n",
    "#     else\n",
    "#         @assert false\n",
    "#         return 0.0f0\n",
    "#     end\n",
    "# end;\n",
    "\n",
    "# function get_user_counts(\n",
    "#     split::String,\n",
    "#     task::String,\n",
    "#     content::String,\n",
    "#     medium::String,\n",
    "#     by_item::Bool,\n",
    "# )\n",
    "#     df = get_split(\n",
    "#         split,\n",
    "#         task,\n",
    "#         content,\n",
    "#         medium;\n",
    "#         transpose = by_item,\n",
    "#         fields = [:user, :item],\n",
    "#     )\n",
    "#     len = by_item ? num_items(medium) : num_users()\n",
    "#     counts = zeros(eltype(df.rating), len, Threads.nthreads())\n",
    "#     Threads.@threads for i = 1:length(df.user)\n",
    "#         @inbounds counts[df.user[i], Threads.threadid()] += 1\n",
    "#     end\n",
    "#     vec(sum(counts, dims = 2))\n",
    "# end\n",
    "\n",
    "# @memoize function get_counts(\n",
    "#     split::String,\n",
    "#     task::String,\n",
    "#     content::String,\n",
    "#     medium::String;\n",
    "#     per_rating::Bool = true,\n",
    "#     by_item::Bool = false,\n",
    "# )\n",
    "#     user_counts = get_user_counts(split, task, content, medium, by_item)\n",
    "#     if !per_rating\n",
    "#         return user_counts\n",
    "#     end\n",
    "\n",
    "#     df = get_split(\n",
    "#         split,\n",
    "#         task,\n",
    "#         content,\n",
    "#         medium;\n",
    "#         transpose = by_item,\n",
    "#         fields = [:user, :item],\n",
    "#     )\n",
    "#     counts = Array{eltype(user_counts)}(undef, length(df.user))\n",
    "#     Threads.@threads for i = 1:length(counts)\n",
    "#         @inbounds counts[i] = user_counts[df.user[i]]\n",
    "#     end\n",
    "#     counts\n",
    "# end\n",
    "\n",
    "# function get_weights(\n",
    "#     split::String,\n",
    "#     task::String,\n",
    "#     content::String,\n",
    "#     medium::String,\n",
    "#     scheme::String,\n",
    "# )\n",
    "#     powerdecay(get_counts(split, task, content, medium), weighting_scheme(scheme))\n",
    "# end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9986bce-923f-4100-a796-d604b53c2d26",
   "metadata": {},
   "source": [
    "## Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b81ed30f-6bdd-4b6f-8a3c-b8da119a67db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T10:14:27.966",
     "iopub.status.busy": "2023-11-15T10:14:27.966",
     "iopub.status.idle": "2023-11-15T10:14:27.966",
     "shell.execute_reply": "2023-11-15T10:14:27.966"
    }
   },
   "outputs": [],
   "source": [
    "# # given a matrix of features X, a vector of true labels y, and\n",
    "# # a vector of weights w, a regression will find the β\n",
    "# # that minimizes the weighted loss between X * β and y\n",
    "\n",
    "# function regress(X, y, w, implicit::Bool)\n",
    "#     if implicit\n",
    "#         β = softmax(\n",
    "#             Optim.minimizer(\n",
    "#                 Optim.optimize(\n",
    "#                     β -> loss(X * softmax(β), y, w, implicit; multithreaded = false),\n",
    "#                     fill(0.0f0, size(X)[2]),\n",
    "#                     Optim.LBFGS(),\n",
    "#                     autodiff = :forward,\n",
    "#                     Optim.Options(g_tol = 1e-6, iterations = 100),\n",
    "#                 ),\n",
    "#             ),\n",
    "#         )\n",
    "#     else\n",
    "#         λ = Xw = (X .* sqrt.(w))\n",
    "#         yw = (y .* sqrt.(w))\n",
    "#         # prevent singular matrix\n",
    "#         λ = convert(eltype(y), 1f-9) * LinearAlgebra.I(size(Xw)[2])\n",
    "#         β = (Xw'Xw + λ) \\ Xw'yw\n",
    "#     end\n",
    "#     X * β, β\n",
    "# end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "50ac38a4-9047-4ccf-92a6-d2917b7dbadb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-11-15T10:14:27.966",
     "iopub.status.busy": "2023-11-15T10:14:27.966",
     "iopub.status.idle": "2023-11-15T10:14:27.966",
     "shell.execute_reply": "2023-11-15T10:14:27.966"
    }
   },
   "outputs": [],
   "source": [
    "# # regress the given features on the validation set\n",
    "# function regress(\n",
    "#     alphas::Vector{String},\n",
    "#     task::String,\n",
    "#     content::String,\n",
    "#     medium::String,\n",
    "#     implicit::Bool,\n",
    "#     x = nothing,\n",
    "# )\n",
    "#     regress(alphas, \"validation\", task, content, medium, implicit, x)\n",
    "# end\n",
    "\n",
    "# function regress(\n",
    "#     alphas::Vector{String},\n",
    "#     split::String,\n",
    "#     task::String,\n",
    "#     content::String,\n",
    "#     medium::String,\n",
    "#     implicit::Bool,\n",
    "#     x = nothing,\n",
    "# )\n",
    "#     X = regression_features(alphas, split, task, content, medium, implicit, x)\n",
    "#     y = get_split(split, task, content, medium; fields = [:rating]).rating\n",
    "#     w = get_weights(split, task, content, medium, \"inverse\")\n",
    "#     regress(X, y, w, implicit)\n",
    "# end\n",
    "\n",
    "# function regress(\n",
    "#     alphas::Vector{String},\n",
    "#     task::String,\n",
    "#     content::String,\n",
    "#     medium::String,\n",
    "#     implicit::Bool,\n",
    "# )\n",
    "#     regress(alphas, task, content, medium, implicit, nothing)\n",
    "# end\n",
    "\n",
    "# # concatenates x, if given, with the alphas\n",
    "# function regression_features(\n",
    "#     alphas::Vector{String},\n",
    "#     split::String,\n",
    "#     task::String,\n",
    "#     content::String,\n",
    "#     medium::String,\n",
    "#     implicit::Bool,\n",
    "#     x = nothing,\n",
    "# )\n",
    "#     ncols = length(alphas) + (isnothing(x) ? 0 : 1) + implicit\n",
    "#     shape =\n",
    "#         isnothing(x) ? get_split(split, task, content, medium; fields = [:rating]).rating :\n",
    "#         x\n",
    "#     X = Array{eltype(shape),2}(undef, length(shape), ncols)\n",
    "#     @showprogress for j = 1:length(alphas)\n",
    "#         @inbounds X[:, j] = read_alpha(alphas[j], split, task, content, medium).rating\n",
    "#     end\n",
    "\n",
    "#     if implicit\n",
    "#         # add a baseline feature for non-degeneracy\n",
    "#         X[:, length(alphas)+1] .= 1.0f0 / num_items(medium)\n",
    "#     end\n",
    "#     if !isnothing(x)\n",
    "#         X[:, end] = x\n",
    "#     end\n",
    "#     X\n",
    "# end\n",
    "\n",
    "# # linearly combinine the given alphas\n",
    "# function read_alpha(\n",
    "#     alphas::Vector{String},\n",
    "#     split::String,\n",
    "#     task::String,\n",
    "#     content::String,\n",
    "#     medium::String,\n",
    "#     implicit::Bool,\n",
    "# )\n",
    "#     _, β = regress(alphas, task, content, medium, implicit)\n",
    "#     X = regression_features(alphas, split, task, content, medium, implicit)\n",
    "#     df = get_split(split, task, content, medium; fields = [:user, :item])\n",
    "#     RatingsDataset(user = df.user, item = df.item, rating = X * β, medium = medium)\n",
    "# end\n",
    "\n",
    "# # performs a regression on the validation set and then \n",
    "# # calculates the validation loss of that linear combination\n",
    "# function residualized_loss(\n",
    "#     alphas::Vector{String},\n",
    "#     task::String,\n",
    "#     content::String,\n",
    "#     medium::String,\n",
    "#     implicit::Bool,\n",
    "#     x,\n",
    "# )\n",
    "#     split = \"validation\"\n",
    "#     x, β = regress(alphas, task, content, medium, implicit, x)\n",
    "#     y = get_split(split, task, content, medium; fields = [:rating]).rating\n",
    "#     loss(\n",
    "#         x,\n",
    "#         y,\n",
    "#         get_weights(split, task, content, medium, \"inverse\"),\n",
    "#         implicit;\n",
    "#         multithreaded = true,\n",
    "#     )\n",
    "# end\n",
    "\n",
    "# function residualized_loss(\n",
    "#     alphas::Vector{String},\n",
    "#     split::String,\n",
    "#     task::String,\n",
    "#     content::String,\n",
    "#     medium::String,\n",
    "#     implicit::Bool,\n",
    "#     x,\n",
    "#     β,\n",
    "# )\n",
    "#     X = regression_features(alphas, split, task, content, medium, implicit, x)\n",
    "#     x = X * β\n",
    "#     y = get_split(split, task, content, medium; fields = [:rating]).rating\n",
    "#     loss(\n",
    "#         x,\n",
    "#         y,\n",
    "#         get_weights(split, task, content, medium, \"inverse\"),\n",
    "#         implicit;\n",
    "#         multithreaded = true,\n",
    "#     )\n",
    "# end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.9.2",
   "language": "julia",
   "name": "julia-1.9"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba949471-e864-4ebf-b949-7772e87b6057",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Helper functions that are useful for generating alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f693eb8-9aab-4305-a6ee-17e885f3f24d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import Flux: softmax\n",
    "import JLD2\n",
    "import LRUCache: LRU\n",
    "import Memoize: @memoize\n",
    "import NBInclude: @nbinclude\n",
    "import Optim\n",
    "import ProgressMeter: @showprogress\n",
    "import Setfield\n",
    "import Setfield: @set\n",
    "import SparseArrays"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd094a91-95a1-4007-a3c6-748cda48f03d",
   "metadata": {},
   "source": [
    "## General utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9bcd93-0801-4944-9e44-b2b25cc16934",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"AlphaUtils.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d0e0457-b3a2-4283-a855-efd59838d397",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_data_path(file)\n",
    "    path = pwd()\n",
    "    while basename(path) != \"notebooks\"\n",
    "        path = dirname(path)\n",
    "    end\n",
    "    path = dirname(path)\n",
    "    \"$path/data/$file\"\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f749ff84-92d8-4185-89d5-8c06cb2a1139",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fef655-3bf2-494b-870c-96e1b027335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if !@isdefined name\n",
    "    name = \"Alpha\"\n",
    "end\n",
    "function set_logging_outdir(name)\n",
    "    redirect_logging(get_data_path(\"alphas/$name\"))\n",
    "end\n",
    "set_logging_outdir(name);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adffc2d1-1b56-4f2c-820a-847c8e69eb8f",
   "metadata": {},
   "source": [
    "## Structs for handling ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39d7a7e-403e-4104-b2a8-f5c48da9c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user[i] has seen item[i] and given it a score of rating[i]\n",
    "@with_kw struct RatingsDataset\n",
    "    user::Vector{Int32} = []\n",
    "    item::Vector{Int32} = []\n",
    "    rating::Vector{Float32} = []\n",
    "    timestamp::Vector{Float32} = []\n",
    "    user_timestamp::Vector{Float32} = []\n",
    "    item_timestamp::Vector{Float32} = []\n",
    "    status::Vector{Int32} = []\n",
    "    completion::Vector{Float32} = []\n",
    "    rewatch::Vector{Int32} = []\n",
    "    source::Vector{Int32} = []\n",
    "end;\n",
    "\n",
    "# swap users with items\n",
    "function Base.adjoint(x::RatingsDataset)\n",
    "    RatingsDataset(\n",
    "        x.item,\n",
    "        x.user,\n",
    "        x.rating,\n",
    "        x.timestamp,\n",
    "        x.user_timestamp,\n",
    "        x.item_timestamp,\n",
    "        x.status,\n",
    "        x.completion,\n",
    "        x.rewatch,\n",
    "        x.source,\n",
    "    )\n",
    "end\n",
    "\n",
    "# append two datasets\n",
    "function Base.cat(x::RatingsDataset, y::RatingsDataset)\n",
    "    for field in fieldnames(RatingsDataset)\n",
    "        a = length(getfield(x, field)) != 0\n",
    "        b = length(getfield(y, field)) != 0\n",
    "        @assert a == b \"cat: mismatched sizes in $field ($a != $b)\"\n",
    "    end\n",
    "    RatingsDataset(\n",
    "        [x.user; y.user],\n",
    "        [x.item; y.item],\n",
    "        [x.rating; y.rating],\n",
    "        [x.timestamp; y.timestamp],\n",
    "        [x.user_timestamp; y.user_timestamp],\n",
    "        [x.item_timestamp; y.item_timestamp],\n",
    "        [x.status; y.status],\n",
    "        [x.completion; y.completion],\n",
    "        [x.rewatch; y.rewatch],\n",
    "        [x.source; y.source],\n",
    "    )\n",
    "end\n",
    "\n",
    "function Base.filter(x::RatingsDataset, mask::BitVector)\n",
    "    filter_array(a) = length(a) > 0 ? a[mask] : []\n",
    "    RatingsDataset(\n",
    "        filter_array(x.user),\n",
    "        filter_array(x.item),\n",
    "        filter_array(x.rating),\n",
    "        filter_array(x.timestamp),\n",
    "        filter_array(x.user_timestamp),\n",
    "        filter_array(x.item_timestamp),\n",
    "        filter_array(x.status),\n",
    "        filter_array(x.completion),\n",
    "        filter_array(x.rewatch),\n",
    "        filter_array(x.source),\n",
    "    )\n",
    "end;\n",
    "\n",
    "# returns the subset of the data whose userid is atmost userid\n",
    "function filter_users(x::RatingsDataset, max_userid)\n",
    "    mask = x.user .<= max_userid\n",
    "    filter(x, x.user .<= max_userid)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a31d149f-b583-49db-8fd5-403affba7f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some sparse matrix operations require indices to be Int64\n",
    "@with_kw struct RatingsDataset64\n",
    "    user::Vector{Int64}\n",
    "    item::Vector{Int64}\n",
    "    rating::Vector{Float32}\n",
    "end\n",
    "\n",
    "function RatingsDataset64(x::RatingsDataset)\n",
    "    RatingsDataset64(\n",
    "        convert.(Int64, x.user),\n",
    "        convert.(Int64, x.item),\n",
    "        convert.(Float32, x.rating),\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa86422d-a577-49b0-8d79-381809028b55",
   "metadata": {},
   "source": [
    "## Reading and writing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ddd8e-1c8c-49b0-97ef-848107f4af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "@memoize function num_users()\n",
    "    open(get_data_path(\"processed_data/uid_encoding.csv\")) do file\n",
    "        text = read(file, String)\n",
    "        lines = split(text, '\\n')\n",
    "        fields = split(lines[1], ',')\n",
    "        @assert fields[1] == \"max_userid\"\n",
    "        max_userid = parse(Int, fields[2]) + 1\n",
    "        return max_userid\n",
    "    end\n",
    "end\n",
    "\n",
    "@memoize function num_items()\n",
    "    open(get_data_path(\"processed_data/uid_encoding.csv\")) do file\n",
    "        text = read(file, String)\n",
    "        lines = split(text, '\\n')\n",
    "        fields = split(lines[2], ',')\n",
    "        @assert fields[1] == \"max_itemid\"\n",
    "        max_itemid = parse(Int, fields[2]) + 1\n",
    "        return max_itemid\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af54ef89-2778-4329-bbab-f4cde92b2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a split is a collection of (user, item) interactions that are stored as a RatingsDataset\n",
    "function get_split(split::String, content::String; transpose::Bool = false, fields::Union{Nothing, Vector{Symbol}} = nothing)\n",
    "    @assert split in all_splits && content in all_contents\n",
    "    raw_split(split, content) = get_raw_split(split, content; fields = fields)\n",
    "    if content == \"explicit\"\n",
    "        df = raw_split(split, content)\n",
    "    elseif content == \"implicit\"\n",
    "        df = cat(raw_split(split, \"explicit\"), raw_split(split, \"implicit\"))\n",
    "        df.rating .= 1\n",
    "    elseif content == \"ptw\"\n",
    "        df = raw_split(split, content)\n",
    "        df.rating .= 1\n",
    "    elseif content == \"negative\"\n",
    "        df = raw_split(split, content)\n",
    "        N = length(get_raw_split(split, content; fields = [:user]).user)\n",
    "        df = @set df.rating = fill(0f0, N)\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "    transpose ? df' : df\n",
    "end\n",
    "\n",
    "function get_raw_split(split::String, content::String; fields::Union{Nothing, Vector{Symbol}} = nothing)\n",
    "    @assert split in all_splits && content in all_contents\n",
    "    file = get_data_path(\"splits/$(content)_$(split).jld2\")\n",
    "    df = JLD2.load(file, \"dataset\")\n",
    "    # clear any columns you are not interested in\n",
    "    if !isnothing(fields)\n",
    "        for f in fieldnames(RatingsDataset)\n",
    "            if f ∉ fields\n",
    "                df = Setfield.set(df, Setfield.PropertyLens{f}(), [])\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    df\n",
    "end\n",
    "\n",
    "const all_splits = [\"training\", \"validation\", \"test\"]\n",
    "const all_contents = [\"explicit\", \"implicit\", \"negative\", \"ptw\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a717beaf-8ded-4f72-b6d9-c15f4b929ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an alpha is a model that is used to predict whether a user will like an item.\n",
    "# it's often useful to know an alpha model's value for a given (user, item) pair.\n",
    "# alphas can be expensive to compute, so we precompute the model's values on\n",
    "# (user-item) pairs and store the resultant RatingsDatasets to disk.\n",
    "# storing the model values for all (user, item) pairs would be prohibitively\n",
    "# large, so we only store values for our splits\n",
    "\n",
    "function log_split_loss(\n",
    "    model,\n",
    "    alphas::Vector{String},\n",
    "    content::String,\n",
    "    implicit::Bool,\n",
    "    splits_to_log::Vector{String};\n",
    "    by_split = false,\n",
    ")\n",
    "    β = nothing\n",
    "    for split in splits_to_log\n",
    "        if by_split\n",
    "            x = model(split, content; raw_splits = false)\n",
    "        else\n",
    "            df = get_split(split, content)\n",
    "            x = model(df.user, df.item)\n",
    "        end\n",
    "        @assert length(x) == length(get_split(split, content; fields = [:user]).user)\n",
    "        if isnothing(β)\n",
    "            @assert split == \"validation\"\n",
    "            _, β = regress(alphas, content, implicit, x)\n",
    "        end\n",
    "        @info \"$split loss: $(residualized_loss(alphas, content, implicit, x, β, split)), β: $β\"\n",
    "    end\n",
    "end\n",
    "\n",
    "function write_alpha(\n",
    "    model::Function,\n",
    "    alphas::Vector{String}, # TODO make an optional argument b/c logging is optional\n",
    "    implicit::Bool, # TODO make an optional argument b/c logging is optional\n",
    "    outdir::String;\n",
    "    log_splits::Union{Bool,String} = false, # TODO rename to log_contents\n",
    "    splits_to_log::Vector{String} = [\"validation\", \"training\"], # TODO rename to log_splits\n",
    ")\n",
    "    @info \"deprecated write_alpha\"\n",
    "    if log_splits in all_contents\n",
    "        log_split_loss(model, alphas, log_splits, implicit, splits_to_log)\n",
    "    elseif !log_splits\n",
    "        @info \"not logging split losses\"\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "\n",
    "    predictions = Dict()\n",
    "    for split in all_splits\n",
    "        for content in all_contents\n",
    "            df = get_raw_split(split, content; fields = [:user, :item])\n",
    "            x = model(df.user, df.item)\n",
    "            predictions[\"$(content)_$(split)\"] = RatingsDataset(rating = x)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    outdir = mkpath(get_data_path(\"alphas/$outdir\"))\n",
    "    JLD2.save(\"$outdir/predictions.jld2\", predictions)\n",
    "end\n",
    "\n",
    "function write_alpha(\n",
    "    model::Function,\n",
    "    outdir::String;\n",
    "    by_split::Bool = false,\n",
    "    log::Bool = true,\n",
    "    log_content::Union{String,Nothing} = nothing,        \n",
    "    log_alphas::Vector{String} = String[],\n",
    "    log_splits::Vector{String} = [\"validation\", \"training\"],\n",
    ")\n",
    "    if log\n",
    "        if log_content == \"explicit\"\n",
    "            implicit = false\n",
    "        elseif log_content in [\"implicit\", \"ptw\"]\n",
    "            implicit = true\n",
    "        else\n",
    "            @assert false\n",
    "        end\n",
    "        log_split_loss(\n",
    "            model,\n",
    "            log_alphas,\n",
    "            log_content,\n",
    "            implicit,\n",
    "            log_splits;\n",
    "            by_split = by_split,\n",
    "        )\n",
    "    else\n",
    "        @info \"not logging split losses\"\n",
    "    end\n",
    "\n",
    "    predictions = Dict()\n",
    "    for split in all_splits\n",
    "        for content in all_contents\n",
    "            if by_split\n",
    "                x = model(split, content; raw_splits=true)\n",
    "            else\n",
    "                df = get_raw_split(split, content; fields = [:user, :item])\n",
    "                x = model(df.user, df.item)\n",
    "            end\n",
    "            @assert length(x) == length(get_raw_split(split, content; fields = [:user]).user)\n",
    "            predictions[\"$(content)_$(split)\"] = RatingsDataset(rating = x)\n",
    "        end\n",
    "    end\n",
    "\n",
    "    outdir = mkpath(get_data_path(\"alphas/$outdir\"))\n",
    "    JLD2.save(\"$outdir/predictions.jld2\", predictions)\n",
    "end\n",
    "\n",
    "function write_alpha(\n",
    "    p::SparseArrays.AbstractSparseMatrix,\n",
    "    outdir;\n",
    "    alphas::Vector{String} = String[],\n",
    "    implicit::Union{Bool,Nothing} = nothing,\n",
    "    log_splits::Union{Bool,String} = false, # TODO rename to log_contents\n",
    "    splits_to_log::Vector{String} = [\"validation\", \"training\"], # TODO rename to log_splits\n",
    ")\n",
    "    @info \"deprecated write_alpha\"    \n",
    "    function model(users, items)\n",
    "        r = zeros(length(users))\n",
    "        @tprogress Threads.@threads for j = 1:length(r)\n",
    "            r[j] = p[users[j], items[j]]\n",
    "        end\n",
    "        r\n",
    "    end\n",
    "    write_alpha(\n",
    "        model,\n",
    "        alphas,\n",
    "        implicit,\n",
    "        outdir;\n",
    "        log_splits = log_splits,\n",
    "        splits_to_log = splits_to_log,\n",
    "    )\n",
    "end\n",
    "\n",
    "function read_raw_alpha_impl(alpha::String, split::String, content::String)\n",
    "    file = get_data_path(\"alphas/$(alpha)/predictions.jld2\")\n",
    "    JLD2.load(file, \"$(content)_$(split)\")\n",
    "end\n",
    "\n",
    "\n",
    "function read_raw_alpha(alpha::String, split::String, content::String)\n",
    "    # allow read_alpha to be overridden by hiding the implementation\n",
    "    read_raw_alpha_impl(alpha, split, content)\n",
    "end\n",
    "\n",
    "function read_alpha(alpha::String, split::String, content::String)\n",
    "    @assert split in all_splits && content in all_contents\n",
    "    if content == \"explicit\"\n",
    "        p = read_raw_alpha(alpha, split, content)\n",
    "    elseif content == \"implicit\"\n",
    "        p = cat(\n",
    "            read_raw_alpha(alpha, split, \"explicit\"),\n",
    "            read_raw_alpha(alpha, split, \"implicit\"),\n",
    "        )\n",
    "    elseif content == \"ptw\"\n",
    "        p = read_raw_alpha(alpha, split, \"ptw\")\n",
    "    elseif content == \"negative\"\n",
    "        p = read_raw_alpha(alpha, split, content)\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "    df = get_split(split, content; fields = [:user, :item])\n",
    "    @assert length(df.user) == length(p.rating)\n",
    "    RatingsDataset(user = df.user, item = df.item, rating = p.rating)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5237f49-f24d-43e1-9698-7358d22e7c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params consist of two things:\n",
    "# 1) the hyperparameters that are used to train an alpha\n",
    "# 2) the trained parameters of an alpha \n",
    "# in general, params should contain all information necessary to\n",
    "# efficiently train the alpha model for a new user\n",
    "\n",
    "function write_params(params, outdir)\n",
    "    outdir = mkpath(get_data_path(\"alphas/$outdir\"))\n",
    "    JLD2.save(\"$outdir/params.jld2\", params)\n",
    "end\n",
    "\n",
    "function read_params(alpha)\n",
    "    JLD2.load(get_data_path(\"alphas/$alpha/params.jld2\"))\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d03bdb-6e21-4f41-b7d1-f52f143320da",
   "metadata": {},
   "source": [
    "## Weight decays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3435b41-3aaa-4fd6-a4eb-b04338c3f16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of items a user has seen spans orders of magnitude.\n",
    "# if we place an equal weight on each (user, item) pair, then highly\n",
    "# active users will skew the loss function. It is generally best practice\n",
    "# to weight each user equally (see Deep Neural Networks for YouTube Recommendations \n",
    "# https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf]).\n",
    "# we achieve this by weighting our validation and test loss functions such that each\n",
    "# (user, item) pair has a weight of 1 / |number of items the user has seen|.\n",
    "# \n",
    "# during training, the same skew issue appears. instead of weighting each (user, item)\n",
    "# pair by 1 / |number of items the user has seen|, we take the more general approach\n",
    "# of weighting each (user, item) pair by \n",
    "# |number of items the user has seen| ^ w_u * |number of users that have seen the item| ^ w_a\n",
    "# when w_u=-1 and w_a=0, then we recover the equal-user weighting that we used for\n",
    "# validation and test sets.\n",
    "\n",
    "function powerdecay(x, a)\n",
    "    x == 0 ? zero(eltype(a)) : sign(x) * abs(x)^a\n",
    "end\n",
    "\n",
    "function powerdecay(x::Vector, a)\n",
    "    y = Array{eltype(a)}(undef, length(x))\n",
    "    Threads.@threads for i = 1:length(x)\n",
    "        @inbounds y[i] = powerdecay(x[i], a)\n",
    "    end\n",
    "    y\n",
    "end\n",
    "\n",
    "function weighting_scheme(scheme::Number)\n",
    "    scheme\n",
    "end\n",
    "\n",
    "function weighting_scheme(scheme::String)\n",
    "    if scheme == \"linear\"\n",
    "        return 1.0f0\n",
    "    elseif scheme == \"constant\"\n",
    "        return 0.0f0\n",
    "    elseif scheme == \"inverse\"\n",
    "        return -1.0f0\n",
    "    else\n",
    "        @assert false\n",
    "        return 0.0f0\n",
    "    end\n",
    "end;\n",
    "\n",
    "function get_user_counts(split::RatingsDataset)\n",
    "    counts = zeros(eltype(split.rating), num_users(), Threads.nthreads())\n",
    "    Threads.@threads for i = 1:length(split.user)\n",
    "        @inbounds counts[split.user[i], Threads.threadid()] += 1\n",
    "    end\n",
    "    vec(sum(counts, dims = 2))\n",
    "end\n",
    "\n",
    "@memoize function get_counts(\n",
    "    split::String,\n",
    "    content::String;\n",
    "    per_rating::Bool = true,\n",
    "    by_item::Bool = false,\n",
    ")\n",
    "    split = get_split(split, content; transpose = by_item)\n",
    "    user_counts = get_user_counts(split)\n",
    "\n",
    "    if !per_rating\n",
    "        return user_counts\n",
    "    end\n",
    "\n",
    "    counts = Array{eltype(user_counts)}(undef, length(split.user))\n",
    "    Threads.@threads for i = 1:length(counts)\n",
    "        @inbounds counts[i] = user_counts[split.user[i]]\n",
    "    end\n",
    "    counts\n",
    "end\n",
    "\n",
    "function get_weights(split::String, content::String, scheme::String)\n",
    "    powerdecay(get_counts(split, content), weighting_scheme(scheme))\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c675de5-4b31-471e-9565-8c2f0a38720e",
   "metadata": {},
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea33e3e7-ba24-4f51-937a-2469c71b9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most alphas can be classified as one of two types:\n",
    "# 1) explicit alphas predict what rating a user will give to\n",
    "#    a given show conditional on having watched the show. these \n",
    "#    alphas are trained using mean squared error\n",
    "# 2) implicit alphas predict whether a user will watch a\n",
    "#    a given show. these alphas are trained using\n",
    "#    cross-entropy loss\n",
    "# both loss functions are weighted according to the weight decay\n",
    "# logic described above\n",
    "\n",
    "function weighted_loss(x, y, w, lossfn)\n",
    "    sum(lossfn(x, y) .* w) / sum(w)\n",
    "end\n",
    "\n",
    "function weighted_loss_multithreaded(x, y, w, lossfn)\n",
    "    a = Array{eltype(x)}(undef, Threads.nthreads())\n",
    "    b = Array{eltype(w)}(undef, Threads.nthreads())\n",
    "    Threads.@threads for t = 1:Threads.nthreads()\n",
    "        range = thread_range(length(x))\n",
    "        # Base.sum uses pairwise summation which is important for accuracy\n",
    "        @views weight = sum(w[range])\n",
    "        @views a[Threads.threadid()] =\n",
    "            weighted_loss(x[range], y[range], w[range], lossfn) * weight\n",
    "        b[Threads.threadid()] = weight\n",
    "    end\n",
    "    sum(a) / sum(b)\n",
    "end\n",
    "\n",
    "function error(x, y, w, implicit)\n",
    "    lossfn = implicit ? (x, y) -> -y .* log.(x) : (x, y) -> (x - y) .^ 2\n",
    "    weighted_error(x, y, w, lossfn)\n",
    "end\n",
    "\n",
    "function loss(x, y, w, implicit; normalize = true, multithreaded = false)\n",
    "    if implicit\n",
    "        lossfn = (x, y) -> -y .* log.(x)\n",
    "    else\n",
    "        lossfn = (x, y) -> (x - y) .^ 2\n",
    "    end\n",
    "    if normalize\n",
    "        if multithreaded\n",
    "            evaluator = weighted_loss_multithreaded\n",
    "        else\n",
    "            evaluator = weighted_loss\n",
    "        end\n",
    "    else\n",
    "        evaluator = weighted_unnormalized_loss\n",
    "    end\n",
    "    evaluator(x, y, w, lossfn)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9986bce-923f-4100-a796-d604b53c2d26",
   "metadata": {},
   "source": [
    "## Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ed30f-6bdd-4b6f-8a3c-b8da119a67db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a matrix of features X, a vector of true labels y, and\n",
    "# a vector of weights w, a regression will find the β\n",
    "# that minimizes the weighted between X * β and y. for explicit\n",
    "# alphas, the loss is mean squared error and there is a closed\n",
    "# form solution. for implicit alphas, the loss is cross-entropy\n",
    "# and we solve for β numerically.\n",
    "\n",
    "function regress(X, y, w, implicit::Bool)\n",
    "    if implicit\n",
    "        β = softmax(\n",
    "            Optim.minimizer(\n",
    "                Optim.optimize(\n",
    "                    β -> loss(X * softmax(β), y, w, implicit; multithreaded = true),\n",
    "                    fill(0.0f0, size(X)[2]),\n",
    "                    Optim.NewtonTrustRegion(),\n",
    "                    autodiff = :forward,\n",
    "                    Optim.Options(g_tol = 1e-6, iterations = 100),\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "    else\n",
    "        Xw = (X .* sqrt.(w))\n",
    "        yw = (y .* sqrt.(w))\n",
    "        β = Xw'Xw \\ Xw'yw\n",
    "    end\n",
    "    X * β, β\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ac38a4-9047-4ccf-92a6-d2917b7dbadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regress the given features on the validation set\n",
    "function regress(alphas::Vector{String}, content::String, implicit::Bool, x = nothing)\n",
    "    split = \"validation\"\n",
    "    X = regression_features(alphas, split, content, implicit, x)\n",
    "    y = get_split(split, content).rating\n",
    "    w = get_weights(split, content, \"inverse\")\n",
    "    regress(X, y, w, implicit)\n",
    "end\n",
    "\n",
    "function regress(alphas::Vector{String}, content::String, implicit::Bool)\n",
    "    regress(alphas, content, implicit, nothing)\n",
    "end\n",
    "\n",
    "# concatenates x, if given, with the alphas\n",
    "function regression_features(\n",
    "    alphas::Vector{String},\n",
    "    split::String,\n",
    "    content::String,\n",
    "    implicit::Bool,\n",
    "    x = nothing,\n",
    ")\n",
    "    ncols = length(alphas) + (isnothing(x) ? 0 : 1) + implicit\n",
    "    shape = isnothing(x) ? get_split(split, content).rating : x\n",
    "    X = Array{eltype(shape),2}(undef, length(shape), ncols)\n",
    "    @showprogress for j = 1:length(alphas)\n",
    "        @inbounds X[:, j] = read_alpha(alphas[j], split, content).rating\n",
    "    end\n",
    "\n",
    "    if implicit\n",
    "        # add a baseline feature for non-degeneracy\n",
    "        X[:, length(alphas)+1] .= 1.0f0 / num_items()\n",
    "    end\n",
    "    if !isnothing(x)\n",
    "        X[:, end] = x\n",
    "    end\n",
    "    X\n",
    "end\n",
    "\n",
    "# linearly combinine the given alphas\n",
    "function read_alpha(alphas::Vector{String}, split::String, content::String, implicit::Bool)\n",
    "    df = get_split(split, content)\n",
    "    _, β = regress(alphas, content, implicit)\n",
    "    X = regression_features(alphas, split, content, implicit)\n",
    "    RatingsDataset(user = df.user, item = df.item, rating = X * β)\n",
    "end\n",
    "\n",
    "# performs a regression on the validation set and then \n",
    "# calculates the validation loss of that linear combination\n",
    "function residualized_loss(alphas::Vector{String}, content::String, implicit::Bool, x)\n",
    "    split = \"validation\"\n",
    "    x, β = regress(alphas, content, implicit, x)\n",
    "    y = get_split(split, content).rating\n",
    "    loss(x, y, get_weights(split, content, \"inverse\"), implicit; multithreaded = true)\n",
    "end\n",
    "\n",
    "function residualized_loss(\n",
    "    alphas::Vector{String},\n",
    "    content::String,\n",
    "    implicit::Bool,\n",
    "    x,\n",
    "    β,\n",
    "    split::String,\n",
    ")\n",
    "    X = regression_features(alphas, split, content, implicit, x)\n",
    "    x = X * β\n",
    "    y = get_split(split, content).rating\n",
    "    loss(x, y, get_weights(split, content, \"inverse\"), implicit; multithreaded = true)\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-rc1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

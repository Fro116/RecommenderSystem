{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba949471-e864-4ebf-b949-7772e87b6057",
   "metadata": {},
   "source": [
    "# Common utitities for all alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5f693eb8-9aab-4305-a6ee-17e885f3f24d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# using CSV\n",
    "using DataFrames\n",
    "using FileIO\n",
    "using Flux\n",
    "using JLD2\n",
    "using LinearAlgebra\n",
    "using LoggingExtras\n",
    "using Memoize\n",
    "using Optim\n",
    "using Parameters\n",
    "using ProgressMeter\n",
    "using SparseArrays\n",
    "using Statistics\n",
    "\n",
    "import Dates\n",
    "import LineSearches\n",
    "import JupyterFormatter"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c52c3be3-c7d8-4a18-8d83-f82a0858380a",
   "metadata": {},
   "source": [
    "# General utils\n",
    "* TODO split into own file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b2d03d88-f3cc-45ed-bdf9-ef33b7021a9b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# TODO upstream this into the ProgressMeter\n",
    "const SHOW_PROGRESS_BARS = parse(Bool, get(ENV, \"JULIA_SHOW_PROGRESS_BARS\", \"true\"))\n",
    "\n",
    "macro tprogress(expr)\n",
    "    # let the @progress macro work with Threads.@threads\n",
    "    loop = expr\n",
    "    if loop.head == :macrocall && loop.args[1] == :(Threads.var\"@threads\")\n",
    "        loop = loop.args[end]\n",
    "    end\n",
    "    \n",
    "    p = gensym()    \n",
    "    r = loop.args[1].args[end]\n",
    "    ex = quote\n",
    "        n = Int(round(length($(esc(r))) / Threads.nthreads()))\n",
    "        global $p = Progress(n; showspeed=true, enabled=SHOW_PROGRESS_BARS)\n",
    "        $(esc(expr))\n",
    "        finish!($p)\n",
    "    end\n",
    "    \n",
    "    update = quote\n",
    "        if Threads.threadid() == 1\n",
    "            next!($p)\n",
    "        end\n",
    "    end\n",
    "    push!(loop.args[end].args, update)    \n",
    "    \n",
    "    ex    \n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "673b70f5-bfbf-4975-8125-2e96a962e0ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "JupyterFormatter.enable_autoformat();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6fd43cb7-3f58-412d-b8fd-9fefe907e4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prefer Julia multithreading to BLAS multithreading\n",
    "BLAS.set_num_threads(1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1ad5e6a-7ccb-4886-b500-e57b86cb9e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop training if the parameters have converged\n",
    "@with_kw mutable struct convergence_stopper\n",
    "    tolerance::AbstractFloat\n",
    "    max_iters = Inf\n",
    "    params::AbstractVector\n",
    "    prev_params::AbstractVector\n",
    "    iters = 0\n",
    "end\n",
    "\n",
    "function convergence_stopper(tolerance; max_iters = Inf)\n",
    "    convergence_stopper(\n",
    "        tolerance = tolerance,\n",
    "        max_iters = max_iters,\n",
    "        params = [],\n",
    "        prev_params = [],\n",
    "    )\n",
    "end\n",
    "\n",
    "function stop!(x::convergence_stopper, params)\n",
    "    x.iters += 1\n",
    "    if x.iters > x.max_iters\n",
    "        return true\n",
    "    end\n",
    "\n",
    "    if x.iters == 1\n",
    "        x.params = deepcopy(params)\n",
    "        return false\n",
    "    end\n",
    "\n",
    "    function maxabs(a)\n",
    "        maximum(abs.(a))\n",
    "    end\n",
    "\n",
    "    x.prev_params = deepcopy(x.params)\n",
    "    x.params = deepcopy(params)\n",
    "    maximum(maxabs.(x.params - x.prev_params)) < x.tolerance\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "84f68e28-f0aa-4fa6-a423-10b12953a5b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# stop training if the loss function has stopped decreasing\n",
    "@with_kw mutable struct early_stopper\n",
    "    max_iters = Inf\n",
    "    patience = Inf\n",
    "    min_rel_improvement = 0\n",
    "    iters = 0\n",
    "    iters_without_improvement = 0\n",
    "    loss = NaN\n",
    "end\n",
    "\n",
    "function stop!(x::early_stopper, loss)\n",
    "    x.iters += 1\n",
    "    if x.iters > x.max_iters\n",
    "        return true\n",
    "    end\n",
    "\n",
    "    if x.iters == 1\n",
    "        x.loss = loss\n",
    "        return false\n",
    "    end\n",
    "\n",
    "    if loss < x.loss * (1 - x.min_rel_improvement)\n",
    "        x.loss = loss\n",
    "        x.iters_without_improvement = 0\n",
    "    else\n",
    "        x.iters_without_improvement += 1\n",
    "    end\n",
    "    x.iters_without_improvement > x.patience\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2411a5e8-1398-4d8a-a64c-c50a5e39b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logger that flushes after every log statement\n",
    "struct FlushLogger <: AbstractLogger\n",
    "    logger::ConsoleLogger\n",
    "end\n",
    "\n",
    "function FlushLogger(logger::AbstractLogger)\n",
    "    FlushLogger(logger)\n",
    "end\n",
    "\n",
    "function Logging.handle_message(logger::FlushLogger, args...; kwargs...)\n",
    "    Logging.handle_message(logger.logger, args...; kwargs...)\n",
    "    flush(logger.logger.stream)\n",
    "end\n",
    "\n",
    "Logging.shouldlog(logger::FlushLogger, arg...) = Logging.shouldlog(logger.logger, arg...)\n",
    "Logging.min_enabled_level(logger::FlushLogger) = Logging.min_enabled_level(logger.logger)\n",
    "Logging.catch_exceptions(logger::FlushLogger) = Logging.catch_exceptions(logger.logger)\n",
    "\n",
    "function logging_meta_formatter(level, _module, group, id, file, line)\n",
    "    prefix_color = (\n",
    "        level < Logging.Info ? 4 : level < Logging.Warn ? 6 : level < Logging.Error ? 3 : 1\n",
    "    )\n",
    "    prefix = (level == Logging.Warn ? \"Warning\" : string(level)) * ':'\n",
    "    prefix_color, prefix, \"\"\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "310957e5-891f-4797-879f-0084e8560b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Log to file and stdout at the same time\n",
    "function redirect_logging(outdir)\n",
    "    date_format = \"yyyymmdd HH:MM:SS\"\n",
    "    timestamp_logger(logger) =\n",
    "        TransformerLogger(logger) do log\n",
    "            merge(log, (; message = \"$(Dates.format(Dates.now(), date_format)) $(log.message)\"))\n",
    "        end\n",
    "\n",
    "    outdir = mkpath(outdir)\n",
    "    global_logger(\n",
    "        TeeLogger(\n",
    "            FlushLogger(\n",
    "                ConsoleLogger(\n",
    "                    stderr,\n",
    "                    Logging.Info;\n",
    "                    meta_formatter = logging_meta_formatter,\n",
    "                ),\n",
    "            ) |> timestamp_logger,\n",
    "            FlushLogger(\n",
    "                ConsoleLogger(\n",
    "                    open(\"$(outdir)/log\", write = true),\n",
    "                    Logging.Info;\n",
    "                    meta_formatter = logging_meta_formatter,\n",
    "                ),\n",
    "            ) |> timestamp_logger,\n",
    "        ),\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bd9bcd93-0801-4944-9e44-b2b25cc16934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A custom split layer for Flux\n",
    "struct Split{T}\n",
    "    paths::T\n",
    "end\n",
    "Split(paths...) = Split(paths)\n",
    "Flux.@functor Split\n",
    "(m::Split)(x::AbstractArray) = map(f -> f(x), m.paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "064f7f66-bef4-477f-b8c0-96f8a65cc9d3",
   "metadata": {},
   "source": [
    "# Alpha specific utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94fef655-3bf2-494b-870c-96e1b027335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "redirect_logging(\"../../data/alphas/$name\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f39d7a7e-403e-4104-b2a8-f5c48da9c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "@with_kw struct RatingsDataset\n",
    "    user::Vector{Int32}\n",
    "    item::Vector{Int32}\n",
    "    rating::Vector{Float32}\n",
    "end\n",
    "\n",
    "function Base.adjoint(x::RatingsDataset)\n",
    "    RatingsDataset(x.item, x.user, x.rating)\n",
    "end\n",
    "\n",
    "function get_split(split; implicit = false, transpose = false)\n",
    "    @assert split in [\"training\", \"validation\", \"test\", \"implicit\", \"implicit_training\"]\n",
    "    file = \"../../data/splits/splits.jld2\"\n",
    "    df = load(file, split)\n",
    "    if implicit\n",
    "        df.rating .= 1\n",
    "    end\n",
    "    transpose ? df' : df\n",
    "end\n",
    "\n",
    "function get_alpha(alpha, split)\n",
    "    @assert split in [\"training\", \"validation\", \"test\"]\n",
    "    file = \"../../data/alphas/$(alpha)/predictions.jld2\"\n",
    "    load(file, split)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "816ee316-9b8c-4cfe-b671-d79ddfcc90f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some sparse matrix operations require indices to be Int64\n",
    "@with_kw struct RatingsDataset64\n",
    "    user::Vector{Int64}\n",
    "    item::Vector{Int64}\n",
    "    rating::Vector{Float32}\n",
    "end;\n",
    "\n",
    "function RatingsDataset64(x::RatingsDataset)\n",
    "    RatingsDataset64(\n",
    "        convert.(Int64, x.user),\n",
    "        convert.(Int64, x.item),\n",
    "        convert.(Float32, x.rating),\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "410b8c50-92ac-4369-9b08-1c8b85f8058f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function Base.cat(x::RatingsDataset, y::RatingsDataset)\n",
    "    RatingsDataset([x.user; y.user], [x.item; y.item], [x.rating; y.rating])\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca2ddd8e-1c8c-49b0-97ef-848107f4af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "@memoize function num_items()\n",
    "    maximum(get_split(\"training\").item)\n",
    "end\n",
    "\n",
    "@memoize function num_users()\n",
    "    maximum(get_split(\"training\").user)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d03bdb-6e21-4f41-b7d1-f52f143320da",
   "metadata": {},
   "source": [
    "## Weight decays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a3435b41-3aaa-4fd6-a4eb-b04338c3f16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function safe_exp(x, a)\n",
    "    return x == 0 ? zero(eltype(a)) : x^a\n",
    "end;\n",
    "\n",
    "function weighting_scheme(scheme::String)\n",
    "    if scheme == \"linear\"\n",
    "        return 1\n",
    "    elseif scheme == \"constant\"\n",
    "        return 0\n",
    "    elseif scheme == \"inverse\"\n",
    "        return -1\n",
    "    else\n",
    "        @assert false\n",
    "        return 0\n",
    "    end\n",
    "end;\n",
    "\n",
    "function get_user_counts(split::RatingsDataset)\n",
    "    counts = zeros(eltype(split.rating), maximum(split.user), Threads.nthreads())\n",
    "    @tprogress Threads.@threads for i = 1:length(split.rating)\n",
    "        counts[split.user[i], Threads.threadid()] += 1\n",
    "    end\n",
    "    vec(sum(counts, dims = 2))\n",
    "end\n",
    "\n",
    "@memoize function get_counts(split; per_rating = true, by_item = false)\n",
    "    split = get_split(split; transpose = by_item)\n",
    "    user_counts = get_user_counts(split)\n",
    "\n",
    "    if !per_rating\n",
    "        return user_counts\n",
    "    end\n",
    "\n",
    "    counts = zeros(eltype(user_counts), length(split.user))\n",
    "    Threads.@threads for i = 1:length(counts)\n",
    "        counts[i] = user_counts[split.user[i]]\n",
    "    end\n",
    "    counts\n",
    "end\n",
    "\n",
    "function get_weights(split, scheme::String)\n",
    "    safe_exp.(get_counts(split), weighting_scheme(scheme))\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c675de5-4b31-471e-9565-8c2f0a38720e",
   "metadata": {},
   "source": [
    "## Loss functions and regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea33e3e7-ba24-4f51-937a-2469c71b9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "function weighted_crossentropy_loss(x, y, w)\n",
    "    a = zeros(eltype(x), Threads.nthreads())\n",
    "    b = zeros(eltype(w), Threads.nthreads())\n",
    "    Threads.@threads for i = 1:length(x)\n",
    "        a[Threads.threadid()] += -y[i] * log(x[i]) * w[i]\n",
    "        b[Threads.threadid()] += w[i]\n",
    "    end\n",
    "    sum(a) / sum(b)\n",
    "end\n",
    "\n",
    "function weighted_mean_squared_error(x, y, w)\n",
    "    a = zeros(eltype(x), Threads.nthreads())\n",
    "    b = zeros(eltype(w), Threads.nthreads())\n",
    "    Threads.@threads for i = 1:length(x)\n",
    "        a[Threads.threadid()] +=  (x[i] - y[i]) ^ 2 * w[i]\n",
    "        b[Threads.threadid()] += w[i]\n",
    "    end\n",
    "    sum(a) / sum(b)\n",
    "end\n",
    "\n",
    "loss(x, y, w, implicit) =\n",
    "    implicit ? weighted_crossentropy_loss(x, y, w) : weighted_mean_squared_error(x, y, w)\n",
    "\n",
    "# returns the linear combination that minimizes the loss\n",
    "# For explicit data, there is a closed form solution\n",
    "function regress(X, y, w, implicit)\n",
    "    if implicit\n",
    "        β = softmax(\n",
    "            Optim.minimizer(\n",
    "                optimize(\n",
    "                    β -> loss(X * softmax(β), y, w, implicit),\n",
    "                    fill(0.0f0, size(X)[2]),\n",
    "                    BFGS(),\n",
    "                    autodiff = :forward,\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "        return β, X * β\n",
    "    else\n",
    "        β = (X .* sqrt.(w)) \\ (y .* sqrt.(w))\n",
    "        return X * β, β\n",
    "    end\n",
    "end\n",
    "\n",
    "# returns the linear combination that minimizes the validation loss\n",
    "function regress(x, alphas, implicit)\n",
    "    split = \"validation\"\n",
    "    X = zeros(eltype(x), length(x), length(alphas) + 1)\n",
    "    @tprogress Threads.@threads for j = 1:length(alphas)\n",
    "        X[:, j] = get_alpha(alphas[j], split).rating\n",
    "    end\n",
    "    X[:, end] .= x\n",
    "    y = get_split(split; implicit = implicit).rating\n",
    "    w = get_weights(split, \"inverse\")\n",
    "    regress(X, y, w, implicit)\n",
    "end\n",
    "\n",
    "# returns the minimum loss obtainable by linearly combining the alphas\n",
    "function residualized_loss(x, alphas, implicit, split)\n",
    "    x, _ = regress(x, alphas, implicit)\n",
    "    y = get_split(split; implicit = implicit).rating\n",
    "    loss(x, y, get_weights(split, \"inverse\"), implicit)\n",
    "end\n",
    "\n",
    "# linearly combinine the given alphas\n",
    "function get_alpha(alphas::Vector{String}, split::String, implicit)\n",
    "    df = get_split(split; implicit = implicit)\n",
    "    baseline = implicit ? 1.0f0 / num_items() : 0.0f0\n",
    "    x, _ = regress(fill(baseline, length(get_split(\"validation\").rating)), alphas, implicit)\n",
    "    df.rating .= x\n",
    "    df\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d269cc1-aa79-47b3-bddb-e23c6fc8a80b",
   "metadata": {},
   "source": [
    "## Saving data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a717beaf-8ded-4f72-b6d9-c15f4b929ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "function write_predictions(model, alphas, implicit; outdir = name)\n",
    "    splits_to_save = [\"training\", \"validation\", \"test\"]\n",
    "    splits_to_log = [\"training\", \"validation\"]\n",
    "\n",
    "    predictions = Dict()\n",
    "    for split in splits_to_save\n",
    "        df = residualize(split, alphas, implicit)\n",
    "        x = model(df.user, df.item)\n",
    "        predictions[split] = RatingsDataset(df.user, df.item, x)\n",
    "        if split in splits_to_log\n",
    "            @info \"$(split) loss: $(residualized_loss(x, alphas, implicit, split))\"\n",
    "        end\n",
    "    end\n",
    "\n",
    "    outdir = mkpath(\"../../data/alphas/$outdir\")\n",
    "    save(\"$outdir/predictions.jld2\", predictions)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5237f49-f24d-43e1-9698-7358d22e7c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function write_params(params; outdir = name)\n",
    "    outdir = mkpath(\"../../data/alphas/$outdir\")\n",
    "    save(\"$outdir/params.jld2\", params)\n",
    "end\n",
    "\n",
    "function read_params(alpha)\n",
    "    load(\"../../data/alphas/$alpha/params.jld2\")\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

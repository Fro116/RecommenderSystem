{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba949471-e864-4ebf-b949-7772e87b6057",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Helper functions that are useful for generating alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f693eb8-9aab-4305-a6ee-17e885f3f24d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import Flux: softmax\n",
    "import JLD2\n",
    "import Memoize: @memoize\n",
    "import NBInclude: @nbinclude\n",
    "import Optim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd094a91-95a1-4007-a3c6-748cda48f03d",
   "metadata": {},
   "source": [
    "## General utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd9bcd93-0801-4944-9e44-b2b25cc16934",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"AlphaUtils.ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f749ff84-92d8-4185-89d5-8c06cb2a1139",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94fef655-3bf2-494b-870c-96e1b027335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if !@isdefined name\n",
    "    name = \"Alpha\"\n",
    "end\n",
    "redirect_logging(\"../../data/alphas/$name\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adffc2d1-1b56-4f2c-820a-847c8e69eb8f",
   "metadata": {},
   "source": [
    "## Structs for handling ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f39d7a7e-403e-4104-b2a8-f5c48da9c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user[i] has seen item[i] and given it a score of rating[i]\n",
    "@with_kw struct RatingsDataset\n",
    "    user::Vector{Int32}\n",
    "    item::Vector{Int32}\n",
    "    rating::Vector{Float32}\n",
    "end\n",
    "\n",
    "# swap users with items\n",
    "function Base.adjoint(x::RatingsDataset)\n",
    "    RatingsDataset(x.item, x.user, x.rating)\n",
    "end\n",
    "\n",
    "# Some sparse matrix operations require indices to be Int64\n",
    "@with_kw struct RatingsDataset64\n",
    "    user::Vector{Int64}\n",
    "    item::Vector{Int64}\n",
    "    rating::Vector{Float32}\n",
    "end\n",
    "\n",
    "function RatingsDataset64(x::RatingsDataset)\n",
    "    RatingsDataset64(\n",
    "        convert.(Int64, x.user),\n",
    "        convert.(Int64, x.item),\n",
    "        convert.(Float32, x.rating),\n",
    "    )\n",
    "end\n",
    "\n",
    "# append two datasets\n",
    "function Base.cat(x::RatingsDataset, y::RatingsDataset)\n",
    "    RatingsDataset([x.user; y.user], [x.item; y.item], [x.rating; y.rating])\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca2ddd8e-1c8c-49b0-97ef-848107f4af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we sanitize the splits such that no user/item in the validation\n",
    "# or test splits has a higher id that the the training set does\n",
    "\n",
    "@memoize function num_users()\n",
    "    maximum(get_split(\"training\").user)\n",
    "end\n",
    "\n",
    "@memoize function num_items()\n",
    "    maximum(get_split(\"training\").item)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa86422d-a577-49b0-8d79-381809028b55",
   "metadata": {},
   "source": [
    "## Reading and writing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af54ef89-2778-4329-bbab-f4cde92b2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a split is a collection of (user, item, rating) triples that are stored as a RatingsDataset\n",
    "# \n",
    "# @param split the following splits are supported:\n",
    "#     training: used to train an alpha's parameters\n",
    "#     validation: used to tune an alpha's hyperpameters\n",
    "#     test: used to measure out of sample performance\n",
    "#     implicit: contains all items a user has seen, including shows which they have not rated.\n",
    "#     impliict_training: contains all items in the implicit split that are not in the validation or splits\n",
    "#\n",
    "# @param implicit replace the explicit ratings with an implicit rating. \n",
    "#     the implicit rating is 1 if they watched the series and 0 if they have not\n",
    "# @param transpose return an (item, user, rating) dataset instead of a (user, item, rating) dataset\n",
    "function get_split(split; implicit = false, transpose = false)\n",
    "    # TODO negative test split\n",
    "    @assert split in [\"training\", \"validation\", \"test\", \"implicit\", \"implicit_training\"]\n",
    "    if split in [\"implicit\", \"implicit_training\"]\n",
    "        @assert implicit\n",
    "    end\n",
    "    file = \"../../data/splits/splits.jld2\"\n",
    "    df = JLD2.load(file, split)\n",
    "    if implicit\n",
    "        fill!(df.rating, 1)\n",
    "    end\n",
    "    transpose ? df' : df\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a717beaf-8ded-4f72-b6d9-c15f4b929ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an alpha is a model that is used to predict whether a user will like an item.\n",
    "# it's often useful to know an alpha model's value for a given (user, item) pair.\n",
    "# alphas can be expensive to compute, so we precompute the model's values on\n",
    "# (user-item) pairs and store the resultant RatingsDatasets to disk.\n",
    "# storing the model values for all (user, item) pairs would be prohibitively\n",
    "# large, so we only store values for our splits\n",
    "\n",
    "function write_alpha(model, alphas, implicit; outdir = name)\n",
    "    splits_to_save = [\"validation\", \"training\", \"test\"]\n",
    "    splits_to_not_log = [\"test\"]\n",
    "\n",
    "    β = nothing\n",
    "    predictions = Dict()\n",
    "    for split in splits_to_save\n",
    "        df = get_split(split; implicit = implicit)\n",
    "        x = model(df.user, df.item)\n",
    "        if isnothing(β)\n",
    "            # we need to evaluate the validation set to get the regression coefficients\n",
    "            @assert split == \"validation\"\n",
    "            _, β = regress(x, alphas, implicit)\n",
    "        end\n",
    "        predictions[split] = RatingsDataset(df.user, df.item, x)\n",
    "        if split ∉ splits_to_not_log\n",
    "            @info \"$(split) loss: $(residualized_loss(x, alphas, implicit, β, split))\"\n",
    "        end\n",
    "    end\n",
    "\n",
    "    outdir = mkpath(\"../../data/alphas/$outdir\")\n",
    "    JLD2.save(\"$outdir/predictions.jld2\", predictions)\n",
    "end\n",
    "\n",
    "function read_alpha(alpha, split)\n",
    "    @assert split in [\"training\", \"validation\", \"test\"]\n",
    "    file = \"../../data/alphas/$(alpha)/predictions.jld2\"\n",
    "    JLD2.load(file, split)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5237f49-f24d-43e1-9698-7358d22e7c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params consist of two things:\n",
    "# 1) the hyperparameters that are used to train an alpha\n",
    "# 2) the trained parameters of an alpha \n",
    "# in general, params should contain all information necessary to\n",
    "# efficiently train the alpha model for a new user\n",
    "\n",
    "function write_params(params; outdir = name)\n",
    "    outdir = mkpath(\"../../data/alphas/$outdir\")\n",
    "    JLD2.save(\"$outdir/params.jld2\", params)\n",
    "end\n",
    "\n",
    "function read_params(alpha)\n",
    "    JLD2.load(\"../../data/alphas/$alpha/params.jld2\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d03bdb-6e21-4f41-b7d1-f52f143320da",
   "metadata": {},
   "source": [
    "## Weight decays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3435b41-3aaa-4fd6-a4eb-b04338c3f16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of items a user has seen spans orders of magnitude.\n",
    "# if we place an equal weight on each (user, item) pair, then highly\n",
    "# active users will skew the loss function. It is generally best practice\n",
    "# to weight each user equally (see Deep Neural Networks for YouTube Recommendations \n",
    "# https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf]).\n",
    "# we achieve this by weighting our validation and test loss functions such that each\n",
    "# (user, item) pair has a weight of 1 / |number of items the user has seen|.\n",
    "# \n",
    "# during training, the same skew issue appears. instead of weighting each (user, item)\n",
    "# pair by 1 / |number of items the user has seen|, we take the more general approach\n",
    "# of weighting each (user, item) pair by \n",
    "# |number of items the user has seen| ^ w_u * |number of users that have seen the item| ^ w_a\n",
    "# when w_u=-1 and w_a=0, then we recover the equal-user weighting that we used for\n",
    "# validation and test sets.\n",
    "\n",
    "function expdecay(x, a)\n",
    "    x == 0 ? zero(eltype(a)) : sign(x) * abs(x)^a\n",
    "end\n",
    "\n",
    "function expdecay(x::Vector, a)\n",
    "    y = Array{eltype(a)}(undef, length(x))\n",
    "    Threads.@threads for i = 1:length(x)\n",
    "        @inbounds y[i] = expdecay(x[i], a)\n",
    "    end\n",
    "    y\n",
    "end\n",
    "\n",
    "function weighting_scheme(scheme::String)\n",
    "    if scheme == \"linear\"\n",
    "        return 1f0\n",
    "    elseif scheme == \"constant\"\n",
    "        return 0f0\n",
    "    elseif scheme == \"inverse\"\n",
    "        return -1f0\n",
    "    else\n",
    "        @assert false\n",
    "        return 0f0\n",
    "    end\n",
    "end;\n",
    "\n",
    "function get_user_counts(split::RatingsDataset)\n",
    "    counts = zeros(eltype(split.rating), maximum(split.user), Threads.nthreads())\n",
    "    @tprogress Threads.@threads for i = 1:length(split.rating)\n",
    "        @inbounds counts[split.user[i], Threads.threadid()] += 1\n",
    "    end\n",
    "    vec(sum(counts, dims = 2))\n",
    "end\n",
    "\n",
    "@memoize function get_counts(split; per_rating = true, by_item = false)\n",
    "    split = get_split(split; transpose = by_item)\n",
    "    user_counts = get_user_counts(split)\n",
    "\n",
    "    if !per_rating\n",
    "        return user_counts\n",
    "    end\n",
    "\n",
    "    counts = Array{eltype(user_counts)}(undef, length(split.user))\n",
    "    Threads.@threads for i = 1:length(counts)\n",
    "        @inbounds counts[i] = user_counts[split.user[i]]\n",
    "    end\n",
    "    counts\n",
    "end\n",
    "\n",
    "function get_weights(split, scheme::String)\n",
    "    expdecay(get_counts(split), weighting_scheme(scheme))\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c675de5-4b31-471e-9565-8c2f0a38720e",
   "metadata": {},
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea33e3e7-ba24-4f51-937a-2469c71b9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most alphas can be classified as one of two types:\n",
    "# 1) explicit alphas predict what rating a user will give to\n",
    "#    a given show conditional on having watched the show. these \n",
    "#    alphas are trained using mean squared error\n",
    "# 2) implicit alphas predict whether a user will watch a\n",
    "#    a given show. these alphas are trained using\n",
    "#    cross-entropy loss\n",
    "# both loss functions are weighted according to the weight decay\n",
    "# logic described above\n",
    "\n",
    "function weighted_loss(x, y, w, lossfn)\n",
    "    a = Array{eltype(x)}(undef, Threads.nthreads())\n",
    "    b = Array{eltype(w)}(undef, Threads.nthreads())    \n",
    "    Threads.@threads for t = 1:Threads.nthreads()\n",
    "        range = thread_range(length(x))\n",
    "        # Base.sum uses pairwise summation which is important for accuracy\n",
    "        @views a[Threads.threadid()] = sum(lossfn(x[range], y[range]) .* w[range])\n",
    "        @views b[Threads.threadid()] = sum(w[range])\n",
    "    end\n",
    "    sum(a) / sum(b)\n",
    "end  \n",
    "\n",
    "function loss(x, y, w, implicit)\n",
    "    lossfn = implicit ? (x, y) -> -y .* log.(x) : (x, y) -> (x - y) .^ 2\n",
    "    weighted_loss(x, y, w, lossfn)\n",
    "end;\n",
    "\n",
    "# function weighted_crossentropy_loss(x, y, w)\n",
    "#     weighted_loss(x, y, w, (x, y) -> -y .* log.(x))\n",
    "# end\n",
    "\n",
    "# function weighted_mean_squared_error(x, y, w)\n",
    "#     weighted_loss(x, y, w, (x, y) -> (x - y) .^ 2)\n",
    "# end\n",
    "\n",
    "# loss(x, y, w, implicit) =\n",
    "#     implicit ? weighted_crossentropy_loss(x, y, w) : weighted_mean_squared_error(x, y, w);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9986bce-923f-4100-a796-d604b53c2d26",
   "metadata": {},
   "source": [
    "## Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81ed30f-6bdd-4b6f-8a3c-b8da119a67db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a matrix of features X, a vector of true labels y, and\n",
    "# a vector of weights w, a regression will find the β\n",
    "# that minimizes the weighted between X * β and y. for explicit\n",
    "# alphas, the loss is mean squared error and there is a closed\n",
    "# form solution. for implicit alphas, the loss is cross-entropy\n",
    "# and we solve for β numerically.\n",
    "\n",
    "function regress(X, y, w, implicit)\n",
    "    if implicit\n",
    "        β = softmax(\n",
    "            Optim.minimizer(\n",
    "                Optim.optimize(\n",
    "                    β -> loss(X * softmax(β), y, w, implicit),\n",
    "                    fill(0.0f0, size(X)[2]),\n",
    "                    Optim.NewtonTrustRegion(),\n",
    "                    autodiff = :forward,\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "    else\n",
    "        β = (X .* sqrt.(w)) \\ (y .* sqrt.(w))\n",
    "    end\n",
    "    @info \"regression coefficients: $β\"\n",
    "    X * β, β\n",
    "end\n",
    "\n",
    "# regress the given features on the validation set\n",
    "function regress(x, alphas, implicit)\n",
    "    split = \"validation\"\n",
    "    X = regression_features(x, alphas, split)\n",
    "    y = get_split(split; implicit = implicit).rating\n",
    "    w = get_weights(split, \"inverse\")\n",
    "    regress(X, y, w, implicit)\n",
    "end\n",
    "\n",
    "# concatenates x with the given alphas\n",
    "function regression_features(x, alphas, split)\n",
    "    X = Array{eltype(x),2}(undef, length(x), length(alphas) + 1)\n",
    "    @tprogress Threads.@threads for j = 1:length(alphas)\n",
    "        @inbounds X[:, j] = read_alpha(alphas[j], split).rating\n",
    "    end\n",
    "    X[:, end] = x\n",
    "    X\n",
    "end\n",
    "\n",
    "\n",
    "# performs a regression on the validation set and then \n",
    "# calculates the validation loss of that linear combination\n",
    "function residualized_loss(x, alphas, implicit)\n",
    "    split = \"validation\"\n",
    "    x, β = regress(x, alphas, implicit)\n",
    "    y = get_split(split; implicit = implicit).rating\n",
    "    loss(x, y, get_weights(split, \"inverse\"), implicit)\n",
    "end\n",
    "\n",
    "function residualized_loss(x, alphas, implicit, β, split)\n",
    "    X = regression_features(x, alphas, split)\n",
    "    x = X * β\n",
    "    y = get_split(split; implicit = implicit).rating\n",
    "    loss(x, y, get_weights(split, \"inverse\"), implicit)\n",
    "end\n",
    "\n",
    "# linearly combinine the given alphas\n",
    "function read_alpha(alphas::Vector, split::String, implicit)\n",
    "    df = get_split(split)\n",
    "    baseline = implicit ? 1.0f0 / num_items() : 0.0f0\n",
    "    _, β = regress(fill(baseline, length(get_split(\"validation\").rating)), alphas, implicit)\n",
    "    X = regression_features(fill(baseline, length(df.rating)), alphas, split)\n",
    "    RatingsDataset(df.user, df.item, X * β)\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

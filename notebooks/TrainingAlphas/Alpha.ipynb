{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba949471-e864-4ebf-b949-7772e87b6057",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Helper functions that are useful for generating alphas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5f693eb8-9aab-4305-a6ee-17e885f3f24d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import Flux: softmax\n",
    "import JLD2\n",
    "import LRUCache: LRU\n",
    "import Memoize: @memoize\n",
    "import NBInclude: @nbinclude\n",
    "import Optim\n",
    "import ProgressMeter: @showprogress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd094a91-95a1-4007-a3c6-748cda48f03d",
   "metadata": {},
   "source": [
    "## General utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd9bcd93-0801-4944-9e44-b2b25cc16934",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"AlphaUtils.ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f749ff84-92d8-4185-89d5-8c06cb2a1139",
   "metadata": {},
   "source": [
    "## Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94fef655-3bf2-494b-870c-96e1b027335e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if !@isdefined name\n",
    "    name = \"Alpha\"\n",
    "end\n",
    "redirect_logging(\"../../data/alphas/$name\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adffc2d1-1b56-4f2c-820a-847c8e69eb8f",
   "metadata": {},
   "source": [
    "## Structs for handling ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f39d7a7e-403e-4104-b2a8-f5c48da9c7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# user[i] has seen item[i] and given it a score of rating[i]\n",
    "@with_kw struct RatingsDataset\n",
    "    user::Vector{Int32}\n",
    "    item::Vector{Int32}\n",
    "    rating::Vector{Float32}\n",
    "end\n",
    "\n",
    "# swap users with items\n",
    "function Base.adjoint(x::RatingsDataset)\n",
    "    RatingsDataset(x.item, x.user, x.rating)\n",
    "end\n",
    "\n",
    "# TODO maybe we can delete this with a newer julia version\n",
    "# Some sparse matrix operations require indices to be Int64\n",
    "@with_kw struct RatingsDataset64\n",
    "    user::Vector{Int64}\n",
    "    item::Vector{Int64}\n",
    "    rating::Vector{Float32}\n",
    "end\n",
    "\n",
    "function RatingsDataset64(x::RatingsDataset)\n",
    "    RatingsDataset64(\n",
    "        convert.(Int64, x.user),\n",
    "        convert.(Int64, x.item),\n",
    "        convert.(Float32, x.rating),\n",
    "    )\n",
    "end\n",
    "\n",
    "# append two datasets\n",
    "function Base.cat(x::RatingsDataset, y::RatingsDataset)\n",
    "    RatingsDataset([x.user; y.user], [x.item; y.item], [x.rating; y.rating])\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ca2ddd8e-1c8c-49b0-97ef-848107f4af49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we sanitize the splits such that no user/item in the validation\n",
    "# or test splits has a higher id that the the training set does\n",
    "@memoize function num_users()\n",
    "    max(\n",
    "        maximum(get_split(\"training\", false).user),\n",
    "        maximum(get_split(\"training\", true).user),\n",
    "    )\n",
    "end\n",
    "\n",
    "@memoize function num_items()\n",
    "    max(\n",
    "        maximum(get_split(\"training\", false).item),\n",
    "        maximum(get_split(\"training\", true).item),\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa86422d-a577-49b0-8d79-381809028b55",
   "metadata": {},
   "source": [
    "## Reading and writing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af54ef89-2778-4329-bbab-f4cde92b2c31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a split is a collection of (user, item, rating) triples that are stored as a RatingsDataset\n",
    "# \n",
    "# @param split the following splits are supported:\n",
    "#     training: used to train an alpha's parameters\n",
    "#     validation: used to tune an alpha's hyperpameters\n",
    "#     test: used to measure out of sample performance\n",
    "#\n",
    "# @param implicit replace the explicit ratings with an implicit rating. \n",
    "#     the implicit rating is 1 if they watched the series and 0 if they have not\n",
    "# @param transpose return an (item, user, rating) dataset instead of a (user, item, rating) dataset\n",
    "@memoize LRU{Tuple{String,Bool,Bool},RatingsDataset}(maxsize = 2) function get_split(\n",
    "    split,\n",
    "    implicit;\n",
    "    transpose = false,\n",
    ")\n",
    "    @assert split in [\"training\", \"validation\", \"test\", \"negative\"]\n",
    "\n",
    "    file = \"../../data/splits/splits.jld2\"\n",
    "    if split == \"negative\"\n",
    "        df = JLD2.load(file, split)\n",
    "    elseif implicit\n",
    "        df = cat(JLD2.load(file, \"explicit_\" * split), JLD2.load(file, \"implicit_\" * split))\n",
    "        fill!(df.rating, 1)\n",
    "    else\n",
    "        df = JLD2.load(file, \"explicit_\" * split)\n",
    "    end\n",
    "    transpose ? df' : df\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a717beaf-8ded-4f72-b6d9-c15f4b929ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# an alpha is a model that is used to predict whether a user will like an item.\n",
    "# it's often useful to know an alpha model's value for a given (user, item) pair.\n",
    "# alphas can be expensive to compute, so we precompute the model's values on\n",
    "# (user-item) pairs and store the resultant RatingsDatasets to disk.\n",
    "# storing the model values for all (user, item) pairs would be prohibitively\n",
    "# large, so we only store values for our splits\n",
    "\n",
    "function write_alpha(model, alphas, implicit; outdir = name)\n",
    "    splits_to_save = [\"validation\", \"training\", \"test\", \"negative\"]\n",
    "    splits_to_not_log = [\"test\", \"negative\"]\n",
    "\n",
    "    β = nothing\n",
    "    predictions = Dict()\n",
    "    for split in splits_to_save\n",
    "        df = get_split(split, implicit)\n",
    "        x = model(df.user, df.item)\n",
    "        if isnothing(β)\n",
    "            # we need to evaluate the validation set to get the regression coefficients\n",
    "            @assert split == \"validation\"\n",
    "            _, β = regress(alphas, implicit, x)\n",
    "        end\n",
    "        predictions[split] = RatingsDataset(df.user, df.item, x)\n",
    "        if split ∉ splits_to_not_log\n",
    "            @info \"$(split) loss: $(residualized_loss(alphas, implicit, x, β, split)), β: $β\"\n",
    "        end\n",
    "    end\n",
    "\n",
    "    outdir = mkpath(\"../../data/alphas/$outdir\")\n",
    "    JLD2.save(\"$outdir/predictions.jld2\", predictions)\n",
    "end\n",
    "\n",
    "function read_alpha(alpha, split)\n",
    "    @assert split in [\"training\", \"validation\", \"test\"]\n",
    "    file = \"../../data/alphas/$(alpha)/predictions.jld2\"\n",
    "    JLD2.load(file, split)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5237f49-f24d-43e1-9698-7358d22e7c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# params consist of two things:\n",
    "# 1) the hyperparameters that are used to train an alpha\n",
    "# 2) the trained parameters of an alpha \n",
    "# in general, params should contain all information necessary to\n",
    "# efficiently train the alpha model for a new user\n",
    "\n",
    "function write_params(params; outdir = name)\n",
    "    outdir = mkpath(\"../../data/alphas/$outdir\")\n",
    "    JLD2.save(\"$outdir/params.jld2\", params)\n",
    "end\n",
    "\n",
    "function read_params(alpha)\n",
    "    JLD2.load(\"../../data/alphas/$alpha/params.jld2\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d03bdb-6e21-4f41-b7d1-f52f143320da",
   "metadata": {},
   "source": [
    "## Weight decays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a3435b41-3aaa-4fd6-a4eb-b04338c3f16c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the number of items a user has seen spans orders of magnitude.\n",
    "# if we place an equal weight on each (user, item) pair, then highly\n",
    "# active users will skew the loss function. It is generally best practice\n",
    "# to weight each user equally (see Deep Neural Networks for YouTube Recommendations \n",
    "# https://static.googleusercontent.com/media/research.google.com/en//pubs/archive/45530.pdf]).\n",
    "# we achieve this by weighting our validation and test loss functions such that each\n",
    "# (user, item) pair has a weight of 1 / |number of items the user has seen|.\n",
    "# \n",
    "# during training, the same skew issue appears. instead of weighting each (user, item)\n",
    "# pair by 1 / |number of items the user has seen|, we take the more general approach\n",
    "# of weighting each (user, item) pair by \n",
    "# |number of items the user has seen| ^ w_u * |number of users that have seen the item| ^ w_a\n",
    "# when w_u=-1 and w_a=0, then we recover the equal-user weighting that we used for\n",
    "# validation and test sets.\n",
    "\n",
    "function expdecay(x, a)\n",
    "    x == 0 ? zero(eltype(a)) : sign(x) * abs(x)^a\n",
    "end\n",
    "\n",
    "function expdecay(x::Vector, a)\n",
    "    y = Array{eltype(a)}(undef, length(x))\n",
    "    Threads.@threads for i = 1:length(x)\n",
    "        @inbounds y[i] = expdecay(x[i], a)\n",
    "    end\n",
    "    y\n",
    "end\n",
    "\n",
    "function weighting_scheme(scheme::String)\n",
    "    if scheme == \"linear\"\n",
    "        return 1.0f0\n",
    "    elseif scheme == \"constant\"\n",
    "        return 0.0f0\n",
    "    elseif scheme == \"inverse\"\n",
    "        return -1.0f0\n",
    "    else\n",
    "        @assert false\n",
    "        return 0.0f0\n",
    "    end\n",
    "end;\n",
    "\n",
    "function get_user_counts(split::RatingsDataset)\n",
    "    counts = zeros(eltype(split.rating), maximum(split.user), Threads.nthreads())\n",
    "    @tprogress Threads.@threads for i = 1:length(split.rating)\n",
    "        @inbounds counts[split.user[i], Threads.threadid()] += 1\n",
    "    end\n",
    "    vec(sum(counts, dims = 2))\n",
    "end\n",
    "\n",
    "@memoize function get_counts(split, implicit; per_rating = true, by_item = false)\n",
    "    split = get_split(split, implicit; transpose = by_item)\n",
    "    user_counts = get_user_counts(split)\n",
    "\n",
    "    if !per_rating\n",
    "        return user_counts\n",
    "    end\n",
    "\n",
    "    counts = Array{eltype(user_counts)}(undef, length(split.user))\n",
    "    Threads.@threads for i = 1:length(counts)\n",
    "        @inbounds counts[i] = user_counts[split.user[i]]\n",
    "    end\n",
    "    counts\n",
    "end\n",
    "\n",
    "function get_weights(split, implicit, scheme::String)\n",
    "    expdecay(get_counts(split, implicit), weighting_scheme(scheme))\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c675de5-4b31-471e-9565-8c2f0a38720e",
   "metadata": {},
   "source": [
    "## Loss functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea33e3e7-ba24-4f51-937a-2469c71b9c22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# most alphas can be classified as one of two types:\n",
    "# 1) explicit alphas predict what rating a user will give to\n",
    "#    a given show conditional on having watched the show. these \n",
    "#    alphas are trained using mean squared error\n",
    "# 2) implicit alphas predict whether a user will watch a\n",
    "#    a given show. these alphas are trained using\n",
    "#    cross-entropy loss\n",
    "# both loss functions are weighted according to the weight decay\n",
    "# logic described above\n",
    "\n",
    "function weighted_loss(x, y, w, lossfn)\n",
    "    sum(lossfn(x, y) .* w) / sum(w)\n",
    "end\n",
    "\n",
    "function weighted_loss_multithreaded(x, y, w, lossfn)\n",
    "    a = Array{eltype(x)}(undef, Threads.nthreads())\n",
    "    b = Array{eltype(w)}(undef, Threads.nthreads())\n",
    "    Threads.@threads for t = 1:Threads.nthreads()\n",
    "        range = thread_range(length(x))\n",
    "        # Base.sum uses pairwise summation which is important for accuracy\n",
    "        @views weight = sum(w[range])\n",
    "        @views a[Threads.threadid()] =\n",
    "            weighted_loss(x[range], y[range], w[range], lossfn) * weight\n",
    "        b[Threads.threadid()] = weight\n",
    "    end\n",
    "    sum(a) / sum(b)\n",
    "end\n",
    "\n",
    "function error(x, y, w, implicit)\n",
    "    lossfn = implicit ? (x, y) -> -y .* log.(x) : (x, y) -> (x - y) .^ 2\n",
    "    weighted_error(x, y, w, lossfn)\n",
    "end\n",
    "\n",
    "function loss(x, y, w, implicit; normalize = true, multithreaded = false)\n",
    "    if implicit\n",
    "        lossfn = (x, y) -> -y .* log.(x)\n",
    "    else\n",
    "        lossfn = (x, y) -> (x - y) .^ 2\n",
    "    end\n",
    "    if normalize\n",
    "        if multithreaded\n",
    "            evaluator = weighted_loss_multithreaded\n",
    "        else\n",
    "            evaluator = weighted_loss\n",
    "        end\n",
    "    else\n",
    "        evaluator = weighted_unnormalized_loss\n",
    "    end\n",
    "    evaluator(x, y, w, lossfn)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9986bce-923f-4100-a796-d604b53c2d26",
   "metadata": {},
   "source": [
    "## Regressions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b81ed30f-6bdd-4b6f-8a3c-b8da119a67db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# given a matrix of features X, a vector of true labels y, and\n",
    "# a vector of weights w, a regression will find the β\n",
    "# that minimizes the weighted between X * β and y. for explicit\n",
    "# alphas, the loss is mean squared error and there is a closed\n",
    "# form solution. for implicit alphas, the loss is cross-entropy\n",
    "# and we solve for β numerically.\n",
    "\n",
    "function regress(X, y, w, implicit)\n",
    "    if implicit\n",
    "        β = softmax(\n",
    "            Optim.minimizer(\n",
    "                Optim.optimize(\n",
    "                    β -> loss(X * softmax(β), y, w, implicit; multithreaded = true),\n",
    "                    fill(0.0f0, size(X)[2]),\n",
    "                    Optim.NewtonTrustRegion(),\n",
    "                    autodiff = :forward,\n",
    "                ),\n",
    "            ),\n",
    "        )\n",
    "    else\n",
    "        Xw = (X .* sqrt.(w))\n",
    "        yw = (y .* sqrt.(w))\n",
    "        β = Xw'Xw \\ Xw'yw\n",
    "    end\n",
    "    X * β, β\n",
    "end\n",
    "\n",
    "# regress the given features on the validation set\n",
    "function regress(alphas, implicit, x = nothing)\n",
    "    split = \"validation\"\n",
    "    X = regression_features(alphas, split, implicit, x)\n",
    "    y = get_split(split, implicit).rating\n",
    "    w = get_weights(split, implicit, \"inverse\")\n",
    "    regress(X, y, w, implicit)\n",
    "end\n",
    "\n",
    "# concatenates x, if given, with the alphas\n",
    "function regression_features(alphas, split, implicit, x = nothing)\n",
    "    ncols = length(alphas) + (isnothing(x) ? 0 : 1) + implicit\n",
    "    shape = isnothing(x) ? get_split(split, implicit).rating : x\n",
    "    X = Array{eltype(shape),2}(undef, length(shape), ncols)\n",
    "    @tprogress Threads.@threads for j = 1:length(alphas)\n",
    "        @inbounds X[:, j] = read_alpha(alphas[j], split).rating\n",
    "    end\n",
    "\n",
    "    if implicit\n",
    "        # add a baseline feature for non-degeneracy\n",
    "        @views fill!(X[:, length(alphas)+1], 1.0f0)\n",
    "    end\n",
    "    if !isnothing(x)\n",
    "        X[:, end] = x\n",
    "    end\n",
    "    X\n",
    "end\n",
    "\n",
    "# linearly combinine the given alphas\n",
    "function read_alpha(alphas::Vector, split::String, implicit)\n",
    "    df = get_split(split, implicit)\n",
    "    _, β = regress(alphas, implicit)\n",
    "    X = regression_features(alphas, split, implicit)\n",
    "    RatingsDataset(df.user, df.item, X * β)\n",
    "end\n",
    "\n",
    "# performs a regression on the validation set and then \n",
    "# calculates the validation loss of that linear combination\n",
    "function residualized_loss(alphas, implicit, x)\n",
    "    split = \"validation\"\n",
    "    x, β = regress(alphas, implicit, x)\n",
    "    y = get_split(split, implicit).rating\n",
    "    loss(x, y, get_weights(split, implicit, \"inverse\"), implicit; multithreaded = true)\n",
    "end\n",
    "\n",
    "function residualized_loss(alphas, implicit, x, β, split)\n",
    "    X = regression_features(alphas, split, implicit, x)\n",
    "    x = X * β\n",
    "    y = get_split(split, implicit).rating\n",
    "    loss(x, y, get_weights(split, implicit, \"inverse\"), implicit; multithreaded = true)\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

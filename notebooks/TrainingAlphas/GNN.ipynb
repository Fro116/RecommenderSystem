{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3758ece-9b72-47b4-ae6a-aa364e0443e3",
   "metadata": {},
   "source": [
    "# Generalized Neural Network\n",
    "* A denoising autoencoder that learns the user's ratings and implicit ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc9334a-2287-41d6-885b-a5cca94fe263",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"GNN\";\n",
    "residual_alphas = [\"UserItemBiases\"];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54170f91-c85c-4207-9939-572cad4db024",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "import BSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17593ac-3260-4c01-a5df-91edfcd17e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "using NBInclude\n",
    "@nbinclude(\"Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69280b1f-08cb-4b16-a19a-c85ead6e1f25",
   "metadata": {},
   "outputs": [],
   "source": [
    "BLAS.set_num_threads(Threads.nthreads());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08801fd4-7057-49f0-9fa7-9854d17494cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = gpu;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638f2e93-80aa-4d4f-90ee-d70e3610cd13",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eb458301-7baa-4bd1-88c1-bd8c9193bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "const training = get_residuals(\"training\", residual_alphas);\n",
    "const validation = get_residuals(\"validation\", residual_alphas)\n",
    "# column accesses are faster than row accesses, so we make this an (item, user) matrix \n",
    "const R = sparse(\n",
    "    training.item,\n",
    "    training.user,\n",
    "    convert.(Float32, training.rating),\n",
    "    maximum(training.item) + 1,  # leave room for unseen users and items\n",
    "    maximum(training.user) + 1,\n",
    ");\n",
    "const n_items, n_users = size(R);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c1eed4a0-4b70-468c-acae-645742a69153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.33 μs/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "counts = zeros(n_users, Threads.nthreads())\n",
    "@tprogress Threads.@threads for u in training.user\n",
    "    counts[u, Threads.threadid()] += 1\n",
    "end\n",
    "counts = sum(counts, dims = 2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fd21001b-3626-4bf2-82aa-ba04ba89df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_data(R, split, j, train)\n",
    "    # inputs are the user's ratings (unseen shows get mapped to zero) + implicit ratings + heterogenous features\n",
    "    # outputs are the user's ratings + implicit ratings during training\n",
    "    # outputs are the user's rating + implicit rating for a held out item on their list during inference\n",
    "\n",
    "    # handle users and items that aren't in the training set\n",
    "    u = min(split.user[j], n_users)\n",
    "    i = min(split.item[j], n_items)\n",
    "\n",
    "    # ratings\n",
    "    X1 = collect(R[:, u])\n",
    "    X1[i] = 0\n",
    "    # implicit ratings\n",
    "    X2 = copy(X1)\n",
    "    X2[X2.!=0] .= 1\n",
    "    # heterogeneous features\n",
    "    count = convert(Float32, max(counts[u] - 1, 0) / n_items) # TODO benchmark use of global\n",
    "    X3 = [count, sqrt(count), count^2]\n",
    "    X = vcat(X1, X2, X3)\n",
    "\n",
    "    # outputs\n",
    "    Y1 = zeros(eltype(X1), length(X1))\n",
    "    Y2 = zeros(eltype(X2), length(X2))\n",
    "    if train\n",
    "        mask = X2 .!= 0\n",
    "        Y1[mask] .= X1[mask]\n",
    "        Y2[mask] .= X2[mask]\n",
    "    else\n",
    "        Y1[i] = split.rating[j]\n",
    "        Y2[i] = 1\n",
    "    end\n",
    "\n",
    "    (X, Y1, Y2)\n",
    "end\n",
    "\n",
    "function get_batch(R, split, block_size, train)\n",
    "    items = rand(1:length(split.rating), block_size)\n",
    "    data = [[] for j = 1:Threads.nthreads()]\n",
    "    Threads.@threads for i = 1:length(items)\n",
    "        push!(data[Threads.threadid()], get_data(R, split, items[i], train))\n",
    "    end\n",
    "    X = Flux.batch([data[t][i][1] for t = 1:Threads.nthreads() for i = 1:length(data[t])])\n",
    "    Y1 = Flux.batch([data[t][i][2] for t = 1:Threads.nthreads() for i = 1:length(data[t])])\n",
    "    Y2 = Flux.batch([data[t][i][3] for t = 1:Threads.nthreads() for i = 1:length(data[t])])\n",
    "    [(X, (Y1, Y2))] |> device\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab185e90-4462-454e-9f1e-f776513e7a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom split layer\n",
    "struct Split{T}\n",
    "    paths::T\n",
    "end\n",
    "\n",
    "Split(paths...) = Split(paths)\n",
    "\n",
    "Flux.@functor Split\n",
    "\n",
    "(m::Split)(x::AbstractArray) = map(f -> f(x), m.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "110b7a2f-5927-4837-99f0-980bc72b5034",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Chain(\n",
       "  Dropout(0.5),\n",
       "  Chain(\n",
       "    Dense(33965, 512, relu),            \u001b[90m# 17_390_592 parameters\u001b[39m\n",
       "    Dense(512, 256, relu),              \u001b[90m# 131_328 parameters\u001b[39m\n",
       "    Dense(256, 128, relu),              \u001b[90m# 32_896 parameters\u001b[39m\n",
       "  ),\n",
       "  Split(\n",
       "    Tuple(\n",
       "      Chain(\n",
       "        Dense(128, 256, relu),          \u001b[90m# 33_024 parameters\u001b[39m\n",
       "        Dense(256, 512, relu),          \u001b[90m# 131_584 parameters\u001b[39m\n",
       "        Dense(512, 16981),              \u001b[90m# 8_711_253 parameters\u001b[39m\n",
       "      ),\n",
       "      Chain(\n",
       "        Dense(128, 256, relu),          \u001b[90m# 33_024 parameters\u001b[39m\n",
       "        Dense(256, 512, relu),          \u001b[90m# 131_584 parameters\u001b[39m\n",
       "        Dense(512, 16981),              \u001b[90m# 8_711_253 parameters\u001b[39m\n",
       "      ),\n",
       "    ),\n",
       "  ),\n",
       ")\u001b[90m                   # Total: 18 arrays, \u001b[39m35_306_538 parameters, 134.685 MiB."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# inputs are the user's ratings for all shows (unseen shows get mapped to zero) + implicit ratings + heterogenous features\n",
    "# outputs are the user's ratings for all shows (unseen shows get mapped to zero), implicit ratings\n",
    "# we will train ratings using mse on observed shows, and implicit ratings via crossentropy loss\n",
    "n_items = size(R)[1]\n",
    "encoder = Chain(\n",
    "    Dense(n_items + n_items + 3, 512, relu),\n",
    "    Dense(512, 256, relu),\n",
    "    Dense(256, 128, relu),\n",
    ")\n",
    "rating_decoder = Chain(Dense(128, 256, relu), Dense(256, 512, relu), Dense(512, n_items))\n",
    "implicit_decoder = Chain(Dense(128, 256, relu), Dense(256, 512, relu), Dense(512, n_items))\n",
    "m = Chain(Dropout(0.5), encoder, Split(rating_decoder, implicit_decoder)) |> device\n",
    "ps = Flux.params(m);\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4988ea0-8a00-41f1-857f-6064ef3806a7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2068c6b4-911b-400d-89ca-f7971d8de0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "function rating_loss(ŷ, y)\n",
    "    mask = y .!= 0\n",
    "    Flux.mse(ŷ[mask], y[mask])\n",
    "end\n",
    "\n",
    "implicit_loss(ŷ, y) = Flux.logitcrossentropy(ŷ, y)\n",
    "\n",
    "function implicit_loss(ŷ, y, mask)\n",
    "    ŷ[mask] .= -1e3\n",
    "    implicit_loss(ŷ, y)\n",
    "end\n",
    "\n",
    "function loss_components(x, y, train)\n",
    "    ŷ = m(x)\n",
    "    if train\n",
    "        return (rating_loss(ŷ[1], y[1]), implicit_loss(ŷ[2], y[2]))\n",
    "    else\n",
    "        mask = (x.!=0)[1:n_items, :]\n",
    "        return (rating_loss(ŷ[1], y[1]), implicit_loss(ŷ[2], y[2], mask))\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d20f19ce-36f6-45a4-82f5-b560f62b0bb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ADAM();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2be3fd86-8685-42b7-9061-d82f1a4a6064",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:20\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:08\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "best_loss = Inf\n",
    "patience = 10\n",
    "iters_without_improvement = 0\n",
    "continue_training = true\n",
    "iters = 0\n",
    "\n",
    "\n",
    "function evalcb(R, split, train)\n",
    "    losses = []\n",
    "    @showprogress for epoch = 1:100\n",
    "        push!(losses, loss_components(get_batch(R, split, 128, train)[1]..., train))\n",
    "    end\n",
    "    reduce(.+, losses) ./ length(losses)\n",
    "end\n",
    "\n",
    "\n",
    "const training_baseline_loss = evalcb(R, training, true)\n",
    "const inference_baseline_loss = evalcb(R, training, false);\n",
    "function loss(x, y)\n",
    "    sum(loss_components(x, y, true) ./ training_baseline_loss)\n",
    "end\n",
    "\n",
    "function evalcb()\n",
    "    # print losses and perform early stopping\n",
    "    testmode!(m)\n",
    "    @debug \"iteration: $iters\"\n",
    "    training_losses = evalcb(R, training, true)\n",
    "    training_loss = sum(training_losses ./ training_baseline_loss)\n",
    "    @debug \"training losses: $(training_losses) -> $(training_loss)\"\n",
    "    inference_losses = evalcb(R, validation, false)\n",
    "    loss = sum(inference_losses ./ inference_baseline_loss)\n",
    "    @debug \"validation losses: $(inference_losses) -> $(loss)\"\n",
    "    if loss < best_loss\n",
    "        global best_loss = loss\n",
    "        global iters_without_improvement = 0\n",
    "        BSON.@save \"../../data/alphas/$name/model.bson\" m\n",
    "    else\n",
    "        global iters_without_improvement += 1\n",
    "        if iters_without_improvement >= patience\n",
    "            global continue_training = false\n",
    "        end\n",
    "    end\n",
    "    trainmode!(m)\n",
    "end\n",
    "\n",
    "throttled_cb = Flux.throttle(evalcb, 30);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17bda612-f8a6-4d0e-ad9a-358f8a19f06a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220128 05:21:28 iteration: 0\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220128 05:21:38 training losses: (1.6617624f0, 4147.5684f0) -> 2.0450315\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220128 05:21:48 validation losses: (1.685081f0, 9.700835f0) -> 1.9845676\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220128 05:22:33 iteration: 28\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:07\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220128 05:22:41 training losses: (1.5716187f0, 3470.235f0) -> 1.8218625\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220128 05:22:52 validation losses: (1.6143215f0, 7.847826f0) -> 1.7524025\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220128 05:23:35 iteration: 52\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:08\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220128 05:23:43 training losses: (1.5600922f0, 3489.5684f0) -> 1.8196124\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:08\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220128 05:23:51 validation losses: (1.6372696f0, 7.612869f0) -> 1.7416399\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220128 05:24:34 iteration: 77\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:08\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220128 05:24:42 training losses: (1.5157745f0, 3411.2927f0) -> 1.7730964\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:08\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220128 05:24:50 validation losses: (1.5406777f0, 7.5578184f0) -> 1.6794605\n"
     ]
    }
   ],
   "source": [
    "while continue_training\n",
    "    batch = get_batch(R, training, 128, true)\n",
    "    Flux.train!(loss, ps, batch, opt, cb = throttled_cb)\n",
    "    iters += 1\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdd719b-7f8b-491e-bafa-8aa56a9545e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Write predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceec8522-af45-44ab-a398-afba5f255efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function get_data(R, u)\n",
    "#     X = collect(R[:, u])\n",
    "#     Xr = copy(X)\n",
    "#     Xr[Xr.!=0] .= 1\n",
    "#     X = vcat(X, Xr)\n",
    "\n",
    "#     # add heterogeneous features\n",
    "#     weight = sum(Xr .!= 0)\n",
    "#     nitems_feature = weight / size(R)[1]\n",
    "#     push!(X, nitems_feature)\n",
    "#     push!(X, sqrt(nitems_feature))\n",
    "#     push!(X, nitems_feature^2)\n",
    "#     X\n",
    "# end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4bc90f8-550f-4595-b2f3-f2c1723f3f7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function model(users, items)\n",
    "#     df = RatingsDataset(users, items, fill(0, length(users)))\n",
    "#     predictions = zeros(length(users))\n",
    "#     deduped_users = collect(Set(users))\n",
    "#     @tprogress Threads.@threads for i = 1:length(deduped_users)\n",
    "#         u = deduped_users[i]\n",
    "#         alpha = m(get_data(R, u))\n",
    "#         for j = 1:length(users)\n",
    "#             if users[j] == u\n",
    "#                 predictions[j] = alpha[items[j]]\n",
    "#             end\n",
    "#         end\n",
    "#     end\n",
    "#     predictions\n",
    "# end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522022d5-6a7d-481b-8452-3ca7d2d6bb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BSON.@load \"../../data/alphas/$name/model.bson\" m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9d19bc-a152-4365-9abf-4873b26c985d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_predictions(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4574797e-7f50-4061-b614-37e013d4e9e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

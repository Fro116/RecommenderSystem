{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2df5351f-2171-4365-b750-8984d42c5fe5",
   "metadata": {},
   "source": [
    "# ErrorModel\n",
    "* Uses LightGBM to estimate the error for a given (user, item) prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69b5a19a-24f5-4730-afe2-f451d27d18e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: lib_lightgbm found in system dirs!\n",
      "└ @ LightGBM /Users/kundan/.julia/packages/LightGBM/A7zVd/src/LightGBM.jl:28\n"
     ]
    }
   ],
   "source": [
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"TreeModelBase.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "edf2b7dc-6ec0-44f9-9f88-1df84ba11362",
   "metadata": {},
   "outputs": [],
   "source": [
    "const all_features = [\n",
    "    \"SimpleAverage\",\n",
    "    \"SimpleExplicitBaseline\",\n",
    "    \"LinearExplicit\",\n",
    "    \"NonlinearExplicit\",\n",
    "    \"Explicit\",\n",
    "    \"UniformBaseline\",\n",
    "    \"PopularityBaseline\",\n",
    "    \"LinearImplicit\",\n",
    "]\n",
    "const error_model = true;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "517ce91a-bf09-446a-8be9-a7c5bbe0c0f3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.13 μs/it)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.147553 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 1522\n",
      "[LightGBM] [Info] Number of data points in the train set: 15175754, number of used features: 6\n",
      "[LightGBM] [Info] Start training from score 1.024479\n",
      "Iteration: 1, test_1's l2: 0.8206789065694721\n",
      "Iteration: 2, test_1's l2: 0.8141767075006339\n",
      "Iteration: 3, test_1's l2: 0.8088130227830761\n",
      "Iteration: 4, test_1's l2: 0.8045180703634134\n",
      "Iteration: 5, test_1's l2: 0.8010523020565593\n",
      "Iteration: 6, test_1's l2: 0.7982129454825391\n",
      "Iteration: 7, test_1's l2: 0.7959023904874811\n",
      "Iteration: 8, test_1's l2: 0.7939925317363982\n",
      "Iteration: 9, test_1's l2: 0.792478386107538\n",
      "Iteration: 10, test_1's l2: 0.7912436750758239\n",
      "Iteration: 11, test_1's l2: 0.7902079871064229\n",
      "Iteration: 12, test_1's l2: 0.7894077483398277\n",
      "Iteration: 13, test_1's l2: 0.7886960626905776\n",
      "Iteration: 14, test_1's l2: 0.7881795596189534\n",
      "Iteration: 15, test_1's l2: 0.787715271960151\n",
      "Iteration: 16, test_1's l2: 0.7873360935848793\n",
      "Iteration: 17, test_1's l2: 0.7870299545696007\n",
      "Iteration: 18, test_1's l2: 0.7867877597268661\n",
      "Iteration: 19, test_1's l2: 0.7865385015431291\n",
      "Iteration: 20, test_1's l2: 0.7864027173581559\n",
      "Iteration: 21, test_1's l2: 0.7862332931360131\n",
      "Iteration: 22, test_1's l2: 0.7861176397573979\n",
      "Iteration: 23, test_1's l2: 0.7859871368873589\n",
      "Iteration: 24, test_1's l2: 0.7859343448532667\n",
      "Iteration: 25, test_1's l2: 0.7858388513353439\n",
      "Iteration: 26, test_1's l2: 0.7857912805677272\n",
      "Iteration: 27, test_1's l2: 0.7857189586945852\n",
      "Iteration: 28, test_1's l2: 0.7856788775513811\n",
      "Iteration: 29, test_1's l2: 0.785642114713266\n",
      "Iteration: 30, test_1's l2: 0.7856365434548688\n",
      "Iteration: 31, test_1's l2: 0.7856275435989579\n",
      "Iteration: 32, test_1's l2: 0.7856361484173862\n",
      "Iteration: 33, test_1's l2: 0.7856089467154548\n",
      "Iteration: 34, test_1's l2: 0.7855929770806462\n",
      "Iteration: 35, test_1's l2: 0.785588033091137\n",
      "Iteration: 36, test_1's l2: 0.7855887188564431\n",
      "Iteration: 37, test_1's l2: 0.7855819400109035\n",
      "Iteration: 38, test_1's l2: 0.785607814329591\n",
      "Iteration: 39, test_1's l2: 0.7856088926124044\n",
      "Iteration: 40, test_1's l2: 0.7855890617081557\n",
      "Iteration: 41, test_1's l2: 0.7856118269896387\n",
      "Iteration: 42, test_1's l2: 0.7856100106829557\n",
      "Iteration: 43, test_1's l2: 0.7855968677160132\n",
      "Iteration: 44, test_1's l2: 0.7855980043375975\n",
      "Iteration: 45, test_1's l2: 0.7856239901481737\n",
      "Iteration: 46, test_1's l2: 0.785630463732078\n",
      "Early stopping at iteration 47, the best iteration round is 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220612 02:16:42 Saving model... (this may take a while)\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:11 ( 0.66 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.70 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.69 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:04 ( 0.68 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.67 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.68 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.47 μs/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "train_model(all_features, [\"Explicit\"], false, \"test\", \"ErrorExplicit\", true);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "765ef7e7-abf6-432e-b55d-2eea75753f32",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 (35.92 ns/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 (39.39 ns/it)\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Auto-choosing row-wise multi-threading, the overhead of testing was 0.097677 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 1526\n",
      "[LightGBM] [Info] Number of data points in the train set: 20711239, number of used features: 8\n",
      "[LightGBM] [Info] Start training from score 0.052895\n",
      "Iteration: 1, test_1's l2: 0.006810364671202766\n",
      "Iteration: 2, test_1's l2: 0.006721719563261\n",
      "Iteration: 3, test_1's l2: 0.006650289196064511\n",
      "Iteration: 4, test_1's l2: 0.006592117393126235\n",
      "Iteration: 5, test_1's l2: 0.006544174136245655\n",
      "Iteration: 6, test_1's l2: 0.006504971658749989\n",
      "Iteration: 7, test_1's l2: 0.006473128825175209\n",
      "Iteration: 8, test_1's l2: 0.006447014246912758\n",
      "Iteration: 9, test_1's l2: 0.006425583316597733\n",
      "Iteration: 10, test_1's l2: 0.006408011572007234\n",
      "Iteration: 11, test_1's l2: 0.00639333553931268\n",
      "Iteration: 12, test_1's l2: 0.0063814080103751095\n",
      "Iteration: 13, test_1's l2: 0.006371489820986619\n",
      "Iteration: 14, test_1's l2: 0.006363568232756643\n",
      "Iteration: 15, test_1's l2: 0.0063568186278523\n",
      "Iteration: 16, test_1's l2: 0.006351100888323058\n",
      "Iteration: 17, test_1's l2: 0.006346108518713234\n",
      "Iteration: 18, test_1's l2: 0.006341902663277268\n",
      "Iteration: 19, test_1's l2: 0.006338299572575283\n",
      "Iteration: 20, test_1's l2: 0.006335141141722453\n",
      "Iteration: 21, test_1's l2: 0.006332474598711104\n",
      "Iteration: 22, test_1's l2: 0.006330147420625866\n",
      "Iteration: 23, test_1's l2: 0.006328135405186344\n",
      "Iteration: 24, test_1's l2: 0.006326220158283401\n",
      "Iteration: 25, test_1's l2: 0.006324559490168863\n",
      "Iteration: 26, test_1's l2: 0.0063230945065690285\n",
      "Iteration: 27, test_1's l2: 0.006321732097648434\n",
      "Iteration: 28, test_1's l2: 0.006320639413594692\n",
      "Iteration: 29, test_1's l2: 0.006319511155260496\n",
      "Iteration: 30, test_1's l2: 0.006318576769565518\n",
      "Iteration: 31, test_1's l2: 0.00631756385079358\n",
      "Iteration: 32, test_1's l2: 0.00631668251615443\n",
      "Iteration: 33, test_1's l2: 0.00631582955390449\n",
      "Iteration: 34, test_1's l2: 0.006315089971185789\n",
      "Iteration: 35, test_1's l2: 0.006314277275615953\n",
      "Iteration: 36, test_1's l2: 0.006313785349089685\n",
      "Iteration: 37, test_1's l2: 0.006313127919315706\n",
      "Iteration: 38, test_1's l2: 0.006312537339098417\n",
      "Iteration: 39, test_1's l2: 0.006311967091752941\n",
      "Iteration: 40, test_1's l2: 0.006311280626987319\n",
      "Iteration: 41, test_1's l2: 0.0063107936864989994\n",
      "Iteration: 42, test_1's l2: 0.006310371253262689\n",
      "Iteration: 43, test_1's l2: 0.00630978019246161\n",
      "Iteration: 44, test_1's l2: 0.00630935327801399\n",
      "Iteration: 45, test_1's l2: 0.006308880677721858\n",
      "Iteration: 46, test_1's l2: 0.006308479357597018\n",
      "Iteration: 47, test_1's l2: 0.006308089164737001\n",
      "Iteration: 48, test_1's l2: 0.006307613894895061\n",
      "Iteration: 49, test_1's l2: 0.006307231974317751\n",
      "Iteration: 50, test_1's l2: 0.006306844162212867\n",
      "Iteration: 51, test_1's l2: 0.006306527453254626\n",
      "Iteration: 52, test_1's l2: 0.006306108006700437\n",
      "Iteration: 53, test_1's l2: 0.006305771005758193\n",
      "Iteration: 54, test_1's l2: 0.006305509825877576\n",
      "Iteration: 55, test_1's l2: 0.006305245945946331\n",
      "Iteration: 56, test_1's l2: 0.006304926750418686\n",
      "Iteration: 57, test_1's l2: 0.0063045914018437545\n",
      "Iteration: 58, test_1's l2: 0.006304285501117466\n",
      "Iteration: 59, test_1's l2: 0.006304045563527498\n",
      "Iteration: 60, test_1's l2: 0.006303887792818818\n",
      "Iteration: 61, test_1's l2: 0.00630371889650029\n",
      "Iteration: 62, test_1's l2: 0.0063035178756830675\n",
      "Iteration: 63, test_1's l2: 0.00630338665759427\n",
      "Iteration: 64, test_1's l2: 0.0063031237497221445\n",
      "Iteration: 65, test_1's l2: 0.006302935002249079\n",
      "Iteration: 66, test_1's l2: 0.0063026537469821715\n",
      "Iteration: 67, test_1's l2: 0.006302525424469924\n",
      "Iteration: 68, test_1's l2: 0.006302264599487067\n",
      "Iteration: 69, test_1's l2: 0.006302065283260509\n",
      "Iteration: 70, test_1's l2: 0.006301917947528224\n",
      "Iteration: 71, test_1's l2: 0.006301665886280096\n",
      "Iteration: 72, test_1's l2: 0.0063014176892691575\n",
      "Iteration: 73, test_1's l2: 0.006301248893852801\n",
      "Iteration: 74, test_1's l2: 0.006301013881872135\n",
      "Iteration: 75, test_1's l2: 0.0063008357308855885\n",
      "Iteration: 76, test_1's l2: 0.006300687702412553\n",
      "Iteration: 77, test_1's l2: 0.00630046134392041\n",
      "Iteration: 78, test_1's l2: 0.006300293426985477\n",
      "Iteration: 79, test_1's l2: 0.006300159640069903\n",
      "Iteration: 80, test_1's l2: 0.006300027463096239\n",
      "Iteration: 81, test_1's l2: 0.006299930477063558\n",
      "Iteration: 82, test_1's l2: 0.0062997595253390555\n",
      "Iteration: 83, test_1's l2: 0.006299632729215462\n",
      "Iteration: 84, test_1's l2: 0.0062995535050583955\n",
      "Iteration: 85, test_1's l2: 0.006299375687430014\n",
      "Iteration: 86, test_1's l2: 0.006299315396184185\n",
      "Iteration: 87, test_1's l2: 0.006299180837944076\n",
      "Iteration: 88, test_1's l2: 0.006299079694068459\n",
      "Iteration: 89, test_1's l2: 0.006299011653780874\n",
      "Iteration: 90, test_1's l2: 0.006298802565050774\n",
      "Iteration: 91, test_1's l2: 0.0062986453118011616\n",
      "Iteration: 92, test_1's l2: 0.006298514136882671\n",
      "Iteration: 93, test_1's l2: 0.0062984837871144905\n",
      "Iteration: 94, test_1's l2: 0.006298405904821304\n",
      "Iteration: 95, test_1's l2: 0.006298297408049945\n",
      "Iteration: 96, test_1's l2: 0.006298154359726273\n",
      "Iteration: 97, test_1's l2: 0.00629810047931956\n",
      "Iteration: 98, test_1's l2: 0.006297930818079962\n",
      "Iteration: 99, test_1's l2: 0.006297848632605822\n",
      "Iteration: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220612 02:22:45 Saving model... (this may take a while)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100, test_1's l2: 0.006297775795143437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:11 ( 0.65 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.66 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.67 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:03 ( 0.64 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.67 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 0.66 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 0.44 μs/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "train_model(all_features, [\"LinearImplicit\"], true, \"test\", \"ErrorImplicit\", true);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-rc1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

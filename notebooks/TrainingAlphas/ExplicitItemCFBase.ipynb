{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3758ece-9b72-47b4-ae6a-aa364e0443e3",
   "metadata": {},
   "source": [
    "# Item Collaborative Filtering\n",
    "* This notebook implements item-based collaborative filtering\n",
    "* Prediction is $\\tilde r_{ij} = \\dfrac{\\sum_{k \\in N(j)} w_{kj}^{\\lambda_w}r_{ik}^{\\lambda_r}}{\\sum_{k \\in N(j)} w_{kj}^{\\lambda_w} + \\lambda}$ for item-based collaborative filtering\n",
    "* $r_{ij}$ is the rating for user $i$ and item $j$\n",
    "* $w_{kj}$ is the similarity between items $j$ and $k$\n",
    "* $N(j)$ is the largest $K$ sorted by $w_{kj}$\n",
    "* $\\lambda_w, \\lambda_r, \\lambda$ are regularization parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d17593ac-3260-4c01-a5df-91edfcd17e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import LinearAlgebra: norm\n",
    "import Setfield: @set\n",
    "import SparseArrays: sparse\n",
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bff8e524-e8f8-48bd-9ca7-c28a05a122b8",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Determine the neighborhoods for each user and item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "275b8d1d-b0f1-4a72-bff2-ed1c615beae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_correlation_matrix_outdir(residual_alphas, name = name)\n",
    "    # if the matrix is already stored on disk, return its filepath\n",
    "    # otherwise, regenerate the matrix and store it to disk\n",
    "    outdir = \"$name/$(hash(residual_alphas))\"\n",
    "    if ispath(\"../../data/alphas/$outdir\")\n",
    "        return outdir\n",
    "    end\n",
    "\n",
    "    @info \"generating similarity matrix for $residual_alphas\"\n",
    "    training = RatingsDataset64(get_residuals(\"training\", residual_alphas))\n",
    "    R = sparse(\n",
    "        training.user,\n",
    "        training.item,\n",
    "        training.rating,\n",
    "        maximum(training.user),\n",
    "        maximum(training.item),\n",
    "    )\n",
    "    S = zeros(eltype(R), maximum(training.item), maximum(training.item))\n",
    "\n",
    "    norms = map(norm, eachslice(R, dims = 2))\n",
    "    norms[norms.==0] .= 1 # prevent division by 0\n",
    "    @tprogress Threads.@threads for i = 1:size(S)[1]\n",
    "        S[:, i] = vec(R[:, i]' * R) ./ norms ./ norms[i]\n",
    "    end\n",
    "\n",
    "    write_params(Dict(\"S\" => S), outdir)\n",
    "    outdir\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "687c68e6-5d2d-470b-a513-9ba157a4ef89",
   "metadata": {},
   "outputs": [],
   "source": [
    "function read_similarity_matrix(outdir)\n",
    "    read_params(outdir)[\"S\"]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd34115c-51b5-4af1-908d-4322a46d5918",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_abs_neighborhood(item, S, K)\n",
    "    weights = S[:, item]\n",
    "    # ensure that the neighborhood for an item does not include itself\n",
    "    weights[item] = Inf\n",
    "    K = Int(min(K, length(weights) - 1))\n",
    "    order = partialsortperm(abs.(weights), 2:K+1, rev = true)\n",
    "    order, weights[order]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00ebb580-b942-4113-8d60-78a83042d876",
   "metadata": {},
   "outputs": [],
   "source": [
    "isnonzero(x) = !isapprox(x, 0.0, atol = eps(Float32))\n",
    "\n",
    "# evaluate a quartic polynomial at x\n",
    "function polynomial_transform(x, λ)\n",
    "    y = abs(x)\n",
    "    w = λ[1] + λ[2] * y + λ[3] * y ^ 2 + λ[4] * y^3 + λ[5] * y^4\n",
    "    sign(x) * w\n",
    "end\n",
    "\n",
    "# each prediction is just the weighted sum of all items in the neighborhood\n",
    "# we apply regularization terms to decay the weights, ratings, and final prediction\n",
    "function make_prediction(item, users, R, get_neighborhood, λ)\n",
    "    if item > size(R)[2]\n",
    "        # the item was not in our training set; we have no information\n",
    "        return zeros(length(item))\n",
    "    end\n",
    "    items, weights = get_neighborhood(item)\n",
    "    weights = polynomial_transform.(weights, tuple(λ[1:5]))\n",
    "    predictions = zeros(eltype(weights), length(users))\n",
    "    weight_sum = zeros(eltype(weights), length(users))\n",
    "    for u = 1:length(users)\n",
    "        for (i, weight) in zip(items, weights)\n",
    "            if isnonzero(R[users[u], i])\n",
    "                predictions[u] += weight * polynomial_transform(R[users[u], i], λ[6:10])\n",
    "                weight_sum[u] += abs(weight)\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    for u = 1:length(users)\n",
    "        predictions[u] /= (weight_sum[u] + 1)\n",
    "    end\n",
    "    predictions\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5214736f-516e-4d6f-8f0b-92171355ebe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "function collaborative_filtering(training, inference, get_neighborhood, λ)\n",
    "    R = sparse(\n",
    "        training.user,\n",
    "        training.item,\n",
    "        training.rating,\n",
    "        maximum(training.user),\n",
    "        maximum(training.item),\n",
    "    )\n",
    "\n",
    "    preds = zeros(eltype(λ), length(inference.rating))\n",
    "    @tprogress Threads.@threads for item in collect(Set(inference.item))\n",
    "        mask = inference.item .== item \n",
    "        preds[mask] = make_prediction(item, inference.user[mask], R, get_neighborhood, λ)\n",
    "    end\n",
    "\n",
    "    preds\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c815cbbe-7300-4c9d-9163-4e554a9752e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@with_kw struct cf_params\n",
    "    name::Any\n",
    "    training_residuals::Any\n",
    "    validation_residuals::Any\n",
    "    neighborhood_type::Any\n",
    "    S::Any # the similarity matrix\n",
    "    K::Any # the neighborhood size\n",
    "    λ::Vector{Float32}\n",
    "end;\n",
    "\n",
    "to_dict(x::T) where {T} = Dict(string(fn) => getfield(x, fn) for fn ∈ fieldnames(T));"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94cf908b-4b56-412a-9765-c13021874f41",
   "metadata": {},
   "source": [
    "## Item based CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "904a3cc2-c5e7-4e1b-810a-b3616c4d1b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_residuals(split, residual_alphas)\n",
    "    df = get_split(split, false)\n",
    "    ratings = df.rating - read_alpha(residual_alphas, split, false).rating\n",
    "    RatingsDataset(df.user, df.item, ratings)\n",
    "end\n",
    "\n",
    "function get_training(residual_alphas)\n",
    "    get_residuals(\"training\", residual_alphas)\n",
    "end\n",
    "\n",
    "function get_validation(residual_alphas)\n",
    "    get_residuals(\"validation\", residual_alphas)\n",
    "end\n",
    "\n",
    "function get_inference()\n",
    "    splits = reduce(cat, [get_split(split, false) for split in all_raw_splits])\n",
    "    RatingsDataset(\n",
    "        user = splits.user,\n",
    "        item = splits.item,\n",
    "        rating = fill(0.0f0, length(splits.rating)),\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "755b9b34-ffa0-48d9-bf99-5ee735c04036",
   "metadata": {},
   "outputs": [],
   "source": [
    "function optimize_model(param)\n",
    "    # unpack parameters\n",
    "    redirect_logging(\"../../data/alphas/$(param.name)\")\n",
    "    training = get_training(param.training_residuals)\n",
    "    validation = get_validation(param.validation_residuals)\n",
    "    S = read_similarity_matrix(param.S)\n",
    "    K = param.K\n",
    "    neighborhood_types = Dict(\"abs\" => get_abs_neighborhood)\n",
    "    neighborhoods = i -> neighborhood_types[param.neighborhood_type](i, S, K)\n",
    "\n",
    "    # optimize hyperparameters\n",
    "    function validation_mse(λ)\n",
    "        preds = collaborative_filtering(training, validation, neighborhoods, λ)\n",
    "        loss = residualized_loss(param.validation_residuals, false, preds)\n",
    "        @info \"loss: $loss\"\n",
    "        loss\n",
    "    end\n",
    "    res = Optim.optimize(\n",
    "        validation_mse,\n",
    "        param.λ,\n",
    "        Optim.NewtonTrustRegion(),\n",
    "        autodiff = :forward,\n",
    "        Optim.Options(show_trace = true, extended_trace = true),\n",
    "    )\n",
    "    param = @set param.λ = Optim.minimizer(res)\n",
    "\n",
    "    # save predictions\n",
    "    inference = get_inference()\n",
    "    preds = collaborative_filtering(training, inference, neighborhoods, param.λ)\n",
    "    sparse_preds = sparse(inference.user, inference.item, preds)\n",
    "    function model(users, items, predictions)\n",
    "        result = zeros(length(users))\n",
    "        for i = 1:length(users)\n",
    "            if users[i] <= size(predictions)[1] && items[i] <= size(predictions)[2]\n",
    "                result[i] = predictions[users[i], items[i]]\n",
    "            end\n",
    "        end\n",
    "        result\n",
    "    end\n",
    "    write_predictions(\n",
    "        (users, items) -> model(users, items, sparse_preds),\n",
    "        outdir = param.name,\n",
    "        residual_alphas = param.validation_residuals,\n",
    "    )\n",
    "    write_params(to_dict(param), param.name)\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-rc1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

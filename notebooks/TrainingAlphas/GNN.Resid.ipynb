{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3758ece-9b72-47b4-ae6a-aa364e0443e3",
   "metadata": {},
   "source": [
    "# Generalized Neural Network\n",
    "* A denoising autoencoder that learns the user's ratings and implicit ratings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc9334a-2287-41d6-885b-a5cca94fe263",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"GNN.Resid\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54170f91-c85c-4207-9939-572cad4db024",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Random\n",
    "import BSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17593ac-3260-4c01-a5df-91edfcd17e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "using NBInclude\n",
    "@nbinclude(\"Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08801fd4-7057-49f0-9fa7-9854d17494cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = gpu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ede3b9a1-1dc8-4b10-aab0-03ceb5d27be1",
   "metadata": {},
   "outputs": [],
   "source": [
    "Random.seed!(20220130);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638f2e93-80aa-4d4f-90ee-d70e3610cd13",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f724408-2a16-4d0d-adb3-9a1ddbe283bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:02:48\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:04\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "const residual_alphas = [\n",
    "    [\"UserItemBiases\"]\n",
    "    [\"GNN\"]\n",
    "    [\"ItemCF.$K\" for K in [2^4, 2^6, 2^8, 2^10, 2^12]]\n",
    "    [\"MatrixFactorization.$K\" for K in [10, 20, 40]] # TODO make 8,16,32\n",
    "    [\"ItemCF.Resid.$alpha.1.$K\" for alpha in [\"ItemCF\", \"GNN\", \"MF\"] for K in [2^8]]\n",
    "]\n",
    "const training = get_residuals(\"training\", residual_alphas)\n",
    "const validation = get_residuals(\"validation\", residual_alphas)\n",
    "const implicit = get_split(\"implicit\")\n",
    "const n_items = num_items() + 1 # leave room to map unseen items\n",
    "const n_users = maximum(training.user) + 1; # leave room to map unseen users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eb458301-7baa-4bd1-88c1-bd8c9193bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# column accesses are faster than row accesses, so we make this an (item, user) matrix \n",
    "const R = sparse(training.item, training.user, training.rating, n_items, n_users)\n",
    "const Ri = sparse(implicit.item, implicit.user, implicit.rating, n_items, n_users);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1eed4a0-4b70-468c-acae-645742a69153",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:06 ( 0.42 μs/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "# number of items each user has seen\n",
    "counts = zeros(Float32, n_users, Threads.nthreads())\n",
    "@tprogress Threads.@threads for u in implicit.user\n",
    "    counts[u, Threads.threadid()] += 1\n",
    "end\n",
    "counts = sum(counts, dims = 2);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fd21001b-3626-4bf2-82aa-ba04ba89df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_data(split, j, train)\n",
    "    # inputs are the user's ratings (unseen shows get mapped to zero) + implicit ratings + heterogenous features\n",
    "    # during training, outputs are the user's ratings + implicit ratings \n",
    "    # during inference, outputs are the user's rating + implicit rating for a held out item on their list\n",
    "\n",
    "    # handle users and items that aren't in the training set\n",
    "    u = min(split.user[j], n_users)\n",
    "    i = min(split.item[j], n_items)\n",
    "\n",
    "    # ratings\n",
    "    X1 = collect(R[:, u])\n",
    "    X1[i] = 0\n",
    "    # implicit ratings\n",
    "    X2 = collect(Ri[:, u])\n",
    "    X2[i] = 0\n",
    "    # heterogeneous features\n",
    "    count = convert(Float32, max(counts[u] - 1, 0) / n_items)\n",
    "    X3 = [count, sqrt(count), count^2]\n",
    "    X = vcat(X1, X2, X3)\n",
    "\n",
    "    # outputs\n",
    "    Y1 = zeros(eltype(X1), length(X1))\n",
    "    Y2 = zeros(eltype(X2), length(X2))\n",
    "    if train\n",
    "        mask = X2 .!= 0\n",
    "        Y1[mask] .= X1[mask]\n",
    "        Y2[mask] .= X2[mask]\n",
    "    else\n",
    "        Y1[i] = split.rating[j]\n",
    "        Y2[i] = 1\n",
    "    end\n",
    "\n",
    "    (X, Y1, Y2)\n",
    "end\n",
    "\n",
    "function get_batch(split, block_size, train)\n",
    "    idxs = rand(1:length(split.rating), block_size)\n",
    "    data = [[] for j = 1:Threads.nthreads()]\n",
    "    Threads.@threads for i = 1:length(items)\n",
    "        push!(data[Threads.threadid()], get_data(split, idxs[i], train))\n",
    "    end\n",
    "    X = Flux.batch([data[t][i][1] for t = 1:Threads.nthreads() for i = 1:length(data[t])])\n",
    "    Y1 = Flux.batch([data[t][i][2] for t = 1:Threads.nthreads() for i = 1:length(data[t])])\n",
    "    Y2 = Flux.batch([data[t][i][3] for t = 1:Threads.nthreads() for i = 1:length(data[t])])\n",
    "    [(X, (Y1, Y2))] |> device\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ab185e90-4462-454e-9f1e-f776513e7a7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom split layer\n",
    "struct Split{T}\n",
    "    paths::T\n",
    "end\n",
    "Split(paths...) = Split(paths)\n",
    "Flux.@functor Split\n",
    "(m::Split)(x::AbstractArray) = map(f -> f(x), m.paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5406c13a-b4e4-4cad-9fa3-ba51e3e65b3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "generate_model (generic function with 1 method)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function generate_model()\n",
    "    # inputs are the user's ratings for all shows (unseen shows get mapped to zero) + implicit ratings + heterogenous features\n",
    "    # outputs are the user's ratings for all shows (unseen shows get mapped to zero), implicit ratings\n",
    "    # we will train ratings using mse on observed shows, and implicit ratings via crossentropy loss\n",
    "    encoder = Chain(\n",
    "        Dense(n_items + n_items + 3, 512, relu),\n",
    "        Dense(512, 256, relu),\n",
    "        Dense(256, 128, relu),\n",
    "    )\n",
    "    rating_decoder =\n",
    "        Chain(Dense(128, 256, relu), Dense(256, 512, relu), Dense(512, n_items))\n",
    "    implicit_decoder =\n",
    "        Chain(Dense(128, 256, relu), Dense(256, 512, relu), Dense(512, n_items))\n",
    "    m = Chain(Dropout(0.5), encoder, Split(rating_decoder, implicit_decoder)) |> device\n",
    "    m\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4988ea0-8a00-41f1-857f-6064ef3806a7",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2068c6b4-911b-400d-89ca-f7971d8de0dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "function rating_loss(ŷ, y)\n",
    "    # only compute loss on items the user has seen\n",
    "    mask = y .!= 0\n",
    "    Flux.mse(ŷ[mask], y[mask])\n",
    "end\n",
    "\n",
    "implicit_loss(ŷ, y) = Flux.logitcrossentropy(ŷ, y)\n",
    "\n",
    "function implicit_loss(ŷ, y, mask)\n",
    "    # we're predicting a held out series\n",
    "    # so we zero out items in the user's training set\n",
    "    ŷ[mask] .= -1e3\n",
    "    implicit_loss(ŷ, y)\n",
    "end\n",
    "\n",
    "function loss_components(m, x, y, train)\n",
    "    ŷ = m(x)\n",
    "    if train\n",
    "        return (rating_loss(ŷ[1], y[1]), implicit_loss(ŷ[2], y[2]))\n",
    "    else\n",
    "        mask = (x.!=0)[1:n_items, :]\n",
    "        return (rating_loss(ŷ[1], y[1]), implicit_loss(ŷ[2], y[2], mask))\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "49d99b66-1951-42d5-9922-e02785ad1b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "function reset_training()\n",
    "    global best_loss = Inf\n",
    "    global patience = 10\n",
    "    global iters_without_improvement = 0\n",
    "    global continue_training = true\n",
    "    global iters = 0\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0397c765-0d9c-44b5-bd7c-60cc9ed44d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_model(model_name, seed)\n",
    "    Random.seed!(seed)\n",
    "    m = generate_model()\n",
    "    ps = Flux.params(m)\n",
    "    reset_training()\n",
    "    BLAS.set_num_threads(Threads.nthreads())\n",
    "\n",
    "    # Setup early stopping callbacks\n",
    "    function evalcb(split, train)\n",
    "        losses = []\n",
    "        @showprogress for epoch = 1:100\n",
    "            push!(losses, loss_components(m, get_batch(split, 128, train)[1]..., train))\n",
    "        end\n",
    "        reduce(.+, losses) ./ length(losses)\n",
    "    end\n",
    "\n",
    "    function evalcb()\n",
    "        # print losses and perform early stopping\n",
    "        testmode!(m)\n",
    "        @debug \"iteration: $iters\"\n",
    "        training_losses = evalcb(training, true)\n",
    "        training_loss = sum(training_losses ./ training_baseline_loss)\n",
    "        @debug \"training losses: $(training_losses) -> $(training_loss)\"\n",
    "        inference_losses = evalcb(validation, false)\n",
    "        inference_loss = sum(inference_losses ./ inference_baseline_loss)\n",
    "        @debug \"validation losses: $(inference_losses) -> $(inference_loss)\"\n",
    "        if inference_loss < best_loss\n",
    "            global best_loss = inference_loss\n",
    "            global iters_without_improvement = 0\n",
    "            BSON.@save \"../../data/alphas/$name/model.$(model_name).bson\" m\n",
    "        else\n",
    "            global iters_without_improvement += 1\n",
    "            if iters_without_improvement >= patience\n",
    "                global continue_training = false\n",
    "            end\n",
    "        end\n",
    "        trainmode!(m)\n",
    "    end\n",
    "\n",
    "    # Setup loss\n",
    "    training_baseline_loss = evalcb(training, true)\n",
    "    inference_baseline_loss = evalcb(training, false)\n",
    "    throttled_cb = Flux.throttle(evalcb, 600)\n",
    "    opt = ADAMW(0.001, (0.9, 0.999), 1e-3)\n",
    "\n",
    "    function loss(x, y)\n",
    "        sum(loss_components(m, x, y, true) ./ training_baseline_loss)\n",
    "    end\n",
    "\n",
    "    # Train model\n",
    "    while continue_training\n",
    "        batch = get_batch(training, 128, true)\n",
    "        Flux.train!(loss, ps, batch, opt, cb = throttled_cb)\n",
    "        global iters += 1\n",
    "    end\n",
    "\n",
    "    Dict(\n",
    "        \"name\" => \"$name.$model_name\",\n",
    "        \"loss\" => best_loss,\n",
    "        \"patience\" => patience,\n",
    "        \"iters\" => iters,\n",
    "        \"model\" => \"../../data/alphas/$name/model.$(model_name).bson\",\n",
    "        \"residual_alphas\" => residual_alphas,\n",
    "        \"seed\" => seed,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdd719b-7f8b-491e-bafa-8aa56a9545e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Write predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ceec8522-af45-44ab-a398-afba5f255efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_data(u)\n",
    "    # ratings\n",
    "    X1 = collect(R[:, u])\n",
    "    # implicit ratings\n",
    "    X2 = collect(Ri[:, u])\n",
    "    # heterogeneous features\n",
    "    count = convert(Float32, max(counts[u] - 1, 0) / n_items)\n",
    "    X3 = [count, sqrt(count), count^2]\n",
    "    vcat(X1, X2, X3)\n",
    "end\n",
    "\n",
    "function get_batch(users)\n",
    "    data = [[] for j = 1:Threads.nthreads()]\n",
    "    Threads.@threads for i = 1:length(users)\n",
    "        push!(data[Threads.threadid()], get_data(users[i]))\n",
    "    end\n",
    "    X = Flux.batch([data[t][i] for t = 1:Threads.nthreads() for i = 1:length(data[t])])\n",
    "    X |> device\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3af0b836-f8dd-4a6d-b9d1-c20f1d518bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "function gmodel(m, users, items)\n",
    "    ratings = zeros(length(users))\n",
    "    implicit = zeros(length(users))\n",
    "    deduped_users = collect(Set(users))\n",
    "    batch(arr, n) = [arr[i:min(i + n - 1, end)] for i = 1:n:length(arr)]\n",
    "    batches = batch(deduped_users, 128)\n",
    "    @tprogress Threads.@threads for i = 1:length(batches)\n",
    "        b = batches[i]\n",
    "        alpha = m(get_batch(b)) |> cpu\n",
    "        user_to_idx = Dict(zip(b, 1:length(b)))\n",
    "        for j = 1:length(users)\n",
    "            if users[j] in keys(user_to_idx)\n",
    "                idx = user_to_idx[users[j]]\n",
    "                ratings[j] = alpha[1][items[j], idx]\n",
    "                implicit[j] = alpha[2][items[j], idx]\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    ratings, implicit\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9327642b-9991-44d5-ab0c-7ce6033d461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_prediction(sparse_preds, users, items)\n",
    "    preds = zeros(length(users))\n",
    "    @tprogress Threads.@threads for j = 1:length(preds)\n",
    "        preds[j] = sparse_preds[users[j], items[j]]\n",
    "    end\n",
    "    preds\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "46d999f4-f2b4-4d71-944b-754aead7de77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "save_model (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function save_model(params)\n",
    "    BSON.@load params[\"model\"] m\n",
    "    testmode!(m)\n",
    "    BLAS.set_num_threads(1) # gmodel already multithreads\n",
    "\n",
    "    full_df = reduce(cat, [training, validation, get_residuals(\"test\", residual_alphas)])\n",
    "    ratings, _ = gmodel(m, full_df.user, full_df.item)\n",
    "    sparse_preds = sparse(full_df.user, full_df.item, ratings)\n",
    "    model(users, items) = make_prediction(sparse_preds, users, items)\n",
    "\n",
    "    write_params(params, outdir = params[\"name\"])\n",
    "    write_predictions(model, residual_alphas = residual_alphas, outdir = params[\"name\"])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4670b295-b3f0-44ce-8220-958a9147f410",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220226 01:55:26 The GPU function is being called but the GPU is not accessible. \n",
      "\u001b[38;5;6m\u001b[1m└ \u001b[22m\u001b[39mDefaulting back to the CPU. (No action is required if you want to run on the CPU).\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:16\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:22\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 01:57:01 iteration: 0\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 01:57:12 training losses: (0.8532783f0, 5068.1943f0) -> 1.9878938\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:11\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 01:57:23 validation losses: (1.2928891f0, 9.8290415f0) -> 2.339808\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 02:07:42 iteration: 407\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 02:07:52 training losses: (0.84576035f0, 4161.637f0) -> 1.8013179\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 02:08:02 validation losses: (1.2674407f0, 6.49998f0) -> 1.974639\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 02:18:17 iteration: 787\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 02:18:27 training losses: (0.82801056f0, 4233.4316f0) -> 1.794728\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 02:18:37 validation losses: (1.2403048f0, 6.381114f0) -> 1.934428\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 02:28:54 iteration: 1180\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 02:29:03 training losses: (0.8328252f0, 4156.878f0) -> 1.7853196\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 02:29:12 validation losses: (1.2792398f0, 6.3647394f0) -> 1.9731\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 02:39:15 iteration: 1575\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 02:39:26 training losses: (0.8416045f0, 4042.8396f0) -> 1.773176\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 02:39:36 validation losses: (1.2705405f0, 6.369191f0) -> 1.9645401\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 02:49:39 iteration: 1960\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 02:49:49 training losses: (0.83201146f0, 4081.305f0) -> 1.7695483\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 02:49:59 validation losses: (1.2259463f0, 6.344644f0) -> 1.9158403\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 03:00:14 iteration: 2352\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 03:00:24 training losses: (0.81762487f0, 4116.8457f0) -> 1.7597642\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 03:00:34 validation losses: (1.3217957f0, 6.338871f0) -> 2.0145571\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 03:10:36 iteration: 2752\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 03:10:47 training losses: (0.8264822f0, 4104.7285f0) -> 1.767703\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 03:10:56 validation losses: (1.3082118f0, 6.3180842f0) -> 1.9983681\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 03:20:59 iteration: 3147\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 03:21:09 training losses: (0.8291838f0, 4195.853f0) -> 1.7887235\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 03:21:19 validation losses: (1.3322543f0, 6.275338f0) -> 2.018927\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 03:31:22 iteration: 3535\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 03:31:32 training losses: (0.8234955f0, 4068.046f0) -> 1.7570293\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 03:31:42 validation losses: (1.2862968f0, 6.2861924f0) -> 1.9724176\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 03:41:45 iteration: 3930\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 03:41:54 training losses: (0.81344926f0, 4116.1255f0) -> 1.7547598\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 03:42:04 validation losses: (1.3110147f0, 6.2485065f0) -> 1.9941909\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 03:52:06 iteration: 4328\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 03:52:16 training losses: (0.8121946f0, 4074.7231f0) -> 1.7451775\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 03:52:26 validation losses: (1.290233f0, 6.3067417f0) -> 1.9785869\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 04:02:27 iteration: 4726\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 04:02:38 training losses: (0.831246f0, 4023.096f0) -> 1.7572391\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 04:02:48 validation losses: (1.2802329f0, 6.2918825f0) -> 1.9667141\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 04:12:50 iteration: 5119\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 04:13:00 training losses: (0.82178587f0, 3979.42f0) -> 1.7376543\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 04:13:11 validation losses: (1.2553209f0, 6.241087f0) -> 1.9357346\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 04:23:13 iteration: 5515\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 04:23:23 training losses: (0.8002358f0, 4127.246f0) -> 1.7415519\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:09\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 04:23:33 validation losses: (1.2386041f0, 6.228283f0) -> 1.9171121\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 04:33:34 iteration: 5898\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 04:33:45 training losses: (0.8086638f0, 4050.9368f0) -> 1.7363997\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220226 04:33:55 validation losses: (1.2861022f0, 6.282872f0) -> 1.9718779\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:05\u001b[39m\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "TaskFailedException\n\n\u001b[91m    nested task error: \u001b[39mUndefVarError: m not defined\n    Stacktrace:\n     [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4mIn[16]:9\u001b[0m\u001b[90m [inlined]\u001b[39m\n     [2] \u001b[0m\u001b[1m(::var\"#989#threadsfor_fun#56\"{Vector{Int32}, Vector{Int32}, Vector{Vector{Int32}}, Vector{Float64}, Vector{Float64}, UnitRange{Int64}})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90monethread\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[35mMain\u001b[39m \u001b[90m./\u001b[39m\u001b[90;4mthreadingconstructs.jl:81\u001b[0m\n     [3] \u001b[0m\u001b[1m(::var\"#989#threadsfor_fun#56\"{Vector{Int32}, Vector{Int32}, Vector{Vector{Int32}}, Vector{Float64}, Vector{Float64}, UnitRange{Int64}})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[35mMain\u001b[39m \u001b[90m./\u001b[39m\u001b[90;4mthreadingconstructs.jl:48\u001b[0m",
     "output_type": "error",
     "traceback": [
      "TaskFailedException\n\n\u001b[91m    nested task error: \u001b[39mUndefVarError: m not defined\n    Stacktrace:\n     [1] \u001b[0m\u001b[1mmacro expansion\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[90m./\u001b[39m\u001b[90;4mIn[16]:9\u001b[0m\u001b[90m [inlined]\u001b[39m\n     [2] \u001b[0m\u001b[1m(::var\"#989#threadsfor_fun#56\"{Vector{Int32}, Vector{Int32}, Vector{Vector{Int32}}, Vector{Float64}, Vector{Float64}, UnitRange{Int64}})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[90monethread\u001b[39m::\u001b[0mBool\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[35mMain\u001b[39m \u001b[90m./\u001b[39m\u001b[90;4mthreadingconstructs.jl:81\u001b[0m\n     [3] \u001b[0m\u001b[1m(::var\"#989#threadsfor_fun#56\"{Vector{Int32}, Vector{Int32}, Vector{Vector{Int32}}, Vector{Float64}, Vector{Float64}, UnitRange{Int64}})\u001b[22m\u001b[0m\u001b[1m(\u001b[22m\u001b[0m\u001b[1m)\u001b[22m\n    \u001b[90m   @ \u001b[39m\u001b[35mMain\u001b[39m \u001b[90m./\u001b[39m\u001b[90;4mthreadingconstructs.jl:48\u001b[0m",
      "",
      "Stacktrace:",
      " [1] wait",
      "   @ ./task.jl:322 [inlined]",
      " [2] threading_run(func::Function)",
      "   @ Base.Threads ./threadingconstructs.jl:34",
      " [3] macro expansion",
      "   @ ./threadingconstructs.jl:93 [inlined]",
      " [4] macro expansion",
      "   @ ~/RecommenderSystem/notebooks/TrainingAlphas/Alpha.ipynb:In[+3]:13 [inlined]",
      " [5] gmodel(users::Vector{Int32}, items::Vector{Int32})",
      "   @ Main ./In[16]:7",
      " [6] save_model(params::Dict{String, Any})",
      "   @ Main ./In[18]:7",
      " [7] top-level scope",
      "   @ ./In[19]:3",
      " [8] eval",
      "   @ ./boot.jl:360 [inlined]",
      " [9] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base ./loading.jl:1116"
     ]
    }
   ],
   "source": [
    "seeds = hash.(rand(Int, 1))\n",
    "for i in 1:length(seeds)\n",
    "    save_model(train_model(i, seeds[i]))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f99721ec-38ea-40cf-bbb7-d2ff9128f361",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Progress: 100%|███████████████████████████| Time: 0:00:14 ( 1.53 μs/it)\n",
    "# [ Info: 20220130 13:41:55 training set: RMSE 1.0846514400339415 MAE 0.8076981570774939 R2 0.28584964713185324\n",
    "# Progress: 100%|███████████████████████████| Time: 0:00:00 ( 1.33 μs/it)\n",
    "# [ Info: 20220130 13:41:58 validation set: RMSE 1.2024856553053038 MAE 0.892453189382654 R2 0.17030444448299753\n",
    "# Progress: 100%|███████████████████████████| Time: 0:00:00 ( 1.33 μs/it)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3758ece-9b72-47b4-ae6a-aa364e0443e3",
   "metadata": {},
   "source": [
    "# Neural Network Base Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d17593ac-3260-4c01-a5df-91edfcd17e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "using Random\n",
    "using SparseArrays\n",
    "using Statistics: var\n",
    "\n",
    "import BSON\n",
    "import CUDA\n",
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "08801fd4-7057-49f0-9fa7-9854d17494cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "function device(x)\n",
    "    gpu(x)\n",
    "end\n",
    "\n",
    "# efficiently convert a sparse cpu matrix into a dense CUDA array\n",
    "function device(x::AbstractSparseArray)\n",
    "    CUDA.functional() ? CUDA.CuArray(gpu(x)) : x\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c030f566-08b7-46ad-9b69-182e559a9f89",
   "metadata": {},
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abba16e9-f406-49c4-8af1-6e0afde838c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "@with_kw struct Hyperparams\n",
    "    # model\n",
    "    implicit::Bool\n",
    "    model::String\n",
    "    # batching\n",
    "    batch_size::Int\n",
    "    input_data::String\n",
    "    user_sampling_scheme::String\n",
    "    # optimizer\n",
    "    l2penalty::Float32\n",
    "    learning_rate::Float32\n",
    "    optimizer::String\n",
    "    # training\n",
    "    patience::Int\n",
    "    seed::UInt64\n",
    "    # loss\n",
    "    item_weight_decay::Float32\n",
    "    regularization_params::Vector{Float32}\n",
    "    residual_alphas::Vector{String}\n",
    "    residual_beta::Float32\n",
    "    user_weight_decay::Float32\n",
    "end\n",
    "\n",
    "function to_dict(x::Hyperparams)\n",
    "    Dict(string(key) => getfield(x, key) for key ∈ fieldnames(Hyperparams))\n",
    "end\n",
    "\n",
    "function Base.string(x::Hyperparams)\n",
    "    if x.implicit\n",
    "        @assert 0 <= x.residual_beta && x.residual_beta <= 1\n",
    "    end\n",
    "    fields = [x for x in fieldnames(Hyperparams)]\n",
    "    max_field_size = maximum(length(string(k)) for k in fields)\n",
    "    ret = \"Hyperparameters:\\n\"\n",
    "    for f in fields\n",
    "        ret *= \"$(rpad(string(f), max_field_size)) => $(getfield(x, f))\\n\"\n",
    "    end\n",
    "    ret\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33d3fa63-a407-4e8d-86d2-b54b50e6d6ac",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bd9bcd93-0801-4944-9e44-b2b25cc16934",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A layer that takes one input and splits it into many\n",
    "struct Split{T}\n",
    "    paths::T\n",
    "end\n",
    "Split(paths...) = Split(paths)\n",
    "Flux.@functor Split\n",
    "(m::Split)(x::AbstractArray) = map(f -> f(x), m.paths)\n",
    "\n",
    "# A layer that takes many inputs and joins them into one\n",
    "Join(combine, paths) = Parallel(combine, paths)\n",
    "Join(combine, paths...) = Join(combine, paths);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "321ca69a-0b42-4859-8594-af05d93e52f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A layer that adds a 1-D vector to the input\n",
    "struct BiasLayer\n",
    "    b::Any\n",
    "end\n",
    "BiasLayer(n::Integer; init = randn) = BiasLayer(init(Float32, n))\n",
    "(m::BiasLayer)(x) = x .+ m.b\n",
    "Flux.@functor BiasLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0bf80688-1e79-420a-9710-ae82a5b8184e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implements a baseline predictor given by R[i, j] = u[i] + a[j]\n",
    "function user_item_biases()\n",
    "    U = Flux.Embedding(num_users() => 1)\n",
    "    A = BiasLayer(num_items())\n",
    "    m = Chain(U, A) |> device\n",
    "end\n",
    "\n",
    "# regularization is λ_u variance(u) + λ_a variance(a)\n",
    "function user_item_biases_regularization(m)\n",
    "    var(m[1].weight) * G.regularization_params[1] + var(m[2].b) * G.regularization_params[2]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c8db136-b854-4cf5-8e8e-8dd6fbc28081",
   "metadata": {},
   "outputs": [],
   "source": [
    "function build_model()\n",
    "    if G.model == \"user_item_biases\"\n",
    "        return user_item_biases()\n",
    "    end\n",
    "    @assert false\n",
    "end\n",
    "\n",
    "function regularization_loss(m)\n",
    "    if G.model == \"user_item_biases\"\n",
    "        return user_item_biases_regularization(m)\n",
    "    end\n",
    "    @assert false\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826b1aac-67d5-4dec-be8b-1e6c65b4d252",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1c39d34-3212-4131-8e1d-68021044fc7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function one_hot_inputs(split)\n",
    "    X = collect(1:num_users())\n",
    "    Y = sparse(get_split(split; implicit = G.implicit))\n",
    "    X, Y\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "272ebd7c-a236-4a22-b0af-17759579f995",
   "metadata": {},
   "outputs": [],
   "source": [
    "@memoize function get_epoch(split)\n",
    "    if G.input_data == \"one_hot\"\n",
    "        X, Y = one_hot_inputs(split)\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "\n",
    "    # construct residuals\n",
    "    residuals = read_alpha(G.residual_alphas, split, G.implicit)\n",
    "    residuals.rating .*= G.residual_beta\n",
    "    Z = sparse(residuals)\n",
    "\n",
    "    # construct loss-function weights\n",
    "    if split == \"training\"\n",
    "        weights =\n",
    "            expdecay(get_counts(split), G.user_weight_decay) .*\n",
    "            expdecay(get_counts(split; by_item = true), G.item_weight_decay)\n",
    "    else\n",
    "        weights = expdecay(get_counts(split), weighting_scheme(\"inverse\"))\n",
    "    end\n",
    "    W = sparse(get_split(split; implicit = G.implicit), weights)\n",
    "\n",
    "    X, Y, Z, W\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01a52cbc-01d6-487c-8293-702ef156698a",
   "metadata": {},
   "source": [
    "# Batching\n",
    "* Turns an epoch into minibatches\n",
    "* Each data point will appear in a minibatch with a probability proportional to its sampling weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aa2f87d3-1942-4abc-88ca-6b83433443c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "function SparseArrays.sparse(split::RatingsDataset)\n",
    "    sparse(split.item, split.user, split.rating, num_items(), num_users())\n",
    "end\n",
    "\n",
    "function SparseArrays.sparse(split::RatingsDataset, ratings)\n",
    "    sparse(split.item, split.user, ratings, num_items(), num_users())\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea29632c-edd2-436c-a103-54182bcb21a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "function slice(x::AbstractVector, range)\n",
    "    x[range]\n",
    "end\n",
    "\n",
    "function slice(x::AbstractMatrix, range)\n",
    "    x[:, range]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "203dd198-8047-4470-8e80-4640739dd8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_sampling_order(split)\n",
    "    weighting_scheme = split == \"training\" ? G.user_sampling_scheme : \"constant\"\n",
    "    if weighting_scheme == \"constant\"\n",
    "        return shuffle(1:num_users())\n",
    "    else\n",
    "        weights = expdecay(\n",
    "            get_counts(split; per_rating = false),\n",
    "            weighting_scheme(G.user_sampling_scheme),\n",
    "        )\n",
    "        return sample(1:num_users(), Weights(weights), num_users())\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "72f35efa-decd-42ed-bcae-f7ea7cab6a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# performs the following steps\n",
    "# 1) shuffle the epoch by the sampling order\n",
    "# 2) split the epoch into minibatches of size batch_size\n",
    "# 3) return the iter-th minibatch\n",
    "function get_batch(epoch, iter, batch_size, sampling_order)\n",
    "    sampling_order = 1:num_users()\n",
    "    range = sampling_order[(iter-1)*batch_size+1:min(iter * batch_size, num_users())]\n",
    "    process(x) = slice(x, range) |> device\n",
    "    [process.(epoch)], range\n",
    "end;\n",
    "\n",
    "function get_batch(epoch, iter, batch_size)\n",
    "    sampling_order = 1:num_users()\n",
    "    get_batch(epoch, iter, batch_size, sampling_order)\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4988ea0-8a00-41f1-857f-6064ef3806a7",
   "metadata": {},
   "source": [
    "## Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52c6be0c-9646-4495-9bc5-bfd7b87ecc73",
   "metadata": {},
   "outputs": [],
   "source": [
    "function model_loss(m, x, y, z, w)\n",
    "    p = m(x)\n",
    "    if G.implicit\n",
    "        q = softmax(p) .* G.residual_beta + z .* (1 - G.residual_beta)\n",
    "    else\n",
    "        q = p + z .* G.residual_beta\n",
    "    end\n",
    "    loss(q, y, w, G.implicit)\n",
    "end\n",
    "\n",
    "function training_loss(m, x, y, z, w)\n",
    "    model_loss(m, x, y, z, w) + regularization_loss(m)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4a6fafbb-d3c1-4e77-862f-004f11b6b7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "function split_loss(m, split)\n",
    "    epoch = get_epoch(split)\n",
    "    loss = 0\n",
    "    @showprogress for iter = 1:Int(ceil(num_users() / G.batch_size))\n",
    "        batch, _ = get_batch(epoch, iter, G.batch_size)\n",
    "        loss += model_loss(m, batch[1]...)\n",
    "    end\n",
    "    loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcaca12c-72cd-43a2-9d6f-6e04ef91f765",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "735c1cdd-01f6-49da-b0d4-241c68909355",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the preimage of the index -> split.user[index] mapping\n",
    "# this is primarily a performance optimization\n",
    "@memoize function user_to_output_indices(split)\n",
    "    users = get_split(split; implicit = G.implicit).user\n",
    "    user_to_output_idxs = [Dict() for t = 1:Threads.nthreads()]\n",
    "    @tprogress Threads.@threads for j = 1:length(users)\n",
    "        u = users[j]\n",
    "        t = Threads.threadid()\n",
    "        if u ∉ keys(user_to_output_idxs[t])\n",
    "            user_to_output_idxs[t][u] = []\n",
    "        end\n",
    "        push!(user_to_output_idxs[t][u], j)\n",
    "    end\n",
    "    merge(vcat, user_to_output_idxs...)\n",
    "end;\n",
    "\n",
    "function evaluate(m, split)\n",
    "    # get model inputs\n",
    "    user_to_output_idxs = user_to_output_indices(split)\n",
    "    df = get_split(split; implicit = G.implicit)\n",
    "    users = df.user\n",
    "    items = df.item\n",
    "    epoch = get_epoch(split)\n",
    "\n",
    "    # compute predictions    \n",
    "    batch_size = G.batch_size\n",
    "    activation = G.implicit ? softmax : identity\n",
    "    ratings = zeros(Float32, length(users))\n",
    "    @showprogress for iter = 1:Int(ceil(num_users() / batch_size))\n",
    "        batch, sampled_users = get_batch(epoch, iter, batch_size)\n",
    "        alpha = activation(m(batch[1][1])) |> cpu\n",
    "\n",
    "        for j = 1:length(sampled_users)\n",
    "            u = sampled_users[j]\n",
    "            if u in keys(user_to_output_idxs)\n",
    "                for output_idx in user_to_output_idxs[u]\n",
    "                    ratings[output_idx] = alpha[items[output_idx], j]\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "\n",
    "    RatingsDataset(user = users, item = items, rating = ratings)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc2f56ca-4dd2-4fc3-956f-cd345f2f788f",
   "metadata": {},
   "outputs": [],
   "source": [
    "function snapshot_loss(m)\n",
    "    split_loss(m, \"training\"), split_loss(m, \"validation\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c791e6dc-8d74-4004-8dd7-6a87d6599434",
   "metadata": {},
   "outputs": [],
   "source": [
    "function checkpoint(m)\n",
    "    training_loss, validation_loss = snapshot_loss(m)\n",
    "    @info \"training loss $training_loss, validation loss $validation_loss\"\n",
    "    validation_loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2503872c-79e8-405c-acbb-518416c5c360",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dd02cc13-2680-4297-a746-784faaba3a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "function continue_training(m, opt, stop_criteria, model_path)\n",
    "    validation_loss = checkpoint(m)\n",
    "    if validation_loss < stop_criteria.loss\n",
    "        BSON.@save model_path m opt\n",
    "    end\n",
    "    !stop!(stop_criteria, validation_loss)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d61e7743-4bc9-4f75-a38d-b5e02ed1e516",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_epoch!(m, opt; checkpoint_rate = Inf)\n",
    "    LinearAlgebra.BLAS.set_num_threads(Threads.nthreads())\n",
    "    ps = Flux.params(m)\n",
    "    epoch = get_epoch(\"training\")\n",
    "    sampling_order = get_sampling_order(\"training\")\n",
    "    batchloss(x, y, z, w) = training_loss(m, x, y, z, w)\n",
    "\n",
    "    nbatches = Int(ceil(length(sampling_order) / G.batch_size))\n",
    "    @showprogress for iter = 1:nbatches\n",
    "        batch, _ = get_batch(epoch, iter, G.batch_size, sampling_order)\n",
    "        Flux.train!(batchloss, ps, batch, opt)\n",
    "\n",
    "        if iter % checkpoint_rate == 0\n",
    "            checkpoint(m)\n",
    "        end\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b4ade3b7-52e5-4b22-9337-694708eb76d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function train_model(hyperparams::Hyperparams)\n",
    "    # unpack parameters\n",
    "    global G = hyperparams\n",
    "    Random.seed!(G.seed)\n",
    "    m = build_model()\n",
    "    if G.optimizer == \"ADAM\"\n",
    "        opt = ADAMW(G.learning_rate, (0.9, 0.999), G.l2penalty)\n",
    "    else\n",
    "        @assert false\n",
    "    end\n",
    "    stop_criteria = early_stopper(patience = G.patience)\n",
    "    model_path = \"../../data/alphas/$name/model.$(hash(G)).bson\"\n",
    "\n",
    "    # Train model\n",
    "    train_epoch!(m, opt)\n",
    "    while continue_training(m, opt, stop_criteria, model_path)\n",
    "        train_epoch!(m, opt)\n",
    "    end\n",
    "\n",
    "    model_path\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9ec5fc00-e357-4789-8d7a-4b011db000ba",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "hyp = Hyperparams(\n",
    "    # model\n",
    "    implicit = false,\n",
    "    model = \"user_item_biases\",\n",
    "    # batching\n",
    "    batch_size = 128,\n",
    "    input_data = \"one_hot\",\n",
    "    user_sampling_scheme = \"constant\",\n",
    "    # optimizer\n",
    "    l2penalty = 0,\n",
    "    learning_rate = 0.001,\n",
    "    optimizer = \"ADAM\",\n",
    "    # training\n",
    "    patience = 100000,\n",
    "    seed = 20220524,\n",
    "    # loss\n",
    "    item_weight_decay = 0,\n",
    "    regularization_params = Float32[0, 0],\n",
    "    residual_alphas = [],\n",
    "    residual_beta = 0,\n",
    "    user_weight_decay = 0,\n",
    ");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c8132266-aa18-496c-943d-dc58445ec5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "G = hyp\n",
    "m = build_model();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e6132061-f4a8-4baa-bad5-0b5379dd874b",
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ADAM();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7d839185-f43e-458f-8f40-4ffdb0b75f1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:01 ( 1.40 μs/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 (33.11 ns/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 (30.20 ns/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "epoch = get_epoch(\"training\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "965232b6-abbb-4e7d-9db3-f11cd5a867be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:02:50\u001b[39m:07\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "176.285394 seconds (224.32 M allocations: 15.359 GiB, 7.24% gc time, 58.07% compilation time)\n"
     ]
    }
   ],
   "source": [
    "@time train_epoch!(m, opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9adb2994-f96a-4ef4-bc18-0b5fc09dd8c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:16\u001b[39m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16.466511 seconds (11.28 M allocations: 3.983 GiB, 14.79% gc time, 16.40% compilation time)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48495.31f0"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@time split_loss(m, \"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "54195aff-a4ad-4e18-b18f-876b1d678e10",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:34\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:13\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:34\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:13\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:34\u001b[39m\n",
      "\u001b[32mProgress:  24%|█████████▊                               |  ETA: 0:00:10\u001b[39m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 34.450639 seconds (31.66 M allocations: 5.222 GiB, 8.16% gc time)\n",
      " 13.217715 seconds (6.68 M allocations: 3.740 GiB, 12.45% gc time)\n",
      " 34.101590 seconds (31.67 M allocations: 5.222 GiB, 8.04% gc time)\n",
      " 13.206094 seconds (6.67 M allocations: 3.740 GiB, 12.44% gc time)\n",
      " 34.401832 seconds (31.67 M allocations: 5.222 GiB, 8.11% gc time)\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "InterruptException:",
     "output_type": "error",
     "traceback": [
      "InterruptException:",
      "",
      "Stacktrace:",
      "  [1] process_events",
      "    @ ./libuv.jl:104 [inlined]",
      "  [2] wait()",
      "    @ Base ./task.jl:838",
      "  [3] yield()",
      "    @ Base ./task.jl:721",
      "  [4] nonblocking_synchronize",
      "    @ ~/.julia/packages/CUDA/GGwVa/lib/cudadrv/stream.jl:150 [inlined]",
      "  [5] (::CUDA.var\"#185#186\"{Float32, Vector{Float32}, Int64, CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, Int64, Int64})()",
      "    @ CUDA ~/.julia/packages/CUDA/GGwVa/src/array.jl:410",
      "  [6] #context!#63",
      "    @ ~/.julia/packages/CUDA/GGwVa/lib/cudadrv/state.jl:164 [inlined]",
      "  [7] context!",
      "    @ ~/.julia/packages/CUDA/GGwVa/lib/cudadrv/state.jl:161 [inlined]",
      "  [8] unsafe_copyto!(dest::Vector{Float32}, doffs::Int64, src::CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, soffs::Int64, n::Int64)",
      "    @ CUDA ~/.julia/packages/CUDA/GGwVa/src/array.jl:406",
      "  [9] copyto!",
      "    @ ~/.julia/packages/CUDA/GGwVa/src/array.jl:360 [inlined]",
      " [10] getindex",
      "    @ ~/.julia/packages/GPUArrays/Zecv7/src/host/indexing.jl:89 [inlined]",
      " [11] #25",
      "    @ ~/.julia/packages/GPUArrays/Zecv7/src/host/indexing.jl:75 [inlined]",
      " [12] task_local_storage(body::GPUArrays.var\"#25#28\"{CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, key::Symbol, val::Bool)",
      "    @ Base ./task.jl:281",
      " [13] macro expansion",
      "    @ ~/.julia/packages/GPUArrays/Zecv7/src/host/indexing.jl:74 [inlined]",
      " [14] _mapreduce(f::typeof(identity), op::typeof(Base.add_sum), As::CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}; dims::Colon, init::Nothing)",
      "    @ GPUArrays ~/.julia/packages/GPUArrays/Zecv7/src/host/mapreduce.jl:73",
      " [15] #mapreduce#20",
      "    @ ~/.julia/packages/GPUArrays/Zecv7/src/host/mapreduce.jl:31 [inlined]",
      " [16] mapreduce",
      "    @ ~/.julia/packages/GPUArrays/Zecv7/src/host/mapreduce.jl:31 [inlined]",
      " [17] #_sum#735",
      "    @ ./reducedim.jl:894 [inlined]",
      " [18] _sum",
      "    @ ./reducedim.jl:894 [inlined]",
      " [19] #_sum#734",
      "    @ ./reducedim.jl:893 [inlined]",
      " [20] _sum",
      "    @ ./reducedim.jl:893 [inlined]",
      " [21] #sum#732",
      "    @ ./reducedim.jl:889 [inlined]",
      " [22] sum",
      "    @ ./reducedim.jl:889 [inlined]",
      " [23] weighted_loss(x::CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, y::CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, w::CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, lossfn::var\"#40#42\")",
      "    @ Main ~/RecommenderSystem/notebooks/TrainingAlphas/Alpha.ipynb:In[10]:12",
      " [24] #loss#38",
      "    @ ~/RecommenderSystem/notebooks/TrainingAlphas/Alpha.ipynb:In[10]:30 [inlined]",
      " [25] loss(x::CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, y::CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, w::CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, implicit::Bool)",
      "    @ Main ~/RecommenderSystem/notebooks/TrainingAlphas/Alpha.ipynb:In[10]:28",
      " [26] model_loss(m::Chain{Tuple{Flux.Embedding{CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, BiasLayer}}, x::CUDA.CuArray{Int64, 1, CUDA.Mem.DeviceBuffer}, y::CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, z::CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}, w::CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer})",
      "    @ Main ./In[14]:8",
      " [27] macro expansion",
      "    @ ./In[15]:6 [inlined]",
      " [28] macro expansion",
      "    @ ~/.julia/packages/ProgressMeter/sN2xr/src/ProgressMeter.jl:938 [inlined]",
      " [29] split_loss(m::Chain{Tuple{Flux.Embedding{CUDA.CuArray{Float32, 2, CUDA.Mem.DeviceBuffer}}, BiasLayer}}, split::String)",
      "    @ Main ./In[15]:4",
      " [30] macro expansion",
      "    @ ./timing.jl:220 [inlined]",
      " [31] top-level scope",
      "    @ ./In[28]:3",
      " [32] eval",
      "    @ ./boot.jl:373 [inlined]",
      " [33] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base ./loading.jl:1196"
     ]
    }
   ],
   "source": [
    "for i in 1:100\n",
    "    @time train_epoch!(m, opt)\n",
    "    @time split_loss(m, \"training\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9cb77551-12e3-4677-9fde-bb3fb09b7668",
   "metadata": {},
   "outputs": [],
   "source": [
    "#using BenchmarkTools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c212ba93-b27a-4da5-abe2-234426f9637c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ProgressMeter.@showprogress for j = 1:10\n",
    "#     train_epoch!(m, opt)\n",
    "#     @info split_loss(m, \"training\")\n",
    "# end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7d53da21-b0d6-467a-9028-8f1c9745d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split_loss(m, \"validation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "85d76ef5-0654-448e-9080-5f3dcd553d66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_model(hyp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbdd719b-7f8b-491e-bafa-8aa56a9545e3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Write predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9327642b-9991-44d5-ab0c-7ce6033d461d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function make_prediction(sparse_preds, users, items)\n",
    "#     preds = zeros(length(users))\n",
    "#     @tprogress Threads.@threads for j = 1:length(preds)\n",
    "#         preds[j] = sparse_preds[users[j], items[j]]\n",
    "#     end\n",
    "#     preds\n",
    "# end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "46d999f4-f2b4-4d71-944b-754aead7de77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function save_model(model_path, hyperparams::Hyperparams, outdir)\n",
    "#     global G = hyperparams\n",
    "#     BSON.@load model_path m\n",
    "#     training = evaluate(m, \"training\")\n",
    "#     validation = evaluate(m, \"validation\")\n",
    "#     test = evaluate(m, \"test\")\n",
    "#     df = reduce(cat, [training, validation, test])\n",
    "#     sparse_preds = sparse(df.user, df.item, df.rating)\n",
    "\n",
    "#     write_predictions(\n",
    "#         (users, items) -> make_prediction(sparse_preds, users, items),\n",
    "#         residual_alphas = G.validation_residuals,\n",
    "#         outdir = outdir,\n",
    "#         implicit = G.train_implicit_model,\n",
    "#     )\n",
    "#     params = to_dict(G)\n",
    "#     params[\"model\"] = model_path\n",
    "#     write_params(params, outdir = outdir)\n",
    "# end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c26b887e-756b-440e-bbd6-b2842fd184b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function fit(hyperparams::Hyperparams, outdir)\n",
    "#     redirect_logging(\"../../data/alphas/$outdir\")\n",
    "#     @info string(hyperparams)\n",
    "#     model_path = train_model(hyperparams)\n",
    "#     save_model(model_path, hyperparams, outdir)\n",
    "# end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "252b8c25-eaca-43e2-8992-3d8a1ae37409",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# hyperparams = Hyperparams(\n",
    "#     use_derived_features = true,\n",
    "#     train_implicit_model = true,\n",
    "#     activation = \"relu\",\n",
    "#     autoencode = true,\n",
    "#     batch_size = 128,\n",
    "#     dropout_perc = 0.5,\n",
    "#     dropout_rescale = false,\n",
    "#     layers = [512, 256, 128, 256, 512],\n",
    "#     l2penalty = 1e-5,\n",
    "#     learning_rate = 0.001,\n",
    "#     optimizer = \"ADAM\",\n",
    "#     patience = 10,\n",
    "#     sampling_weight_scheme = \"linear\",\n",
    "#     training_residuals = [\"UserItemBiases\"],\n",
    "#     training_weight_scheme = \"linear\",\n",
    "#     use_residualized_validation_loss = false,\n",
    "#     validation_residuals = [\"UserItemBiases\"],\n",
    "#     validation_weight_scheme = \"constant\",\n",
    "#     seed = 20220501 * hash(name),\n",
    "# )\n",
    "\n",
    "# #fit(hyperparams, \"GNN.Rating.Test.2\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.2",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3758ece-9b72-47b4-ae6a-aa364e0443e3",
   "metadata": {},
   "source": [
    "# Matrix Factorization\n",
    "* Prediction is $\\tilde R = UA^T$ \n",
    "* Loss fuction is $L = \\lVert (R - \\tilde R)^\\Omega \\rVert _2^2 + \\lambda_u \\lVert U \\rVert _2^2 + \\lambda_a \\lVert A \\rVert _2^2$\n",
    "* $\\Omega$ is the set of oberved pairs $(i, j)$\n",
    "* $M^\\Omega$ is the projection of $M$ onto $\\Omega$ for any matrix $M$, that is $M_{ij}^\\Omega$ is defined to be $M_{ij}$ when $(i, j) \\in \\Omega$ and $0$ otherwise\n",
    "* $U$ is an $m x k$ matrix, $A$ is an $n x k$ matrix and $R$ is the $m x n$ ratings matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7cc9334a-2287-41d6-885b-a5cca94fe263",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14-element Vector{String}:\n",
       " \"UserItemBiases\"\n",
       " \"ItemCF.16\"\n",
       " \"ItemCF.64\"\n",
       " \"ItemCF.256\"\n",
       " \"ItemCF.1024\"\n",
       " \"ItemCFResid.16\"\n",
       " \"ItemCFResid.64\"\n",
       " \"ItemCFResid.256\"\n",
       " \"ItemCFResid.1024\"\n",
       " \"MatrixFactorization.10\"\n",
       " \"MatrixFactorization.20\"\n",
       " \"MatrixFactorization.40\"\n",
       " \"ItemCFRelated.all\"\n",
       " \"ItemCFEmbed.1024\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "name = \"MatrixFactorizationGenre\";\n",
    "# residual_alphas = [\"UserItemBiases\"];\n",
    "downcast_to_int(x) = isinteger(x) ? Int(x) : x\n",
    "residual_alphas = [\n",
    "    [\"UserItemBiases\"]\n",
    "    [\"ItemCF.$K\" for K in downcast_to_int.([2^4, 2^6, 2^8, 2^10])]\n",
    "    [\"ItemCFResid.$K\" for K in downcast_to_int.([2^4, 2^6, 2^8, 2^10])]\n",
    "    [\"MatrixFactorization.$K\" for K in downcast_to_int.([10, 20, 40])]\n",
    "    [\"ItemCFRelated.$name\" for name in [\"all\"]]\n",
    "    # [\"UserCF.1024\"]\n",
    "    [\"ItemCFEmbed.1024\"] # 0.12%\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54170f91-c85c-4207-9939-572cad4db024",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d17593ac-3260-4c01-a5df-91edfcd17e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "using NBInclude\n",
    "@nbinclude(\"Alpha.ipynb\");\n",
    "@nbinclude(\"XGBoostFeatures.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "eb458301-7baa-4bd1-88c1-bd8c9193bebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "const training = get_residuals(\"training\", residual_alphas)\n",
    "const validation = get_residuals(\"validation\", residual_alphas);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f52a69-0231-4bff-8a9f-26bb16ee9f33",
   "metadata": {},
   "source": [
    "# Alternating Least Squares Algorithm\n",
    "* $u_{ik} = \\dfrac{\\sum_{j \\in \\Omega_i}(r_{ij} - \\tilde r_{ij} + u_{ik}a_{kj})}{\\sum_{j \\in \\Omega_i} a_j^2 + \\lambda_u}$\n",
    "* $\\Omega$ is the set of (user, item) pairs that we have ratings for\n",
    "* $\\Omega_i$ is subset of $\\Omega$ for which the user is the $i$-th user\n",
    "* Note that this equation is equivalent to solving $A^{\\Omega_i} u_i = R^{\\Omega_i}$ with $L_2$ regularization $\\lambda_u$, where $\\Omega_i = \\{(i', j) \\in \\Omega | i' = i \\}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c9e3f1ca-34cc-48b6-8c28-7deb35939858",
   "metadata": {},
   "outputs": [],
   "source": [
    "function make_prediction(users, items, U, A)\n",
    "    r = zeros(eltype(U), length(users))\n",
    "    @views Threads.@threads for i = 1:length(r)\n",
    "        if (users[i] <= size(U)[1]) && (items[i] <= size(A)[1])\n",
    "            r[i] = dot(U[users[i], :], A[items[i], :])\n",
    "        end\n",
    "    end\n",
    "    r\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c27971b0-684c-49b5-8c12-bb6666664f81",
   "metadata": {},
   "outputs": [],
   "source": [
    "function calc_loss(df, U, A)\n",
    "    truth = df.rating\n",
    "    pred = make_prediction(df.user, df.item, U, A)\n",
    "    β = pred \\ truth\n",
    "    loss = mse(truth, pred .* β)\n",
    "    @debug \"loss: $loss β: $β\"\n",
    "    loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "04463bd7-c9df-4866-b929-c6217b38e0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "function ridge_regression(X, y, λ)\n",
    "    (Matrix(X'X) + λ * I(size(X)[2])) \\ Vector(X'y)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea373a98-e714-4083-8cfc-dddc4dd2c91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# julia matrices are column major by default so we take adjoints to make them row major\n",
    "@memoize function sparse_csr(i, j, v, m, n)\n",
    "    sparse(j, i, v, n, m)'\n",
    "end;\n",
    "\n",
    "@memoize function gaussian_init_csr(source, K, el_type)\n",
    "    Random.seed!(20211204 * hash(source) * K)\n",
    "    (zeros(el_type, K, maximum(source)) + randn(K, maximum(source)) * K^(-1 / 4))'\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a9094b8d-eea5-4ecd-b743-a7a245d3f281",
   "metadata": {},
   "outputs": [],
   "source": [
    "function sparse_subset(A, rows)\n",
    "    # returns a sparse matrix B such that: \n",
    "    # size(B) == size(A), B[rows, :] == A[rows, :], and B[~rows, :] == 0\n",
    "    K = size(A)[2]\n",
    "    nzval = vec(A[rows, :])\n",
    "    rowval = repeat(rows, K)\n",
    "    colptr = [1 + (x - 1) * length(rows) for x = 1:K+1]\n",
    "    SparseMatrixCSC(size(A)..., colptr, rowval, nzval)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c2e8700-dfa0-421a-b833-1fb40f47566a",
   "metadata": {},
   "outputs": [],
   "source": [
    "function update_users!(users, items, ratings, U, A, λ_u)\n",
    "    R = sparse_csr(users, items, ratings, size(U)[1], size(A)[1])\n",
    "    @tprogress Threads.@threads for i = 1:size(U)[1]\n",
    "        X = sparse_subset(A, rowvals(R[i, :]))\n",
    "        y = R[i, :]\n",
    "        U[i, :] = ridge_regression(X, y, λ_u)\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0371f61-27bf-4f52-b822-d060f7be01b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:02 ( 2.16 ms/it)\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "const A = genre_embedding()\n",
    "const K = size(A)[2]\n",
    "\n",
    "function train_model(training, validation, λ_u, stop_criteria)\n",
    "    @debug \"training model with parameters [$λ_u]\"\n",
    "    users, items, ratings = training.user, training.item, training.rating\n",
    "    U = copy(gaussian_init_csr(users, K, eltype(λ_u)))\n",
    "    loss = Inf\n",
    "\n",
    "    while !stop!(stop_criteria, loss)\n",
    "        update_users!(users, items, ratings, U, A, λ_u)\n",
    "        calc_loss(training, U, A)\n",
    "        loss = calc_loss(validation, U, A)\n",
    "    end\n",
    "    U, A, loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d44f0871-3bb4-4083-8bdb-3cb53233298c",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1a09d0ba-09cb-48c3-84b0-d0eb57d1e0f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "function validation_mse(λ)\n",
    "    λ = exp.(λ) # ensure λ is nonnegative\n",
    "    # stop early so we can spend more computation exploring the parameter space\n",
    "    stop_criteria = early_stopper(max_iters = 1)\n",
    "    U, A, loss = train_model(training, validation, λ..., stop_criteria)\n",
    "    loss\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b672be0c-bb3c-47f5-af74-d91fbdcd55b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "function optimize_model()\n",
    "    # Find the best regularization hyperparameters\n",
    "    res = optimize(\n",
    "        λ -> validation_mse(λ),\n",
    "        [1.0],\n",
    "        LBFGS(),\n",
    "        autodiff = :forward,\n",
    "        Optim.Options(show_trace = true, extended_trace = true),\n",
    "    )\n",
    "    λ = exp.(Optim.minimizer(res))\n",
    "    @info \"The optimal [λ_u] is $λ, found in \" *\n",
    "          repr(Optim.f_calls(res)) *\n",
    "          \" function calls\"\n",
    "\n",
    "    # train model\n",
    "    stop_criteria =\n",
    "        early_stopper(max_iters = 100, patience = 5, min_rel_improvement = 0.0001)\n",
    "    U, A, loss = train_model(training, validation, λ..., stop_criteria)\n",
    "\n",
    "    # save model\n",
    "    outdir = \"$name.$K\"\n",
    "    model(users, items) = make_prediction(users, items, U, A)\n",
    "    write_predictions(model, outdir = outdir, save_training = true)\n",
    "    write_params(\n",
    "        Dict(\"U\" => U, \"A\" => A, \"λ\" => λ, \"K\" => K, \"residual_alphas\" => residual_alphas),\n",
    "        outdir = outdir,\n",
    "    )\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19bcd5ef-10d1-48a8-9db0-49a07f64c0a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220107 14:14:38 training model with parameters [Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(2.718281828459045,2.718281828459045)]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:01:11 ( 2.54 ms/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220107 14:15:55 loss: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(0.8786093359726957,0.020388291095571293) β: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(1.3980502802576982,0.2103072726307749)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220107 14:15:56 loss: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(1.1941826256190053,-9.35899760091501e-5) β: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(0.053890205787598615,0.023710932612840033)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter     Function value   Gradient norm \n",
      "     0     1.194183e+00     9.358998e-05\n",
      " * Current step size: 1.0\n",
      " * time: 5.1975250244140625e-5\n",
      " * g(x): [-9.35899760091501e-5]\n",
      " * x: [1.0]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220107 14:15:56 training model with parameters [Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(2.7185362442953567,2.7185362442953567)]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:01:09 ( 2.46 ms/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220107 14:17:10 loss: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(0.8786112441406648,0.020388895743581974) β: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(1.3980699633358216,0.2103163848375754)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220107 14:17:11 loss: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(1.1941826168597511,-9.359361578860486e-5) β: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(0.053892424956163025,0.02371227784926389)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220107 14:17:11 training model with parameters [Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(2.719554145781755,2.719554145781755)]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:01:09 ( 2.46 ms/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220107 14:18:25 loss: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(0.8786188773784015,0.020391314122711793) β: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(1.3981487041811538,0.21035283808400873)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220107 14:18:26 loss: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(1.1941825818193286,-9.360817601315434e-5) β: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(0.053901302889549536,0.02371765967493991)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220107 14:18:26 training model with parameters [Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(2.724649373061279,2.724649373061279)]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:01:09 ( 2.46 ms/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220107 14:19:40 loss: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(0.8786570571437385,0.020403400904573175) β: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(1.3985426131773688,0.21053521042176343)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220107 14:19:41 loss: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(1.1941824065354374,-9.368100370023225e-5) β: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(0.05394572279206713,0.023744589936320244)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220107 14:19:41 training model with parameters [Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(2.7502690602989115,2.7502690602989115)]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:01:09 ( 2.46 ms/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220107 14:20:54 loss: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(0.8788482948909222,0.020463706489330526) β: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(1.4005172877442233,0.21144973143993895)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220107 14:20:55 loss: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(1.1941815280689179,-9.40458065867535e-5) β: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(0.054168580242880036,0.023879771223762267)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220107 14:20:55 training model with parameters [Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(2.8820266223915767,2.8820266223915767)]\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:01:11 ( 2.52 ms/it)\u001b[39m\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220107 14:22:09 loss: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(0.8798128937901742,0.020761966925320473) β: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(1.4105201974528043,0.21608966108604313)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220107 14:22:10 loss: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(1.194177084237925,-9.588647214167837e-5) β: Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(0.055302075023933146,0.02456913649317723)\n",
      "\u001b[38;5;4m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;4m\u001b[1mDebug: \u001b[22m\u001b[39m20220107 14:22:10 training model with parameters [Dual{ForwardDiff.Tag{var\"#53#54\", Float64}}(3.6417658040700287,3.6417658040700287)]\n",
      "\u001b[32mProgress:  33%|████████▉                  |  ETA: 0:00:48 ( 2.51 ms/it)\u001b[39m"
     ]
    }
   ],
   "source": [
    "optimize_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21e91df6-cca6-489a-8515-6e8e68a0b770",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

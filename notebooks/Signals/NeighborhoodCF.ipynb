{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neighborhood-based Collaborative Filtering\n",
    "* Implements Item-Item and User-User Collaborative Filtering\n",
    "* See [Item-Based Collaborative Filtering Recommendation Algorithms](http://www.ra.ethz.ch/cdstore/www10/papers/pdf/p519.pdf) and [An Empirical Analysis of Design Choices in Neighborhood-Based Collaborative Filtering Algorithms](https://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.586.3847&rep=rep1&type=pdf)\n",
    "* For a given user, we compute:\n",
    "  1) A predicted score and variance for each item they have not rated\n",
    "  2) The leave-one-out-cross-validation prediction for each item they have rated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO read these hyperparameters from a file\n",
    "# Change this to get recommendations for a different user\n",
    "recommendee = \"Fro116\"\n",
    "\n",
    "# parameters chosen by cross-validation\n",
    "item_neighborhood_size = 724\n",
    "item_nonneg_corrs = True\n",
    "user_neighborhood_size = 11585\n",
    "user_nonneg_corrs = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = f\"../../data/recommendations/{recommendee}\"\n",
    "os.chdir(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pickle.load(open(\"../../processed_data/user_anime_lists.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace ratings in the database with the updated list\n",
    "user_df = pickle.load(open(\"user_anime_list.pkl\", \"rb\"))\n",
    "df = pd.concat([df.loc[lambda x: ~x.username.isin(user_df.username)], user_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.set_index('username')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta(score):\n",
    "    return score.groupby(\"anime_id\").apply(\n",
    "        lambda x: np.dot(x[\"score\"], x[\"corr\"]) / x[\"corr\"].abs().sum()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_variance(score):\n",
    "    # The following formulae are used to compute the variance of delta. Delta\n",
    "    # is a weighted sum of the form δ = Σ(s_i * w_i) / (Σw_i), where s_i is\n",
    "    # a vector scores and w_i is the weight.\n",
    "    #\n",
    "    # By linearity, it suffices to compute (s_i * w_i) / (Σw_i).\n",
    "    # The variance for (w_i) / (Σw_i) can be estimated by doing a Taylor Approximation.\n",
    "    # See equation 20 of https://www.stat.cmu.edu/~hseltman/files/ratio.pdf. The\n",
    "    # formula for the ratio of two correlated variables R,S is\n",
    "    # Var(R/S) = E[R]^2/E[S]^2(Var[R]/E[R]^2 - 2Cov(R,S)/(E[R]E[S]) + Var[S]/E[S]^2)\n",
    "    #\n",
    "    # Lastly we take the product distribution of s_i and (w_i) / (Σw_i).\n",
    "    def correction_factor(x):\n",
    "        return (\n",
    "            1\n",
    "            + x[\"corr_var\"] / (x[\"corr\"] ** 2)\n",
    "            - 2 * x[\"corr_var\"] / (x[\"corr\"].abs().sum() * x[\"corr\"].abs())\n",
    "            + x[\"corr_var\"].sum() / (x[\"corr\"].abs().sum() ** 2)\n",
    "        )\n",
    "\n",
    "    delta_var = score.groupby(\"anime_id\").apply(\n",
    "        lambda x: np.sum(\n",
    "            x[\"score_var\"] * x[\"corr\"] ** 2 * correction_factor(x)\n",
    "        )\n",
    "        / (x[\"corr\"].abs().sum() ** 2)\n",
    "    )\n",
    "\n",
    "    # if the var < 0, then the ratio distribution approximation failed,\n",
    "    # usually because sample size is too small\n",
    "    delta_var.loc[lambda x: x < 0] = np.inf\n",
    "\n",
    "    # Apply a bessel-like correction to unbias the variance\n",
    "    effective_sample_size = score.groupby(\"anime_id\")[\"effective_sample_size\"].median()\n",
    "    delta_var.loc[effective_sample_size <= 1] = np.inf\n",
    "    delta_var.loc[effective_sample_size > 1] *= effective_sample_size / (\n",
    "        effective_sample_size - 1\n",
    "    )\n",
    "\n",
    "    return delta_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deltas(is_df, anime_ids, recommendee, neighborhood_size, score_fn):\n",
    "    # get the neighborhood for each item\n",
    "    score = score_fn(is_df, recommendee, neighborhood_size)\n",
    "\n",
    "    # extract model features\n",
    "    pred_df = pd.DataFrame()\n",
    "    pred_df[\"delta\"] = get_delta(score)\n",
    "    pred_df[\"delta_var\"] = get_delta_variance(score)\n",
    "    pred_df = pred_df.loc[lambda x: x.index.isin(anime_ids)]\n",
    "\n",
    "    # fill in missing predictions with nan\n",
    "    for anime_id in set(anime_ids) - set(pred_df.index):\n",
    "        pred_df = pred_df.append(pd.Series(name=anime_id, dtype=float))\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache()\n",
    "def get_item_corrs():\n",
    "    corrs = pickle.load(open(\"../../processed_data/item_correlations.pkl\", \"rb\"))\n",
    "    if item_nonneg_corrs:\n",
    "        corrs[\"similarity\"] = corrs[\"corr\"]\n",
    "    else:\n",
    "        corrs[\"similarity\"] = corrs[\"corr\"].abs()\n",
    "    corrs = corrs.dropna()\n",
    "    corrs = corrs.loc[\n",
    "        lambda x: x.index.get_level_values(\"anime_id_x\")\n",
    "        != x.index.get_level_values(\"anime_id_y\")\n",
    "    ]\n",
    "    corrs = corrs.sort_values(by=\"similarity\")\n",
    "    return corrs\n",
    "\n",
    "\n",
    "def get_item_scores(df, recommendee, neighborhood_size):\n",
    "    corrs = get_item_corrs()\n",
    "    corrs = corrs.groupby(\"anime_id_x\").tail(neighborhood_size)\n",
    "    score = df.loc[recommendee].merge(\n",
    "        corrs.reset_index(\"anime_id_x\"), left_on=\"anime_id\", right_on=\"anime_id_y\",\n",
    "    )\n",
    "    score = score.drop(\"anime_id\", axis=1).rename({\"anime_id_x\": \"anime_id\"}, axis=1)\n",
    "\n",
    "    weights = score.groupby(\"anime_id\").apply(lambda x: x[\"corr\"].abs().sum())\n",
    "    average_weight = corrs.groupby(\"anime_id_x\").apply(lambda x: x[\"corr\"].abs().mean())\n",
    "    average_weight.index.rename(\"anime_id\", inplace=True)\n",
    "    effective_sample_size = pd.DataFrame(weights / average_weight).rename(\n",
    "        {0: \"effective_sample_size\"}, axis=1\n",
    "    )\n",
    "    score = score.merge(effective_sample_size, on=\"anime_id\")\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_corrs(df, recommendee):\n",
    "    user_subset = df.loc[[recommendee]].merge(df.reset_index(), on=\"anime_id\")\n",
    "    corr_numerator = user_subset.groupby(\"username\").apply(\n",
    "        lambda x: np.dot(x[\"score_x\"], x[\"score_y\"])\n",
    "    )\n",
    "    corr_denom = df.groupby(\"username\").apply(\n",
    "        lambda x: np.sqrt(np.dot(x[\"score\"], x[\"score\"]))\n",
    "    )\n",
    "    corr_denom *= corr_denom.loc[recommendee]\n",
    "    corrs = pd.DataFrame((corr_numerator / corr_denom), columns=[\"corr\"])\n",
    "    if user_nonneg_corrs:\n",
    "        corrs[\"similarity\"] = corrs[\"corr\"]\n",
    "    else:\n",
    "        corrs[\"similarity\"] = corrs[\"corr\"].abs()\n",
    "    corrs[\"corr_size\"] = user_subset.groupby(\"username\").size()\n",
    "    corrs = corrs.drop(recommendee)\n",
    "    corrs = corrs.dropna()\n",
    "    return corrs\n",
    "\n",
    "\n",
    "def get_user_scores(df, recommendee, neighborhood_size):\n",
    "    corrs = get_user_corrs(df, recommendee)\n",
    "\n",
    "    # We assume variance is the same as the variance for pearson correlation.\n",
    "    # see https://www.jstor.org/stable/2277400?seq=1\n",
    "    corrs = corrs.loc[lambda x: x[\"corr_size\"] > 2]\n",
    "    corrs[\"corr_var\"] = (1 - corrs[\"corr\"] * corrs[\"corr\"]) ** 2 / (\n",
    "        corrs[\"corr_size\"] - 2\n",
    "    )\n",
    "    corrs = corrs.sort_values(by=\"similarity\").dropna()[-neighborhood_size:]\n",
    "\n",
    "    score = (df.merge(pd.DataFrame(corrs), on=\"username\")).dropna()\n",
    "\n",
    "    weights = score.groupby(\"anime_id\").apply(lambda x: x[\"corr\"].abs().sum())\n",
    "    average_weight = corrs[\"corr\"].abs().mean()\n",
    "    effective_sample_size = pd.DataFrame(weights / average_weight).rename(\n",
    "        {0: \"effective_sample_size\"}, axis=1\n",
    "    )\n",
    "    score = score.merge(effective_sample_size, on=\"anime_id\")\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_deltas(df, recommendee, neighborhood_size, score_fn, signal_name):\n",
    "    # compute out-of-sample deltas\n",
    "    oos_pred_dfs = []\n",
    "    K = len(df.loc[recommendee])\n",
    "    np.random.seed(1)\n",
    "    splits = np.array_split(df.loc[recommendee].sample(frac=1), K)\n",
    "    for split in tqdm(splits):\n",
    "        oos_df = split\n",
    "        is_df = df.loc[\n",
    "            lambda x: ~(\n",
    "                (x.index.get_level_values(\"username\") == recommendee)\n",
    "                & x.anime_id.isin(oos_df.anime_id)\n",
    "            )\n",
    "        ]\n",
    "        oos_pred_df = get_deltas(\n",
    "            is_df=is_df,\n",
    "            anime_ids=list(oos_df.anime_id),\n",
    "            recommendee=recommendee,\n",
    "            neighborhood_size=neighborhood_size,\n",
    "            score_fn=score_fn,\n",
    "        )\n",
    "        oos_pred_dfs.append(oos_pred_df)\n",
    "    oos_pred_df = pd.concat(oos_pred_dfs)\n",
    "    oos_pred_df.to_pickle(f\"{signal_name}_loocv.pkl\")\n",
    "\n",
    "\n",
    "    # compute deltas over the full data\n",
    "    pred_df = get_deltas(\n",
    "        is_df=df,\n",
    "        anime_ids=list(df.anime_id),\n",
    "        recommendee=recommendee,\n",
    "        neighborhood_size=neighborhood_size,\n",
    "        score_fn=score_fn,\n",
    "    )\n",
    "\n",
    "    # store deltas\n",
    "    pred_df.to_pickle(f\"{signal_name}.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 349/349 [4:48:16<00:00, 49.56s/it]  \n"
     ]
    }
   ],
   "source": [
    "# each iteration takes several minutes\n",
    "store_deltas(\n",
    "    df=df,\n",
    "    recommendee=recommendee,\n",
    "    neighborhood_size=item_neighborhood_size,\n",
    "    score_fn=get_item_scores,\n",
    "    signal_name=\"item\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 349/349 [9:09:24<00:00, 94.45s/it]     \n"
     ]
    }
   ],
   "source": [
    "# each iteration takes several minutes\n",
    "store_deltas(\n",
    "    df=df,\n",
    "    recommendee=recommendee,\n",
    "    neighborhood_size=user_neighborhood_size,\n",
    "    score_fn=get_user_scores,\n",
    "    signal_name=\"user\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

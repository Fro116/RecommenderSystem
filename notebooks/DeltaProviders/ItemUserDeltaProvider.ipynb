{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "from matplotlib import pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "@functools.wraps(smf.ols)\n",
    "def lm(*args, **kwargs):\n",
    "    return smf.ols(*args, **kwargs).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change this to get recommendations for a different user\n",
    "recommendee = \"Fro116\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache()\n",
    "def get_data():\n",
    "    raw_df = pd.read_csv(\"UserAnimeList.csv\")\n",
    "    filtered_df = raw_df[[\"username\", \"anime_id\", \"my_score\"]].loc[\n",
    "        lambda x: x[\"my_score\"] != 0\n",
    "    ]\n",
    "\n",
    "    def read_xml(file, username):\n",
    "        import xml.etree.ElementTree as ET\n",
    "\n",
    "        xml_data = open(file, \"r\").read()  # Read file\n",
    "        root = ET.XML(xml_data)  # Parse XML\n",
    "\n",
    "        data = []\n",
    "        cols = []\n",
    "        for i, child in enumerate(root):\n",
    "            data.append([subchild.text for subchild in child])\n",
    "            cols.append(child.tag)\n",
    "        new_list = pd.DataFrame(data).T\n",
    "        new_list.columns = cols\n",
    "\n",
    "        df = (\n",
    "            new_list.loc[[0, 9]]\n",
    "            .T.dropna()\n",
    "            .rename({0: \"anime_id\", 9: \"my_score\"}, axis=1)\n",
    "        )\n",
    "        df[\"username\"] = username\n",
    "        df[\"anime_id\"] = df[\"anime_id\"].astype(int)\n",
    "        df[\"my_score\"] = df[\"my_score\"].astype(int)\n",
    "        df[\"username\"] = df[\"username\"].astype(str)\n",
    "        df = df.loc[lambda x: x[\"my_score\"] != 0]\n",
    "        df = df.reset_index(drop=True)\n",
    "        return df\n",
    "\n",
    "    def add_user(full_df, xml_file, username):\n",
    "        user_df = read_xml(xml_file, username)\n",
    "        without_user = full_df.loc[lambda x: x[\"username\"] != username]\n",
    "        return pd.concat([without_user, user_df], ignore_index=True)\n",
    "\n",
    "    filtered_df = add_user(filtered_df, \"user_profiles/Fro116.xml\", \"Fro116\")\n",
    "    average_rating = filtered_df[\"my_score\"].mean()\n",
    "    user_bias = (\n",
    "        pd.DataFrame(filtered_df.groupby(\"username\")[\"my_score\"].mean()).rename(\n",
    "            {\"my_score\": \"user_bias\"}, axis=1\n",
    "        )\n",
    "        - average_rating\n",
    "    )\n",
    "    anime_bias = (\n",
    "        pd.DataFrame(filtered_df.groupby(\"anime_id\")[\"my_score\"].mean()).rename(\n",
    "            {\"my_score\": \"anime_bias\"}, axis=1\n",
    "        )\n",
    "        - average_rating\n",
    "    )\n",
    "\n",
    "    filtered_df = filtered_df.merge(anime_bias, on=[\"anime_id\"]).merge(\n",
    "        user_bias, on=[\"username\"]\n",
    "    )\n",
    "    filtered_df[\"blp\"] = (\n",
    "        filtered_df[\"anime_bias\"] + filtered_df[\"user_bias\"] + average_rating\n",
    "    )\n",
    "    filtered_df[\"normalized_score\"] = filtered_df[\"my_score\"] - filtered_df[\"blp\"]\n",
    "    filtered_df = filtered_df.set_index(\"username\")\n",
    "    filtered_df = filtered_df.dropna()\n",
    "    return filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta(score):\n",
    "    return score.groupby(\"anime_id\").apply(\n",
    "        lambda x: np.dot(x[\"normalized_score\"], x[\"corr\"]) / x[\"corr\"].abs().sum()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_delta_variance(score):\n",
    "    # The following formulae are used to compute the variance of the delta. Delta\n",
    "    # is a weighted sum of the form δ = Σ(s_i * w_i) / (Σw_i), where s_i is\n",
    "    # a vector scores and w_i is the weight.\n",
    "    #\n",
    "    # By linearity, it suffices to compute (s_i * w_i) / (Σw_i). We assume that\n",
    "    # Var(s_i) is the same as the variance over all items s_i has rated). We treat\n",
    "    # w_i as a random variable with mean w_i and variance corr['corr_var']\n",
    "    #\n",
    "    # The variance for (w_i) / (Σw_i) can be estimated by doing a Taylor Approximation.\n",
    "    # See equation 20 of https://www.stat.cmu.edu/~hseltman/files/ratio.pdf. The\n",
    "    # formula for the ratio of two correlated variables R,S is\n",
    "    # Var(R/S) = E[R]^2/E[S]^2(Var[R]/E[R]^2 - 2Cov(R,S)/(E[R]E[S]) + Var[S]/E[S]^2)\n",
    "    #\n",
    "    # Lastly we take the product distribution of s_i and (w_i) / (Σw_i).\n",
    "    def correction_factor(x):\n",
    "        return (\n",
    "            1\n",
    "            + x[\"corr_var\"] / (x[\"corr\"] ** 2)\n",
    "            - 2 * x[\"corr_var\"] / (x[\"corr\"].abs().sum() * x[\"corr\"].abs())\n",
    "            + x[\"corr_var\"].sum() / (x[\"corr\"].abs().sum() ** 2)\n",
    "        )\n",
    "\n",
    "    delta_var = score.groupby(\"anime_id\").apply(\n",
    "        lambda x: np.sum(\n",
    "            x[\"normalized_score_var\"] * x[\"corr\"] ** 2 * correction_factor(x)\n",
    "        )\n",
    "        / (x[\"corr\"].abs().sum() ** 2)\n",
    "    )\n",
    "\n",
    "    # if the var < 0, then the ratio distribution approximation failed,\n",
    "    # usually because sample size is too small\n",
    "    delta_var.loc[lambda x: x < 0] = np.inf\n",
    "\n",
    "    # The above is a biased estimator of the variance. To unbias the estimator,\n",
    "    # we need to apply a Bessel-like correction. See the formula in\n",
    "    # (https://stats.stackexchange.com/questions/47325/bias-correction-in-weighted-variance)\n",
    "    bias_correction = (\n",
    "        score.set_index(\"anime_id\")\n",
    "        .loc[score.groupby(\"anime_id\").size() > 1]\n",
    "        .groupby(\"anime_id\")\n",
    "        .apply(\n",
    "            lambda x: (x[\"corr\"].abs().sum() ** 2)\n",
    "            / (x[\"corr\"].abs().sum() ** 2 - (x[\"corr\"] ** 2).sum())\n",
    "        )\n",
    "    )\n",
    "    delta_var *= bias_correction\n",
    "    return delta_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deltas(is_df, anime_ids, recommendee, neighborhood_size, score_fn):\n",
    "    # get the neighborhood for each item\n",
    "    score = score_fn(is_df, recommendee, neighborhood_size)\n",
    "\n",
    "    # extract model features\n",
    "    pred_df = pd.DataFrame()\n",
    "    pred_df[\"delta\"] = get_delta(score)\n",
    "    pred_df[\"delta_var\"] = get_delta_variance(score)\n",
    "    pred_df = pred_df.loc[lambda x: x.index.isin(anime_ids)]\n",
    "\n",
    "    # fill in missing predictions with nan\n",
    "    for anime_id in set(anime_ids) - set(pred_df.index):\n",
    "        pred_df = pred_df.append(pd.Series(name=anime_id, dtype=float))\n",
    "    return pred_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@functools.lru_cache()\n",
    "def get_item_corrs():\n",
    "    corrs = pickle.load(open(\"item_correlations/correlations.pkl\", \"rb\"))\n",
    "    corrs[\"similarity\"] = corrs[\"corr\"].abs()\n",
    "    corrs = corrs.dropna()\n",
    "    corrs = corrs.loc[\n",
    "        lambda x: x.index.get_level_values(\"anime_id_x\")\n",
    "        != x.index.get_level_values(\"anime_id_y\")\n",
    "    ]\n",
    "    corrs = corrs.sort_values(by=\"similarity\")\n",
    "    return corrs\n",
    "\n",
    "\n",
    "def get_item_scores(df, recommendee, neighborhood_size):\n",
    "    corrs = get_item_corrs()\n",
    "    corrs = corrs.groupby(\"anime_id_x\").tail(neighborhood_size)\n",
    "    score = df.loc[recommendee].merge(\n",
    "        corrs.reset_index(\"anime_id_x\"), left_on=\"anime_id\", right_on=\"anime_id_y\",\n",
    "    )\n",
    "\n",
    "    user_var = (\n",
    "        pd.DataFrame(df.groupby(\"username\")[\"normalized_score\"].var())\n",
    "        .rename({\"normalized_score\": \"user_var\"}, axis=1)\n",
    "        .dropna()\n",
    "    )\n",
    "    score[\"normalized_score_var\"] = user_var.loc[recommendee].squeeze()\n",
    "    score = score.drop(\"anime_id\", axis=1).rename({\"anime_id_x\": \"anime_id\"}, axis=1)\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_corrs(df, recommendee):\n",
    "    user_subset = df.loc[[recommendee]].merge(df.reset_index(), on=\"anime_id\")\n",
    "    corr_numerator = user_subset.groupby(\"username\").apply(\n",
    "        lambda x: np.dot(x[\"normalized_score_x\"], x[\"normalized_score_y\"])\n",
    "    )\n",
    "    corr_denom = df.groupby(\"username\").apply(\n",
    "        lambda x: np.sqrt(np.dot(x[\"normalized_score\"], x[\"normalized_score\"]))\n",
    "    )\n",
    "    corr_denom *= corr_denom.loc[recommendee]\n",
    "    corrs = pd.DataFrame((corr_numerator / corr_denom), columns=[\"corr\"])\n",
    "    corrs[\"similarity\"] = corrs[\"corr\"].abs()\n",
    "    corrs[\"corr_size\"] = user_subset.groupby(\"username\").size()\n",
    "    corrs = corrs.drop(recommendee)    \n",
    "    corrs = corrs.dropna()\n",
    "    return corrs\n",
    "\n",
    "\n",
    "def get_user_scores(df, recommendee, neighborhood_size):\n",
    "    corrs = get_user_corrs(df, recommendee)\n",
    "\n",
    "    # We assume variance is the same as the variance for pearson correlation.\n",
    "    # see https://www.jstor.org/stable/2277400?seq=1\n",
    "    corrs = corrs.loc[lambda x: x[\"corr_size\"] > 2]\n",
    "    corrs[\"corr_var\"] = (1 - corrs[\"corr\"] * corrs[\"corr\"]) ** 2 / (\n",
    "        corrs[\"corr_size\"] - 2\n",
    "    )\n",
    "    corrs = corrs.sort_values(by=\"similarity\").dropna()[-neighborhood_size:]\n",
    "\n",
    "    score = (df.merge(pd.DataFrame(corrs), on=\"username\")).dropna()\n",
    "\n",
    "    user_var = (\n",
    "        pd.DataFrame(df.groupby(\"username\")[\"normalized_score\"].var())\n",
    "        .rename({\"normalized_score\": \"normalized_score_var\"}, axis=1)\n",
    "        .dropna()\n",
    "    )\n",
    "    score = score.merge(user_var, on=\"username\")\n",
    "\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_deltas(recommendee, neighborhood_size, score_fn, delta_name):\n",
    "    df = get_data()\n",
    "\n",
    "    # compute cross-validated deltas\n",
    "    oos_pred_dfs = []\n",
    "    K = len(df.loc[recommendee])\n",
    "    np.random.seed(1)\n",
    "    splits = np.array_split(df.loc[recommendee].sample(frac=1), K)\n",
    "    for split in tqdm(splits):\n",
    "        oos_df = split\n",
    "        is_df = df.loc[\n",
    "            lambda x: ~(\n",
    "                (x.index.get_level_values(\"username\") == recommendee)\n",
    "                & x.anime_id.isin(oos_df.anime_id)\n",
    "            )\n",
    "        ]\n",
    "        oos_pred_df = get_deltas(\n",
    "            is_df=is_df,\n",
    "            anime_ids=list(oos_df.anime_id),\n",
    "            recommendee=recommendee,\n",
    "            neighborhood_size=neighborhood_size,\n",
    "            score_fn=score_fn,\n",
    "        )\n",
    "        oos_pred_dfs.append(oos_pred_df)\n",
    "    oos_pred_df = pd.concat(oos_pred_dfs)\n",
    "\n",
    "    # compute deltas over the full data\n",
    "    is_pred_df = get_deltas(\n",
    "        is_df=df,\n",
    "        anime_ids=list(df.anime_id),\n",
    "        recommendee=recommendee,\n",
    "        neighborhood_size=neighborhood_size,\n",
    "        score_fn=score_fn,\n",
    "    )\n",
    "\n",
    "    # store deltas\n",
    "    outdir = f\"deltas/{recommendee}\"\n",
    "    if not os.path.exists(outdir):\n",
    "        os.mkdir(outdir)\n",
    "    oos_pred_df.to_pickle(os.path.join(outdir, f\"{delta_name}_oos.pkl\"))\n",
    "    is_pred_df.to_pickle(os.path.join(outdir, f\"{delta_name}_is.pkl\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def store_baselines(recommendee):\n",
    "    df = get_data()\n",
    "    df.loc[recommendee][['anime_id', 'normalized_score']].to_pickle(f'deltas/{recommendee}/recommendee.pkl')\n",
    "    \n",
    "    average_rating = df[\"my_score\"].mean()\n",
    "    user_bias = (\n",
    "        pd.DataFrame(df.groupby(\"username\")[\"my_score\"].mean()).rename(\n",
    "            {\"my_score\": \"user_bias\"}, axis=1\n",
    "        )\n",
    "        - average_rating\n",
    "    )\n",
    "    anime_bias = (\n",
    "        pd.DataFrame(df.groupby(\"anime_id\")[\"my_score\"].mean()).rename(\n",
    "            {\"my_score\": \"anime_bias\"}, axis=1\n",
    "        )\n",
    "        - average_rating\n",
    "    )\n",
    "    blp = anime_bias + user_bias.loc[recommendee].squeeze() + average_rating\n",
    "    blp = blp.rename({'anime_bias': 'blp'}, axis=1)    \n",
    "    blp.to_pickle(f'deltas/{recommendee}/blp.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 185/375 [3:42:25<3:48:26, 72.14s/it]  \n",
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/Users/kundan/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 3418, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-12-1e51958603d8>\", line 1, in <module>\n",
      "    store_deltas(\n",
      "  File \"<ipython-input-10-a7aeca2855b1>\", line 17, in store_deltas\n",
      "    oos_pred_df = get_deltas(\n",
      "  File \"<ipython-input-7-ef7d89086c96>\", line 8, in get_deltas\n",
      "    pred_df[\"delta_var\"] = get_delta_variance(score)\n",
      "  File \"<ipython-input-6-3eb50c9cedee>\", line 39, in get_delta_variance\n",
      "    score.set_index(\"anime_id\")\n",
      "  File \"/Users/kundan/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\", line 859, in apply\n",
      "    result = self._python_apply_general(f, self._selected_obj)\n",
      "  File \"/Users/kundan/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\", line 892, in _python_apply_general\n",
      "    keys, values, mutated = self.grouper.apply(f, data, self.axis)\n",
      "  File \"/Users/kundan/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/ops.py\", line 179, in apply\n",
      "    result_values, mutated = splitter.fast_apply(f, sdata, group_keys)\n",
      "  File \"/Users/kundan/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/ops.py\", line 965, in fast_apply\n",
      "    return libreduction.apply_frame_axis0(sdata, f, names, starts, ends)\n",
      "  File \"pandas/_libs/reduction.pyx\", line 364, in pandas._libs.reduction.apply_frame_axis0\n",
      "  File \"<ipython-input-6-3eb50c9cedee>\", line 43, in <lambda>\n",
      "    lambda x: (x[\"corr\"].abs().sum() ** 2)\n",
      "  File \"/Users/kundan/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\", line 2878, in __getitem__\n",
      "    return self._get_item_cache(key)\n",
      "  File \"/Users/kundan/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3545, in _get_item_cache\n",
      "    res._set_as_cached(item, self)\n",
      "  File \"/Users/kundan/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\", line 3185, in _set_as_cached\n",
      "    self._cacher = (item, weakref.ref(cacher))\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kundan/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\", line 2045, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/kundan/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 1170, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/Users/kundan/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 316, in wrapped\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/kundan/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 350, in _fixed_getinnerframes\n",
      "    records = fix_frame_records_filenames(inspect.getinnerframes(etb, context))\n",
      "  File \"/Users/kundan/opt/anaconda3/lib/python3.8/inspect.py\", line 1503, in getinnerframes\n",
      "    frameinfo = (tb.tb_frame,) + getframeinfo(tb, context)\n",
      "  File \"/Users/kundan/opt/anaconda3/lib/python3.8/inspect.py\", line 1465, in getframeinfo\n",
      "    lines, lnum = findsource(frame)\n",
      "  File \"/Users/kundan/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\", line 182, in findsource\n",
      "    lines = linecache.getlines(file, globals_dict)\n",
      "  File \"/Users/kundan/opt/anaconda3/lib/python3.8/linecache.py\", line 47, in getlines\n",
      "    return updatecache(filename, module_globals)\n",
      "  File \"/Users/kundan/opt/anaconda3/lib/python3.8/linecache.py\", line 137, in updatecache\n",
      "    lines = fp.readlines()\n",
      "  File \"/Users/kundan/opt/anaconda3/lib/python3.8/codecs.py\", line 319, in decode\n",
      "    def decode(self, input, final=False):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m<ipython-input-12-1e51958603d8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m store_deltas(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mrecommendee\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecommendee\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mneighborhood_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-a7aeca2855b1>\u001b[0m in \u001b[0;36mstore_deltas\u001b[0;34m(recommendee, neighborhood_size, score_fn, delta_name)\u001b[0m\n\u001b[1;32m     16\u001b[0m         ]\n\u001b[0;32m---> 17\u001b[0;31m         oos_pred_df = get_deltas(\n\u001b[0m\u001b[1;32m     18\u001b[0m             \u001b[0mis_df\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mis_df\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-ef7d89086c96>\u001b[0m in \u001b[0;36mget_deltas\u001b[0;34m(is_df, anime_ids, recommendee, neighborhood_size, score_fn)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mpred_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"delta\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_delta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mpred_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"delta_var\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_delta_variance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0mpred_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpred_df\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0manime_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-3eb50c9cedee>\u001b[0m in \u001b[0;36mget_delta_variance\u001b[0;34m(score)\u001b[0m\n\u001b[1;32m     38\u001b[0m     bias_correction = (\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"anime_id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0;34m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgroupby\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"anime_id\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, func, *args, **kwargs)\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m                 \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_apply_general\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_selected_obj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    860\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/groupby.py\u001b[0m in \u001b[0;36m_python_apply_general\u001b[0;34m(self, f, data)\u001b[0m\n\u001b[1;32m    891\u001b[0m         \"\"\"\n\u001b[0;32m--> 892\u001b[0;31m         \u001b[0mkeys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrouper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    893\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, f, data, axis)\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 179\u001b[0;31m                 \u001b[0mresult_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmutated\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplitter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfast_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgroup_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/groupby/ops.py\u001b[0m in \u001b[0;36mfast_apply\u001b[0;34m(self, f, sdata, names)\u001b[0m\n\u001b[1;32m    964\u001b[0m         \u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_slices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mslabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mngroups\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 965\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlibreduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_frame_axis0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstarts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mends\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    966\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/_libs/reduction.pyx\u001b[0m in \u001b[0;36mpandas._libs.reduction.apply_frame_axis0\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-3eb50c9cedee>\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     42\u001b[0m         .apply(\n\u001b[0;32m---> 43\u001b[0;31m             \u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"corr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m             \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"corr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"corr\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   2877\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_getitem_multilevel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2878\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_item_cache\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2879\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_get_item_cache\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m   3544\u001b[0m             \u001b[0mcache\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3545\u001b[0;31m             \u001b[0mres\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_as_cached\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3546\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/pandas/core/generic.py\u001b[0m in \u001b[0;36m_set_as_cached\u001b[0;34m(self, item, cacher)\u001b[0m\n\u001b[1;32m   3184\u001b[0m         \"\"\"\n\u001b[0;32m-> 3185\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cacher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweakref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcacher\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2044\u001b[0m                         \u001b[0;31m# in the engines. This should return a list of strings.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2045\u001b[0;31m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2046\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'KeyboardInterrupt' object has no attribute '_render_traceback_'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/interactiveshell.py\u001b[0m in \u001b[0;36mshowtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   2045\u001b[0m                         \u001b[0mstb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_render_traceback_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2046\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2047\u001b[0;31m                         stb = self.InteractiveTB.structured_traceback(etype,\n\u001b[0m\u001b[1;32m   2048\u001b[0m                                             value, tb, tb_offset=tb_offset)\n\u001b[1;32m   2049\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1434\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1435\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1436\u001b[0;31m         return FormattedTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1437\u001b[0m             self, etype, value, tb, tb_offset, number_of_lines_of_context)\n\u001b[1;32m   1438\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1334\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose_modes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1335\u001b[0m             \u001b[0;31m# Verbose modes need a full traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1336\u001b[0;31m             return VerboseTB.structured_traceback(\n\u001b[0m\u001b[1;32m   1337\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtb_offset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnumber_of_lines_of_context\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1338\u001b[0m             )\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mstructured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1191\u001b[0m         \u001b[0;34m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1192\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1193\u001b[0;31m         formatted_exception = self.format_exception_as_a_whole(etype, evalue, etb, number_of_lines_of_context,\n\u001b[0m\u001b[1;32m   1194\u001b[0m                                                                tb_offset)\n\u001b[1;32m   1195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mformat_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m   1149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1151\u001b[0;31m         \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_recursion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morig_etype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mevalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat_records\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_unique\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecursion_repeat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/ultratb.py\u001b[0m in \u001b[0;36mfind_recursion\u001b[0;34m(etype, value, records)\u001b[0m\n\u001b[1;32m    449\u001b[0m     \u001b[0;31m# first frame (from in to out) that looks different.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_recursion_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0metype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m     \u001b[0;31m# Select filename, lineno, func_name to track frames with\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "store_deltas(\n",
    "    recommendee=recommendee,\n",
    "    neighborhood_size=64,\n",
    "    score_fn=get_item_scores,\n",
    "    delta_name=\"item\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 71/375 [2:10:21<9:09:06, 108.38s/it] "
     ]
    }
   ],
   "source": [
    "store_deltas(\n",
    "    recommendee=recommendee,\n",
    "    neighborhood_size=8192,\n",
    "    score_fn=get_user_scores,\n",
    "    delta_name=\"user\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "store_baselines(recommendee=recommendee)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO figure out how to make loocv faster"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

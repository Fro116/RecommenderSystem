{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a267fa3-cdb3-4a96-affc-6f03ee3fa040",
   "metadata": {},
   "source": [
    "# NeuralUserItemBiases\n",
    "* See the corresponding file in `../TrainingAlphas` for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d47f2c65-9add-4db8-ae90-94ec7b96367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"NeuralMF\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3f3bee8-6535-49b7-b0ae-d3fc19a73cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "986012aa-408e-47ff-90db-4a6d45ad0fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"../TrainingAlphas/Neural/NeuralNetworkBase.ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10e3130-12fc-4e15-b13a-93cacb24d97e",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cdb0148-e04c-4a43-b6de-8eece18b7385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO share with other neural network alphas\n",
    "\n",
    "# Override methods in NeuralNetworkBase to use recommendee splits\n",
    "\n",
    "@memoize LRU{Any,Any}(maxsize = 2) function get_epoch_outputs(split, implicit, num_users)\n",
    "    @assert split == \"training\"\n",
    "    sparse(get_recommendee_split(implicit))\n",
    "end\n",
    "\n",
    "@memoize LRU{Any,Any}(maxsize = 2) function get_epoch_residuals(\n",
    "    split,\n",
    "    residual_alphas,\n",
    "    implicit,\n",
    "    num_users,\n",
    ")\n",
    "    @assert split == \"training\"\n",
    "    sparse(read_recommendee_alpha(residual_alphas, implicit))\n",
    "end\n",
    "\n",
    "@memoize LRU{Any,Any}(maxsize = 2) function get_epoch_weights(\n",
    "    split,\n",
    "    user_weight_decay,\n",
    "    item_weight_decay,\n",
    "    implicit,\n",
    "    num_users,\n",
    ")\n",
    "    @assert split == \"training\"\n",
    "    df = get_recommendee_split(implicit)\n",
    "    user_counts = fill(length(df.rating), num_items())\n",
    "    weights =\n",
    "        expdecay(user_counts, user_weight_decay) .* expdecay(\n",
    "            get_counts(split, implicit; by_item = true, per_rating = false),\n",
    "            item_weight_decay,\n",
    "        )\n",
    "\n",
    "    sparse(RatingsDataset(df.user, df.item, weights[df.item]))\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43845621-6712-4c61-acb8-85dff670f062",
   "metadata": {},
   "source": [
    "## Retrain user embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64be777a-24d7-465e-8ec3-3cbd8e0ddb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "function retrain_user_embeddings(params)\n",
    "    hyp = params[\"retrain_hyp\"]\n",
    "    global G = @set hyp.num_users = 1\n",
    "    m = build_retrain_model(G, params[\"m\"]) |> device\n",
    "    ps = Flux.params(m[1])\n",
    "    opt = get_optimizer(G.optimizer, G.learning_rate, G.regularization_params)\n",
    "    epochs = params[\"epochs\"] - 1 # the first epoch is not used for training\n",
    "\n",
    "    @showprogress for _ = 1:epochs\n",
    "        train_epoch!(m, ps, opt)\n",
    "        apply_zero_gradient!(m, ps, opt, true)\n",
    "    end\n",
    "    global G = nothing\n",
    "    m |> cpu\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401c7d33-c086-4310-9b16-f8f5e569e94d",
   "metadata": {},
   "source": [
    "## Write alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce6c7d84-10a7-47e8-878b-a0649e2b2e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_alpha(source)\n",
    "    @info \"computing alpha $source\"\n",
    "    params = read_params(source)\n",
    "    m = retrain_user_embeddings(params)\n",
    "\n",
    "    # todo generalize saving and share with other neural alphas\n",
    "    activation = params[\"hyp\"].implicit ? softmax : identity\n",
    "    preds = activation(m(1))\n",
    "    write_recommendee_alpha(preds, source)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b86d4a9-55f2-424e-ac49-7d3db140648c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function compute_alpha()\n",
    "    #compute_alpha(\"NeuralExplicitUserItemBiases\")\n",
    "    compute_alpha(\"NeuralImplicitUserItemBiases\")\n",
    "    compute_alpha(\"NeuralExplicitMatrixFactorization\")\n",
    "    compute_alpha(\"NeuralImplicitMatrixFactorization\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59d867fd-9a23-4870-aadf-0138bb678fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220629 00:54:15 computing alpha NeuralImplicitUserItemBiases\n",
      "\u001b[38;5;6m\u001b[1m┌ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220629 00:54:18 The GPU function is being called but the GPU is not accessible. \n",
      "\u001b[38;5;6m\u001b[1m└ \u001b[22m\u001b[39mDefaulting back to the CPU. (No action is required if you want to run on the CPU).\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 (56.90 ns/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 3.16 ns/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:31\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220629 00:54:50 computing alpha NeuralExplicitMatrixFactorization\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 (34.01 ns/it)\u001b[39m\n",
      "\u001b[32mProgress: 100%|███████████████████████████| Time: 0:00:00 ( 4.16 ns/it)\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220629 00:54:54 computing alpha NeuralImplicitMatrixFactorization\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:10\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "compute_alpha();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "af5597b7-122b-4ef6-a381-a67b110fd589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Any} with 6 entries:\n",
       "  \"epochs\"          => 7\n",
       "  \"retrain_loss\"    => 6.33872\n",
       "  \"m\"               => Chain(Embedding(2714683 => 64), Dense(64 => 20340; bias=…\n",
       "  \"hyp\"             => Hyperparameters:…\n",
       "  \"validation_loss\" => 6.36908\n",
       "  \"retrain_hyp\"     => Hyperparameters:…"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_params(\"NeuralImplicitMatrixFactorization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1ee604fa-8c08-41a3-8d5e-748c8f8979d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Any} with 6 entries:\n",
       "  \"epochs\"          => 2\n",
       "  \"retrain_loss\"    => 1.57229\n",
       "  \"m\"               => Chain(Embedding(2714683 => 64), Dense(64 => 20340; bias=…\n",
       "  \"hyp\"             => Hyperparameters:…\n",
       "  \"validation_loss\" => 1.57184\n",
       "  \"retrain_hyp\"     => Hyperparameters:…"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_params(\"NeuralExplicitMatrixFactorization\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "42de8fdd-3154-4708-a926-0d1651a1b8d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{String, Any} with 6 entries:\n",
       "  \"epochs\"          => 8\n",
       "  \"retrain_loss\"    => 7.30032\n",
       "  \"m\"               => Chain(Embedding(2714683 => 1), BiasLayer(Float32[-4.4112…\n",
       "  \"hyp\"             => Hyperparameters:…\n",
       "  \"validation_loss\" => 7.30033\n",
       "  \"retrain_hyp\"     => Hyperparameters:…"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_params(\"NeuralImplicitUserItemBiases\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3565ad15-c2d7-4b93-8487-609d47516cf3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-rc1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

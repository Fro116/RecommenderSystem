{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a267fa3-cdb3-4a96-affc-6f03ee3fa040",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Bayesian Personalized Ranking\n",
    "* See the corresponding file in `../../TrainingAlphas` for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f2c65-9add-4db8-ae90-94ec7b96367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "const source_name = \"MLE.Ensemble\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a253f1-62e3-4deb-86b7-6683b2e677ee",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "username = \"\"\n",
    "task = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f3bee8-6535-49b7-b0ae-d3fc19a73cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import NBInclude: @nbinclude\n",
    "import SparseArrays: sparse\n",
    "@nbinclude(\"../Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0f70f4-6f64-40b8-84e9-ada8b55e39c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_query_features(alphas::Vector{String})\n",
    "    A = Matrix{Float32}(undef, num_items(), length(alphas))\n",
    "    @tprogress Threads.@threads for i = 1:length(alphas)\n",
    "        A[:, i] = read_recommendee_alpha(alphas[i], \"all\").rating\n",
    "    end\n",
    "    collect(A')\n",
    "end\n",
    "\n",
    "function get_implicit_features()\n",
    "    df = get_recommendee_split(\"implicit\")\n",
    "    sparse(df.item, df.user, df.rating, num_items(), 1)\n",
    "end\n",
    "\n",
    "function get_explicit_features()\n",
    "    df = get_recommendee_split(\"explicit\")\n",
    "    sparse(df.item, df.user, df.rating, num_items(), 1)\n",
    "end\n",
    "\n",
    "function get_user_features()\n",
    "    collect(vcat(get_implicit_features(), get_explicit_features()))\n",
    "end\n",
    "\n",
    "function get_embedding(\n",
    "    u::Integer,\n",
    "    a::Integer,\n",
    "    q::Integer,\n",
    "    user_features::AbstractMatrix,\n",
    "    query_features::AbstractMatrix,\n",
    ")\n",
    "    user_features[:, u], [a], query_features[:, q]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59101ab4-beb0-4cf6-87e1-5b285a4e8698",
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_alpha()\n",
    "    params = read_params(\"$task/$source_name\")\n",
    "    U = get_user_features()\n",
    "    Q = get_query_features(params[\"hyp\"].alphas)\n",
    "    Q = (Q .- params[\"inference_data\"][\"μ\"]) ./ params[\"inference_data\"][\"σ\"]\n",
    "    m = params[\"m\"]\n",
    "    scores = Array{Float32}(undef, num_items())\n",
    "    @tprogress Threads.@threads for i = 1:num_items()\n",
    "        sample = get_embedding(1, i, i, U, Q)\n",
    "        scores[i] = m(sample)[1]\n",
    "    end\n",
    "    write_recommendee_alpha(scores, \"$task/$source_name\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91741710-819b-473f-804b-9be6eed3d13a",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_alpha();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.3",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

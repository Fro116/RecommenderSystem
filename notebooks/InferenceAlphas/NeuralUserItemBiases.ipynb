{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a267fa3-cdb3-4a96-affc-6f03ee3fa040",
   "metadata": {},
   "source": [
    "# NeuralUserItemBiases\n",
    "* See the corresponding file in `../TrainingAlphas` for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d47f2c65-9add-4db8-ae90-94ec7b96367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"NeuralUserItemBiases\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a3f3bee8-6535-49b7-b0ae-d3fc19a73cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "986012aa-408e-47ff-90db-4a6d45ad0fd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "@nbinclude(\"../TrainingAlphas/NeuralNetworkBase.ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10e3130-12fc-4e15-b13a-93cacb24d97e",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cdb0148-e04c-4a43-b6de-8eece18b7385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override methods in NeuralNetworkBase to use recommendee splits\n",
    "\n",
    "@memoize LRU{Any,Any}(maxsize = 2) function get_epoch_outputs(split, implicit, num_users)\n",
    "    @assert split == \"training\"\n",
    "    sparse(get_recommendee_split(implicit))\n",
    "end\n",
    "\n",
    "@memoize LRU{Any,Any}(maxsize = 2) function get_epoch_residuals(\n",
    "    split,\n",
    "    residual_alphas,\n",
    "    implicit,\n",
    "    num_users,\n",
    ")\n",
    "    @assert split == \"training\"\n",
    "    sparse(read_recommendee_alpha(residual_alphas, implicit))\n",
    "end\n",
    "\n",
    "@memoize LRU{Any,Any}(maxsize = 2) function get_epoch_weights(\n",
    "    split,\n",
    "    user_weight_decay,\n",
    "    item_weight_decay,\n",
    "    implicit,\n",
    "    num_users,\n",
    ")\n",
    "    @assert split == \"training\"\n",
    "    df = get_recommendee_split(implicit)\n",
    "    user_counts = fill(length(df.rating), num_items())\n",
    "    weights =\n",
    "        expdecay(user_counts, user_weight_decay) .* expdecay(\n",
    "            get_counts(split, implicit; by_item = true, per_rating = false),\n",
    "            item_weight_decay,\n",
    "        )\n",
    "\n",
    "    sparse(RatingsDataset(df.user, df.item, weights[df.item]))\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43845621-6712-4c61-acb8-85dff670f062",
   "metadata": {},
   "source": [
    "## Retrain user embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "64be777a-24d7-465e-8ec3-3cbd8e0ddb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "function retrain_user_embeddings(params)\n",
    "    hyp = params[\"retrain_hyp\"]\n",
    "    global G = @set hyp.num_users = 1\n",
    "    m = build_retrain_model(G, params[\"m\"]) |> device\n",
    "    ps = Flux.params(m[1])\n",
    "    opt = get_optimizer(G.optimizer, G.learning_rate, G.regularization_params)\n",
    "\n",
    "    @showprogress for _ = 1:params[\"epochs\"]\n",
    "        train_epoch!(m, ps, opt)\n",
    "        apply_zero_gradient!(m, ps, opt, true)\n",
    "    end\n",
    "    global G = nothing\n",
    "    m |> cpu\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401c7d33-c086-4310-9b16-f8f5e569e94d",
   "metadata": {},
   "source": [
    "## Write alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ce6c7d84-10a7-47e8-878b-a0649e2b2e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_alpha(source)\n",
    "    @info \"computing alpha $source\"\n",
    "    params = read_params(source)\n",
    "    m = retrain_user_embeddings(params)\n",
    "    preds = m(1)\n",
    "    write_recommendee_alpha(preds, source)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b86d4a9-55f2-424e-ac49-7d3db140648c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function compute_alpha()\n",
    "    compute_alpha(\"NeuralExplicitUserItemBiases\")\n",
    "    compute_alpha(\"NeuralImplicitUserItemBiases\")\n",
    "    compute_alpha(\"NeuralExplicitMatrixFactorization\")\n",
    "    compute_alpha(\"NeuralImplicitMatrixFactorization\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59d867fd-9a23-4870-aadf-0138bb678fca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220618 13:56:12 computing alpha NeuralExplicitUserItemBiases\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:01:07\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220618 13:57:24 computing alpha NeuralImplicitUserItemBiases\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter     Function value   Gradient norm \n",
      "     0     9.849667e+00     0.000000e+00\n",
      " * time: 0.008617162704467773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220618 13:57:35 computing alpha NeuralExplicitMatrixFactorization\n",
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:02\u001b[39m\n",
      "\u001b[38;5;6m\u001b[1m[ \u001b[22m\u001b[39m\u001b[38;5;6m\u001b[1mInfo: \u001b[22m\u001b[39m20220618 13:57:39 computing alpha NeuralImplicitMatrixFactorization\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter     Function value   Gradient norm \n",
      "     0     7.866368e+00     3.492808e-01\n",
      " * time: 2.7179718017578125e-5\n",
      "     1     7.534700e+00     1.322128e-01\n",
      " * time: 0.6021480560302734\n",
      "     2     7.442744e+00     4.278617e-02\n",
      " * time: 1.122122049331665\n",
      "     3     7.415466e+00     1.126432e-02\n",
      " * time: 1.7214510440826416\n",
      "     4     7.409862e+00     3.949660e-03\n",
      " * time: 2.316575050354004\n",
      "     5     7.407974e+00     1.255889e-03\n",
      " * time: 2.835313081741333\n",
      "     6     7.407395e+00     3.691816e-04\n",
      " * time: 3.4461541175842285\n",
      "     7     7.407246e+00     1.358968e-04\n",
      " * time: 4.045407056808472\n",
      "     8     7.407190e+00     5.112632e-05\n",
      " * time: 4.561211109161377\n",
      "     9     7.407169e+00     2.053520e-05\n",
      " * time: 5.167686223983765\n",
      "    10     7.407159e+00     8.916975e-06\n",
      " * time: 5.763728141784668\n",
      "    11     7.407155e+00     3.442694e-06\n",
      " * time: 6.279336214065552\n",
      "    12     7.407153e+00     1.426109e-06\n",
      " * time: 6.885868072509766\n",
      "    13     7.407153e+00     6.137319e-07\n",
      " * time: 7.4780731201171875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:00:15\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "compute_alpha();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-rc1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

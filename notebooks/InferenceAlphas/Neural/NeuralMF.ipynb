{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0a267fa3-cdb3-4a96-affc-6f03ee3fa040",
   "metadata": {},
   "source": [
    "# NeuralMF\n",
    "* See the corresponding file in `../../TrainingAlphas` for more details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d47f2c65-9add-4db8-ae90-94ec7b96367a",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"NeuralMF\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f3bee8-6535-49b7-b0ae-d3fc19a73cbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import NBInclude: @nbinclude\n",
    "@nbinclude(\"../Alpha.ipynb\")\n",
    "@nbinclude(\"../../TrainingAlphas/Neural/NeuralNetworkBase.ipynb\");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e10e3130-12fc-4e15-b13a-93cacb24d97e",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdb0148-e04c-4a43-b6de-8eece18b7385",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Override methods in NeuralNetworkBase to use recommendee splits\n",
    "\n",
    "@memoize LRU{Any,Any}(maxsize = 2) function get_epoch_outputs(split, implicit, num_users)\n",
    "    @assert split == \"training\"\n",
    "    sparse(get_recommendee_split(implicit))\n",
    "end\n",
    "\n",
    "@memoize LRU{Any,Any}(maxsize = 2) function get_epoch_residuals(\n",
    "    split,\n",
    "    residual_alphas,\n",
    "    implicit,\n",
    "    num_users,\n",
    ")\n",
    "    @assert split == \"training\"\n",
    "    sparse(read_recommendee_alpha(residual_alphas, implicit))\n",
    "end\n",
    "\n",
    "@memoize LRU{Any,Any}(maxsize = 2) function get_epoch_weights(\n",
    "    split,\n",
    "    user_weight_decay,\n",
    "    item_weight_decay,\n",
    "    implicit,\n",
    "    num_users,\n",
    ")\n",
    "    @assert split == \"training\"\n",
    "    df = get_recommendee_split(implicit)\n",
    "    user_counts = fill(length(df.rating), num_items())\n",
    "    weights =\n",
    "        expdecay(user_counts, user_weight_decay) .* expdecay(\n",
    "            get_counts(split, implicit; by_item = true, per_rating = false),\n",
    "            item_weight_decay,\n",
    "        )\n",
    "\n",
    "    sparse(RatingsDataset(df.user, df.item, weights[df.item]))\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43845621-6712-4c61-acb8-85dff670f062",
   "metadata": {},
   "source": [
    "## Retrain user embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64be777a-24d7-465e-8ec3-3cbd8e0ddb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "function retrain_user_embeddings(params)\n",
    "    # the weight initialization cares about the number of users,\n",
    "    # so let's initialize assuming we have all users and then fine tune \n",
    "    # a single layer\n",
    "    init_embedding = build_retrain_model(params[\"retrain_hyp\"], params[\"m\"])[1].weight[:, 1]\n",
    "    hyp = params[\"retrain_hyp\"]\n",
    "    global G = @set hyp.num_users = 1\n",
    "    m = build_retrain_model(G, params[\"m\"])\n",
    "    m[1].weight .= init_embedding\n",
    "    m = m |> device\n",
    "    Random.seed!(G.seed)\n",
    "    ps = Flux.params(m[1])\n",
    "    opt = get_optimizer(G.optimizer, G.learning_rate, G.regularization_params)\n",
    "    # -1 epoch because the first call to stop! happens before training\n",
    "    epochs = params[\"epochs\"] - 1\n",
    "    @showprogress for _ = 1:epochs\n",
    "        train_epoch!(m, ps, opt)\n",
    "        apply_zero_gradient!(m, ps, opt, true)\n",
    "    end\n",
    "    global G = nothing\n",
    "    m |> cpu\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401c7d33-c086-4310-9b16-f8f5e569e94d",
   "metadata": {},
   "source": [
    "## Write alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6c7d84-10a7-47e8-878b-a0649e2b2e2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_alpha(source)\n",
    "    @info \"computing alpha $source\"\n",
    "    params = read_params(source)\n",
    "    m = retrain_user_embeddings(params)\n",
    "    activation = params[\"hyp\"].implicit ? softmax : identity\n",
    "    preds = activation(m(1))\n",
    "    write_recommendee_alpha(preds, source)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b86d4a9-55f2-424e-ac49-7d3db140648c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "function compute_alpha()\n",
    "    compute_alpha(\"NeuralImplicitUserItemBiases\")\n",
    "    compute_alpha(\"NeuralImplicitMatrixFactorization\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d867fd-9a23-4870-aadf-0138bb678fca",
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_alpha();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.8.0-rc1",
   "language": "julia",
   "name": "julia-1.8"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

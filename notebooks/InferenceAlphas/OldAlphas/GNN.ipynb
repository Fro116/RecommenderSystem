{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3758ece-9b72-47b4-ae6a-aa364e0443e3",
   "metadata": {},
   "source": [
    "# General Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31294b0f-f9ad-47f9-a6a7-8e004a20b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "source = \"GNN\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "54170f91-c85c-4207-9939-572cad4db024",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux\n",
    "import BSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2980ef8-4e80-4e30-bd25-f14970595252",
   "metadata": {},
   "outputs": [],
   "source": [
    "using NBInclude\n",
    "@nbinclude(\"Alpha.ipynb\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "08801fd4-7057-49f0-9fa7-9854d17494cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = gpu;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "34c2fd75-531e-4794-a9ae-07ead4419be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{String}:\n",
       " \"UserItemBiases\""
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "read_params(\"GNN.1\")[\"residual_alphas\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "638f2e93-80aa-4d4f-90ee-d70e3610cd13",
   "metadata": {},
   "source": [
    "## Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "69230c4b-c1f5-427c-a0af-434bb6122514",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_data(alpha)\n",
    "    training = get_residuals(\"recommendee\", read_params(alpha)[\"residual_alphas\"])\n",
    "    implicit = get_implicit_list()\n",
    "    n_items = num_items() + 1\n",
    "\n",
    "    X1 = zeros(Float32, n_items)\n",
    "    X1[training.item] = training.rating\n",
    "    X2 = zeros(Float32, n_items)\n",
    "    X2[implicit.item] = implicit.rating\n",
    "\n",
    "    features = [\n",
    "        length(training.item) / n_items,\n",
    "        length(implicit.item) / n_items,\n",
    "        sum(get_split(\"recommendee\").rating) / length(training.item) / 10,\n",
    "    ]\n",
    "    features = convert.(Float32, features)\n",
    "    X3 = vcat(features, features .^ 2, sqrt.(features))\n",
    "\n",
    "    X = vcat(X1, X2, X3)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee91bdfa-841b-4ec1-a6e5-e10d854d535c",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_alphas()\n",
    "    [\n",
    "        x for x in read_params(\"CombineSignals\")[\"alphas\"] if\n",
    "        startswith(x, \"GNN\") && !endswith(x, \".Implicit\")\n",
    "    ]\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9926a40-3738-4849-b5ca-bba6b120db82",
   "metadata": {},
   "outputs": [],
   "source": [
    "function compute_alpha(alpha)\n",
    "    params = read_params(alpha)\n",
    "    BSON.@load params[\"model\"] m\n",
    "    if occursin(\"Rating\", alpha)\n",
    "        ratings = m(get_data(alpha))\n",
    "        write_recommendee_alpha(x -> ratings[x], outdir = \"$alpha\")\n",
    "    elseif occursin(\"Implicit\", alpha)\n",
    "        implicit = m(get_data(alpha))\n",
    "        softmax = exp.(implicit)\n",
    "        softmax = softmax ./ sum(softmax)\n",
    "        write_recommendee_alpha(x -> softmax[x], outdir = \"$alpha\")\n",
    "    else\n",
    "        ratings, implicit = m(get_data(alpha))\n",
    "        softmax = exp.(implicit)\n",
    "        softmax = softmax ./ sum(softmax)\n",
    "        write_recommendee_alpha(x -> ratings[x], outdir = \"$alpha\")\n",
    "        write_recommendee_alpha(x -> softmax[x], outdir = \"$alpha.Implicit\")\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aee4dc7a-6c5d-48d1-9b01-54e185326b65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:01:01\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "@showprogress for alpha in get_alphas()\n",
    "    if should_compute(alpha)\n",
    "        compute_alpha(alpha)\n",
    "    end\n",
    "end;"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.3",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetch User Anime List\n",
    "* Given a user, we get an up-to-date version of their anime list\n",
    "* Supports reading public anime-lists from MyAnimeList and AniList\n",
    "* Other websites can be used by exporting the list to XML (see https://malscraper.azurewebsites.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import time\n",
    "from io import StringIO\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "username = \"\"\n",
    "source = \"\"\n",
    "task = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allowed_sources = [\"MAL\", \"AniList\", \"Kitsu\", \"Training\"]\n",
    "assert source in allowed_sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join(\"../../data/recommendations\", username)\n",
    "if not os.path.exists(data_path):\n",
    "    os.makedirs(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"FetchMediaList\")\n",
    "logger.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter(\n",
    "    \"%(name)s:%(levelname)s:%(asctime)s: %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "for stream in [\n",
    "    logging.StreamHandler(),\n",
    "]:\n",
    "    stream.setFormatter(formatter)\n",
    "    logger.addHandler(stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Fetching lists for {username} from {source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_from_api(username, medium):\n",
    "    df, ret = get_user_media_list(username, medium)\n",
    "    if not ret:\n",
    "        raise Exception(f\"Could not resolve list for {username}\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_from_mal(username, medium):\n",
    "    pwd = os.getcwd()\n",
    "    try:\n",
    "        os.chdir(\"../API/API\")\n",
    "        %run MalApi.ipynb\n",
    "        df = import_from_api(username, medium)\n",
    "    finally:\n",
    "        os.chdir(pwd)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_from_anilist(username, medium):\n",
    "    pwd = os.getcwd()\n",
    "    try:\n",
    "        os.chdir(\"../API/API\")\n",
    "        %run AnilistApi.ipynb\n",
    "        userid = get_userid(username, medium)\n",
    "        df = import_from_api(userid)\n",
    "    finally:\n",
    "        os.chdir(pwd)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_from_kitsu(username, medium):\n",
    "    pwd = os.getcwd()\n",
    "    try:\n",
    "        os.chdir(\"../API/API\")\n",
    "        %run KitsuApi.ipynb\n",
    "        userid = get_userid(username, medium)\n",
    "        df = import_from_api(userid)\n",
    "    finally:\n",
    "        os.chdir(pwd)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_from_splits(username, medium, splits):\n",
    "    prefix = username + \",\"\n",
    "    userid = int(username)\n",
    "    lines = []\n",
    "    for content in [\"explicit\", \"implicit\", \"ptw\"]:\n",
    "        for split in splits:\n",
    "            fn = f\"../../data/splits/{content}.{task}.{split}.user_{medium}_list.csv\"\n",
    "            with open(fn) as f:\n",
    "                header = False\n",
    "                for line in tqdm(f):\n",
    "                    if not header:\n",
    "                        header = True\n",
    "                        fields = line.strip().split(\",\")\n",
    "                        assert fields.index(\"username\") == 0\n",
    "                        if not lines:\n",
    "                            lines.append(line)\n",
    "                        continue\n",
    "                    if line.startswith(prefix):\n",
    "                        lines.append(line)\n",
    "    df = pd.read_csv(StringIO(\"\\n\".join(lines)))\n",
    "    return df\n",
    "\n",
    "\n",
    "def import_from_training(username, medium):\n",
    "    return import_from_splits(username, medium, [\"training\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import_fns = {\n",
    "    \"MAL\": import_from_mal,\n",
    "    \"AniList\": import_from_anilist,\n",
    "    \"Kitsu\": import_from_kitsu,\n",
    "    \"Training\": import_from_training,\n",
    "}\n",
    "if not source in import_fns:\n",
    "    raise Exception(f\"Unsupported animelist source {source}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_path(source, medium):\n",
    "    return os.path.join(data_path, f\"user_{medium}_list.{source.lower()}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for medium in [\"anime\", \"manga\"]:\n",
    "    df = import_fns[source](username, medium)\n",
    "    for prev_source in allowed_sources:\n",
    "        path = save_path(prev_source, medium)\n",
    "        if os.path.exists(path):\n",
    "            os.remove(path)\n",
    "    df.to_csv(save_path(source, medium), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

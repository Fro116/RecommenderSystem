{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as st\n",
    "import statsmodels.formula.api as smf\n",
    "from scipy.special import gamma\n",
    "\n",
    "\n",
    "@functools.wraps(smf.ols)\n",
    "def lm(*args, **kwargs):\n",
    "    return smf.ols(*args, **kwargs).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommendee = \"Fro116\"\n",
    "neighborhood_size = 64\n",
    "confidence_interval = 0.99\n",
    "full_neighborhoods = False\n",
    "perform_regression = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "anime = pd.read_csv(\"AnimeList.csv\")\n",
    "anime = anime[[\"anime_id\", \"title\", \"type\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"UserAnimeList.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(283045, 14478, 0.01954064606703893, 80076112)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df[\"username\"].unique()), len(df[\"anime_id\"].unique()), len(df) / (\n",
    "    len(df[\"username\"].unique()) * len(df[\"anime_id\"].unique())\n",
    "), len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = df[[\"username\", \"anime_id\", \"my_score\"]].loc[lambda x: x[\"my_score\"] != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add additional user anime-lists\n",
    "extraUsers = pickle.load(open(\"user_profiles/ExtraUserAnimeLists.pkl\", \"rb\"))\n",
    "filtered_df = filtered_df.loc[lambda x: ~x[\"username\"].isin(extraUsers.username)]\n",
    "filtered_df = pd.concat([filtered_df, extraUsers], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "average_rating = filtered_df[\"my_score\"].mean()\n",
    "user_bias = (\n",
    "    pd.DataFrame(filtered_df.groupby(\"username\")[\"my_score\"].mean()).rename(\n",
    "        {\"my_score\": \"user_bias\"}, axis=1\n",
    "    )\n",
    "    - average_rating\n",
    ")\n",
    "anime_bias = (\n",
    "    pd.DataFrame(filtered_df.groupby(\"anime_id\")[\"my_score\"].mean()).rename(\n",
    "        {\"my_score\": \"anime_bias\"}, axis=1\n",
    "    )\n",
    "    - average_rating\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df = filtered_df.merge(anime_bias, on=[\"anime_id\"]).merge(\n",
    "    user_bias, on=[\"username\"]\n",
    ")\n",
    "filtered_df[\"normalized_score\"] = (\n",
    "    filtered_df[\"my_score\"]\n",
    "    - filtered_df[\"anime_bias\"]\n",
    "    - filtered_df[\"user_bias\"]\n",
    "    - average_rating\n",
    ")\n",
    "filtered_df = filtered_df.set_index(\"username\")\n",
    "filtered_df = filtered_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anime_id</th>\n",
       "      <th>my_score</th>\n",
       "      <th>anime_bias</th>\n",
       "      <th>user_bias</th>\n",
       "      <th>normalized_score</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>username</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>karthiga</th>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>0.960563</td>\n",
       "      <td>-0.059899</td>\n",
       "      <td>0.605474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>karthiga</th>\n",
       "      <td>59</td>\n",
       "      <td>7</td>\n",
       "      <td>0.040202</td>\n",
       "      <td>-0.059899</td>\n",
       "      <td>-0.474165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>karthiga</th>\n",
       "      <td>74</td>\n",
       "      <td>7</td>\n",
       "      <td>0.316282</td>\n",
       "      <td>-0.059899</td>\n",
       "      <td>-0.750244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>karthiga</th>\n",
       "      <td>120</td>\n",
       "      <td>7</td>\n",
       "      <td>0.309858</td>\n",
       "      <td>-0.059899</td>\n",
       "      <td>-0.743820</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>karthiga</th>\n",
       "      <td>178</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.227339</td>\n",
       "      <td>-0.059899</td>\n",
       "      <td>-0.206623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>temptemptemp</th>\n",
       "      <td>10040</td>\n",
       "      <td>6</td>\n",
       "      <td>-1.636718</td>\n",
       "      <td>-1.493861</td>\n",
       "      <td>1.636718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cinnamoroller</th>\n",
       "      <td>12963</td>\n",
       "      <td>10</td>\n",
       "      <td>-0.798861</td>\n",
       "      <td>2.506139</td>\n",
       "      <td>0.798861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>inactiveX</th>\n",
       "      <td>5143</td>\n",
       "      <td>7</td>\n",
       "      <td>-0.652952</td>\n",
       "      <td>-0.493861</td>\n",
       "      <td>0.652952</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>omgm</th>\n",
       "      <td>5581</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.857497</td>\n",
       "      <td>-2.493861</td>\n",
       "      <td>1.857497</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CategoryKing</th>\n",
       "      <td>33669</td>\n",
       "      <td>1</td>\n",
       "      <td>-1.592346</td>\n",
       "      <td>-6.493861</td>\n",
       "      <td>1.592346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>46358418 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               anime_id  my_score  anime_bias  user_bias  normalized_score\n",
       "username                                                                  \n",
       "karthiga             21         9    0.960563  -0.059899          0.605474\n",
       "karthiga             59         7    0.040202  -0.059899         -0.474165\n",
       "karthiga             74         7    0.316282  -0.059899         -0.750244\n",
       "karthiga            120         7    0.309858  -0.059899         -0.743820\n",
       "karthiga            178         7   -0.227339  -0.059899         -0.206623\n",
       "...                 ...       ...         ...        ...               ...\n",
       "temptemptemp      10040         6   -1.636718  -1.493861          1.636718\n",
       "cinnamoroller     12963        10   -0.798861   2.506139          0.798861\n",
       "inactiveX          5143         7   -0.652952  -0.493861          0.652952\n",
       "omgm               5581         5   -1.857497  -2.493861          1.857497\n",
       "CategoryKing      33669         1   -1.592346  -6.493861          1.592346\n",
       "\n",
       "[46358418 rows x 5 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filtered_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_corrs = pickle.load(open(\"item_correlations/correlations.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_corrs[\"similarity\"] = all_corrs[\"corr\"].abs()\n",
    "all_corrs = all_corrs.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs = all_corrs.loc[\n",
    "    lambda x: x.index.get_level_values(\"anime_id_x\")\n",
    "    != x.index.get_level_values(\"anime_id_y\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "if full_neighborhoods:\n",
    "    corrs = corrs.groupby(\"anime_id_x\").apply(lambda x: x.sort_values(by=\"similarity\"))\n",
    "else:\n",
    "    corrs = corrs.groupby(\"anime_id_x\").apply(\n",
    "        lambda x: x.sort_values(by=\"similarity\")[-neighborhood_size:]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs.index = corrs.index.droplevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score = filtered_df.loc[recommendee].merge(\n",
    "    corrs.reset_index(\"anime_id_x\"), left_on=\"anime_id\", right_on=\"anime_id_y\"\n",
    ")\n",
    "\n",
    "user_var = (\n",
    "    pd.DataFrame(filtered_df.groupby(\"username\")[\"normalized_score\"].var())\n",
    "    .rename({\"normalized_score\": \"user_var\"}, axis=1)\n",
    "    .dropna()\n",
    ")\n",
    "score[\"user_var\"] = user_var.loc[recommendee].squeeze()\n",
    "\n",
    "anime_var = (\n",
    "    pd.DataFrame(filtered_df.groupby(\"anime_id\")[\"normalized_score\"].var())\n",
    "    .rename({\"normalized_score\": \"anime_var\"}, axis=1)\n",
    "    .dropna()\n",
    ")\n",
    "score = score.merge(anime_var, on=\"anime_id\")\n",
    "\n",
    "score = score.drop(\"anime_id\", axis=1).rename({\"anime_id_x\": \"anime_id\"}, axis=1)\n",
    "\n",
    "if full_neighborhoods:\n",
    "    score = (\n",
    "        score.groupby(\"anime_id\")\n",
    "        .apply(lambda x: x.sort_values(by=\"similarity\")[-neighborhood_size:])\n",
    "        .reset_index(drop=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas = score.groupby(\"anime_id\").apply(\n",
    "    lambda x: np.dot(x[\"normalized_score\"], x[\"corr\"]) / x[\"corr\"].abs().sum()\n",
    ")\n",
    "weights = score.groupby(\"anime_id\").apply(lambda x: x[\"corr\"].abs().sum())\n",
    "counts = score.groupby(\"anime_id\").size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following formulae are used to compute the variance of the delta. Delta\n",
    "# is a weighted sum of the form Î´ = Î£(s_i * w_i) / (Î£w_i), where s_i is\n",
    "# a vector scores for item i and w_i is the weight for item_i.\n",
    "#\n",
    "# By linearity, it suffices to compute (s_i * w_i) / (Î£w_i). We assume that\n",
    "# Var(s_i) is the same as the variance over the vector s_i (i.e. over\n",
    "# all users s_i has rated). We treat w_i as a random variable with mean w_i\n",
    "# and variance corr['corr_var']\n",
    "#\n",
    "# The variance for (w_i) / (Î£w_i) can be estimated by doing a Taylor Approximation.\n",
    "# See equation 20 of https://www.stat.cmu.edu/~hseltman/files/ratio.pdf. The\n",
    "# formula for the ratio of two correlated variables R,S is\n",
    "# Var(R/S) = E[R]^2/E[S]^2(Var[R]/E[R]^2 - 2Cov(R,S)/(E[R]E[S]) + Var[S]/E[S]^2)\n",
    "#\n",
    "# Lastly we take the product distribution of s_i and (w_i) / (Î£w_i).\n",
    "def correction_factor(x):\n",
    "    return (\n",
    "        1\n",
    "        + x[\"corr_var\"] / (x[\"corr\"] ** 2)\n",
    "        - 2 * x[\"corr_var\"] / (x[\"corr\"].abs().sum() * x[\"corr\"].abs())\n",
    "        + x[\"corr_var\"].sum() / (x[\"corr\"].abs().sum() ** 2)\n",
    "    )\n",
    "\n",
    "\n",
    "delta_var = score.groupby(\"anime_id\").apply(\n",
    "    lambda x: np.sum(x[\"user_var\"] * x[\"corr\"] ** 2 * correction_factor(x))\n",
    "    / (x[\"corr\"].abs().sum() ** 2)\n",
    ")\n",
    "\n",
    "# if the var < 0, then the ratio distribution approximation failed,\n",
    "# usually because sample size is too small\n",
    "delta_var.loc[lambda x: x < 0] = np.inf\n",
    "\n",
    "# Apply a bessel correction to unbias the variance\n",
    "average_weight = corrs.groupby(\"anime_id_x\").apply(lambda x: x[\"corr\"].abs().mean())\n",
    "effective_sample_size = weights / average_weight\n",
    "delta_var.loc[effective_sample_size <= 1] = np.inf\n",
    "delta_var.loc[effective_sample_size > 1] *= effective_sample_size / (effective_sample_size - 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_df = pd.DataFrame()\n",
    "pred_df[\"delta\"] = deltas\n",
    "pred_df[\"weight\"] = weights\n",
    "pred_df[\"counts\"] = counts\n",
    "pred_df[\"delta_sem\"] = np.sqrt(delta_var)\n",
    "\n",
    "# # Unbias the standard deviation estimate\n",
    "# # See https://en.wikipedia.org/wiki/Unbiased_estimation_of_standard_deviation#Results_for_the_normal_distribution\n",
    "# def standard_deviation_bias(n):\n",
    "#     if n < 1:\n",
    "#         return np.inf\n",
    "#     if gamma((n - 1) / 2) == np.inf:\n",
    "#         return 1\n",
    "#     return np.sqrt(2 / (n - 1)) * gamma(n / 2) / gamma((n - 1) / 2)\n",
    "# pred_df[\"delta_sem\"] /= effective_sample_size.apply(standard_deviation_bias)\n",
    "\n",
    "pred_df[\"blp\"] = anime_bias + user_bias.loc[recommendee].squeeze() + average_rating\n",
    "pred_df = pred_df.dropna()\n",
    "\n",
    "recomendee_seen_shows = filtered_df.loc[recommendee].merge(pred_df, on=[\"anime_id\"])\n",
    "recomendee_seen_shows[\"target\"] = (\n",
    "    recomendee_seen_shows[\"my_score\"] - recomendee_seen_shows[\"blp\"]\n",
    ")\n",
    "if perform_regression:\n",
    "\n",
    "    model = lm(\"target ~ delta + 0\", recomendee_seen_shows)\n",
    "    pred_df[\"score\"] = model.predict(pred_df) + pred_df[\"blp\"]\n",
    "    pred_df[\"sem\"] = np.sqrt(\n",
    "        (\n",
    "            (pred_df[\"delta_sem\"] ** 2 + pred_df[\"delta\"] ** 2)\n",
    "            * (model.bse[\"delta\"] ** 2 + model.params[\"delta\"] ** 2)\n",
    "        )\n",
    "        - pred_df[\"delta\"] ** 2 * model.params[\"delta\"] ** 2\n",
    "    )\n",
    "else:\n",
    "    pred_df[\"score\"] = pred_df[\"delta\"] + pred_df[\"blp\"]\n",
    "    pred_df[\"sem\"] = pred_df[\"delta_sem\"]\n",
    "\n",
    "\n",
    "zscore = st.norm.ppf(1 - (1 - confidence_interval) / 2)\n",
    "pred_df[\"score_lower_bound\"] = pred_df[\"score\"] - pred_df[\"sem\"] * zscore\n",
    "pred_df[\"score_upper_bound\"] = pred_df[\"score\"] + pred_df[\"sem\"] * zscore\n",
    "\n",
    "pred_df = pred_df.merge(anime, on=\"anime_id\")\n",
    "pred_df = pred_df.set_index(\"anime_id\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that setting blp = 1 is reasonable\n",
    "print(lm(\"my_score ~ delta + blp + 0\", recomendee_seen_shows).summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm that the top shows are ones that the user rates highly\n",
    "pred_df.loc[lambda x: x[\"delta\"] > 0].sort_values(\n",
    "    by=\"score_lower_bound\", ascending=False\n",
    ")[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_recs = pred_df.drop(filtered_df.loc[recommendee].anime_id, errors=\"ignore\").loc[\n",
    "    lambda x: (x[\"type\"] != \"Movie\")\n",
    "    & (x[\"type\"] != \"Special\")\n",
    "    & (x[\"type\"] != \"OVA\")\n",
    "    & (x[\"type\"] != \"ONA\")\n",
    "    & (x[\"type\"] != \"Music\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_recs.loc[lambda x: (x[\"delta\"] > 0)].sort_values(\n",
    "    by=\"score_lower_bound\", ascending=False\n",
    ")[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_recs.loc[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_df.loc[\"Fro116\"].loc[lambda x: x['anime_id'].isin([31964, 1575, 2904, 1535, 121, 2001, 245])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

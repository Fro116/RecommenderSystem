{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbf03b87-063f-46fe-b392-0d6399dca361",
   "metadata": {},
   "source": [
    "# Generate Splits\n",
    "* Create training, validation and test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b1ceb4-d65a-410a-b876-93c491c0cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import yaml\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992a0836-bb2b-4956-b075-49dbf38aa079",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"../../data/processed_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24a8f49-53b5-4106-8fe5-84ba572eead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"../../data/splits\"\n",
    "os.makedirs(outdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c751bc98-5002-4bf3-bb4c-08f88b2ac167",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "media = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc60a8ff-ec51-4294-82a0-a945a36ad69e",
   "metadata": {},
   "source": [
    "# Sort items by timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa6376f-09f3-4b44-8117-9771371572d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shard_by_user(file, num_shards):\n",
    "    try:\n",
    "        outfiles = []\n",
    "        for i in range(num_shards):\n",
    "            outfiles.append(open(f\"{file}.shard.{i}\", \"w\"))\n",
    "        with open(file) as in_file:\n",
    "            header = False\n",
    "            for line in tqdm(in_file):\n",
    "                if not header:\n",
    "                    header = True\n",
    "                    user_col = line.strip().split(\",\").index(\"userid\")\n",
    "                    for f in outfiles:\n",
    "                        f.write(line)\n",
    "                    continue\n",
    "                fields = line.strip().split(\",\")\n",
    "                user = fields[user_col]\n",
    "                outfiles[int(user) % num_shards].write(line)\n",
    "    finally:\n",
    "        for f in outfiles:\n",
    "            f.close()\n",
    "\n",
    "\n",
    "def temporal_sort(input_fn, output_fn):\n",
    "    df = pd.read_csv(input_fn, dtype=str)\n",
    "    for key, dtype in zip([\"userid\", \"update_order\", \"updated_at\"], [int, int, float]):\n",
    "        df[key] = df[key].astype(dtype)\n",
    "    df = df.sort_values(by=[\"userid\", \"update_order\", \"updated_at\"]).reset_index(\n",
    "        drop=True\n",
    "    )\n",
    "    df[\"unit\"] = 1\n",
    "    df[\"forward_order\"] = (\n",
    "        df.groupby(\"userid\", group_keys=False)[\"unit\"]\n",
    "        .apply(lambda x: x.cumsum())\n",
    "        .values\n",
    "    )\n",
    "    df[\"backward_order\"] = (\n",
    "        df.groupby(\"userid\", group_keys=False)[\"unit\"]\n",
    "        .apply(lambda x: x.cumsum()[::-1])\n",
    "        .values\n",
    "    )\n",
    "    df.to_csv(output_fn, index=False)\n",
    "\n",
    "\n",
    "def sharded_temporal_sort(input_fn, output_fn, num_shards=16):\n",
    "    shard_by_user(input_fn, num_shards)\n",
    "    for i in tqdm(range(num_shards)):\n",
    "        temporal_sort(f\"{input_fn}.shard.{i}\", f\"{output_fn}.shard.{i}\")\n",
    "        os.remove(f\"{input_fn}.shard.{i}\")\n",
    "    with open(output_fn, \"w\") as outfile:\n",
    "        for i in tqdm(range(num_shards)):\n",
    "            fn = f\"{output_fn}.shard.{i}\"\n",
    "            with open(fn) as infile:\n",
    "                header = False\n",
    "                for line in infile:\n",
    "                    if not header:\n",
    "                        header = True\n",
    "                        if i == 0:\n",
    "                            outfile.write(line)\n",
    "                        continue\n",
    "                    outfile.write(line)\n",
    "            os.remove(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14505770-a2c1-42b3-a096-ab84e8ea6225",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharded_temporal_sort(\n",
    "    os.path.join(source_dir, f\"user_{media}_list.csv\"),\n",
    "    os.path.join(outdir, f\"user_{media}_list.sorted.training.csv\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f73bc9e-efa3-441e-8bc3-5be752a3ba43",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sharded_temporal_sort(\n",
    "    os.path.join(source_dir, f\"prune.{media}.knowledge_cutoff.csv\"),\n",
    "    os.path.join(outdir, f\"user_{media}_list.sorted.test.csv\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08844257-5ad8-47a2-9cd3-c59c5009764e",
   "metadata": {},
   "source": [
    "# Generate splits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70ac8124-64c4-42db-a292-d1757d776fbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_split(userid):\n",
    "    if userid % 100 == 0:\n",
    "        return \"validation\"\n",
    "    else:\n",
    "        return \"training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d872c37-a89e-4efb-8189-58e59c943da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cutoff(days):\n",
    "    def parse_line(file, field, format=int):\n",
    "        line = file.readline()\n",
    "        fields = line.strip().split(\",\")\n",
    "        assert len(fields) == 2\n",
    "        assert fields[0] == field\n",
    "        return format(fields[1])\n",
    "\n",
    "    with open(os.path.join(source_dir, \"timestamps.csv\")) as f:\n",
    "        min_timestamp = parse_line(f, \"min_timestamp\")\n",
    "        max_timestamp = parse_line(f, \"max_timestamp\")\n",
    "\n",
    "    with open(os.path.join(source_dir, \"knowledge_cutoff.csv\")) as f:\n",
    "        knowledge_cutoff = parse_line(f, \"knowledge_cutoff\", float)\n",
    "\n",
    "    seconds_in_day = 24 * 60 * 60\n",
    "    return knowledge_cutoff - days * seconds_in_day / (max_timestamp - min_timestamp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb12e98-4d09-4e4a-868f-e28d255337f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_training_splits(timestamp_cutoff, num_interactions):\n",
    "    input_fn = os.path.join(outdir, f\"user_{media}_list.sorted.training.csv\")\n",
    "    files = {\n",
    "        x: open(os.path.join(outdir, f\"{x}.user_{media}_list.csv\"), \"w\")\n",
    "        for x in [\"training\", \"validation\"]\n",
    "    }\n",
    "    with open(input_fn) as f:\n",
    "        header = False\n",
    "        for line in tqdm(f):\n",
    "            fields = line.strip().split(\",\")\n",
    "            if not header:\n",
    "                header = True\n",
    "                timestamp_col = fields.index(\"updated_at\")\n",
    "                user_col = fields.index(\"userid\")\n",
    "                order_col = fields.index(\"backward_order\")\n",
    "                for g in files.values():\n",
    "                    g.write(line)\n",
    "                continue\n",
    "            userid = int(fields[user_col])\n",
    "            timestamp = float(fields[timestamp_col])\n",
    "            order = int(fields[order_col])\n",
    "            train = (\n",
    "                (timestamp < timestamp_cutoff)\n",
    "                or (order > num_interactions)\n",
    "                or get_split(userid) == \"training\"\n",
    "            )\n",
    "            split = \"training\" if train else \"validation\"\n",
    "            files[split].write(line)\n",
    "    for f in files.values():\n",
    "        f.close()\n",
    "    os.remove(input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd823e2-59ec-4221-ac48-51b00e44d498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_test_splits(num_interactions):\n",
    "    input_fn = os.path.join(outdir, f\"user_{media}_list.sorted.test.csv\")\n",
    "    output_fn = os.path.join(outdir, f\"test.user_{media}_list.csv\")\n",
    "    with open(input_fn) as f:\n",
    "        with open(output_fn, \"w\") as g:\n",
    "            header = False\n",
    "            for line in tqdm(f):\n",
    "                fields = line.strip().split(\",\")\n",
    "                if not header:\n",
    "                    header = True\n",
    "                    user_col = fields.index(\"userid\")\n",
    "                    order_col = fields.index(\"forward_order\")\n",
    "                    g.write(line)\n",
    "                    continue\n",
    "                userid = int(fields[user_col])\n",
    "                order = int(fields[order_col])\n",
    "                if order <= num_interactions and get_split(userid) == \"training\":\n",
    "                    g.write(line)\n",
    "    os.remove(input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a846304-9f02-4d1d-a77c-18a71fd48e05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_settings():\n",
    "    with open(\"../../environment/settings.yml\", \"r\") as f:\n",
    "        return yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da7f883-b430-405c-bf49-968d8ca9d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# interactions will go in the val split if the user is in the val split\n",
    "# AND the the interaction is one of the user's N most recent watches\n",
    "# AND the interaction occured less that M days ago\n",
    "settings = get_settings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f31d6cd-bcef-4778-bd6d-6fc071ae1997",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_training_splits(\n",
    "    get_cutoff(settings[\"cutoff_days\"]),\n",
    "    settings[\"cutoff_interactions\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31e5cc01-8583-4d0a-b929-1bd28484d892",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_test_splits(num_interactions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

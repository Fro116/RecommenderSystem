{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbf03b87-063f-46fe-b392-0d6399dca361",
   "metadata": {},
   "source": [
    "# Split the data into training/validation/test/negative sets\n",
    "* The explicit rating data is split into a 90%/10% training/test ratio\n",
    "* The training set is further split into a training set and a validation set, using the same 90/10 ratio\n",
    "* The userids and itemids for the validation and test splits are clipped such that the maximum userid and the maximum itemid occur within the training set (this will simplify array indexing later on).\n",
    "* A negative set is sampled uniformly at random. This set consists of (user, item) pairs that the user did not watch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54b1ceb4-d65a-410a-b876-93c491c0cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "992a0836-bb2b-4956-b075-49dbf38aa079",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"../../data/processed_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "167c509b-62a9-492d-965c-78e5631e7085",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"../../data/splits\"\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c2a0e857-4540-4732-a475-9f88b8c79fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f06f40a8-8747-40a9-92da-8c0778b33a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits the input file into a training set and a test set\n",
    "def split(input_fn, train_fn, test_fn, p_training=0.9):\n",
    "    with open(input_fn, \"r\") as in_file, open(train_fn, \"w\") as training, open(\n",
    "        test_fn, \"w\"\n",
    "    ) as test:\n",
    "        header = False\n",
    "        for line in tqdm(in_file):\n",
    "            if not header:\n",
    "                header = True\n",
    "                training.write(line)\n",
    "                test.write(line)\n",
    "                continue\n",
    "            if random.random() < p_training:\n",
    "                training.write(line)\n",
    "            else:\n",
    "                test.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bf5209b3-e097-4796-9dab-683971484de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scans every line of the input file. If the line satisfies the\n",
    "# condition, then it is removed from the input file and appended\n",
    "# to the output file\n",
    "def clip(input_fn, output_fn, condition):\n",
    "    with open(input_fn, \"r\") as in_file, open(input_fn + \"~\", \"w\") as tmp_in_file, open(\n",
    "        output_fn, \"a\"\n",
    "    ) as out_file:\n",
    "        header = False\n",
    "        for line in tqdm(in_file):\n",
    "            if not header:\n",
    "                header = True\n",
    "                tmp_in_file.write(line)\n",
    "                continue\n",
    "            if condition(line):\n",
    "                tmp_in_file.write(line)\n",
    "            else:\n",
    "                out_file.write(line)\n",
    "        os.rename(input_fn + \"~\", input_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "62435eba-94fe-4070-acbd-6cc5b66eda40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_ids(input_fns):\n",
    "    max_userid = -1\n",
    "    max_itemid = -1\n",
    "    for input_fn in input_fns:\n",
    "        with open(input_fn, \"r\") as in_file:\n",
    "            header = False\n",
    "            for line in tqdm(in_file):\n",
    "                if not header:\n",
    "                    header = True\n",
    "                    continue\n",
    "                userid, itemid, rating = line.split(\",\")\n",
    "                max_userid = max(max_userid, int(userid))\n",
    "                max_itemid = max(max_itemid, int(itemid))\n",
    "    return max_userid, max_itemid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0462bf66-4d6a-43ad-8539-50574f8f9b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dict of user -> set of item ids\n",
    "def get_user_item_pairs(input_fns):\n",
    "    user_items = {}\n",
    "    for input_fn in input_fns:\n",
    "        with open(input_fn, \"r\") as in_file:\n",
    "            header = False\n",
    "            for line in tqdm(in_file):\n",
    "                if not header:\n",
    "                    header = True\n",
    "                    continue\n",
    "                userid, itemid, rating = line.split(\",\")\n",
    "                userid, itemid = int(userid), int(itemid)\n",
    "                if userid not in user_items:\n",
    "                    user_items[userid] = set()\n",
    "                user_items[userid].add(itemid)\n",
    "    return user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2a08ef5-ef6c-4ba8-bc06-3fd2d83c7ee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def length(input_fn):\n",
    "    lines = 0\n",
    "    with open(input_fn, \"r\") as in_file:\n",
    "        header = False\n",
    "        for line in tqdm(in_file):\n",
    "            if not header:\n",
    "                header = True\n",
    "                continue\n",
    "            lines += 1\n",
    "    return lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f9d19563-f0a7-4599-9ecc-ad0f98502b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writes out a split of `sample_size` (user, item) pairs that\n",
    "# are sampled uniformly at random from (user, item) pairs where\n",
    "# the user has not seen the item\n",
    "def sample_negative_set(\n",
    "    user_item_pairs, max_userid, max_itemid, sample_size, output_fn\n",
    "):\n",
    "    with open(output_fn, \"w\") as out_file:\n",
    "        out_file.write(\"user,item,rating\\n\")\n",
    "        with tqdm(total=sample_size) as pbar:\n",
    "            while sample_size > 0:\n",
    "                user = random.randint(0, max_userid - 1)\n",
    "                item = random.randint(0, max_itemid - 1)\n",
    "                if user in user_item_pairs and item in user_item_pairs[user]:\n",
    "                    continue\n",
    "                if user not in user_item_pairs:\n",
    "                    user_item_pairs[user] = set()\n",
    "                user_item_pairs[user].add(item)\n",
    "                out_file.write(f\"{user},{item},0\\n\")\n",
    "                sample_size -= 1\n",
    "                pbar.update(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519843b7-f8c2-4e8a-be36-016de0b8f68a",
   "metadata": {},
   "source": [
    "## Construct training/validation/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed80de47-da9d-429e-984b-2e21fdc7f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_splits(feature):\n",
    "    assert feature in {\"explicit\", \"implicit\"}\n",
    "    split(\n",
    "        os.path.join(source_dir, f\"user_{feature}_lists.csv\"),\n",
    "        os.path.join(outdir, f\"{feature}_trainval.csv\"),\n",
    "        os.path.join(outdir, f\"{feature}_test.csv\"),\n",
    "    )\n",
    "    split(\n",
    "        os.path.join(outdir, f\"{feature}_trainval.csv\"),\n",
    "        os.path.join(outdir, f\"{feature}_training.csv\"),\n",
    "        os.path.join(outdir, f\"{feature}_validation.csv\"),\n",
    "    )\n",
    "    os.remove(os.path.join(outdir, f\"{feature}_trainval.csv\"))\n",
    "\n",
    "    max_training_userid, max_training_itemid = get_max_ids(\n",
    "        [os.path.join(outdir, f\"{feature}_training.csv\")]\n",
    "    )\n",
    "\n",
    "    def filter_maxids(x):\n",
    "        userid, itemid, rating = x.split(\",\")\n",
    "        return (int(userid) <= max_training_userid) and (\n",
    "            int(itemid) <= max_training_itemid\n",
    "        )\n",
    "\n",
    "    clip(\n",
    "        os.path.join(outdir, f\"{feature}_validation.csv\"),\n",
    "        os.path.join(outdir, f\"{feature}_training.csv\"),\n",
    "        filter_maxids,\n",
    "    )\n",
    "\n",
    "    clip(\n",
    "        os.path.join(outdir, f\"{feature}_test.csv\"),\n",
    "        os.path.join(outdir, f\"{feature}_training.csv\"),\n",
    "        filter_maxids,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "65525017-7a5e-444b-8c96-6204cacf2e06",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168626003it [01:15, 2238288.04it/s]\n",
      "151763170it [01:09, 2173577.91it/s]\n",
      "136583943it [02:20, 973885.12it/s] \n",
      "15179228it [00:13, 1111835.63it/s]\n",
      "16862834it [00:15, 1057356.98it/s]\n",
      "61471672it [00:27, 2260328.50it/s]\n",
      "55322163it [00:25, 2182538.43it/s]\n",
      "49787458it [00:52, 954731.22it/s] \n",
      "5534706it [00:05, 1058907.45it/s]\n",
      "6149510it [00:05, 1057751.87it/s]\n"
     ]
    }
   ],
   "source": [
    "generate_splits(\"explicit\")\n",
    "generate_splits(\"implicit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa856c27-f960-47b3-8637-791dce23b0d2",
   "metadata": {},
   "source": [
    "## Construct the negative test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a633681d-0fb7-439e-b9d1-f5c6aa3c7a85",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "168626003it [04:29, 626164.80it/s] \n",
      "61471672it [03:06, 330120.87it/s]\n",
      "136583943it [02:21, 964650.75it/s]\n",
      "49787458it [00:51, 965288.95it/s]\n",
      "16862834it [00:04, 3826675.19it/s]\n",
      "6149510it [00:01, 3825311.77it/s]\n",
      "100%|████████████████████████████| 23012342/23012342 [07:02<00:00, 54411.42it/s]\n"
     ]
    }
   ],
   "source": [
    "user_items = get_user_item_pairs(\n",
    "    [\n",
    "        os.path.join(source_dir, f\"user_{feature}_lists.csv\")\n",
    "        for feature in [\"explicit\", \"implicit\"]\n",
    "    ]\n",
    ")\n",
    "max_userid, max_itemid = get_max_ids(\n",
    "    [\n",
    "        os.path.join(outdir, f\"{feature}_training.csv\")\n",
    "        for feature in [\"explicit\", \"implicit\"]\n",
    "    ]\n",
    ")\n",
    "num_negative_samples = sum(\n",
    "    length(os.path.join(outdir, f\"{feature}_test.csv\"))\n",
    "    for feature in [\"explicit\", \"implicit\"]\n",
    ")\n",
    "sample_negative_set(\n",
    "    user_items,\n",
    "    max_userid,\n",
    "    max_itemid,\n",
    "    num_negative_samples,\n",
    "    os.path.join(outdir, \"negative.csv\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f63dc06-142e-4834-8318-8fbcb309b768",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

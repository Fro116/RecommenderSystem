{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbf03b87-063f-46fe-b392-0d6399dca361",
   "metadata": {},
   "source": [
    "# Generate Splits\n",
    "* We split the dataset into explicit interactions, implicit interactinos, and plan-to-watch interactions\n",
    "* Each of the above splits is further separated into a training, validation, and test split\n",
    "* The training/validation/test splits are temporally separated per user, and are in an approximately 90/5/5 ratio\n",
    "* In addition, a negative split is sampled. This set consists of (user, item) pairs that the user did not watch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b1ceb4-d65a-410a-b876-93c491c0cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992a0836-bb2b-4956-b075-49dbf38aa079",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"../../data/processed_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24a8f49-53b5-4106-8fe5-84ba572eead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir= \"../../data/splits\"\n",
    "os.makedirs(outdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a0e857-4540-4732-a475-9f88b8c79fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4a1ed8-3bf5-4571-b02d-b2494298e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_sort(input_fn, output_fn):\n",
    "    user_anime_lists = pd.read_csv(input_fn)\n",
    "    # fast pseudorandom shuffle\n",
    "    rng = list(range(len(user_anime_lists)))\n",
    "    c = 1\n",
    "    p = 15485863 # a prime number\n",
    "    n = len(rng)\n",
    "    for i in tqdm(range(n)):\n",
    "        rng[i] = c\n",
    "        c = (c * p) % n\n",
    "    user_anime_lists[\"rng\"] = rng\n",
    "    user_anime_lists = user_anime_lists.sort_values(by=[\"timestamp\", \"rng\"])\n",
    "    user_anime_lists = user_anime_lists.drop(\"rng\", axis=1)\n",
    "    user_anime_lists.to_csv(output_fn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec474dc-e9c2-49d1-a912-07a02a85dad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_counts(input_fn):\n",
    "    user_to_count = {}\n",
    "    with open(input_fn, \"r\") as in_file:\n",
    "        header = False\n",
    "        for line in tqdm(in_file):\n",
    "            if not header:\n",
    "                header = True\n",
    "                continue\n",
    "            fields = line.strip().split(\",\")\n",
    "            user = fields[0]\n",
    "            if user not in user_to_count:\n",
    "                user_to_count[user] = 0\n",
    "            user_to_count[user] += 1\n",
    "    return user_to_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f06f40a8-8747-40a9-92da-8c0778b33a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splits the input file into a training set and a test set\n",
    "def temporal_split(input_fn, train_fn, test_fn, p_training):\n",
    "    user_counts = get_user_counts(input_fn)\n",
    "    seen_counts = {u: 0 for u in user_counts}\n",
    "    with open(input_fn, \"r\") as in_file, open(train_fn, \"w\") as training, open(\n",
    "        test_fn, \"w\"\n",
    "    ) as test:\n",
    "        header = False\n",
    "        for line in tqdm(in_file):\n",
    "            if not header:\n",
    "                header = True\n",
    "                training.write(line)\n",
    "                test.write(line)\n",
    "                continue\n",
    "            username = line.strip().split(\",\")[0]\n",
    "            if (\n",
    "                seen_counts[username] + random.random()\n",
    "                < user_counts[username] * p_training\n",
    "            ):\n",
    "                training.write(line)\n",
    "            else:\n",
    "                test.write(line)\n",
    "            seen_counts[username] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d872c37-a89e-4efb-8189-58e59c943da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(input_fn, train_fn, test_fn, p_training):\n",
    "    with open(input_fn, \"r\") as in_file, open(train_fn, \"w\") as training, open(\n",
    "        test_fn, \"w\"\n",
    "    ) as test:\n",
    "        header = False\n",
    "        for line in tqdm(in_file):\n",
    "            if not header:\n",
    "                header = True\n",
    "                training.write(line)\n",
    "                test.write(line)\n",
    "                continue\n",
    "            if random.random() < p_training:\n",
    "                training.write(line)\n",
    "            else:\n",
    "                test.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5209b3-e097-4796-9dab-683971484de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scans every line of the input file. If the line satisfies the\n",
    "# condition, then it is removed from the input file and written\n",
    "# to the output file\n",
    "def subset(input_fn, output_fn, condition):\n",
    "    with open(input_fn, \"r\") as in_file, open(output_fn, \"w\") as out_file:\n",
    "        header = False\n",
    "        for line in tqdm(in_file):\n",
    "            if not header:\n",
    "                header = True\n",
    "                out_file.write(line)\n",
    "                continue\n",
    "            if condition(line):\n",
    "                out_file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519843b7-f8c2-4e8a-be36-016de0b8f68a",
   "metadata": {},
   "source": [
    "## Construct training/validation/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80de47-da9d-429e-984b-2e21fdc7f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_temporal_splits():\n",
    "    feature = \"user_anime_list_sorted\"\n",
    "    temporal_sort(\n",
    "        os.path.join(source_dir, \"user_anime_list.csv\"),\n",
    "        os.path.join(outdir, f\"{feature}.csv\"),\n",
    "    )\n",
    "    temporal_split(\n",
    "        os.path.join(outdir, f\"{feature}.csv\"),\n",
    "        os.path.join(outdir, f\"{feature}_training.csv\"),\n",
    "        os.path.join(outdir, f\"{feature}_valtest.csv\"),\n",
    "        0.9,\n",
    "    )\n",
    "    random_split(\n",
    "        os.path.join(outdir, f\"{feature}_valtest.csv\"),\n",
    "        os.path.join(outdir, f\"{feature}_validation.csv\"),\n",
    "        os.path.join(outdir, f\"{feature}_test.csv\"),\n",
    "        0.5,\n",
    "    )\n",
    "    os.remove(os.path.join(outdir, f\"{feature}_valtest.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61ef704-e06a-45a0-987c-263721df50ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_content_splits(split):\n",
    "    subset(\n",
    "        os.path.join(outdir, f\"user_anime_list_sorted_{split}.csv\"),\n",
    "        os.path.join(outdir, f\"ptw_{split}.csv\"),\n",
    "        lambda x: x.strip().split(\",\")[4] == \"1\",\n",
    "    )\n",
    "    subset(\n",
    "        os.path.join(outdir, f\"user_anime_list_sorted_{split}.csv\"),\n",
    "        os.path.join(outdir, f\"implicit_{split}.csv\"),\n",
    "        lambda x: float(x.strip().split(\",\")[2]) == 0\n",
    "        and x.strip().split(\",\")[4] != \"1\",\n",
    "    )\n",
    "    subset(\n",
    "        os.path.join(outdir, f\"user_anime_list_sorted_{split}.csv\"),\n",
    "        os.path.join(outdir, f\"explicit_{split}.csv\"),\n",
    "        lambda x: float(x.strip().split(\",\")[2]) != 0\n",
    "        and x.strip().split(\",\")[4] != \"1\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa856c27-f960-47b3-8637-791dce23b0d2",
   "metadata": {},
   "source": [
    "## Construct negative splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0462bf66-4d6a-43ad-8539-50574f8f9b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns a dict of user -> set of item ids\n",
    "def get_user_item_pairs(input_fns):\n",
    "    user_items = {}\n",
    "    for input_fn in input_fns:\n",
    "        with open(input_fn, \"r\") as in_file:\n",
    "            header = False\n",
    "            for line in tqdm(in_file):\n",
    "                if not header:\n",
    "                    header = True\n",
    "                    continue\n",
    "                fields = line.strip().split(\",\")\n",
    "                userid = fields[0]\n",
    "                itemid = fields[1]\n",
    "                userid, itemid = int(userid), int(itemid)\n",
    "                if userid not in user_items:\n",
    "                    user_items[userid] = set()\n",
    "                user_items[userid].add(itemid)\n",
    "    return user_items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66573a69-5238-4e89-b19c-fbeff9bfea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_ids(input_fn):\n",
    "    max_userid = -1\n",
    "    max_itemid = -1\n",
    "    with open(input_fn, \"r\") as in_file:\n",
    "        header = False\n",
    "        for line in tqdm(in_file):\n",
    "            if not header:\n",
    "                header = True\n",
    "                continue\n",
    "            fields = line.strip().split(\",\")\n",
    "            userid = fields[0]\n",
    "            itemid = fields[1]\n",
    "            userid, itemid = int(userid), int(itemid)\n",
    "            max_userid = max(max_userid, int(userid))\n",
    "            max_itemid = max(max_itemid, int(itemid))\n",
    "    return max_userid, max_itemid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9d19563-f0a7-4599-9ecc-ad0f98502b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# writes out a split of `sample_size` (user, item) pairs that\n",
    "# are sampled uniformly at random from (user, item) pairs where\n",
    "# the user has not seen the item\n",
    "def sample_negative_set(\n",
    "    user_item_pairs, max_userid, max_itemid, sample_size, output_fn\n",
    "):\n",
    "    with open(output_fn, \"w\") as out_file:\n",
    "        out_file.write(\"user,item\\n\")\n",
    "        with tqdm(total=sample_size) as pbar:\n",
    "            while sample_size > 0:\n",
    "                user = random.randint(0, max_userid)\n",
    "                item = random.randint(0, max_itemid)\n",
    "                if user in user_item_pairs and item in user_item_pairs[user]:\n",
    "                    continue\n",
    "                if user not in user_item_pairs:\n",
    "                    user_item_pairs[user] = set()\n",
    "                user_item_pairs[user].add(item)\n",
    "                out_file.write(f\"{user},{item}\\n\")\n",
    "                sample_size -= 1\n",
    "                pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99ff6ac-3304-48d8-bfe6-9f716c3c4036",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_negative_splits():\n",
    "    max_userid, max_itemid = get_max_ids(os.path.join(outdir, \"user_anime_list_sorted.csv\"))\n",
    "    splits = [\"training\", \"validation\", \"test\"]\n",
    "    num_samples = max_userid * 100    \n",
    "    for i in range(len(splits)):\n",
    "        user_item_pairs = get_user_item_pairs(\n",
    "            [os.path.join(outdir, f\"user_anime_list_sorted_{x}.csv\") for x in splits[:i]]\n",
    "        )\n",
    "        sample_negative_set(user_item_pairs, max_userid, max_itemid, num_samples, os.path.join(outdir, f\"negative_{splits[i]}.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935eac6b-2160-4c75-b8fa-4428af4a1425",
   "metadata": {},
   "source": [
    "## Write splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65525017-7a5e-444b-8c96-6204cacf2e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_temporal_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5df27b-f77e-4b9a-a6c1-10a39ead09b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split in [\"training\", \"validation\", \"test\"]:\n",
    "    generate_content_splits(split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "088cbcf6-68f5-47a4-9ae8-88131c32897f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "generate_negative_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24475ca-b926-4edf-a1d7-13dc972fd71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_userid, max_itemid = get_max_ids(os.path.join(outdir, \"user_anime_list_sorted.csv\"))\n",
    "with open(os.path.join(source_dir, \"uid_encoding.csv\"), 'w') as out_file:\n",
    "    out_file.write(f\"max_userid,{max_userid}\\n\")\n",
    "    out_file.write(f\"max_itemid,{max_itemid}\\n\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

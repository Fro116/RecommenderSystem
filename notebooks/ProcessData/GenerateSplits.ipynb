{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbf03b87-063f-46fe-b392-0d6399dca361",
   "metadata": {},
   "source": [
    "# Generate Splits\n",
    "* We split the dataset into by interaction type: whether the user rated the item, watched the item, \n",
    "  or put the item on their plan-to-watch list\n",
    "* Each of the above splits is further separated into a training, validation, and test split\n",
    "* The training split consists of all data for half the users,\n",
    "  and all data except the most recent month for the other half\n",
    "* The validation and test splits are a random partition of the remaining data\n",
    "* Any items that are not present in the training set are removed from the validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b1ceb4-d65a-410a-b876-93c491c0cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992a0836-bb2b-4956-b075-49dbf38aa079",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"../../data/processed_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24a8f49-53b5-4106-8fe5-84ba572eead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"../../data/splits\"\n",
    "os.makedirs(outdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a0e857-4540-4732-a475-9f88b8c79fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa6376f-09f3-4b44-8117-9771371572d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shard_by_user(file, num_shards):\n",
    "    try:\n",
    "        outfiles = []\n",
    "        for i in range(num_shards):\n",
    "            outfiles.append(open(f\"{file}.shard.{i}\", \"w\"))\n",
    "        with open(file, \"r\") as in_file:\n",
    "            header = False\n",
    "            for line in tqdm(in_file):\n",
    "                if not header:\n",
    "                    header = True\n",
    "                    user_col = line.strip().split(\",\").index(\"username\")\n",
    "                    for f in outfiles:\n",
    "                        f.write(line)\n",
    "                    continue\n",
    "                fields = line.strip().split(\",\")\n",
    "                user = fields[user_col]\n",
    "                outfiles[int(user) % num_shards].write(line)\n",
    "    finally:\n",
    "        for f in outfiles:\n",
    "            f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4a1ed8-3bf5-4571-b02d-b2494298e3c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_sort(input_fn, output_fn):\n",
    "    user_anime_lists = pd.read_csv(input_fn)\n",
    "    user_anime_lists = user_anime_lists.sort_values(\n",
    "        by=[\"username\", \"timestamp\"]\n",
    "    ).reset_index(drop=True)\n",
    "    user_anime_lists.to_csv(output_fn, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaf60acd-b530-448d-bd57-581c4009664b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sharded_temporal_sort(input_fn, output_fn, num_shards=16):\n",
    "    shard_by_user(input_fn, num_shards)\n",
    "    for i in tqdm(range(num_shards)):\n",
    "        temporal_sort(f\"{input_fn}.shard.{i}\", f\"{output_fn}.shard.{i}\")\n",
    "        os.remove(f\"{input_fn}.shard.{i}\")\n",
    "    with open(output_fn, \"w\") as outfile:\n",
    "        for i in tqdm(range(num_shards)):\n",
    "            fn = f\"{output_fn}.shard.{i}\"\n",
    "            with open(fn, \"r\") as infile:\n",
    "                header = False\n",
    "                for line in infile:\n",
    "                    if not header:\n",
    "                        header = True\n",
    "                        if i == 0:\n",
    "                            outfile.write(line)\n",
    "                        continue\n",
    "                    outfile.write(line)\n",
    "            os.remove(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9bb885-4271-4830-b92f-3341a70434d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def combined_split(input_fn, train_fn, test_fn, training_param, split_type):\n",
    "    with open(input_fn, \"r\") as in_file, open(train_fn, \"w\") as training, open(\n",
    "        test_fn, \"w\"\n",
    "    ) as test:\n",
    "        header = False\n",
    "        for line in tqdm(in_file):\n",
    "            if not header:\n",
    "                header = True\n",
    "                status_col = line.strip().split(\",\").index(\"status\")\n",
    "                timestamp_col = line.strip().split(\",\").index(\"timestamp\")\n",
    "                user_col = line.strip().split(\",\").index(\"username\")                \n",
    "                training.write(line)\n",
    "                test.write(line)\n",
    "                continue\n",
    "\n",
    "            fields = line.strip().split(\",\")\n",
    "            timestamp = float(fields[timestamp_col])\n",
    "            userid = int(fields[timestamp_col])\n",
    "            rand = random.random()\n",
    "\n",
    "            if split_type == \"random\":\n",
    "                for_training = rand < training_param\n",
    "            elif split_type == \"temporal\":\n",
    "                for_training = (timestamp < training_param) or (userid % 2 == 0)\n",
    "            else:\n",
    "                assert False\n",
    "\n",
    "            if for_training:\n",
    "                training.write(line)\n",
    "            else:\n",
    "                test.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d872c37-a89e-4efb-8189-58e59c943da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_split(input_fn, train_fn, test_fn, p_training):\n",
    "    combined_split(input_fn, train_fn, test_fn, p_training, \"random\")\n",
    "\n",
    "\n",
    "def temporal_split(input_fn, train_fn, test_fn, test_months):\n",
    "    with open(os.path.join(source_dir, \"processing_encodings.csv\"), \"r\") as in_file:\n",
    "\n",
    "        def parse_line(field):\n",
    "            line = in_file.readline()\n",
    "            fields = line.split(\",\")\n",
    "            assert len(fields) == 2\n",
    "            assert fields[0] == field\n",
    "            return int(fields[1])\n",
    "\n",
    "        min_timestamp = parse_line(\"min_timestamp\")\n",
    "        max_timestamp = parse_line(\"max_timestamp\")\n",
    "    seconds_in_month = 2.628e6\n",
    "    month = seconds_in_month / (max_timestamp - min_timestamp)\n",
    "    combined_split(input_fn, train_fn, test_fn, 1 - month * test_months, \"temporal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5209b3-e097-4796-9dab-683971484de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# scans every line of the input file. If the line satisfies the\n",
    "# condition, then it is written to the output file\n",
    "def subset(input_fn, output_fn, condition):\n",
    "    with open(input_fn, \"r\") as in_file, open(output_fn, \"w\") as out_file:\n",
    "        header = False\n",
    "        for line in tqdm(in_file):\n",
    "            if not header:\n",
    "                header = True\n",
    "                out_file.write(line)\n",
    "                continue\n",
    "            if condition(line):\n",
    "                out_file.write(line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "519843b7-f8c2-4e8a-be36-016de0b8f68a",
   "metadata": {},
   "source": [
    "## Construct training/validation/test splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed80de47-da9d-429e-984b-2e21fdc7f376",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_temporal_splits():\n",
    "    outfn = \"user_anime_list_sorted\"\n",
    "    sharded_temporal_sort(\n",
    "        os.path.join(source_dir, \"user_anime_list.csv\"),\n",
    "        os.path.join(outdir, f\"{outfn}.csv\"),\n",
    "    )\n",
    "    temporal_split(\n",
    "        os.path.join(outdir, f\"{outfn}.csv\"),\n",
    "        os.path.join(outdir, f\"{outfn}_training.csv\"),\n",
    "        os.path.join(outdir, f\"{outfn}_valtest.csv\"),\n",
    "        3.0,  # use the last 3 months as the validation/test sets\n",
    "    )\n",
    "    random_split(\n",
    "        os.path.join(outdir, f\"{outfn}_valtest.csv\"),\n",
    "        os.path.join(outdir, f\"{outfn}_validation.csv\"),\n",
    "        os.path.join(outdir, f\"{outfn}_test.csv\"),\n",
    "        0.5,\n",
    "    )\n",
    "    os.remove(os.path.join(outdir, f\"{outfn}_valtest.csv\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61ef704-e06a-45a0-987c-263721df50ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_content_splits(split, valid_itemids):\n",
    "    with open(os.path.join(outdir, f\"user_anime_list_sorted_{split}.csv\")) as f:\n",
    "        first_line = f.readline()\n",
    "    fields = first_line.strip().split(\",\")\n",
    "    score_col = fields.index(\"score\")\n",
    "    status_col = fields.index(\"status\")\n",
    "    item_col = fields.index(\"animeid\")\n",
    "\n",
    "    def invalid(x):\n",
    "        return int(x.strip().split(\",\")[item_col]) not in valid_itemids\n",
    "\n",
    "    def is_ptw(x):\n",
    "        return x.strip().split(\",\")[status_col] == \"1\"\n",
    "\n",
    "    def is_implicit(x):\n",
    "        return float(x.strip().split(\",\")[score_col]) == 0\n",
    "\n",
    "    subset(\n",
    "        os.path.join(outdir, f\"user_anime_list_sorted_{split}.csv\"),\n",
    "        os.path.join(outdir, f\"invalid_{split}.csv\"),\n",
    "        lambda x: invalid(x),\n",
    "    )\n",
    "    subset(\n",
    "        os.path.join(outdir, f\"user_anime_list_sorted_{split}.csv\"),\n",
    "        os.path.join(outdir, f\"ptw_{split}.csv\"),\n",
    "        lambda x: not invalid(x) and is_ptw(x),\n",
    "    )\n",
    "    subset(\n",
    "        os.path.join(outdir, f\"user_anime_list_sorted_{split}.csv\"),\n",
    "        os.path.join(outdir, f\"implicit_{split}.csv\"),\n",
    "        lambda x: not invalid(x) and not is_ptw(x) and is_implicit(x),\n",
    "    )\n",
    "    subset(\n",
    "        os.path.join(outdir, f\"user_anime_list_sorted_{split}.csv\"),\n",
    "        os.path.join(outdir, f\"explicit_{split}.csv\"),\n",
    "        lambda x: not invalid(x) and not is_ptw(x) and not is_implicit(x),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66573a69-5238-4e89-b19c-fbeff9bfea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_ids(input_fn):\n",
    "    max_userid = -1\n",
    "    max_itemid = -1\n",
    "    with open(input_fn, \"r\") as in_file:\n",
    "        header = False\n",
    "        for line in tqdm(in_file):\n",
    "            if not header:\n",
    "                user_col = line.strip().split(\",\").index(\"username\")\n",
    "                item_col = line.strip().split(\",\").index(\"animeid\")\n",
    "                header = True\n",
    "                continue\n",
    "            fields = line.strip().split(\",\")\n",
    "            userid = fields[user_col]\n",
    "            itemid = fields[item_col]\n",
    "            userid, itemid = int(userid), int(itemid)\n",
    "            max_userid = max(max_userid, int(userid))\n",
    "            max_itemid = max(max_itemid, int(itemid))\n",
    "    return max_userid, max_itemid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a6e434-b79d-4b07-8729-172dafe91e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_ids(input_fn):\n",
    "    uids = set()\n",
    "    with open(input_fn, \"r\") as in_file:\n",
    "        header = False\n",
    "        for line in tqdm(in_file):\n",
    "            if not header:\n",
    "                header = True\n",
    "                item_col = line.strip().split(\",\").index(\"animeid\")\n",
    "                timestamp_col = line.strip().split(\",\").index(\"timestamp\")\n",
    "                continue\n",
    "            fields = line.strip().split(\",\")\n",
    "            if math.isclose(float(fields[timestamp_col]), -1):\n",
    "                # skip rows with corrupted timestamps\n",
    "                continue\n",
    "            itemid = int(fields[item_col])\n",
    "            uids.add(itemid)\n",
    "    return uids"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "935eac6b-2160-4c75-b8fa-4428af4a1425",
   "metadata": {},
   "source": [
    "## Write splits "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65525017-7a5e-444b-8c96-6204cacf2e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_temporal_splits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24475ca-b926-4edf-a1d7-13dc972fd71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_userid, max_itemid = get_max_ids(os.path.join(outdir, \"user_anime_list_sorted.csv\"))\n",
    "valid_itemids = get_item_ids(\n",
    "    os.path.join(outdir, \"user_anime_list_sorted_training.csv\")\n",
    ")\n",
    "\n",
    "with open(os.path.join(source_dir, \"uid_encoding.csv\"), \"w\") as out_file:\n",
    "    out_file.write(f\"max_userid,{max_userid}\\n\")\n",
    "    out_file.write(f\"max_itemid,{max_itemid}\\n\")\n",
    "    for uid in valid_itemids:\n",
    "        out_file.write(f\"valid_itemid,{uid}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5df27b-f77e-4b9a-a6c1-10a39ead09b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for split in [\"training\", \"validation\", \"test\"]:\n",
    "    generate_content_splits(split, valid_itemids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dbf03b87-063f-46fe-b392-0d6399dca361",
   "metadata": {},
   "source": [
    "# Generate Splits\n",
    "* There are two tasks we create datasets for -- random item prediction, and next item prediction\n",
    "* Users are randomly sharded between the tasks and each task has its own training, validation and test split\n",
    "* Each split is further partitioned by interaction type: whether the user rated the item, watched the item, \n",
    "  or put the item on their plan-to-watch list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54b1ceb4-d65a-410a-b876-93c491c0cd4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992a0836-bb2b-4956-b075-49dbf38aa079",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = \"../../data/processed_data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b24a8f49-53b5-4106-8fe5-84ba572eead5",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"../../data/splits\"\n",
    "os.makedirs(outdir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2a0e857-4540-4732-a475-9f88b8c79fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(20220128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c751bc98-5002-4bf3-bb4c-08f88b2ac167",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "media = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc60a8ff-ec51-4294-82a0-a945a36ad69e",
   "metadata": {},
   "source": [
    "# Sort items by timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa6376f-09f3-4b44-8117-9771371572d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shard_by_user(file, num_shards):\n",
    "    try:\n",
    "        outfiles = []\n",
    "        for i in range(num_shards):\n",
    "            outfiles.append(open(f\"{file}.shard.{i}\", \"w\"))\n",
    "        with open(file, \"r\") as in_file:\n",
    "            header = False\n",
    "            for line in tqdm(in_file):\n",
    "                if not header:\n",
    "                    header = True\n",
    "                    user_col = line.strip().split(\",\").index(\"username\")\n",
    "                    for f in outfiles:\n",
    "                        f.write(line)\n",
    "                    continue\n",
    "                fields = line.strip().split(\",\")\n",
    "                user = fields[user_col]\n",
    "                outfiles[int(user) % num_shards].write(line)\n",
    "    finally:\n",
    "        for f in outfiles:\n",
    "            f.close()\n",
    "\n",
    "\n",
    "def temporal_sort(input_fn, output_fn):\n",
    "    df = pd.read_csv(input_fn)\n",
    "    df = df.sort_values(by=[\"username\", \"timestamp\"]).reset_index(drop=True)\n",
    "    df[\"unit\"] = 1\n",
    "    df[\"order\"] = (\n",
    "        df.groupby(\"username\")[\"unit\"].apply(lambda x: x.cumsum()[::-1]).values\n",
    "    )\n",
    "    df = df.drop(columns=\"unit\")\n",
    "    df.to_csv(output_fn, index=False)\n",
    "\n",
    "\n",
    "def sharded_temporal_sort(input_fn, output_fn, num_shards=16):\n",
    "    shard_by_user(input_fn, num_shards)\n",
    "    for i in tqdm(range(num_shards)):\n",
    "        temporal_sort(f\"{input_fn}.shard.{i}\", f\"{output_fn}.shard.{i}\")\n",
    "        os.remove(f\"{input_fn}.shard.{i}\")\n",
    "    with open(output_fn, \"w\") as outfile:\n",
    "        for i in tqdm(range(num_shards)):\n",
    "            fn = f\"{output_fn}.shard.{i}\"\n",
    "            with open(fn, \"r\") as infile:\n",
    "                header = False\n",
    "                for line in infile:\n",
    "                    if not header:\n",
    "                        header = True\n",
    "                        if i == 0:\n",
    "                            outfile.write(line)\n",
    "                        continue\n",
    "                    outfile.write(line)\n",
    "            os.remove(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14505770-a2c1-42b3-a096-ab84e8ea6225",
   "metadata": {},
   "outputs": [],
   "source": [
    "sharded_temporal_sort(\n",
    "    os.path.join(source_dir, f\"user_{media}_list.csv\"),\n",
    "    os.path.join(outdir, f\"user_{media}_list_sorted.csv\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5c58fb0-b4c2-4ad1-b726-6c389ee8371a",
   "metadata": {},
   "source": [
    "# Determine which task the user is assigned to"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722d60f6-5ec2-4916-b520-24642b6480b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL_TASKS = [\"temporal\", \"temporal_causal\"]\n",
    "\n",
    "\n",
    "def get_assignment(tasks, worker):\n",
    "    return tasks[worker % len(tasks)]\n",
    "\n",
    "\n",
    "def get_split(userid):\n",
    "    return get_assignment([\"training\", \"validation\", \"test\"], userid)\n",
    "\n",
    "\n",
    "def get_task(userid):\n",
    "    return get_assignment(ALL_TASKS, userid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08844257-5ad8-47a2-9cd3-c59c5009764e",
   "metadata": {},
   "source": [
    "# Generate task splits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d872c37-a89e-4efb-8189-58e59c943da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_temporal_percentage(test_months):\n",
    "    with open(os.path.join(source_dir, f\"{media}_processing_encodings.csv\"), \"r\") as in_file:\n",
    "\n",
    "        def parse_line(field):\n",
    "            line = in_file.readline()\n",
    "            fields = line.split(\",\")\n",
    "            assert len(fields) == 2\n",
    "            assert fields[0] == field\n",
    "            return int(fields[1])\n",
    "\n",
    "        min_timestamp = parse_line(\"min_timestamp\")\n",
    "        max_timestamp = parse_line(\"max_timestamp\")\n",
    "    seconds_in_month = 2.628e6\n",
    "    month = seconds_in_month / (max_timestamp - min_timestamp)\n",
    "    return 1 - month * test_months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cb12e98-4d09-4e4a-868f-e28d255337f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_splits(input_fn, output_fn, training_params):\n",
    "    tasks = ALL_TASKS\n",
    "    assert len(training_params) == len(tasks)\n",
    "    training = [\n",
    "        open(os.path.join(outdir, f\"{task}.training.{output_fn}\"), \"w\")\n",
    "        for task in tasks\n",
    "    ]\n",
    "    validation = [\n",
    "        open(os.path.join(outdir, f\"{task}.validation.{output_fn}\"), \"w\")\n",
    "        for task in tasks\n",
    "    ]\n",
    "    test = [\n",
    "        open(os.path.join(outdir, f\"{task}.test.{output_fn}\"), \"w\") for task in tasks\n",
    "    ]\n",
    "\n",
    "    with open(os.path.join(outdir, input_fn), \"r\") as in_file:\n",
    "        header = False\n",
    "        for line in tqdm(in_file):\n",
    "            fields = line.strip().split(\",\")\n",
    "            if not header:\n",
    "                header = True\n",
    "                status_col = fields.index(\"status\")\n",
    "                timestamp_col = fields.index(\"timestamp\")\n",
    "                user_col = fields.index(\"username\")\n",
    "                order_col = fields.index(\"order\")\n",
    "                for i in range(len(tasks)):\n",
    "                    training[i].write(line)\n",
    "                    validation[i].write(line)\n",
    "                    test[i].write(line)\n",
    "                continue\n",
    "\n",
    "            timestamp = float(fields[timestamp_col])\n",
    "            userid = int(fields[user_col])\n",
    "            order = int(fields[order_col])\n",
    "            rand = random.random()\n",
    "\n",
    "            task = get_task(userid)\n",
    "            if task == \"random\":\n",
    "                train = rand < training_params[tasks.index(task)]\n",
    "            elif task == \"temporal\":\n",
    "                train = timestamp < training_params[tasks.index(task)]\n",
    "            elif task == \"temporal_causal\":\n",
    "                train = (timestamp < training_params[tasks.index(task)][0]) or (\n",
    "                    order > training_params[tasks.index(task)][1]\n",
    "                )\n",
    "            else:\n",
    "                assert False\n",
    "\n",
    "            if train:\n",
    "                training[tasks.index(task)].write(line)\n",
    "            else:\n",
    "                split = get_split(userid)\n",
    "                if split == \"training\":\n",
    "                    training[tasks.index(task)].write(line)\n",
    "                elif split == \"validation\":\n",
    "                    validation[tasks.index(task)].write(line)\n",
    "                elif split == \"test\":\n",
    "                    test[tasks.index(task)].write(line)\n",
    "                else:\n",
    "                    assert False\n",
    "\n",
    "        for i in range(len(tasks)):\n",
    "            training[i].close()\n",
    "            validation[i].close()\n",
    "            test[i].close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da7f883-b430-405c-bf49-968d8ca9d48f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the temporal holdout split will be (interactions within the last 1.5 months)\n",
    "# the temporal_causal holdout split will be (interactions within the last 1.5 months) AND (one of the 5 most recent interactions)\n",
    "generate_splits(\n",
    "    f\"user_{media}_list_sorted.csv\",\n",
    "    f\"user_{media}_list.csv\",\n",
    "    [get_temporal_percentage(1.5), (get_temporal_percentage(1.5), 5)],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc98e5d4-8d23-408f-9b8d-8fd3d21fea3d",
   "metadata": {},
   "source": [
    "# Generate content splits!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999ba28b-d15b-4055-9dba-93c36659113b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subset(input_fn, output_fn, condition):\n",
    "    with open(input_fn, \"r\") as in_file, open(output_fn, \"w\") as out_file:\n",
    "        header = False\n",
    "        for line in tqdm(in_file):\n",
    "            if not header:\n",
    "                header = True\n",
    "                out_file.write(line)\n",
    "                continue\n",
    "            if condition(line):\n",
    "                out_file.write(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d61ef704-e06a-45a0-987c-263721df50ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_content_splits(fn, valid_itemids):\n",
    "    with open(os.path.join(outdir, fn), \"r\") as f:\n",
    "        first_line = f.readline()\n",
    "    fields = first_line.strip().split(\",\")\n",
    "    score_col = fields.index(\"score\")\n",
    "    status_col = fields.index(\"status\")\n",
    "    item_col = fields.index(f\"{media}id\")\n",
    "\n",
    "    def invalid(x):\n",
    "        return int(x.strip().split(\",\")[item_col]) not in valid_itemids\n",
    "\n",
    "    def is_ptw(x):\n",
    "        return x.strip().split(\",\")[status_col] == \"1\"\n",
    "\n",
    "    def is_implicit(x):\n",
    "        return float(x.strip().split(\",\")[score_col]) == 0\n",
    "\n",
    "    subset(\n",
    "        os.path.join(outdir, fn),\n",
    "        os.path.join(outdir, f\"invalid.{fn}\"),\n",
    "        lambda x: invalid(x),\n",
    "    )\n",
    "    subset(\n",
    "        os.path.join(outdir, fn),\n",
    "        os.path.join(outdir, f\"ptw.{fn}\"),\n",
    "        lambda x: not invalid(x) and is_ptw(x),\n",
    "    )\n",
    "    subset(\n",
    "        os.path.join(outdir, fn),\n",
    "        os.path.join(outdir, f\"implicit.{fn}\"),\n",
    "        lambda x: not invalid(x) and not is_ptw(x) and is_implicit(x),\n",
    "    )\n",
    "    subset(\n",
    "        os.path.join(outdir, fn),\n",
    "        os.path.join(outdir, f\"explicit.{fn}\"),\n",
    "        lambda x: not invalid(x) and not is_ptw(x) and not is_implicit(x),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66573a69-5238-4e89-b19c-fbeff9bfea98",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_ids(input_fn):\n",
    "    max_userid = -1\n",
    "    max_itemid = -1\n",
    "    with open(input_fn, \"r\") as in_file:\n",
    "        header = False\n",
    "        for line in tqdm(in_file):\n",
    "            if not header:\n",
    "                user_col = line.strip().split(\",\").index(\"username\")\n",
    "                item_col = line.strip().split(\",\").index(f\"{media}id\")\n",
    "                header = True\n",
    "                continue\n",
    "            fields = line.strip().split(\",\")\n",
    "            userid = fields[user_col]\n",
    "            itemid = fields[item_col]\n",
    "            userid, itemid = int(userid), int(itemid)\n",
    "            max_userid = max(max_userid, int(userid))\n",
    "            max_itemid = max(max_itemid, int(itemid))\n",
    "    return max_userid, max_itemid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a6e434-b79d-4b07-8729-172dafe91e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_item_ids(input_fns):\n",
    "    uids = set()\n",
    "    for input_fn in input_fns:\n",
    "        with open(input_fn, \"r\") as in_file:\n",
    "            header = False\n",
    "            for line in tqdm(in_file):\n",
    "                if not header:\n",
    "                    header = True\n",
    "                    item_col = line.strip().split(\",\").index(f\"{media}id\")\n",
    "                    timestamp_col = line.strip().split(\",\").index(\"timestamp\")\n",
    "                    continue\n",
    "                fields = line.strip().split(\",\")\n",
    "                if math.isclose(float(fields[timestamp_col]), -1):\n",
    "                    # skip rows with corrupted timestamps\n",
    "                    continue\n",
    "                itemid = int(fields[item_col])\n",
    "                uids.add(itemid)\n",
    "    return uids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24475ca-b926-4edf-a1d7-13dc972fd71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_userid, max_itemid = get_max_ids(\n",
    "    os.path.join(outdir, f\"user_{media}_list_sorted.csv\")\n",
    ")\n",
    "valid_itemids = get_item_ids(\n",
    "    [\n",
    "        os.path.join(outdir, f\"{task}.training.user_{media}_list.csv\")\n",
    "        for task in ALL_TASKS\n",
    "    ]\n",
    ")\n",
    "\n",
    "with open(os.path.join(source_dir, f\"{media}_uid_encoding.csv\"), \"w\") as out_file:\n",
    "    out_file.write(f\"max_userid,{max_userid}\\n\")\n",
    "    out_file.write(f\"max_itemid,{max_itemid}\\n\")\n",
    "    for uid in valid_itemids:\n",
    "        out_file.write(f\"valid_itemid,{uid}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5df27b-f77e-4b9a-a6c1-10a39ead09b1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for task in ALL_TASKS:\n",
    "    for split in [\"training\", \"validation\", \"test\"]:\n",
    "        generate_content_splits(f\"{task}.{split}.user_{media}_list.csv\", valid_itemids)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

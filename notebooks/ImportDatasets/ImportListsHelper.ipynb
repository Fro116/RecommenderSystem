{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f0cf86-8682-41cd-9bb3-eaa4dcc4140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import os\n",
    "from functools import cache\n",
    "\n",
    "import pandas as pd\n",
    "from filelock import FileLock\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899d5b72-0a1b-45c0-9af0-40949355ad50",
   "metadata": {},
   "source": [
    "## Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d879788-9624-456a-89c6-7ad3cb2af196",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_HEADER = [\n",
    "    \"source\",\n",
    "    \"medium\",\n",
    "    \"userid\",\n",
    "    \"mediaid\",\n",
    "    \"status\",\n",
    "    \"rating\",\n",
    "    \"updated_at\",\n",
    "    \"created_at\",\n",
    "    \"started_at\",\n",
    "    \"finished_at\",\n",
    "    \"update_order\",\n",
    "    \"progress\",\n",
    "    \"repeat_count\",\n",
    "    \"priority\",\n",
    "    \"sentiment\",\n",
    "    \"sentiment_score\",\n",
    "    \"owned\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8a2f4f-cc00-4be0-8362-c91687309adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_MAP = {\"mal\": 0, \"anilist\": 1, \"kitsu\": 2, \"animeplanet\": 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c25f85-7b05-4ee3-babd-8fbd3a69b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATUS_MAP = {\n",
    "    \"rewatching\": 7,\n",
    "    \"completed\": 6,\n",
    "    \"currently_watching\": 5,\n",
    "    \"planned\": 4,\n",
    "    \"on_hold\": 3,\n",
    "    \"dropped\": 2,\n",
    "    \"wont_watch\": 1,\n",
    "    \"none\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6a4307-a1ca-48f1-b0cd-622ba8ba590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEDIUM_MAP = {\"manga\": 0, \"anime\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8212661a-49a9-41f6-81fb-5b5ca088b64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_int(x, map={}, allow_neg=False):\n",
    "    if x in map:\n",
    "        return map[x]\n",
    "    x = int(x)\n",
    "    if not allow_neg:\n",
    "        assert x >= 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c6192fd-6d42-4272-b714-24b8e156de3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_negative_ts(x):\n",
    "    # sometimes the api returns a negative timestamp. TODO fix upstream\n",
    "    if '-' in x:\n",
    "        return \"0\"\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdf6bad-7f76-48dc-a98f-a06ad645ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def get_media_progress(medium):\n",
    "    df = pd.read_csv(os.path.join(MEDIA_DIR, f\"{medium}.csv\"))\n",
    "    if medium == \"anime\":\n",
    "        return {\"episodes\": df.set_index(f\"{medium}_id\")[\"num_episodes\"].to_dict()}\n",
    "    elif medium == \"manga\":\n",
    "        return {\n",
    "            \"volumes\": df.set_index(f\"{medium}_id\")[\"num_volumes\"].to_dict(),\n",
    "            \"chapters\": df.set_index(f\"{medium}_id\")[\"num_chapters\"].to_dict(),\n",
    "        }\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "\n",
    "def get_completion(x, xmax):\n",
    "    if xmax == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return min(1.0, x / xmax)\n",
    "\n",
    "\n",
    "def get_progress(medium, uid, progress, progress_volumes):\n",
    "    df = get_media_progress(medium)\n",
    "    if medium == \"anime\":\n",
    "        return get_completion(progress, df[\"episodes\"].get(uid, 0))\n",
    "    elif medium == \"manga\":\n",
    "        return max(\n",
    "            get_completion(progress, df[\"chapters\"].get(uid, 0)),\n",
    "            get_completion(progress_volumes, df[\"volumes\"].get(uid, 0)),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9967f1-7c1b-4dd9-ae4e-a9bb402c6c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT_MAP = {\n",
    "    \"positive\": 3,\n",
    "    \"neutral\": 2,\n",
    "    \"negative\": 1,\n",
    "    \"none\": 0,\n",
    "}\n",
    "\n",
    "\n",
    "def compute_sentiments(texts):\n",
    "    sentiments = {}\n",
    "    if not texts:\n",
    "        return sentiments\n",
    "    texts.sort(key=len)\n",
    "    logger.info(f\"Performing sentiment analysis on {len(texts)} texts\")\n",
    "    lock = FileLock(\"gpu.lock\")\n",
    "    with lock:\n",
    "        # TODO finetune and calibrate this model on domain data\n",
    "        modelname = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "        model = pipeline(model=modelname, truncation=True, device=\"cuda\")\n",
    "        model.tokenizer.model_max_length = 512\n",
    "        outputs = model(texts, batch_size=16)\n",
    "    for x, y in zip(texts, outputs):\n",
    "        sentiments[x] = {\n",
    "            \"sentiment\": y[\"label\"],\n",
    "            \"score\": y[\"score\"],\n",
    "        }\n",
    "    sentiments[\"\"] = {\n",
    "        \"sentiment\": \"none\",\n",
    "        \"score\": 0,\n",
    "    }\n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d310995-87d9-497e-b4c0-c880b39e8a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_score(score):\n",
    "    score = float(score)\n",
    "    if not (score >= 0 and score <= 10):\n",
    "        logger.warning(f\"invalid score {score}, replacing with 0\")\n",
    "        score = 0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d8ad4f-577b-4ee5-b346-ad48809b390f",
   "metadata": {},
   "source": [
    "## Source parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df81c2e-cf75-426a-a179-f1cb7498ef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(input_fn, header_fields, text_fields):\n",
    "    logger.info(f\"Sanitizing entries in {input_fn}\")\n",
    "    total_lines = 0\n",
    "    total_texts = set()\n",
    "\n",
    "    partition = input_fn.split(\".\")[-2]\n",
    "    output_fn = input_fn + \"~\"\n",
    "    with open(input_fn, \"r\") as in_file:\n",
    "        with open(output_fn, \"w\") as out_file:\n",
    "            header = False\n",
    "            for line in tqdm(in_file):\n",
    "                if not header:\n",
    "                    header = True\n",
    "                    correct_header = \",\".join(header_fields) + \"\\n\"\n",
    "                    if line != correct_header:\n",
    "                        logger.warning(\n",
    "                            f\"Replacing malformed header line {line.strip()} \"\n",
    "                            f\"with correct header {correct_header.strip()}\"\n",
    "                        )\n",
    "                        line = correct_header\n",
    "                    out_file.write(line)\n",
    "                    total_lines += 1\n",
    "                    continue\n",
    "                fields = line.strip().split(\",\")\n",
    "                if len(fields) != len(header_fields):\n",
    "                    logger.warning(\n",
    "                        f\"Deleting malformed line in user_{MEDIUM}_list.csv: {line} \"\n",
    "                    )\n",
    "                    continue\n",
    "                for tf in text_fields:\n",
    "                    total_texts.add(fields[header_fields.index(tf)])\n",
    "                out_file.write(line)\n",
    "                total_lines += 1\n",
    "        os.replace(output_fn, input_fn)\n",
    "    return {\n",
    "        \"lines\": total_lines,\n",
    "        \"texts\": total_texts,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9a2a06-d490-4988-92a7-c41942a06e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_line(line, metadata):\n",
    "    try:\n",
    "        fields = parse_fields(line, metadata)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: could not parse {line}\")\n",
    "        raise e\n",
    "    assert len(fields) == len(OUTPUT_HEADER)\n",
    "    return \",\".join(str(fields[x]) for x in OUTPUT_HEADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be270f28-a900-4a84-8507-4356122e1be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(infile, outfile, metadata):\n",
    "    logger.info(f\"processing entries in {infile}\")\n",
    "    with open(infile, \"r\") as in_file:\n",
    "        with open(outfile, \"w\") as out_file:\n",
    "            header = False\n",
    "            for line in tqdm(in_file, total=metadata[\"lines\"]):\n",
    "                if not header:\n",
    "                    header = True\n",
    "                    out_file.write(\",\".join(OUTPUT_HEADER) + \"\\n\")\n",
    "                    continue\n",
    "                out_file.write(process_line(line.strip(), metadata) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e85f3a8-3771-402a-9f7b-8841a401aa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_notebook(nb):\n",
    "    cwd = os.getcwd()\n",
    "    try:\n",
    "        os.chdir(os.path.dirname(nb))\n",
    "        script = os.path.basename(nb)\n",
    "        %run $script\n",
    "    finally:\n",
    "        os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34c55ba-1862-42fb-b4e5-0f8978fc9bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_notebook(f\"./{SOURCE.capitalize()}.ipynb\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

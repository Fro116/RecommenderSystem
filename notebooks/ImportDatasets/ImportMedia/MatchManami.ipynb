{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b501b679-f08c-49c7-8beb-ea01498070e8",
   "metadata": {},
   "source": [
    "# Match Items Using Manami's Offline Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c24fed74-bf63-4769-8e36-00f002d5b6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import logging\n",
    "import os\n",
    "from functools import cache\n",
    "\n",
    "import pandas as pd\n",
    "from curl_cffi import requests\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cc25c6-3c9b-4cd6-850f-9fd5f757ad7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def get_offline_database(medium):\n",
    "    # Imports mappings from https://github.com/manami-project/anime-offline-database\n",
    "    assert medium == \"anime\"\n",
    "    url = \"https://github.com/manami-project/anime-offline-database/raw/master/anime-offline-database.json\"\n",
    "    max_timeout = 300\n",
    "    timeout = 1\n",
    "    while True:\n",
    "        try:\n",
    "            r = requests.get(url)\n",
    "            if not r.ok:\n",
    "                raise ValueError\n",
    "            return r.json()\n",
    "        except:\n",
    "            time.sleep(timeout)\n",
    "            timeout *= 2\n",
    "            if timeout > max_timeout:\n",
    "                logging.error(\"could not download mappings\")\n",
    "                return {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2a591b-2c17-4ed6-af54-efc7b311a273",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def get_valid_ids(medium, source):\n",
    "    df = pd.read_csv(\n",
    "        f\"../../../data/media/sources/{source}.{medium}.csv\",\n",
    "        keep_default_na=False,\n",
    "        dtype=str,\n",
    "    )\n",
    "    return set(df.uid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342482a0-aaf3-473a-8722-3a38df1b1fb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_database_mapping(medium, source1, source2):\n",
    "    def get_key(urls, source):\n",
    "        for x in d[\"sources\"]:\n",
    "            if source == \"mal\":\n",
    "                if \"myanimelist.net\" in x:\n",
    "                    return x.split(\"/\")[-1]\n",
    "            elif source == \"anilist\":\n",
    "                if \"anilist.co\" in x:\n",
    "                    return x.split(\"/\")[-1]\n",
    "            elif source == \"animeplanet\":\n",
    "                if \"anime-planet.com\" in x:\n",
    "                    return x.split(\"/\")[-1]\n",
    "            elif source == \"kitsu\":\n",
    "                if \"kitsu.app\" in x:\n",
    "                    return x.split(\"/\")[-1]\n",
    "        return None\n",
    "\n",
    "    mapping = {}\n",
    "    if medium == \"anime\":\n",
    "        db = get_offline_database(medium)\n",
    "        valid_keys1 = get_valid_ids(medium, source1)\n",
    "        valid_keys2 = get_valid_ids(medium, source2)\n",
    "        for d in db[\"data\"]:\n",
    "            k1 = get_key(d[\"sources\"], source1)\n",
    "            k2 = get_key(d[\"sources\"], source2)\n",
    "            if k1 in valid_keys1 and k2 in valid_keys2:\n",
    "                mapping[k1] = k2\n",
    "    keys = list(mapping)\n",
    "    values = [mapping[k] for k in keys]\n",
    "    return pd.DataFrame.from_dict({source1: keys, source2: values})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b000216e-ad28-4609-a305-29ec96543d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"../../../data/media/manami\"\n",
    "os.makedirs(outdir, exist_ok=True)\n",
    "os.chdir(outdir)\n",
    "sources = [\"mal\", \"anilist\", \"kitsu\", \"animeplanet\"]\n",
    "for medium in [\"manga\", \"anime\"]:\n",
    "    for i in range(len(sources)):\n",
    "        for j in range(i + 1, len(sources)):\n",
    "            df = get_database_mapping(medium, sources[j], sources[i])\n",
    "            df.to_csv(f\"{medium}.{sources[j]}.{sources[i]}.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

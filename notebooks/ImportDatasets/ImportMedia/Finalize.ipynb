{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63d0f00-cdc1-449d-a456-c18f57b10c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import JupyterFormatter\n",
    "JupyterFormatter.enable_autoformat();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e43962-5c9c-4a1c-9e3a-8e49897db8cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import CSV\n",
    "import DataFrames\n",
    "import Dates\n",
    "import JSON\n",
    "import Glob\n",
    "import ProgressMeter: @showprogress, next!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c098a533-335c-43b4-906d-456fbbae7fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "function read_csv(x; kw...)\n",
    "    CSV.read(x, DataFrames.DataFrame; types = String, missingstring = nothing, kw...)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8705c158-4f45-485e-83ee-d6dfb9e06485",
   "metadata": {},
   "outputs": [],
   "source": [
    "function get_data_path(file)\n",
    "    path = pwd()\n",
    "    while basename(path) != \"notebooks\"\n",
    "        path = dirname(path)\n",
    "    end\n",
    "    path = dirname(path)\n",
    "    joinpath(path, \"data\", file)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aee54c1-bdde-4bb5-ac38-b82259396002",
   "metadata": {},
   "outputs": [],
   "source": [
    "const src = get_data_path(\"media\")\n",
    "const dst = get_data_path(\"processed_data\")\n",
    "const SOURCES = [\"mal\", \"anilist\", \"kitsu\", \"animeplanet\"]\n",
    "if !ispath(dst)\n",
    "    mkpath(dst)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318f86f4-e20f-4f4b-8324-8055eebabca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save media\n",
    "for m in [\"manga\", \"anime\"]\n",
    "    cp(\"$src/match/$m.csv\", \"$dst/$m.csv\", force = true)\n",
    "    cp(\"$src/relations/$m.relations.csv\", \"$dst/$m.relations.csv\", force = true)\n",
    "    for s in SOURCES\n",
    "        cp(\"$src/sources/$s.$m.csv\", \"$dst/$s.$m.csv\", force = true)\n",
    "    end\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e9ee0e4-08ef-4745-bafb-c3be38c74702",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save timestamps\n",
    "function parse_timestamp(x)\n",
    "    # there can be negative timestamps if users manually input a bogus date\n",
    "    if isempty(x) || startswith(x, \"-\")\n",
    "        return 0\n",
    "    end\n",
    "    parse(Int, x)\n",
    "end\n",
    "\n",
    "maxts = -Inf\n",
    "mints = Inf\n",
    "for s in SOURCES\n",
    "    files = Glob.glob(\"$s/user_media_facts/user_?????_list.*.csv\", get_data_path(\"\"))\n",
    "    @showprogress for f in files\n",
    "        df = read_csv(f)\n",
    "        ts = (df.updated_at .|> parse_timestamp) |> y -> filter(x -> x != 0, y)\n",
    "        maxts = ts |> y -> maximum(y; init = maxts)\n",
    "        mints = ts |> y -> minimum(y; init = mints)\n",
    "\n",
    "    end\n",
    "end\n",
    "@assert maxts > 0 && maxts <= Dates.datetime2unix(Dates.now()) maxts\n",
    "@assert mints != Inf && mints >= Dates.datetime2unix(Dates.DateTime(2002, 1, 1)) mints\n",
    "@assert mints <= maxts (mints, maxts)\n",
    "open(\"$dst/timestamps.csv\", \"w\") do f\n",
    "    write(f, \"min_ts,max_ts\\n\")\n",
    "    write(f, \"$mints,$maxts\\n\")\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f42c7ef-5b79-4dd4-aa11-cf5cc48ec7fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# save userids\n",
    "function get_userid_map()\n",
    "    uid = 1\n",
    "    user_maps = Dict{String,Dict{String,Int}}()\n",
    "    for s in SOURCES\n",
    "        user_maps[s] = Dict{String,Int}()\n",
    "        files = Glob.glob(\"$s/user_media_facts/user_status.*.csv\", get_data_path(\"\"))\n",
    "        for f in sort(files)\n",
    "            for username in read_csv(f).username\n",
    "                if username âˆ‰ keys(user_maps[s])\n",
    "                    user_maps[s][username] = uid\n",
    "                    uid += 1\n",
    "                else\n",
    "                    @warn \"duplicate username $username\"\n",
    "                    user_maps[s][username] = 0\n",
    "                end\n",
    "            end\n",
    "        end\n",
    "    end\n",
    "    userids = []\n",
    "    for (s, v) in user_maps\n",
    "        for (username, userid) in v\n",
    "            push!(userids, (s, username, userid))\n",
    "        end\n",
    "    end\n",
    "    DataFrames.DataFrame(userids, [:source, :username, :userid])\n",
    "end\n",
    "\n",
    "CSV.write(\"$dst/userid_map.csv\", get_userid_map());"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c2ea42-3a9b-4534-ba2f-32460fc0d424",
   "metadata": {},
   "outputs": [],
   "source": [
    "function archive_training_data()\n",
    "    path = get_data_path(\"raw_training_data\")\n",
    "    if !ispath(path)\n",
    "        mkpath(path)\n",
    "    end\n",
    "    for s in SOURCES\n",
    "        mv(get_data_path(s), \"$path/$s\")\n",
    "    end\n",
    "end\n",
    "\n",
    "archive_training_data();"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.10.2",
   "language": "julia",
   "name": "julia-1.10"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

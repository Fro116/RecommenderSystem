{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "15b873be-8bb1-48aa-bf48-ccd9a4ff5a09",
   "metadata": {},
   "source": [
    "# Import Lists\n",
    "* Converts user lists into a shared format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ccf9c9-b404-4a62-887f-fdf42dc076c2",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f0cf86-8682-41cd-9bb3-eaa4dcc4140a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import glob\n",
    "import logging\n",
    "import os\n",
    "from functools import cache\n",
    "\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1125b1-84a6-4b75-be3e-d5265e017279",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "MEDIUM = \"\"\n",
    "SOURCE = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a483591-08d0-4ab7-9ea7-b8ff12bcb859",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_dir = f\"../../data/{SOURCE}/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0704ccb0-363c-43e4-bbaa-acdc5f4ed2cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdir = \"../../data/raw_data\"\n",
    "if not os.path.exists(outdir):\n",
    "    os.mkdir(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b97641-c924-4918-baf8-69698ff11c29",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(SOURCE)\n",
    "logger.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter(\n",
    "    \"%(name)s:%(levelname)s:%(asctime)s: %(message)s\", datefmt=\"%Y-%m-%d %H:%M:%S\"\n",
    ")\n",
    "for stream in [\n",
    "    logging.StreamHandler(),\n",
    "]:\n",
    "    stream.setFormatter(formatter)\n",
    "    logger.addHandler(stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "899d5b72-0a1b-45c0-9af0-40949355ad50",
   "metadata": {},
   "source": [
    "## Mappings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d879788-9624-456a-89c6-7ad3cb2af196",
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_HEADER = [\n",
    "    \"source\",\n",
    "    \"medium\",\n",
    "    \"userid\",\n",
    "    \"mediaid\",\n",
    "    \"status\",\n",
    "    \"rating\",\n",
    "    \"updated_at\",\n",
    "    \"created_at\",\n",
    "    \"started_at\",\n",
    "    \"finished_at\",\n",
    "    \"update_order\",\n",
    "    \"progress\",\n",
    "    \"repeat_count\",\n",
    "    \"priority\",\n",
    "    \"sentiment\",\n",
    "    \"sentiment_score\",\n",
    "    \"owned\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8a2f4f-cc00-4be0-8362-c91687309adf",
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_MAP = {\"mal\": 0, \"anilist\": 1, \"kitsu\": 2, \"animeplanet\": 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c25f85-7b05-4ee3-babd-8fbd3a69b268",
   "metadata": {},
   "outputs": [],
   "source": [
    "STATUS_MAP = {\n",
    "    \"rewatching\": 7,\n",
    "    \"completed\": 6,\n",
    "    \"currently_watching\": 5,\n",
    "    \"planned\": 4,\n",
    "    \"on_hold\": 3,\n",
    "    \"dropped\": 2,\n",
    "    \"wont_watch\": 1,\n",
    "    \"none\": 0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a6a4307-a1ca-48f1-b0cd-622ba8ba590a",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEDIUM_MAP = {\"manga\": 0, \"anime\": 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8212661a-49a9-41f6-81fb-5b5ca088b64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_int(x, map={}, allow_neg=False):\n",
    "    if x in map:\n",
    "        return map[x]\n",
    "    x = int(x)\n",
    "    if not allow_neg:\n",
    "        assert x >= 0\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fdf6bad-7f76-48dc-a98f-a06ad645ac74",
   "metadata": {},
   "outputs": [],
   "source": [
    "@cache\n",
    "def get_media_progress(medium):\n",
    "    df = pd.read_csv(os.path.join(outdir, f\"{medium}.csv\"))\n",
    "    if medium == \"anime\":\n",
    "        return {\"episodes\": df.set_index(f\"{medium}_id\")[\"num_episodes\"].to_dict()}\n",
    "    elif medium == \"manga\":\n",
    "        return {\n",
    "            \"volumes\": df.set_index(f\"{medium}_id\")[\"num_volumes\"].to_dict(),\n",
    "            \"chapters\": df.set_index(f\"{medium}_id\")[\"num_chapters\"].to_dict(),\n",
    "        }\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "\n",
    "def get_completion(x, xmax):\n",
    "    if xmax == 0:\n",
    "        return 0.0\n",
    "    else:\n",
    "        return min(1.0, x / xmax)\n",
    "\n",
    "\n",
    "def get_progress(medium, uid, progress, progress_volumes):\n",
    "    df = get_media_progress(medium)\n",
    "    if medium == \"anime\":\n",
    "        return get_completion(progress, df[\"episodes\"].get(uid, 0))\n",
    "    elif medium == \"manga\":\n",
    "        return max(\n",
    "            get_completion(progress, df[\"chapters\"].get(uid, 0)),\n",
    "            get_completion(progress_volumes, df[\"volumes\"].get(uid, 0)),\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9967f1-7c1b-4dd9-ae4e-a9bb402c6c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENTIMENT_MAP = {\n",
    "    \"positive\": 3,\n",
    "    \"neutral\": 2,\n",
    "    \"negative\": 1,\n",
    "    \"none\": 0,\n",
    "}\n",
    "\n",
    "\n",
    "def compute_sentiments(texts):\n",
    "    logger.info(f\"Performing sentiment analysis on {len(texts)} texts\")\n",
    "    sentiments = {}\n",
    "    # TODO finetune and calibrate this model on domain data\n",
    "    modelname = \"cardiffnlp/twitter-xlm-roberta-base-sentiment\"\n",
    "    model = pipeline(model=modelname, truncation=True, device=\"cuda\")\n",
    "    model.tokenizer.model_max_length = 512\n",
    "    outputs = model(texts, batch_size=8)\n",
    "    for x, y in zip(texts, outputs):\n",
    "        sentiments[x] = {\n",
    "            \"sentiment\": y[\"label\"],\n",
    "            \"score\": y[\"score\"],\n",
    "        }\n",
    "    sentiments[\"\"] = {\n",
    "        \"sentiment\": \"none\",\n",
    "        \"score\": 0,\n",
    "    }\n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d310995-87d9-497e-b4c0-c880b39e8a05",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_score(score):\n",
    "    score = float(score)\n",
    "    if not (score >= 0 and score <= 10):\n",
    "        logger.warning(f\"invalid score {score}, replacing with 0\")\n",
    "        score = 0\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0d8ad4f-577b-4ee5-b346-ad48809b390f",
   "metadata": {},
   "source": [
    "## Source parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df81c2e-cf75-426a-a179-f1cb7498ef27",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(input_fn, header_fields, text_fields):\n",
    "    logger.info(f\"Sanitizing entries in {input_fn}\")\n",
    "    total_lines = 0\n",
    "    total_texts = set()\n",
    "\n",
    "    partition = input_fn.split(\".\")[-2]\n",
    "    output_fn = input_fn + \"~\"\n",
    "    with open(input_fn, \"r\") as in_file:\n",
    "        with open(output_fn, \"w\") as out_file:\n",
    "            header = False\n",
    "            for line in tqdm(in_file):\n",
    "                if not header:\n",
    "                    header = True\n",
    "                    correct_header = \",\".join(header_fields) + \"\\n\"\n",
    "                    if line != correct_header:\n",
    "                        logger.warning(\n",
    "                            f\"Replacing malformed header line {line.strip()} \"\n",
    "                            f\"with correct header {correct_header.strip()}\"\n",
    "                        )\n",
    "                        line = correct_header\n",
    "                    out_file.write(line)\n",
    "                    total_lines += 1\n",
    "                    continue\n",
    "                fields = line.strip().split(\",\")\n",
    "                if len(fields) != len(header_fields):\n",
    "                    logger.warning(\n",
    "                        f\"Deleting malformed line in user_{media}_list.csv: {line} \"\n",
    "                    )\n",
    "                    continue\n",
    "                for tf in text_fields:\n",
    "                    total_texts.add(fields[header_fields.index(tf)])\n",
    "                out_file.write(line)\n",
    "                total_lines += 1\n",
    "        os.replace(output_fn, input_fn)\n",
    "    return {\n",
    "        \"lines\": total_lines,\n",
    "        \"texts\": total_texts,\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9a2a06-d490-4988-92a7-c41942a06e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_line(line, metadata):\n",
    "    try:\n",
    "        fields = parse_fields(line, metadata)\n",
    "    except Exception as e:\n",
    "        print(f\"Error: could not parse {line}\")\n",
    "        raise e\n",
    "    assert len(fields) == len(OUTPUT_HEADER)\n",
    "    return \",\".join(str(fields[x]) for x in OUTPUT_HEADER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be270f28-a900-4a84-8507-4356122e1be5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(infile, outfile, metadata):\n",
    "    logger.info(f\"processing entries in {infile}\")\n",
    "    needs_header = not os.path.exists(outfile)\n",
    "    with open(infile, \"r\") as in_file:\n",
    "        with open(outfile, \"a\") as out_file:\n",
    "            header = False\n",
    "            for line in tqdm(in_file, total=metadata[\"lines\"]):\n",
    "                if not header:\n",
    "                    header = True\n",
    "                    if needs_header:\n",
    "                        out_file.write(\",\".join(OUTPUT_HEADER) + \"\\n\")\n",
    "                    continue\n",
    "                out_file.write(process_line(line.strip(), metadata) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e85f3a8-3771-402a-9f7b-8841a401aa3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_notebook(nb):\n",
    "    cwd = os.getcwd()\n",
    "    try:\n",
    "        os.chdir(os.path.dirname(nb))\n",
    "        script = os.path.basename(nb)\n",
    "        %run $script\n",
    "    finally:\n",
    "        os.chdir(cwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34c55ba-1862-42fb-b4e5-0f8978fc9bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import_notebook(f\"./{SOURCE.capitalize()}.ipynb\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f919df2e-021a-4791-b769-bd794d43d225",
   "metadata": {},
   "source": [
    "## Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d72c47-a667-4515-9dc9-ed86119e7194",
   "metadata": {},
   "outputs": [],
   "source": [
    "fn = os.path.join(outdir, f\"user_{MEDIUM}_list.{SOURCE}.csv\")\n",
    "if os.path.exists(fn):\n",
    "    os.remove(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9e03c3b-ed64-4182-ad32-d032728b8265",
   "metadata": {},
   "outputs": [],
   "source": [
    "media_path = os.path.join(source_dir, f\"user_media_facts/user_{MEDIUM}_list.*.csv\")\n",
    "media_fns = glob.glob(media_path)\n",
    "for file in media_fns:\n",
    "    data = preprocess(file, INPUT_HEADER, TEXT_FIELDS)\n",
    "    data[\"sentiments\"] = compute_sentiments(list(data[\"texts\"]))\n",
    "    process(\n",
    "        file,\n",
    "        os.path.join(outdir, f\"user_{MEDIUM}_list.{SOURCE}.csv\"),\n",
    "        data,\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
